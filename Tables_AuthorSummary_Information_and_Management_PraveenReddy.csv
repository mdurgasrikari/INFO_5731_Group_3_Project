index,Author Summary
0,We used a self-developed Python app and collected a random sample of 765 posts and their linked comments published from 1 January to the end of April 2020 on the NSW1 and VIC2 Department of Health Facebook page. Table 2 presents a summary of our initial Facebook dataset.
1,"To investigate official Facebook use against misinformation, we analysed 29 posts that directly addressed COVID-related uncertainties or misinformation. This targeted approach aimed to understand official strategies to counter misinformation during the pandemic. These posts aligned with the four major thematic areas of the COVID-19 infodemic identified by the ?Coronavirus Disease 2019 (COVID-19) Situation Report?85? (WHO, 2020). Table 3 showcases samples of these posts by Australian health agencies."
2,"We conducted nineteen semi-structured interviews, averaging an hour each, with professionals from the health agencies whose Facebook activities we studied. These interviews, held online via Zoom, aimed to deepen our understanding of the topic, gauge the extent of the problem, comprehend the organisational approach to using Facebook against COVID-19 misinformation, and benefit from the experts' tactical knowledge. All interview participants held roles in the public health sector, as shown in Table 4. They were recognised for their exceptional academic and hands-on knowledge in the field, qualifying them as experts. Although our engagement with these experts significantly influenced our interpretation of the study's results, it's essential to clarify that only data from six informants were incorporated into this study. These six (rows i to vi in Table 4) were directly involved in managing and operating public health social media communication and were recognised as online community administrators."
3,"A total of 120 participants (Mage = 30.98, SDage = 8.14) were recruited by Qualtrics (see Table 4). Participants were randomly assigned to one of the two priming conditions (maximisers = 60 and satisficers = 60). The priming task and shopping task were the same as in Study 1. In this study, participants were asked to shop and select a new footwear product using a real-world omnichannel retailer. Perceived omnichannel interaction quality and MTS were measured as advised in Study 1. Perceived content integration capability was measured using two items adapted from Sun et al. (2020), such as ?I trust my ability to process the information I gather from different channels?. Participants responded to all items using a seven-point Likert scale ranging from 1 (strongly disagree) to 7 (strongly agree)."
4,"A one-way ANOVA was used for the manipulation check using the MTS measures. Results show that maximisers scored higher in the MTS compared to satisficers (Mmaximisers = 5.95, SD = 0.42, Msatisficers = 4.30, SD = 0.52, F[1,118] = 359.280, p < 0.001). Therefore, the significant results of the manipulation checks confirm the success of the priming method used in this study. To examine the proposed mediation pathway (H2), we used SPSS PROCESS macro model 4 (Hayes, 2017) with 5000 iterations. Shoppers? decision-making styles (coded as maximisers = 1 and satisficers = 0) served as the independent variable, while perceived content integration capability was the mediator variable, and perceived omnichannel interaction quality was the dependent variable. Results show that shoppers? decision-making styles had a positive effect on perceived content integration capability (? = 0.600, t = 3.497, p < .001), which in turn positively influenced perceived omnichannel interaction quality (? = 0.447, t = 6.945, p < .001). In line with H2, the indirect effect (ab) of shoppers? decision-making styles on perceived omnichannel interaction quality through perceived content integration capability was positive and significant. Thus, perceived content integration capability mediated the proposed relationship as the confidence interval excluded zero (? = 0.268, 95% CI = [0.115, 0.445]), as presented in Fig. 2 and Table 6."
5,"Our study used stratified random sampling of 950 companies, establishing equal probability that any firm could be selected at any step during sampling. The companies were contacted by phone and e-mail to explain the study?s purpose and offer them the opportunity to receive the results once the study was finished. Analyzing the results in aggregate and promising confidentiality of responses increased the response rate (36.10%, 343 valid responses (see Table 4)) and reduced the possibility of desirability bias."
6,"A comparative analysis of two groups of respondents was performed, the companies that returned the completed survey within three weeks of receiving it and the companies that returned the survey only after follow-up reminders. This test assumes that late respondents are similar to non-respondents (Armstrong & Overton, 1977). Comparing the characteristics of the firms with late vs. early respondents (Table 5) indicated no significant differences between early and late respondents."
7,"Table 3 shows the participating companies. Company A is an industrial technology provider with approximately 250 employees from various sectors, with a focus on engineering and software development. Their product relates to circular economy and recycling, and according to their own presentation, environmental sustainability is already embedded in their culture. Company B is an industrial software provider with approximately 400 employees who are mainly software developers due to their core B2B software product. Company B is making various sustainability efforts, such as offsetting its emissions, using green power, and switching to electric vehicles, but its employees have not been as involved in its sustainability strategy. Company C is a glass manufacturer with approximately 150 employees. The majority of these employees work in the production halls and often come from abroad or have little education. In administration, about 30 employees work in research and development, procurement, sales, marketing and process optimization. The company attaches great importance to the recycling and reuse of its glass products and environmentally compatible production, but is particularly interested in new approaches to creatively involve its employees and motivate them to adopt sustainable behavior. Finally, Company D is a web design agency with 30 employees, mainly software developers and UX designers. Environmental sustainability has gained importance for them as a key criterion of responsible and sustainable digitalization. However, the company is not yet engaged in efforts for sustainability."
8,Survey Items for Satisfaction.
9,Survey Items for Performance Expectancy.
10,"In total, we conducted 21 interviews. The data collection reached saturation when the interview data showed no new information (Jacobson & Harrison, 2022). Table 3 describes the participants? demographics. We elaborated an interview guide with 13 questions inspired by the theoretical model tested in the previous studies. The average time for each interview was 20 min. Interviews were conducted face-to-face and mediated by videoconferencing technology (Zoom) in Portuguese by the last author, who transcribed, anonymized, and translated the scripts into English."
11,"After the data collection, panel A of Table 1 presents the characteristics of the sample firms. For instance, the mean of the sample firms' net income and total assets are $3292.382 million and $ 139,398 million, respectively. At the same time, the mean of sales, total liabilities and employee number of the sample firms are $ 24,361.830 million, $ 11,933.500 million, and 66,487, respectively. Panel B and C of Table 1 show the distribution of the sample firms by industry (via its two-digit SIC codes) and year. It illustrates that AI-enabled B2B marketing activities are most popular in the services industry (i.e., SIC 70?89), which takes 56.18% of the total sample. The distribution panel shows that most of the firms only started using AI for their B2B marketing practices during 2016?2020, with 2017 as the peak year."
12,"After performing the binary logistic regression model, we acquire the propensity score, which indicates the probability of implementing AI-enabled B2B marketing initiatives for all firms included in the model. Then, we use a nearest-neighbor one-on-one matching method to identify the control firms. To improve the matching quality, we set a predetermined caliper of 0.02, which measures the absolute distance between the control and treatment firms' propensity scores (Ye et al., 2020). As shown in Model 1 (pre-match model) of Table 2, the number of firms included in the regression model is 1423, consisting of 89 treatment firms collected from Factiva, 1334 potential control firms with the same 4-digit SIC codes as the treatment firms. 87 out of the 89 treatment firms are matched successfully through the above-mentioned matching procedures and criteria. Therefore, the total sample size for this research reached 174, including 87 treatment firms and 87 matched control firms. Model 1 shows that the coefficients of marketing efficiency are negatively significant, while the coefficients of firm size, liquidity and R&D intensity are positively significant. This result indicates that firms with lower marketing efficiency, larger firm size, higher firm liquidity and greater R&D intensity tend to be more likely to employ AI technology for their B2B marketing practices. Also, we further check the matching quality by comparing the results of pre-match and post-match logistic regressions. As shown in Model 2 (post-match model) in Table 2, there are no statistically significant predictors, thus indicating a satisfying matching quality is achieved."
13,"Table 4 shows the descriptive statistics, including means and standard deviations, and the correlations of all variables in Eq. (1). "
14,"Table 5 presents the results of cross-sectional regression analysis with CAR over the event window (-1, 0) as the dependent variable. More specifically, model 1 is the basic model and only includes all control variables. In model 2, the direct effect of AI-enabled B2B marketing is introduced. The interactions between AI-enabled B2B marketing and industry dynamism and customer complexity are sequentially included in models 3 and 4. The F-tests (p < 0.05) show that these four models are significant, with adjusted R-squared values between 0.071 and 0.141. To test for multicollinearity, we calculate the full model's variance inflation factor (VIF). The maximum and mean values of VIF are 1.93 and 1.40 (much lower than the threshold of 10), thus suggesting that multicollinearity is not a concern in our models (Kennedy, 1998)."
15,"To facilitate our focus group discussion, we meticulously framed our research objectives to provide clear guidance on the purpose of our study, as outlined in Table 6. These predefined objectives served as a framework for our inquiries during the workshop. The discussion revolved around the examination of the three hypotheses central to our research. For Hypothesis 1, participants engaged in conversations addressing questions such as ""Could you share your thoughts on why shareholders generally react positively to AI implementation in B2B marketing?"" and ""What specific benefits or expectations do you associate with AI adoption in B2B marketing?"" Hypothesis 2 prompted discussions with questions such as ""From your perspective, how do industry dynamics and concerns affect your perception of AI adoption in B2B marketing?"" and ""Do you believe that firms in more dynamic industries have unique considerations when it comes to AI implementation? Please elaborate."" Hypothesis 3 guided participants to respond to queries like ""What challenges or complexities do you perceive in firms with more complex customer bases when implementing AI in B2B marketing?"" and ""Could you provide examples of situations where shareholders may have concerns about AI adoption in such firms?""."
16,"Following a similar strategy as Study 1, in Study 2, we obtained 508 [Females= 260] filled-in questionnaires from UK-based participants [Median Age= 33.78 years; Median Income= ?32,820]. In both studies, our final sample was skewed toward younger adults compared to the UK population. Table 1 presents the sample demographics of studies 1 and 2."
17,"In Table 2, we present the descriptive statistics of the variables in the study. There are positive and statistically significant correlations between the antecedents (i.e., perceived privacy concern, anthropomorphic chatbots, and perceived empathy) and the mediators [i.e., perceived ability (rprivacy concerns, perceived ability=-0.21, p < 0.001; ranthropomorphic chatbots, perceived ability =0.25, p < 0.001; rperceived empathy, perceived ability=0.34, p < 0.001), perceived benevolence (rprivacy concerns, perceived benevolence=-0.06, p < 0.10; ranthropomorphic chatbots, perceived benevolence =0.28, p < 0.001; rperceived empathy, perceived beenvolence=0.24, p < 0.001), and perceived integrity (rprivacy concern, perceived intergrity=-0.05, p < 0.10; ranthropomorphic chatbots, perceived integrity =0.33, p < 0.001; rperceived empathy, perceived integrity=0.28, p < 0.001)."
18,We tested hypotheses 1?6 using a structural equation model. We employed MPLUS 8.0 to test the structural model. Table 4 presents the results of the hypothesis tests.
19,"We predicted through the sixth hypothesis that perceived ability, perceived benevolence, and perceived integrity act as mediators between the antecedents (perceived privacy concerns, anthropomorphism, and perceived empathy) and customer outcome (i.e., consumer forgiveness and nWOM). To test the mediation models, we employed Hayes? (2018) procedure and further employed a bootstrapping re-sample value of 5000. In Table 5, we present the results of the mediation analyses."
20,"Next, from Table 6, we can observe that the correlations of the antecedents and the mediators are positive and statistically significant, and the correlations of the mediators and the two outcome variables: consumer forgiveness and nWOM, are in the expected directions. These encouraging findings provide preliminary evidence in support of the study hypotheses."
21,"Next, we tested the measurement model using MPLUS 8.0. The Study 2 measurement model reported a good fit (Chi-square/df= 2.83; RMSEA= 0.042; CFI= 0.955; TLI= 0.963). We also assessed the constructs? convergent and discriminant validities (Fornell & Larcker, 1981) that we report in Table 7."
22,"Finally, to test hypothesis six, we employed a strategy similar to Study 1, i.e., Hayes?s (2018) mediation procedure with a bootstrapping resample value 5000. We present the results of the mediation analyses in Table 8. The estimated path coefficient for the indirect effect of perceived privacy concerns on consumer forgiveness through perceived ability (Column 1 of Table 8) was statistically significant (? = -0.0089; LCI=-0.0122; UCI=-0.0056). Also, the estimated path coefficient for the indirect effect of perceived privacy concerns on nWOM through perceived ability (Column 2 of Table 8) was statistically significant (? = 0.0092; LCI=0.0044; UCI=0.0140). From Column 3 of Table 8, we observe that the estimated path coefficients for the indirect effects of chatbot anthropomorphism through perceived ability (? = 0.0125; LCI=0.0062; UCI=0.0188), perceived benevolence (? = 0.0208; LCI=0.0124; UCI=0.0292), and perceived integrity (? = 0.0298; LCI=0.0204; UCI=0.0392) on consumer forgiveness were statistically significant. Also, in Column 4 of Table 8, we observe that the estimated path coefficients for the indirect effects of anthropomorphism through perceived ability (? = -0.0127; LCI=-0.0178; UCI=-0.0076), perceived benevolence (? = -0.0175; LCI=-0.0246; UCI=-0.0104), and perceived integrity (? = -0.0352; LCI=-0.0481; UCI=-0.0223) on nWOM were statistically significant. Finally, in Column 5 of Table 8, we observe that the estimated path coefficients for the indirect effects of perceived empathy through perceived ability (? = 0.0193; LCI=0.0107; UCI=0.0279), perceived benevolence (? = 0.0261; LCI=0.0169; UCI=0.0353), and perceived integrity (? = 0.0292; LCI=0.0190; UCI=0.0394) on consumer forgiveness were statistically significant. Similarly, in Column 6 of Table 8, we observe that the estimated path coefficients for the indirect effects of perceived empathy through perceived ability (? = -0.0175; LCI=-0.0269; UCI=-0.0081), perceived benevolence (? = -0.0220; LCI=-0.0329; UCI=-0.0111), and perceived integrity (? = -0.0352; LCI=-0.0494; UCI=-0.0210) on nWOM were statistically significant."
23,"We studied in detail the creative practices of ISD teams at the WealthTech headquarters in Switzerland and various subsidiaries worldwide. The style of involvement was that of an embedded researcher having in-depth access to the research site (Walsham, 2006), including meeting rooms, in-house workstations, and the intranet. For nearly three years, from February 2013 to December 2015, the lead author spent several days weekly onsite in the Swiss offices, having access to an in-house workstation and intranet. There, the author conducted 32 interviews to get an in-depth understanding of creativity in ISD teams from a participant?s perspective (Walsham, 2006). In addition, the author attended meetings to do participant observations, in which a researcher participates actively in discussions, as opposed to acting as a passive outside observer (Walsham, 2006). In April 2014, the author also visited the UK offices to conduct 30 interviews and observe how ISD teams collaborated virtually. Table 1 provides an overview."
24,"We conducted interviews at WealthTech with 62 different ISD team members, ranging from 19 to 100 min. We took care to select a broad sample of participants to capture diverse perspectives, relying on a combination of theoretical sampling (seeking out different ISD team members), purposive sampling (seeking out diverse views), and snowballing (following referrals from other participants). We audio recorded and transcribed all 62 interviews except two, where the participants did not give permission to record, in which case we took notes. Of the 62 interviews, 39 were in German, in which case we translated the quotations into English. The remaining 23 interviews were in English. Table 2 provides an overview."
25,"For the scenario-based experiment (Study 2), we selected and adapted four conversations with KIM representing a 2 ? 2 factorial design: two conversations were completed by KIM, while this was not the case for the other two. In the unsuccessful conversations, the chatbot responded twice with textual elements to restart the conversation. In addition, two conversations were short in terms of the length of the conversation itself and KIM?s responses presenting 2 correct recipes, while the other two conversations were long with a lengthy introduction by KIM, and a detailed textual presentation displaying 5?6 recipes (see Figure A1 in the appendix). The experiment was supported by a German market research institute and took place with 627 participants in February 2022. We asked the respondents to read one sample conversation with KIM thoroughly and to evaluate KIM in terms of the conversation ability score and the three item scales (perceived naturalness of KIM, performance of the chat, satisfaction with the interaction). To check manipulation, they were asked to indicate whether KIM made good recipe suggestions and answered straight to the point ? that is, short and concise. The participants were randomly assigned to one of the four scenarios (see Table 3)."
26,"Both samples consist of more females than males. In the usability study (Study 1), the percentage of females was higher (60.2%) than males (39.0%, 0.8% diverse). In the experiment (Study 2), the gender distribution was more balanced with 51.0% females and 47.7% males (1.3% diverse). The respondents are young, most often 20?25 years (Study 1: 67.5%, Study 2: 62.3%) or 26?30 (Study 1: 16.3%, Study 2: 17.3%) old. The share of respondents under 20 was more than twice the size in Study 2 (14.7% vs. 5.7%) reflecting the aim to include a younger age group. Over time, the claim of familiarity with the term chatbot increased from about two-thirds to three-quarters of the respondents, more often males. In both samples, less than half of the respondents already had experience of chatbot usage. The percentage was higher compared to an earlier study on the acceptance of chatbots (Rese et al., 2020). About two-thirds of the sample in Study 1 use Facebook Messenger, and about half of the sample Study 2. However, the chatbot, KIM, is largely unfamiliar to respondents, in particular in Study 1. With regard to diet preferences, more than half of the respondents follow no special regimen, whilst about a quarter to a third are vegetarians, among them significantly greater numbers of females. Female respondents search for recipes more frequently on the internet in both samples. In general, the time spent searching for a recipe was short. In Study 1, half of the respondents take up to 5 min and another third up to 10 min, whilst in Study 2 about a quarter need longer with up to 20 min and more (see Table 4). While Study 1 relied on a student sample, participants of Study 2 included students (28.2%), employees (43.5%), self-employed (5.9%), pupils (9.3%), and trainees (8.9%)."
27,"With regard to the dialogues, there were no significant differences between female and male participants. Most participants completed the recipe search, corresponding more or less to their food preferences. Often KIM asked two questions about recipe criteria (48.0%), including the ingredients. In 3.3% of the dialogues, KIM referred to all three criteria, whilst not mentioning them explicitly in 21.1% of the conversations. On average, KIM suggested 6 recipes to the user, of which a small number were inappropriate (18.2%). The search was quick, with KIM posting more messages and using more words. KIM?s messages usually included one emoji per dialogue. KIM had to restart the conversation once in almost every dialogue. This had a significantly greater frequency in dialogues with female users, who also received a lower percentage of correct recipes. In about a quarter of the cases, KIM failed to employ a correct greeting, either repeating the same message or omitting the greeting. In the evaluation by external reviewers, KIM received a mean conversational ability score above 0 = poor, machine-like, but still under 50. This score was termed as ?good conversationalist? and was achieved by 2 of the 6 chatbots evaluated (Shah et al., 2016). The users rated KIM slightly better on satisfaction, naturalness, and performance expectancy with a score above the average value of 4 (see Table 5; for a description of the variables, see Table A1 in the appendix)."
28,"For hypotheses on task fulfilment, we relied on a comparison of users successfully and unsuccessfully completing the search for recipes with KIM in Study 1. We compared the mean values of task and conversation elements as well as evaluation criteria for the two groups. Since the group failing to complete the task was small, a non-parametric test ? the Mann-Whitney U Test ? was used (see Table 6)."
29,"With regard to the perceived conversational ability of KIM, we transformed the independent variables with a box-cox transformation to compensate for the non-normal distribution of the data. We employed stepwise regression analysis to integrate into the model not only the independent variables concerning the hypotheses but also all available independent variables from Table A1. We chose this more exploratory approach because of the scarcity of research results on the human?chatbot conversation. We used the four internal and external dependent evaluation variables. Similar to the results from the mean comparison, the external evaluation with the conversational ability score and, to some extent, user satisfaction were shown to be suitable and provided higher R2. Taking the external evaluation ? the conversational ability score ? into account, H1b and H7b were confirmed, and a positive effect of a high percentage of correct recipe suggestions (0.212, p = 0.003) and a negative effect of the number of conversation restarts (-0.506, p = 0.000) were established. For user satisfaction, the positive effect of a high percentage of correct recipe suggestions (0.174, p = 0.043) was also found. Other hypotheses on the perceived conversational ability of KIM could not be proven. The internal evaluation criteria established negative effects for the number of messages, the number of words from the user, the number of greetings by KIM, and the number of wrong recipe suggestions. While the presence of a correct greeting did not show the hypothesized positive effect (H8b), additional greetings had a negative effect (Table 7)."
30,"This research has tried to identify a mix of instrumental (task-oriented) and social (small-talk) conversational elements that influence users? perception of a chatbot and their conversation with it. To investigate conversational ability, we used the task-based and text-based chatbot, KIM, by MAGGI Kochstudio to perform the task of finding an accurate recipe and to undertake an analysis of 123 unstructured chat records (Study 1). An overview of previous studies analysing text-based chatbot conversations supported the identification of relevant features and evaluation variables from usability research (Fr?j? et al., 2000). We focused on several task-based and text-based variables as well as two characteristics of conversational ability that potentially influence the success of KIM in this area. In addition, we relied on an external evaluation by three reviewers based on the conversational ability score (Shah et al., 2016) and a subjective user evaluation following the conversation with KIM using item scales describing user satisfaction (Hornb?, 2006, Shawar and Atwel, 2007, S?erlund, 2022, S?erlund and Oikarinen, 2021). A scenario-based experiment (Study 2) was used to gain further insights into user evaluation of selected conversational elements (see Table 8). The usability study (Study 1) provided insights into several task-based and text features as well as characteristics of conversational ability, and it was used as a source for example dialogues. While chatbot usage could be monitored, the implementation period was rather long with data collected in person. The scenario-based experiment (Study 2) was quickly implemented but was restricted to a few features and did not include real experience with KIM."
31,"In the U.S sample, 50.2% of the respondents were female, 43.4% in the age group of 26?41 years, 40.9% had earned a four-year degree, and 84.3% indicated that the trip was domestic. In the Chinese sample, 56.1% were female, 36.9% in the age group of 26?41, 65.6% had earned a four-year degree, and 97.3% indicated that the trip was domestic. Table 1 shows the demographic profiles of participants in both countries."
32,"Establishing validity and reliability of the measures is essential prior to testing the structural model (Hair Jr et al., 2017; Henseler et al., 2009). We assessed the measurement models for the pooled data and then group 1 (U.S.) and group 2 (China). As displayed in Table 3, constructs were internally consistent since Cronbach?s alpha values were > the 0.70 threshold (Nunnally & Bernstein, 1994). The convergent validity criterion was verified, with average variance extracted (AVE) values all above 0.50 (Fornell & Bookstein, 1982)."
33,"As shown in Table 4, discriminant validity was assessed by heterotrait-monotrait criterion (HTMT). The results indicated good discriminant validity as all HTMT values were below the threshold value of 0.90 (Voorhees et al., 2016). A multicollinearity test was employed via the value inflation factor (VIF). VIF values were less than the 5.0 threshold. Hence, multicollinearity was not an issue. The Harman's single-factor test was utilized to control the threat of common method variance. The results of the exploratory factor analysis (unrotated) showed that no single construct explained more than 44.9% of the observed variance. Common method variance did not seem a concern in this study since it was below 50?60% (Fuller et al., 2016)."
34,"In the second stage, the structural models for group 1 and group 2 were gauged using SmartPLS 3 (Ringle et al., 2015). To assess the structural model, the R? of the endogenous variables was computed for the model?s explanatory power (Hair Jr et al., 2017). As reported in Table 5, consumption achieved R? value of 38.6% (pooled data), 32% (group 1), and 36.2% (group 2); contribution 44.3% (pooled), 38.5% (group 1), and 42.5% (group 2); creation 40.7% (pooled), 29.3% (group 1), and 43.8% (group 2); cold BRQ 27.7% (pooled), 17.9% (group 1), and 49.8% (group 2); hot BRQ 51.1% (pooled), 39.4% (group 1), and 49% (group 2); trip decision-making 23.9% (pooled), 20.2% (group 1), and 13.9% (group 2); and cross-buying 48.9% (pooled), 37.2% (group 1), and 54.9% (group 2). To assess the strength of the hypothesized relations, a bootstrapping test based on 5000 subsamples was performed. As hypothesized, brand involvement had a positive effect on ?consumption,? ?contribution? and ?creation? (H1a, ? = 0.612, p < 0.05; H1b, ? = 0.645, p < 0.05; H1c, ? = 0.603, p < 0.05, respectively). Accordingly, H1a, H1b, and H1c were verified. Additionally, perceived anonymity had a positive effect on ?consumption,? ?contribution? and ?creation? (H2a, ? = 0.038, p < 0.05; H2b, ? = 0.081, p < 0.05; H2c, ? = 0.119, p < 0.05, respectively). Hence, H2a, H2b, and H2c were confirmed. As hypothesized, consumption had a positive effect on both (H3a) cold and (H3b) hot BRQ (? = 0.272, p < 0.05; ? = 0.221, p < 0.05, respectively). Contribution had a positive effect on both (H4a) cold and (H4b) hot BRQ (? = 0.129, p < 0.05; ? = 0.281, p < 0.05, respectively). Additionally, creation had a positive effect on both (H5a) cold and (H5b) hot BRQ (? = 0.170, p < 0.05; ? = 0.269, p < 0.05, respectively). Therefore, H3a, H3b, H4a, H4b, H5a, and H5b were verified. Cold BRQ had a positive effect on trip-decision making (H6a) and cross-buying (H6b) (? = 0.057, p < 0.05; ? = 0.411, p < 0.05, respectively). Finally, hot BRQ had a significant positive effect on trip-decision making (H7a) and cross-buying (H7b) (? = 0.448, p < 0.05; ? = 0.350, p < 0.05, respectively). Thus, H6a, H6b, H7a, and H7b were confirmed."
35,"A multigroup analysis (MGA) was performed to compare the differences between the model for group 1 with the model for group 2. Differences in the path coefficients between the two data sets are shown in Table 6. In the first step, we tested the measurement invariance of composite models (MICOM) (Henseler et al., 2016). Thus, we followed the three-step process. These steps were computing the ?configural invariance,? ?compositional invariance? and ?the equality of means and variances.? . As displayed in Table 5, the full measurement invariance was partially achieved in the comparison between group 1 and group 2 as step (1) was fully established, and step (2) and step (3) were partially established. The following step was related to the employment of a multigroup analysis to test the path coefficients in both groups. Parametric and nonparametric procedures (PLS-MGA and permutation) were applied to investigate group differences (Hair et al., 2018). As shown in Table 5, the findings indicated that significant differences existed in path coefficients between group 1 and group 2. In the relationship between perceived anonymity and ?consumption,? ?contribution? and ?creation? the effects were stronger for group 1 (|??| = 0.113, p < 0.05, |??| = 0.106, p < 0.05, |??| = 0.088, p < 0.05, respectively)."
36,"The two goals of Study1 were to contrast the accuracy of effectiveness prediction (the difference between actual and predicted effectiveness) for email and FtF requests (H1) and to verify whether this overestimation is moderated by the closeness level between the requesters and the targets (H1a). To test these hypotheses, a new variable (Prediction accuracy) was calculated by subtracting Actual effectiveness from Predicted effectiveness. The data was submitted to a univariate ANOVA1 with factors of Media (email vs. FtF ? Between-subjects) and Closeness (Strangers vs. Friends ? Between-subjects), and Prediction accuracy as the DV. We looked at the main effect of Media which was highly significant [F (1, 109) = 22.105, p < 0.001,  = 0.169] showing that the magnitude of inaccuracy was significantly larger in email compared to FtF when Closeness levels are collapsed (H1 supported). However, neither the interaction [F (1, 109) = 0.321, p = 0.572,   = 0.003] nor the main effect of Closeness (F (1, 109) = 0.028, p = 0.867,   <0.001) was significant. Hence, the pattern of overestimation is not different among Friends and Strangers groups, that is the closeness between requesters and targets does not improve the accuracy of predicted effectiveness (H1a is not supported). We also asked participants to report their own feeling about the task (Table 1). We looked at the ANOVAs to see if there are any differences across conditions in terms of participants? feelings about the task. As expected, we found that the Friends group perceive requesting to be easier and feel less awkward approaching a target individual compared to the Strangers group. However, the two groups do not predict any difference in the embarrassment after being rejected. No significant interaction emerged between Media and Closeness nor any main effect for Media was observed (see Table 1)."
37,"We asked our participants one open-ended and several Likert scale questions (Appendix E) to justify their choice of medium. A content analysis of the open-ended question revealed that our Likert questions covered all the reasons provided by participants. Then, a factor analysis was conducted on the reasoning data leading to two factors and two single items (Table 2)."
38,"To test hypotheses 2 through 4, an omnibus logistic regression was conducted (Table 3). All the variables were mean-centred and logistic regression was conducted using the bootstrap method with 5000 resampling. Although we have already observed that a substantial portion of requesters chose email, which is the suboptimal medium according to Study1, the expectation was that their reasons would be different when approaching Strangers vs. Friends. Hence, in the following analysis, we included the interaction terms between Closeness and each of the reasons in Table 2. As seen in Table 3, two significant interactions emerged supporting H3a and H4a but not H2a. Please note that the main effects of factors involved in these significant interaction terms (i.e., Closeness, AwkEmbar, and Convenience) are not interpretable at this stage."
39,"However, we can conclude that Effectiveness does not play a significant role in media selection decision (H2 was not supported) as further confirmed in Table 4. To unpack the significant interaction terms of Closeness, data was split on Closeness levels (Friends vs. Strangers) and separate logistic regressions (bootstrap method with 5000 resampling) were performed for each subset of data (Table 4) with the decision outcome as the dependent variable and reasoning items explained above as independent variables. Although no predictor reached the significance level for the Friends group (H3 and H4 not supported for Friends), the biggest coefficient emerged for Effectiveness. On the other hand, email was more attractive for the Strangers group due to less awkwardness, less embarrassment, and the convenience of an email request (H3 and H4 supported for Strangers). A minority within this group picked the more effective medium for the right reason as shown by the marginally significant coefficient of Effectiveness."
40,"First, we contrasted the media decision by Male and Female participants by running a logistic regression (bootstrap with 5000 resampling) analysis with Closeness, Gender, and the interaction term of the two variables as the IVs and, the media decision outcome as the dependent variable. As shown in Table G1, no significant interaction effect emerged nor any main effect of Gender on media selection was detected."
41,"Second, we looked at the gender effect of reasoning by running an ANOVA analysis which was explained in the main text. Lastly, we excluded the female participants from the data set and ran another logistic regression. The significant interaction terms in Table 3 were also significant in this analysis."
42,"We asked our participants to contrast requesters? perspectives when they are approached FtF and via email. Two separate factor analyses were conducted on FtF and email perspective-taking measures with similar emerging factors as shown in Table A1. Cronbach?s alphas are reported separately for FtF questions and email questions. Separate repeated measure ANOVAs, Closeness (Cls vs. Str ? between-subject) ? perspective-taking index (FtF vs. eml ? within-subject), were conducted for each of the three emerged indices and none of them resulted in a significant interaction between Closeness and the perspective-taking index. It suggests that Participants in both Closeness conditions predicted the same magnitude of change in targets? perspectives when moving from FtF to email. As shown in the last column of Table H1, participants, regardless of their closeness level to the target (main effect of media), acknowledged differences between FtF and email requests for some of the indices and Single measures. We tested whether requesters consider any of the significant indices/measures when predicting the effectiveness of each medium. Index 3 was positively correlated with requesters? prediction of both FtF effectiveness (r(106)= 0.401, p < .0001) and Email effectiveness (r(107)= 0.398, p < 0.001). Index 1 was correlated with Email prediction only (r(106)= 0.246, p = 0.011) but it wasn?t strong and vanished when data was split on the Closeness factor. Single1 was correlated both with Email (r(48)= 0.366, p = 0.010) and FtF (r(48)= 0.475, p = <0.001) predictions but Single2 was only correlated with FtF predictions (r(48)= 0.539, p = <0.001). These significant correlations offer possible causes that make requesters to perceive FtF as a more effective channel for reaching out to targets. However, as shown in Study 1, requesters? perception is not even nearly close to the real extent of the difference between the two channels."
43,"Next, we selected those items with high and distinct loadings on this one factor (= .80). In addition, we sorted out items that did not clearly load on the feeling of creepiness factor. The final item set included seven items (see Table 1)."
44,"Next, we examined the effect of perceived creepiness on resistance. This analysis showed that the creepier participants perceived the SHA, the higher their resistance to using the SHA, supporting H3 (OLS regression including all conditions: B = 0.57, SE =.03, p < .001, d = 1.11). Considering the downstream effects of resistance, we find that all regression paths were significant at p < .001, except for the relationship between ease of use and usage intention (p = .316). In support of H4, resistance exerted a direct negative effect on usage intentions (B = -0.22, SE =.05) and negatively affected perceived usefulness (H5; B = -0.60, SE =.03) and ease of use (H6; B = -0.20, SE =.03). In line with H7, perceived usefulness exerted a positive effect on usage intention (B = 0.71, SE =.03). However, since ease of use did not significantly affect usage intention (B = -0.03, SE =.03), H8 had to be rejected. Finally, we tested the significance of the indirect effects of transparency and tangibility on usage intention through the proposed mediators ? creepiness, resistance, perceived usefulness, and perceived ease of use. Except for the path through perceived ease of use, all indirect effects reached significance at 95% CI. Table 2 provides a detailed overview of all results."
45,"Table 2 showed the demographic information. Specifically, we ranked respondents by the interval between responses to the two rounds of questionnaires, then we compared the demographic information of the early and late 25% of respondents (Armstrong and Overton, 1977, Sivo et al., 2006). The results (Table 2) showed no significant differences in gender, age, education, and usage experience. Therefore, in line with prior literature (Benlian, 2020, Ke et al., 2021, Laumer et al., 2017), we find that, even with a relatively low response rate, the comparative analysis revealed that nonresponse bias was not problematic for the present research."
46,"The longitudinal two-wave design with a time lag between the independent and dependent variables ensured that common method bias (CMB) was alleviated (Sykes, 2015). We also applied the Harmon single-factor test (Podsakoff et al., 2003). We found 10 factors with eigenvalues over 1, and the first factor accounted for 26.75%, lower than the threshold of 40%. In addition, we conducted a fit comparison between the one-factor model and the measurement model (Flynn et al., 2010). The one-factor model fit (?2/df=11231.312/560 =20.06, RMSEA=0.226, SRMR=0.332, CFI=0.182, TLI=0.131) indicated a worse result than the fit of our measurement model (?2/df=1849.975/539 =3.43, RMSEA=0.0072, SRMR=0.051, CFI=0.900, TLI=0.918). Finally, we adopted the marker variable technique to further examine CMB (Malhotra et al., 2006). In particular, the selected marker variable should be unrelated to any other variable in the measurement model (Acharya et al., 2022). We chose the vision of continuity as the marker variable. It refers to the organizational vision of maintaining continuity amidst internal and external changes (Venus et al., 2019), which was an irrelevant variable with two items. Table 3 showed that the correlations between the marker variable and other latent variables were irrelevant. Then, we utilized the lowest positive correlation (r = 0.02) to adjust the correlations among constructs. The results indicated that the difference between unadjusted correlations and adjusted correlations was not significant. Hence, CMB might not be a concern."
47,"We strategically selected 20 respondents from four subsidiaries of the electric company, all of whom had completed both phases of the questionnaires (as indicated in Table 4). Due to the constraints imposed by the COVID-19 pandemic, we conducted telephone interviews as the most practical and safe means of data collection. Each interview, on average, had a duration of approximately 10 min. Within the timeframe, we allocated around 7 min for specific questions tailored to each participant, while the remaining time was dedicated to providing a comprehensive introduction to the research background. While the interviews were relatively short, they were designed to be concise and focused, ensuring that participants? responses provided in-depth insights into their experiences and perspectives related to ES use, particularly in the context of TDS and support structures."
48,"This study used data from the University of Queensland, Australia, to explore the cyber resilience of organizations (Tsen et al., 2020). The dataset consisted of various features of 1473 organizations belonging to the critical and non-critical sectors in Australia, the USA, Canada, and Japan and their associated breaches due to ransomware attacks from 2004 to 2022. The dataset included firms with varying digital intensity, organizational size, network segmentation, EVSS, and CSR. We referred to Statista for data on the average financial losses (Lj) (Statista, 2022) from 2004 to 2022, which are derived from cyber-crime cases reported by the Internet Crime Complaint Center (IC3), which is a part of the FBI. Table 5 summarizes the statistics of the data."
49,Table 6 shows the relationship between the dependent and independent variables.
50,"We used generalized linear models such as LR (Son et al., 2020) in the RRA module to test the hypotheses. Based on the chi-squared test, the goodness of fit of the model was revealed to be significant (p < 0.001) with a small deviance of 66.68. Table 8 reports the parameters of the M1 (LR) model that were significant at the 1% level. Substituting the values from Table 8 into Equation (1), Eq. (3) is determined, as follows (3) Table 8 and Eq. (3) indicate that larger organizations are 6.786 times more likely to face R attacks than NR attacks (p = 0.001), thereby supporting hypothesis H1a. Moreover, if organizations belong to a critical industry, their chances of facing ransomware attacks increase by 5.229 times compared to NR attacks (p = 0.001). This finding supports hypothesis H1b. Similarly, for each unit increase in digital intensity, the odds of R attacks are 13.573 times greater than those of NR attacks (p = 0.001). This result aligns with hypothesis H2a. However, if the network is segmented, the probability of occurrence of R attacks decreases to 0.042 times that of NR attacks (p = 0.001), thereby supporting hypotheses H2b. Table 8 also indicates that for each unit increase in vulnerabilities in the organizational environment, the odds of ransomware attacks increase by 2.734 times compared to other cyberattacks (p = 0.098). This finding supports hypothesis H3. In contrast, if information security governance is properly implemented in an organization, for an increase in every cybersecurity role, the probability of ransomware attacks decreases to 0.421 times that of non-ransomware attacks (p = 0.100), thereby supporting hypothesis H4."
51,"Next, in the RRA module, we used the M1, M2, and M3 models to classify attacks as R or NR. The performances of the three models were measured and compared on the test dataset using the accuracy, precision, recall, and F1-score, as shown in Table 9. It is evident from Table 9 that M1 was better than M2 and M3 because its accuracy, precision, recall, and F1-score were better than those of the other two models. Hence, this study further elaborates on the results of M1 (the LR model). Figs. 3(a) and 3(b) show that M1 could correctly classify or predict 27 out of 29 R and 293 out of 314 NR data points of the test dataset."
52,"Consistent with the literature (Islam et al., 2022, Sun et al., 2020, Sun et al., 2021), Table 2 lists the loadings and cross-loadings of the measurement items. The items loaded in our assumed factors provide preliminary evidence of our data validity."
53,"All the Cronbach?s a values are.76 or larger, indicating sufficient reliability (Nunnally & Bernstein, 1994). All the composite reliability (CR) values are.81 or larger, and all the average variance extracted (AVE) values are.55 or larger. These results indicate acceptable reliability (Bagozzi & Yi, 1988). As shown in Appendix A, all the indicator loadings are.65 or higher, suggesting good convergent validity (Hair et al., 1998). As shown in Table 3, all the positive square roots of the AVE values exceed the associated correlations, indicating discriminant validity (Fornell & Larcker, 1981). To offer enhanced evidence of discriminant validity, we tested and found that all the 95% confidence intervals of the correlations are smaller than all the positive square roots of the AVE values. Psychometric properties may include reliability, validity, and model fit performance. Our measurement model has sufficiently good performance in model fit, i.e., CFI= .97, IFI= .97, NNFI= .96, SRMR= .05 (Bagozzi, 2010)."
54,"We obtained 546 complete responses through a two-wave data collection process. The data indicate that most of our participants were male (86.7%). This proportion is similar to that of the local player population, in which 83% of players are male (GNN, 2016). Most participants were aged = 30 years (82.1%), had a college/university level education or higher (91.4%), and had an income = NT $600,000.00 (79.5%). Most participants had played the focal game for = 5 years (91.1%), showed weekly gameplay hours of < 21 h (87.7%), and had a skill level of gold or below (91.7%). Table 4 shows the demographic profile of the participants. However, the total numbers shown in Table 4 are not always equal to the total collected sample size due to some missing values in the profile data."
55,"As shown in Fig. 2 and Table 5, our structural model explains significant variances in the endogenous constructs: 57% in competence satisfaction, 49% in autonomy satisfaction, 26% in relatedness satisfaction, 49% in game continuance, and 11% in game usage. We suppose that 11% may be adequate, as game usage may be easily affected by schoolwork or workplace and family responsibilities. Moreover, the well-known phenomenon of the intentionsingle bondbehavior gap predicts a high discount in transforming intention to behavior (Fennis et al., 2011)."
56,"We performed the usual bootstrapping process, i.e., 5000 resamplings at the typical significance level of.05 (Nusair et al., 2024). Although not all the path coefficients in our structural model have significant coefficients, the bootstrapping results indicate that all the mediations are significant. This is reasonable, as the bootstrapping method is designed to test the interactions of the path coefficients. Therefore, a single large path coefficient can result in a significant interaction among path coefficients. All the mediation coefficients are significant, justifying the importance of the chosen mediators in our model. Moreover, our model shows that most (but not all) paths have significant coefficients, giving game makers useful insights into game achievability and game immersibility, but not focusing on game creatability."
57,"In total, we received 213 complete responses, which were screened in multiple steps, resulting in 206 valid responses. We excluded 1 response from South Africa, as it was from outside of Europe, and removed 6 responses for inattentive responding (< 0.5 sd in the responses) or for responding at a speed that would be impossible to do attentively (< 5 min). The sample was then examined for missing data. We found two missing values for USE_3 (see Appendix C, Table C1), which were imputed with the median value of the item. Finally, we screened the remaining responses that failed the attention-trap question. We found sufficient variance in their answers, and the respondents took a sufficiently long enough time (> 10 min) to complete the survey. Demographic information about the respondents (n = 206) can be found in Table 1. As can be seen from the table, the survey responses were collected from top management (61), middle management (65), lower management (51), and experts (29). Table 2 depicts information about the companies of the respondents."
58,"In total, we received 213 complete responses, which were screened in multiple steps, resulting in 206 valid responses. We excluded 1 response from South Africa, as it was from outside of Europe, and removed 6 responses for inattentive responding (< 0.5 sd in the responses) or for responding at a speed that would be impossible to do attentively (< 5 min). The sample was then examined for missing data. We found two missing values for USE_3 (see Appendix C, Table C1), which were imputed with the median value of the item. Finally, we screened the remaining responses that failed the attention-trap question. We found sufficient variance in their answers, and the respondents took a sufficiently long enough time (> 10 min) to complete the survey. Demographic information about the respondents (n = 206) can be found in Table 1. As can be seen from the table, the survey responses were collected from top management (61), middle management (65), lower management (51), and experts (29). Table 2 depicts information about the companies of the respondents."
59,"We then proceeded with the CFA by evaluating the fully correlated measurement model. As the first step in assessing the indicator and construct validities, we examined the standardized item loadings for the constructs. All loadings were statistically significant (p < 0.001) and above the recommended 0.707 threshold (Fornell & Larcker, 1981), except for one RESI item, which had a loading of 0.689. Thus, this item was dropped from subsequent analyses. The constructs, items, and their means, standard deviations, and standardized factor loadings are presented in Appendix C (Table C1). Next, we used the Master Validity plug-in of Gaskin et al. (2019) to analyze the discriminant validity of our measurement model (Table 3). According to Fornell and Larcker (1981), the composite reliability (CR) value of all constructs should be above 0.7, the average variance extracted (AVE) should be above 0.5 and larger than the maximum shared variance (MSV), and the square root of each AVE should be larger than all other correlations with the other variables. The CR, AVE, MSV, and square root of the AVE (bolded in diagonal) are reported in Table 3. As can be seen, our data fit all the aforementioned criteria, indicating sufficient convergent and discriminant validity for our model."
60,"We opted to evaluate the model fit for the measurement and path models using the CFI, SRMR, and RMSEA measures. This is in line with the recommendations of Hair et al. (2014), who suggested that model fit should be evaluated with at least one absolute fit measure (e.g., SRMR and RMSEA) and one incremental fit index (e.g., CFI). The suggested cutoffs for these fit measures are = 0.95 for CFI, = 0.08 for SRMR, and = 0.08 for RMSEA, along with > 0.05 for its PClose (Hair et al., 2014). As shown in Table 4, the measurement model?s values were excellent for all of these fit indices. The model?s normed chi-square (?2/df) was 1.515, which falls within the suggested range of 1?3 (Hair et al., 2014). The chi-square test was statistically significant (p < 0.05), indicating poor fit with the data; however, this is common with complex models and larger sample sizes (Schermelleh-Engel et al., 2003). Moreover, Hair et al. (2014) recommend that this measure should not be examined independently but in the context of other model fit measures. As all the other model fit indices were excellent, we can conclude that the measurement model fit the data well. After we moved on to the hypothesis-testing phase, we also evaluated the path model?s fit. Again, the measures were still excellent except for CFI (0.946), which was still close to excellent fit, but within acceptable range (= 0.9) nonetheless."
61,"Four out of twelve of the paths were significant at the p < 0.001 level, two at the p < 0.01 level, and one at the p < 0.05 level. Seven out of the twelve hypotheses were thus supported (see Table 5). For the statistically significant paths, the effect directions (positive or negative) were as hypothesized in the research model (Fig. 1). Thus, the research model had overall empirical support."
62,"Besides testing for the direct effects of each antecedent, we also carried out additional mediation analysis by testing for the indirect effects of the six TOE-based antecedents on organizational XR adoption intention via the perceived organizational value of XR and expected employee resistance to XR constructs. In addition, we tested whether the effect of expected employee resistance to XR on organizational XR adoption intention was mediated via the perceived organizational value of XR. This analysis was carried out using the latent mediation estimand and the Indirect Effects plugin created by Gaskin et al. (2020). The statistically significant paths are presented in Table 6. Mimetic pressure?s effect on organizational XR adoption intention was strongly mediated via the perceived organizational value of XR (? = 0.206; p < 0.001). Organizational support (? = 0.088; p < 0.01), employee technology use skills (? = 0.069; p < 0.05), and trialability (? = 0.047; p < 0.05) had a positive mediated effect on organizational XR adoption intention via expected employee resistance to XR. Other indirect effects were statistically insignificant (p > 0.05)."
63,"Table 1 displays socially accepted risk profiles (for sources, see S.I.2. Comparison data). In food safety, the U.S. Food and Drug Administration (FDA) maintains a Food Defect Levels Handbook, which specifies that it accepts around 7% of defect samples (mainly mold and insect-infestations). About 15% of U.S. citizens contract foodborne illnesses annually, while severe harm is much less common (some 3000 die each year). The U.S. Food Safety and Inspection Service (FSIS) accepts 7.5% of salmonella-positive chicken carcasses and ground beef samples, with harm levels below 0.5% and around 420 U.S. deaths annually. General consumer goods have a different profile. Tracking the number of faulty products sold per year, the U.S. Dept. of Commerce only recalls 0.1%. Their accumulation and frequent use hurts 2%- 4% of U.S. citizens annually. In between these extremes is the risk profile of sports. In soccer, 1 in 32 ball possessions leads to a potentially dangerous foul (3.1%), and 1.5% of U.S. players end up injured. Another extreme is the risk profile of cigarettes. While each cigarette is risky and severe harm levels are notably higher (some 10% die from lung cancer or cardiovascular disease), it is surprising to many that these trackable risks are not life-threatening to some 90% of smokers."
64,"As our analysis aims at bridging measures from computer science, information science, medicine, and the psychological and social sciences, we prioritized expected values and simple conditional probabilities over higher-order meta-analytic statistics (Higgins et al., 2019, Petticrew and Roberts, 2008, Uman, 2011). We still achieve the meta-analytic goal of systematically synthesizing independent studies to calculate an overall effect (Egger and Smith, 1997, Shorten and Shorten, 2013). Table 2 presents the simple framework that conditions algorithmic recommendation output on different kinds of input. While all included studies (N = 151) report the percentage of ?bad? recommendations (first column: X%, Y%, or Z%), we only obtain data on ?good? recommendations for 62 studies (see Table 3). This means that we can distinguish between ?bad? and ?not bad? recommendations for all 151 audits (which is what we will do for most of our analyses), and distinguish between ?good?, ?other/neutral?, and ?bad? for a subgroup of studies (see section ?Recommending utility content?)."
65,"As our analysis aims at bridging measures from computer science, information science, medicine, and the psychological and social sciences, we prioritized expected values and simple conditional probabilities over higher-order meta-analytic statistics (Higgins et al., 2019, Petticrew and Roberts, 2008, Uman, 2011). We still achieve the meta-analytic goal of systematically synthesizing independent studies to calculate an overall effect (Egger and Smith, 1997, Shorten and Shorten, 2013). Table 2 presents the simple framework that conditions algorithmic recommendation output on different kinds of input. While all included studies (N = 151) report the percentage of ?bad? recommendations (first column: X%, Y%, or Z%), we only obtain data on ?good? recommendations for 62 studies (see Table 3). This means that we can distinguish between ?bad? and ?not bad? recommendations for all 151 audits (which is what we will do for most of our analyses), and distinguish between ?good?, ?other/neutral?, and ?bad? for a subgroup of studies (see section ?Recommending utility content?)."
66,"Drawing from the research questions, a range of keywords were identified for the database searches, including ?mobile phone,? ?smart phone,? ?augmented reality,? ?distraction,? and ?multi-tasking.? In line with prior studies (Agarwal et al., 2019, Borges et al., 2021, Yan et al., 2021), Web of Science (WoS) and Scopus were identified as appropriate databases to obtain relevant and reliable journal articles across disciplines (see Table 1). To determine the eligibility of articles, inclusion and exclusion criteria were created in line with PRISMA guidelines (Massaro et al., 2016, Moher et al., 2009, Tranfield et al., 2003), see Fig. 2. Inclusion criteria included i) journal articles investigated mobile or AR technologies, and distraction or multi-tasking, involving customers (i.e., consumption context), ii) journal articles published in English, iii) journal articles published in high-ranking outlets (Scimago Q1 or Q2), iv) journal articles published since 2016 (to ensure the technology studied is up to date), v) journal articles empirical in nature, and vi) full-text versions accessible. The full exclusion criteria included i) publications merely mentioning distraction or multi-tasking, ii) publications where the focus was not on a customer-related experience, iii) publications in other than high-ranking journal articles, and iv) non-empirical research articles."
67,"Three focus groups were conducted (between 5 and 8 participants per session) to examine specific issues (Krueger, 2014). The sessions lasted between 60 and 90 min. The participants were recruited in Spain, following a non-probabilistic, purposive approach. The composition of a focus group should have a certain degree of homogeneity to avoid huge differences in opinion emerging, but it should also be diverse enough to promote discussion and generate useful information (Phillippi & Lauderdale, 2018). As prior knowledge of cultural events can influence participants? perceptions and evaluation of an experience (Lobuono et al., 2016), we selected people with similar levels of knowledge about the cultural event under consideration, but with different characteristics in terms of age, gender, and willingness to adopt new technologies. The focus groups were run until the saturation criterion was met (Malterud et al., 2016). The composition of the focus groups is shown in Table 1."
68,"Analyses of the reliability and convergent validity of the scales were conducted using SmartPLS 4.0 software. The factorial loadings of the indicators exceeded the minimum recommended level of 0.70 (except one, see Appendix B; Hair et al., 2011). The composite reliability of the constructs and the average variance extracted (AVE) values were also higher than the recommended minimum levels (Hair et al., 2011) (see Appendix B). Discriminant validity was assessed based on the criteria of Fornell and Larcker (1981) and heterotrait-monotrait ratios (Kline, 2011), with both approaches returning satisfactory values (see Table 3)."
69,"In this study, exploratory factor analysis and confirmatory factor analysis were used to test the dimensions and items of the evaluation index system for structural validity, convergent validity and discriminant validity. The KMO value of the indicator system is 0.922 > 0.7, Bartlett's test: X2 is 2817.8, p < 0.001, which shows that the indicator system has good structural validity. Table 2 demonstrates the rotated factor loading coefficients after adjustment and deletion in this study. The four factors extracted were named by combining the connotation of each variable; factor 1 was the value of health information content, factor 2 was the reliability of mobile social media, factor 3 was the trustworthiness of health information content, and factor 4 was the interactivity of mobile social media. From the results of principal component extraction, it can be seen that the cumulative explained variance of the extracted 19 question items is 77.31 %, which indicates that the four factors extracted from the 19 question items have a better explanation for the original data."
70,"According to the four-factor model derived from the exploratory factor analysis, the validated factor analysis of the mobile social media health information quality evaluation scale was conducted on the survey questionnaire data using Amos23 software. The results showed (see Table 3) that the factor loadings of the dimensions of interactivity of mobile social media, reliability of mobile social media, the trustworthiness of health information content, and value of health information content ranged from 0.748 to 0.883, 0.781 to 0.908, 0.771 to 0.858, and 0.693 to 0.911, respectively, which were all greater than 0.6, indicating that each of their latent variables corresponding to the AVEs of each dimension were 0.6987, 0.7162, 0.6686, and 0.7118, all of which were greater than 0.6; the combined reliability CRs were 0.8737, 0.9095, 0.8896, and 0.9516, all of which were greater than 0.8, indicating ideal convergent validity."
71,"The final weight and the scores of the four dimensions of the WeChat official accounts' health information quality evaluation system were derived to give a quantitative evaluation of the current situation of WeChat official accounts' health information quality; see Table 5. The total average score of WeChat official accounts health information quality in this empirical study was 48.24, among which the score of the WeChat official accounts subject interaction dimension was 45.20, the score of the WeChat official accounts reliability dimension was 59.95, the score of the content credibility dimension was 28.32, and the score of the information content value dimension was 53.55. It is clear that the quality of health information on WeChat official accounts is generally low, especially the lowest score of content credibility, and the future improvement of health information quality on WeChat official accounts should be promoted from the aspect of content credibility."
72,"To minimise the drop-out rate, we included information about the purpose of the research in the survey, together with a statement guaranteeing the anonymity of the respondents. In addition, we offered some small incentives, such as mugs and umbrellas featuring the university logo, and, at the end of the survey, awarded these to randomly selected participants. To reduce the occurrence of missing values, the participants were required to give their responses to all questions/statements before they could progress to the next page/end of the survey (otherwise, a notification would pop up). Regarding the sample characteristics, 51.5 % were women, 76 % of the total were under 45 years of age, 46.5 % had studied at the higher education level and 63.8 % were in employed work. Table 4 presents the sample characteristics."
73,"Prior to conducting further data analyses, we assessed the multivariate assumptions of normality, linearity, multicollinearity and homoscedasticity [98]. The results of the one-sample Kolmogorov-Smirnov test [99], presented in Table 5, indicate the absence of normal distribution [99], since all 2-tailed asymptotic significance values were 0.000?that is, less than 0.05 [82,96]. Hence, we opted for PLS-SEM in this study because it has been shown to be robust under conditions of non-normality [100]."
74,"We performed an ANOVA to test the linearity of the relationships between variables [100,82], the results of which are presented in Table 6. The results show that there are linear relationships between the dependent (use intention) and independent variables, since all p-values are below 0.05. However, seven out of the eight relationships reveal a statistically significant deviation from linearity, which justified the use of the ANN model?a nonlinear artificial intelligence technique that reflects the structure and operation of the human brain. The only exception was the relationship between price value and use intention, albeit its p-value (0.054) was very close to the significance threshold (0.05)."
75,"Multicollinearity is a problem of high correlation between independent variables [101]. The results of the multicollinearity test performed on our model (see Table 7) indicate that there were no issues of multicollinearity, since all the Variance Inflation Factor (VIF) values were in the range of 1.065?3.562 (i.e., less than 10), and the tolerances were all higher than 0.10 [93,99]."
76,"We evaluated the measurement model by analysing its reliability and convergent and discriminant validity. The reliability analysis included three indicators of internal consistency: Cronbach's alpha (CA; [102]), the Rho coefficient and composite reliability (CR; [103]). The values for all three tests were above the recommended minimum value of 0.7. We assessed CR using average variance extracted (AVE). The AVE indicates the amount of variance a variable obtains from its indicators relative to the amount of variance caused by measurement error. All the AVE values were above the recommended minimum value of 0.5 [104]. Table 8 lists these values for each variable, along with the mean of each item and the outer loadings (i.e., the loads estimated for the relationships in reflective measurement models)."
77,"In this study, the presence of nonresponse bias was detected. To address this issue, we conducted a multigroup analysis, following the approach outlined by Hair et al. [105]. We compared the group of respondents who completed the survey promptly (within the first 5 days of issue) with the group of respondents who completed it later. The results indicated that there were no statistically significant differences between these two groups in terms of all variables (p > 0.05). Consequently, it can be concluded that the potential impact of nonresponse bias on the sample data is likely to be minimal or negligible [106]. Next, we assessed discriminant validity by comparing the squared AVE with the intercorrelation scores. Discriminant validity is achieved if the squared AVE of a variable is greater than the intercorrelation with other variables [107]. We further checked discriminant validity by applying the heterotrait-monotrait (HTMT) ratio. Henseler et al. [108] suggest that a HTMT ratio score above 0.90 indicates a discriminant validity issue. The HTMT ratio scores were all below the threshold, indicating that discriminant validity was achieved (see Table 9)."
78,"First, we tested the research hypotheses by comparative analysis of the coefficients obtained by OLS, using IBM SPSS v20 as a simulation tool. The results, presented in Table 10, confirm that none of the initial eight hypotheses derived from the extended UTAUT2 model could be rejected?that is, that all eight predictors have a statistically significant influence on the dependent variable (use intention). The most influential predictors according to the OLS findings are performance expectancy (?PE?UI=0.321, p-value=0.000), effort expectancy (?EE?UI=0.177, p-value=0.000) and facilitating conditions (?FC?UI=0.150, p-value=0.000), followed by hedonic motivation (?HM?UI=0.120, p-value=0.000), subjective norms (?SN?UI=0.100, p-value=0.000) and habit (?HAB?UI=0.112, p-value=0.000). The least influential predictors as per OLS are risk (?PRISK?UI= -0.084, p-value=0.000) and price value (?PRI-VAL?UI=0.065, p-value=0.006). We assessed the quality of the OLS model using the values of adjusted R2 (which was 0.724) and normalised root mean squared error (RMSE), which was 0.1292. Both values are acceptable, meaning that OLS can be accepted as a valid baseline model."
79,"We also assessed the predictive ability of the model by determining the squared multiple correlation coefficient (R2). The R2 value for use intention was 0.708, meaning that it explains a high proportion of the variance of the model. Furthermore, we examined the standardised root mean square residual (SRMR) value [108] to test the difference between the observed correlation and the predicted correlation as an indicator of model fit. A value of less than 0.08 is considered acceptable. The model proposed in this study yielded a value below this threshold (0.046). We also evaluated effect size (f2) after reviewing research from Chin [109], who indicated that f2 values of 0.02?0.15, 0.15?0.35 and 0.35 or higher suggest that an independent or exogenous latent variable has a small, moderate or large effect, respectively, on a dependent latent variable. The relationship between the variables in the present study was found to exert a significant effect, and the lowest value with regard to f2 pertained to the relationship between perceived value and use intention. Finally, we assessed the predictive relevance of the model using Stone-Geisser's Q2 value. According to Chin [109], a model demonstrates good predictive relevance when its Q2 value is greater than zero. Thus, the present value can be considered adequate. Table 10 summarises all of these results."
80,"One of the potential problems associated with ANNs is overfitting [86], which occurs when the model ?memorises? data from the training sample and loses the ability to generalise when used with previously unseen data. To avoid this problem, we performed 10-fold cross validation [[95], [115]]. A common measure of the prediction accuracy of ANN models is RMSE [91,99] (Table 11). The low RMSE values presented in Table 11 indicate good reliability and high prediction accuracy for the proposed model [101,50]. Finally, we further evaluated the performance of the ANN model by determining its goodness-of-fit coefficient R2 [116,100], using the following formula: where   is the variance of the desired output. The value R2 = 0.957 indicates that the ANN acceptance model explains 95.7 % of the variance of use intention (model output), which is a significant improvement on the PLS-SEM results."
81,"Finally, we performed a sensitivity analysis of the ANN model to determine the importance of each predictor. The importance of a predictor measures the significance of the changes in the output caused by changes in different predictors [62]. The normalised importance is calculated by dividing the importance values of each predictor by the largest importance value [91]. Values for the relative and normalised importance of the ANN model are presented in Table 12."
82,"The most significant predictor of use intention is PE (average importance: 0.256), followed by EE (0.175), FC (0.134) and HM (0.104), which is in line with SEM-PLS findings. Next, the ANN model predicts that SN (0.099) has a more significant impact than HAB (0.089), which differs from SEM-PLS results. Finally, the two least influential predictors were PRISK (0.087) and PRI-VAL (0.057), which was also predicted by SEM-PLS findings. These minor differences between the ANN and SEM-PLS findings can be explained by the higher prediction accuracy of the ANN model and its capacity to consider any nonlinear relationships among the variables [[50], [62]]. A detailed comparison of OLS, SEM-PLS and ANN findings is presented in Table 13 [117]."
83,"Table 14 presents a comparison of similar research studies related to m-payment that have employed the UTAUT2 model as a theoretical framework. As can be seen, the results are aligned with the recent proposals of Al-Okaily et al. [120] and Migliore et al. (2020), which reinforces the generalisability of the findings obtained."
84,"In the experiment, participants were presented with a recommendation provided by DA and were asked to make a decision regarding the promotion of a candidate to a sales manager position. The decision specifically focused on choosing between a female candidate and a male candidate. This scenario aimed to simulate the use of algorithms in real-world promotion decisions, which have significant implications for individuals? lives and careers [108]. To ensure that the sample met the requirements of our study, we included a screening question asking participants about their roles in their respective firms. Participants who did not have managerial roles were excluded from the analysis. This decision was based on the understanding that managers are typically the primary users of DA tools and are responsible for accepting or rejecting the recommendations provided by such tools. The characteristics of the final sample are presented in Table 2."
85,"SPSS 26 was used to conduct the analyses. Cronbach's alphas, composite reliabilities, correlations, descriptive statistics, and the square roots of average variance extracted (diagonal values) are provided in Table 3. The item loadings associated with the constructs are presented in Table 4. To evaluate the presence of common method bias, we performed a marker-variable analysis [110]. We used extraversion as the marker variable, as it is theoretically not related to the variables in the research model. The average correlation between the marker variable and the main variables in the research model was 0.018, suggesting that common method bias was unlikely to exist in the data. To examine the manipulation check for ?just recommendation? versus ?unjust recommendation against women,? we used ANOVA. The results showed that participants in the ?just recommendation? treatment group reported a mean score of 4.35 (SD = 1.53), whereas participants in the ?unjust recommendation? treatment group reported a mean score of 5.31 (SD = 1.45) for the manipulation check question assessing the perception of unjust treatment toward the female candidate. The difference between the two groups was statistically significant (P < 0.05). Therefore, the manipulation of algorithmic injustice was successful."
86,"SPSS 26 was used to conduct the analyses. Cronbach's alphas, composite reliabilities, correlations, descriptive statistics, and the square roots of average variance extracted (diagonal values) are provided in Table 3. The item loadings associated with the constructs are presented in Table 4. To evaluate the presence of common method bias, we performed a marker-variable analysis [110]. We used extraversion as the marker variable, as it is theoretically not related to the variables in the research model. The average correlation between the marker variable and the main variables in the research model was 0.018, suggesting that common method bias was unlikely to exist in the data. To examine the manipulation check for ?just recommendation? versus ?unjust recommendation against women,? we used ANOVA. The results showed that participants in the ?just recommendation? treatment group reported a mean score of 4.35 (SD = 1.53), whereas participants in the ?unjust recommendation? treatment group reported a mean score of 5.31 (SD = 1.45) for the manipulation check question assessing the perception of unjust treatment toward the female candidate. The difference between the two groups was statistically significant (P < 0.05). Therefore, the manipulation of algorithmic injustice was successful."
87,"We performed a hierarchical logistic regression analysis in SPSS 26 to examine (1) the impact of algorithmic injustice on making a discriminatory decision and (2) the moderating role of displacement of responsibility and trust in DA outcomes on that association. The results, presented in Table 5, indicated that the impact of algorithmic injustice on discrimination (H1) was statistically significant (P < 0.001). While the moderating effect of displacement of responsibility on the relationship between algorithmic injustice and discrimination (H3) was not significant, trust in DA outcomes showed a significant moderating effect on the impact of algorithmic injustice on discrimination (P < 0.05) (H5). The findings also demonstrated that the control variables did not have a significant impact on making algorithmically informed, discriminatory decisions. Next, we ran an analysis of covariance (ANCOVA) to examine the effect of discrimination on the perception of guilt (H2). The results indicated that the effect was not significant (P = 0.19), supporting H2. We then added two interaction terms to the ANCOVA model to test the moderating effect of displacement of responsibility on the relation between discrimination and guilt (H4) as well as the moderating impact of trust in DA outcomes on that association (H6). The results showed that while H4 was not significant (P = 0.87), H6 was marginally significant (P = 0.08). In summary, while H1, H2, and H5 were supported, H3 and H4 were not supported, and H6 was partially supported."
88,"Second, we performed a confirmatory factor analysis (CFA). We examined the reliability, convergent validity, and discriminant validity of the latent reflective constructs. The composite reliability (CR) was above the recommended 0.70 threshold [91]. The average variance extracted (AVE) for all constructs exceeded the suggested 0.50 threshold [28], thereby demonstrating good reliability and internal consistency (Table 4), except for our control variable, social desirability (AVE = 0.475). Because social desirability slightly falls below the 0.50 threshold but has a CR of 0.729, we kept social desirability in our model (cf. [28]). All indicators loaded significantly on their latent constructs, and standardized loadings exceeded the required minimum of 0.700, indicating good convergent validity, except for social desirability (Appendix D). In addition, we tested the discriminant validity of the constructs. Since the square root of the AVE of each construct exceeded the squared interconstruct correlations, each construct explained more variance in its indicators than it shared with other constructs (Table 4). "
89,"In addition, all heterotrait?monotrait (HTMT) ratios of correlations (Table 5) were below the 0.85 threshold [36], suggesting no discriminant validity problems. We also examined variance inflation factor (VIF) values to test for multicollinearity in our data. The highest VIF value was between inferences of manipulative intent and mistrust in seal authority (i.e., 3.146), falling below a threshold of 5.0, suggesting that our data are not subject to a severe multicollinearity issue [62]. To assess model fit, we used four metrics [70]: the ??/degrees of freedom (df) ratio, the root mean squared error of approximation (RMSEA), the comparative fit index (CFI), and the Tucker?Lewis index (TLI). Common thresholds for acceptable model fit are ??/df < 3, RMSEA < 0.80, CFI and TLI > 0.90 [32,42]. The CFA model yielded an acceptable model fit (??/df = 2.329; RMSEA = 0.042; CFI = 0.943; TLI = 0.939)."
90,This study set out to identify and empirically test the antecedents and consequences of skepticism toward web seals. We conducted an online experiment to test the proposed hypotheses in a cloud service market context. Our results support the harmful effects of skepticism toward consumers? perception of IS providers (Table 6) and particularly emphasize the central role of seal authority incredibility in the nomological net. This study uncovers skepticism as a critical boundary condition for the effectiveness of web seals because skepticism can lead to the opposite effect of what is intended with them.
91,"The impact of the brand reputation gap on firms? profits is non-monotonic. Specifically, there exists a win-win region within which both firms? profits increase when the brand reputation gap increases (see Table 1 for details)."
92,"We have the following findings, which are consistent with previous ones:1 Firm H sets a higher price in the first period than in the second period when  . Firm L always sets a higher price in the second period than in the first period. 2 Firm H always sets a higher price than firm L in the first period but a lower price in the second period. 3 The profit of firm H is higher than that of firm L ( ) only when the price effect is weak?that is,  . As the price effect strengthens, the profit difference decreases ( ). Here, . 4 As the brand reputation gap increases, the profit difference increases ( ) except when, and this effect is mitigated as the price effect increases ( ). 5 The impact of the brand reputation gap on firms? profits is non-monotonic. Specifically, there exists a win-win region within which both firms? profits increase when the brand reputation gap increases (see Table C1 for details)."
93,"We have the following major findings, which are basically consistent with previous ones: 1 Firm H always sets a higher price than firm L in the first period but a lower price in the second period. 2 The profit of firm H is higher than that of firm L ( ) only when the price effect is weak?that is,  . Here,  3 The impact of the brand reputation gap on firms? profits is non-monotonic. Specifically, there exists a win-win region within which both firms? profits increase when the brand reputation gap increases (see Table D1 for details)."
94,The dimensionality of the constructs was confirmed through an initial exploratory principal components analysis with varimax rotation. The results (Table 4) did not suggest that any items needed to be dropped as all factor loadings were above 0.60 and average variance extracted values were all above 0.50 (Table 4). 
95," Moreover, as per Harman's one factor test, the first factor did not account for a majority of variance, only 14.5 %, suggesting no concerns over common method bias [67,94]. In addition, we considered the marker variable approach to test for common method bias [79]. We selected self-reported experience in management accounting as a marker because it is likely to be subject to a similar disproportionate response or acquiescence bias as other variables, such as levels of BI use and performance. However, it is not expected to be theoretically or statistically related to other model variables. When the marker variable was included as an additional determinant of the dependent variables, the significance of path coefficients did not change, providing further assurance that common method bias was not substantial [79]. Cronbach's alpha was used to measure internal consistency of the multi-item scales and found to be greater than 0.70 for all constructs. This provides support for convergent validity and reliability of our scales. To confirm discriminant validity, we compared inter-construct correlations with the square root of AVE of each construct. The square roots of AVE of each construct are presented along the diagonal of Table 5. These are shown as larger than the inter-construct correlations (i.e., constructs share more variance with their own items than with other constructs in the model). In addition, the HTMT ratios were calculated, and results indicate that the ratios are less than 0.85 [52]. Therefore, discriminant validity was confirmed."
96,"A Mann-Whitney comparison of users in the high advanced use subgroup with those in the low advanced use subgroup reveals significant differences across all model variables, except self-efficacy (Table 6). The mean rank for users classified as high advanced users was higher on all four system attributes, and in BI contribution to performance. These users also ranked significantly higher in task complexity."
97,The structural model was tested using AMOS with results reported in Table 7 indicating 17 out of 22 hypothesized paths were directly supported by the model being tested.
98,"System quality (p < 0.001), data quality (p < 0.01), information quality (p < 0.001), and service quality (p < 0.05) were all found to have positive significance effects on routine use. Furthermore, system quality (p < 0.001), data quality (p < 0.05), information quality (p < 0.001), and service quality (p < 0.01) were all found to have positive significance influence on advanced use, with effect sizes larger for advanced use than routine use, thus supporting H1a, H1b, H3a, H3b, H5b, H5c, H7a, and H7b. To further confirm the effects, we ran additional multiple regressions with bootstrap resampling to determine the overlap, if any, among confidence intervals. As shown in Table 8, we confirm no overlapping confidence intervals for effects of DQ and IQ providing added support to H3b and H5c. Although there is some overlap in confidence intervals for the effects of SQ and SQa, the overlap is not more than 50 % of the confidence interval range, thus giving us confidence to support H1b and H7b that their effects are greater on advanced use than on routine use. We also considered data quality to have additional indirect effects on BI use through effects on information quality. The effect of data quality on information quality is significant, supporting H5a."
99,"We considered the model's goodness of fit, the significance of the path coefficients, and the sign of the path to reach conclusions about moderation [48]. The results (Table 9) indicate that the complexity of the management accountant's tasks increases their opportunity to use the BI system innovatively to support their management accounting function (p < 0.001). Task complexity also has a moderating effect on routine use and performance (p < 0.05). The relationship between use and performance is moderated by task complexity, but the moderating effect is weaker for routine use, supporting both H13a and H13b. This confirms that the more complex the tasks of management accountants, the stronger will be the effect of advanced use on performance. This supports the importance of using the advanced features of the BI system to improve performance under conditions of greater task complexity."
100,"In the third step, which refers to Level 2c in the approach of [19] , the interviews were then coded in two different rounds within a parallel deductive and inductive approach. Within the former, we used our first-order research elements (i.e., the psychological factors from the status quo bias theory) for confirmatory coding of the raw case protocol. After that, in the second coding round, inductive coding was used on the statements extracted within the deductive first round to identify the concrete contextual manifestations of those bias-inducing factors. For instance, the sentence ?I think most people have seen the movie ?The Terminator?, right? I mean, the underlying idea as such was well-intentioned, but if it gets out of hand, if you lose control at some point, you're going to have a huge problem? (Interviewee 24, translated) was labeled with the code ?anchoring effects? in the first round and then with the contextual element ?Portrayal of AI in Hollywood movie (?The Terminator?)? in the second round. These contextual manifestations function as the second-order research elements in this study and the presentation of its results (cf. Fig. 2 and Table 3 in the results section)."
101,"After the participants were given their specific manipulations, they answered manipulation-check questions. These questions enabled us to determine whether participants remembered and understood the manipulations they were given. Table 4 shows the number of samples, means, and standard deviations for each variable. We provided manipulation checks in the following two ways."
102,"We conducted preliminary tests to assess the reliability and validity of the responses. The measurement model analyses involved the reliabilities for each correlation alpha (CRA), called Cronbach's alpha (a). Table 5 shows that all the scores were over the threshold of 0.7 [20,24]. Based on correlation matrix analyses, there were no critical issues regarding convergent validity and discriminant validity (see Fig. B.1). Because all average variances extracted (AVEs) were greater than 0.5, there were no convergent validity issues. The AVE square roots were greater than interconstruct correlations, which also indicated discriminant validity. The total number of violations was less than one-half of the potential comparisons [17]. We also tested the variance inflation factor to examine for potential multicollinearity. Based on the recommended value of 5, it was good in all cases except FE (FA = 2.2, EV = 2.1, FE = 5.2, GS. = 4.8, PC = 1.1) [40]. We tested for and ruled out common method bias using a marker variable and common latent factors in AMOS [72]. Finally, the results of confirmatory factor analysis (CFA) for sustainability demonstrated strong model fit statistics; the root mean square error of approximation (RMSEA) value was 0.043, which is lower than 0.07 [93]; the comparative fit index (CFI) value was 0.985, which is greater than 0.90; the Tucker?Lewis index value (TLI) was 0.982, also greater than 0.90."
103,"As Table 6 shows, to analyze the mediation effects of disclosure intentions between privacy concerns and purchase intentions, we used two tools: SPSS Process and AMOS. The effects of SSCC privacy concerns on disclosure intentions (t(454) = -8.82, p < 0) and disclosure intentions on SSCC purchase intentions (t(454) = 15.16, p < 0) were significant (see Table B.2 and Table B.3). We concluded that there were indirect effects of disclosure intentions between privacy concerns and purchase intentions because the interval between the lower level of confidence interval (BootLLCI) and the upper level of confidence interval (BootULCI) did not include zero (see Table B.3). The results of the model fit (GFI = 0.98, AGFI = 0.96, CFI = 0.99, RMSEA = 0.03) indicated that there was good model fit between the proposed model and the data, such that the data does not require re-specification (see Table B.4)."
104,"We analyzed the relationship between privacy concerns, government subsidies for SSCCs, consumers? disclosure intentions, and purchase intentions when adopting SSCCs. Government subsidies significantly affected consumers? disclosure intentions and purchase intentions when adopting SSCCs (H7 and H8 supported). Table 10 and Fig. 7 show the results of the effect of government subsidies. The mediation effects of disclosure intentions between privacy concerns and purchase intentions when adopting SSCCs had the same results as the previous output because privacy concerns negatively influenced disclosure intentions (H1 supported) that positively affected purchase intentions (H3 supported). Privacy concerns did not directly affect consumers? purchase intentions (H2 not supported)."
105,"Further to the main independent variables, we provide a set of campaign-specific factors to control the model, consistent with Vismara [43] and Nguyen et al. [37]. For instance, we use size of the management team to capture ta project's human capital, while the dummy variable patent indicates the existence of a patent in the project documents and is used as a proxy for projects? intellectual capital. The variable active campaign encompasses parallel projects that raise funds at the same time, which potentially lead to less daily crowdfunding investment in target projects. Some empirical findings indicate that parallel projects diminish support from investors in equity crowdfunding [43] and lenders within lending platforms [18] as well as backers in reward-based crowdfunding [51]. Table 1 provides detailed definitions and descriptive statistics for all variables used. Regarding the number of key statistics in Table 1, on the average, projects attract about 5 investors and raise nearly ?10,000 daily. While the daily average number of investors in equity crowdfunding is comparable to that in other types of crowdfunding markets, such as reward-based crowdfunding [45] or lending-based crowdfunding [24,49], their daily fundraising volume is much higher. This indicates the important and potential role of equity crowdfunding in providing capital to young entrepreneurs. Our sample statistics are, to a large extent, consistent with samples of equity crowdfunding projects from other papers [23,42,43]."
106,We provide a correlation matrix among independent variables in Table 2. The correlation coefficients satisfy the condition of no multicollinearity in the model. We have no pair of variables that are highly correlated.
107,"Table 3 reports the results from our different panel regressions on the presence of herding dynamics in equity crowdfunding. Model 1 shows the results from curvilinear regression (specification 2), while models 2 and 3 report the outcomes of the linear regression in the first and last periods of the crowdfunding campaigns (specification 1). As the dependent variable of the daily number of investors is a non-negative integer, we first use random-effect negative binominal panel regressions in models 1?3 to control for overdispersion. Furthermore, following Xiao [45], we replicate models 1?3 in models 4?6 using random-effect OLS regressions with natural log of daily number of investors as the dependent variable. To confirm the robustness of the results, we also run model 4?6 using fixed-effect regressions. The results appear to be consistent."
108,"To illustrate the dynamics of these information sources throughout the funding process, Table 4 presents different statistics (mean, median, max, min) on the number of discussions and of Facebook and Twitter posts at the end of the first stage and the last stage of the funding cycle. Further to Table 4, Graph 1 shows the average growth rate of number of posts from these sources. The growth rate for each project is calculated as where, NDFTPLS is the number of discussions, Facebook, and Twitter posts at the end of the last stage, and NDFTPFS is the number of discussions, Facebook, and Twitter posts at the end of the first stage."
109,"We ran a series of different tests to confirm the robustness of our analysis. First, we constructed an interaction variable between the logarithm forms of lag investors and days available, which measures the number of days remaining in a funding campaign. We replicate the main analysis using this new interaction term in negative binominal and OLS specifications. Models 1 and 2 of Table 6 show that the interaction term is negative and statistically significant, suggesting that herding momentum is more prevalent toward the final days of the funding campaign (i.e., the number of days available is getting smaller). These results are consistent with our previous findings."
110,"We also replicate our main analysis using an alternative measure for herding, which is the momentum of daily funding amount and total prior funding amount, as used in the prior literature [24,45]. These measures are considered to be good alternative proxies, as information on funding amounts is publicly available in crowdfunding platforms, so as investors can use it in their funding decision-making. Indeed, as discussed in Zhang and Liu [49], investors may herd to solve two key questions of whether they should invest or not and if so, how much they should contribute. Table 7 replicates our main analysis from Table 3 using funding amount momentum as an alternative measure of herding behavior. The results from the robustness checks are largely consistent with the main finding that herding only occurs in the last stages of those funding campaigns. The results from replicating Table 3 using an alternative measure of herding are also robust."
111,"Finally, we extend our main analysis to another important UK equity platform?Seedrs. We replicate our main tests in a sample of 80 projects, listed in Seedrs during 2017?2018, as a method for assessing the validity of our main findings with out-of-sample data. Using a smaller set of control variables than for the Crowdcube projects, our results, illustrated in Table 8, suggest similar herding dynamics among Seedrs projects, with herding momentum appearing strongly in the final stage of the funding campaigns, and confirm our original findings."
112,"The items for the actualization of others- and self-oriented affordances (OAA and SAA, respectively) were developed in an iterative process based on the interview transcripts and often included the exact wording of the participants. Items for measuring the actualizations of affordances were developed for each user's goal-feature combination [57] and assessed on a 5-point Likert scale (1 = strongly disagree; 5 = strongly agree). If participants had trouble understanding an item, they could indicate this by choosing the option ?I don't understand the statement.? In the questionnaire, the items for the actualization of others- and self-oriented affordances were mixed and displayed in random order. Table 4 contains the final survey items with descriptive measures."
113,"Given that the measurement models of our predictors?OAA and SAA?are formative, specific criteria for assessing formative measurement models need to be applied. Some researchers propose that item weights that are significant at the 0.05 level and greater than 0.1 demonstrate high relevance for the formative construct [59]. Not all of our indicators met this criterion (Table 5). However, a simulation study by He [67] shows that it might be misleading and overly simplistic to assess indicator validity based on item weights only. He [67] argues that the contribution of individual items to the formative construct might be obscured by shared variance between indicators. This variance affects neither the predictive power nor the reliability of the construct. Despite the diverging views, there is an agreement not to omit items in formative models purely on statistical grounds. Dropping items alters the meaning of the formative construct and therefore is not recommended [58,59,63,67]. Hence, we kept all items, as each one covered a specific aspect of the constructs that emerged in our qualitative study. Another criterion for indicator validity is variance inflation factors (VIF) below 10 [59,68]. All VIFs of our items were below 1.6, which indicates that multicollinearity is not a problem (Table 5)."
114," Table 2 provides the sample profile information. There were 47 % male and 53 % female participants. More than 80 % of the participants were aged between 18 and 25 years, which is consistent with the statistics of the China Internet Network Information Center (CNNIC) [64] on social media users in China."
115,"The measurement models of reflective and formative variables should be tested differently [69]. For the reflective variables, we examined Cronbach's alpha and composite reliability (CR) for the reliability test, average variance extraction (AVE) values for the convergent validity test, and the square root of the AVE and the correlation coefficient between variables for the discriminant validity test. First, it can be seen from Table 3 that Cronbach's alpha and CR of all variables are more than 0.7, indicating good reliability of the questionnaire [70]. The results show that the AVE of every variable is above 0.5, indicating good convergent validity of the questionnaire [70]. Finally, as shown in Table 4, the square root value of the AVE of all variables is greater than the correlation coefficient between the variable and all other variables, indicating that the scale has good discriminant validity [70]. For the collinearity test, the variance inflation factor (VIF) statistics were used to detect the multicollinearity problem between structures. Inner VIF values range from 1.088 to 3.163, as shown in Table 5; outer VIF values range from 1.669 to 6.565, as shown in Table 3. The general statistical theory believes that the tolerance VIF value can be considered 10 [71]. The range of outer and inner VIF values of this model is far less than their recommended tolerance limits, so there is no serious multicollinearity problem."
116,"The measurement models of reflective and formative variables should be tested differently [69]. For the reflective variables, we examined Cronbach's alpha and composite reliability (CR) for the reliability test, average variance extraction (AVE) values for the convergent validity test, and the square root of the AVE and the correlation coefficient between variables for the discriminant validity test. First, it can be seen from Table 3 that Cronbach's alpha and CR of all variables are more than 0.7, indicating good reliability of the questionnaire [70]. The results show that the AVE of every variable is above 0.5, indicating good convergent validity of the questionnaire [70]. Finally, as shown in Table 4, the square root value of the AVE of all variables is greater than the correlation coefficient between the variable and all other variables, indicating that the scale has good discriminant validity [70]. For the collinearity test, the variance inflation factor (VIF) statistics were used to detect the multicollinearity problem between structures. Inner VIF values range from 1.088 to 3.163, as shown in Table 5; outer VIF values range from 1.669 to 6.565, as shown in Table 3. The general statistical theory believes that the tolerance VIF value can be considered 10 [71]. The range of outer and inner VIF values of this model is far less than their recommended tolerance limits, so there is no serious multicollinearity problem."
117,"The measurement models of reflective and formative variables should be tested differently [69]. For the reflective variables, we examined Cronbach's alpha and composite reliability (CR) for the reliability test, average variance extraction (AVE) values for the convergent validity test, and the square root of the AVE and the correlation coefficient between variables for the discriminant validity test. First, it can be seen from Table 3 that Cronbach's alpha and CR of all variables are more than 0.7, indicating good reliability of the questionnaire [70]. The results show that the AVE of every variable is above 0.5, indicating good convergent validity of the questionnaire [70]. Finally, as shown in Table 4, the square root value of the AVE of all variables is greater than the correlation coefficient between the variable and all other variables, indicating that the scale has good discriminant validity [70]. For the collinearity test, the variance inflation factor (VIF) statistics were used to detect the multicollinearity problem between structures. Inner VIF values range from 1.088 to 3.163, as shown in Table 5; outer VIF values range from 1.669 to 6.565, as shown in Table 3. The general statistical theory believes that the tolerance VIF value can be considered 10 [71]. The range of outer and inner VIF values of this model is far less than their recommended tolerance limits, so there is no serious multicollinearity problem."
118,"VIF values and item weights were examined to assess the reliability and validity of formative variables [69]. The reliability of the variable is considered adequate for VIF values lower than 3.00. If the item weights are significant at the statistical level, that is, if the t-values are greater than 1.960, then the validity test is satisfied. According to the results in Table 6, the formative variable (i.e., intermittent discontinuance) has good reliability and validity."
119,"The results of the structural model and hypothesis tests are presented in Fig. 4 and Table 7. As shown in Fig. 4, the corresponding R2 values for intermittent discontinuance, usage fatigue, and transition fatigue are 0.298, 0.332, and 0.651, respectively, indicating that the structural model has a good fit [75]. Table 7 indicates that all hypotheses are supported except for H3. Information (?=0.450, t = 8.940, P<0.001) and system feature (?=0.197, t = 3.671, P<0.001) overload positively and significantly affect usage fatigue, supporting H1 and H2. "
120,"We conducted a mediation analysis based on the guidelines of Nitzl and Roldan [77] and Zhao et al. [78]. As shown in Table 8, the direct effect of sunk and transition costs is significantly positive, while the indirect effect of transition fatigue is significantly negative. When the direct and indirect effects are both significant and point in opposite directions, the type of mediation is competitive mediation [78]. Therefore, transition fatigue exerts a competitive mediation effect, which weakens the impact of transition and sunk costs on intermittent discontinuance."
121,"Necessity analysis, which is used to identify whether the existence of a variable can be considered a necessary condition for a result, must be tested before analyzing sufficient conditional combinations [82]. Table 9 shows that both the consistency and coverage levels of each variable are below the recommended threshold of 0.9 for necessity analysis [80], indicating that the condition variables could not completely explain the outcome variable. Thus, no single condition was necessary for intermittent discontinuance. In conclusion, further analysis of the conditional configuration combinations is required."
122,"FsQCA3.0 is used to construct a 2K row truth table, where k is the number of antecedents. The recommended consistency measurement threshold is 0.8 or 0.9 [79]. This study chose 0.9 as a cut-off point to ensure a high degree of consistency at this stage of analysis. Fiss [83] recommended that the frequency threshold should be three when the samples exceed 150. This study set the number of acceptable cases to four. The final results for the configurations leading to high and low intermittent discontinuance are listed, respectively, in Tables 10 and 11."
123,"FsQCA3.0 is used to construct a 2K row truth table, where k is the number of antecedents. The recommended consistency measurement threshold is 0.8 or 0.9 [79]. This study chose 0.9 as a cut-off point to ensure a high degree of consistency at this stage of analysis. Fiss [83] recommended that the frequency threshold should be three when the samples exceed 150. This study set the number of acceptable cases to four. The final results for the configurations leading to high and low intermittent discontinuance are listed, respectively, in Tables 10 and 11."
124,"We examine an NFT transactions database sourced from Nadini et al. [30]. It spans from June 2017 to April 2021, containing over 6 million transactions from Ethereum and WAX networks. Table 1 summarizes the dataset. We aggregate the data on a monthly basis and run a battery of statistical tests. The underlying data have been sourced from five different NFT places: OpenSea, Atomic, Decentraland, Cryptokitties and Godsunchained. All the NFTs under consideration belong to the categories games, collectibles, metaverse, and art. The dataset is comprehensive and provides information about the date and time of transaction, accounts of the transacting parties, and transaction amount in USD as well as in Cryptocurrency units. Thus, the dataset is robust, statistically pliable, and representative of the general NFT market. The dataset is summarized in Table 1. The cryptocurrency price data of transactions is then exploited in this study to quantitatively assess the extent of the fraudulent practices prevalent in the NFT markets. All three statistical tests used in this study, Benford's test, Student's t-test for clustering and Power-law fitting, are performed on this parameter only. Fischer's test is then performed on the p-values obtained from the previous tests to address the concerns of type-1 error and p-hacking in the analysis. The present work performs analysis of monthly data to ascertain that wash trading is being thoroughly practiced in the NFT markets."
125,"Meanwhile, MAD conformity deals with the average divergence from an actual digit distribution. As per Nigrini and Miller [63], . We use the same author's decision criteria where values between 0.0012 and 0.0018 are acceptable, between 0.0018 and 0.0022 are marginally acceptable, and beyond 0.0022 are labeled as nonconformity. Results from Table 2 show that and scores from Chi-squared and Mantissa Arc tests necessitate rejection of the null hypothesis for all months. As a robustness check, we run a Distortion Factor Model, which is capable of revealing overstatement and understatement in data. We report the magnitude of the distortion of actual values against what Benford's Law expects. Conformity tests on mean absolute deviation (MAD) register positive results for only two months: September and October 2020. Otherwise, overall evidence overwhelmingly suggests violation of Benford's Law."
126,"Next, we investigate whether clustering takes place in NFT sales prices. Since human traders use round numbers as a mental heuristic to save time, such a test is well-suited to identify potential automatic trades, which often manifest in clusters. For each period, we divide the data into two groups: one with prices that are exact multiples of 1000 base units and another with prices within a 500 unit radius from multiples of 1000 base units. The base for the analysis is 4?10 units. The results of the clustering test in Table 3 show that, for 33 out of the 42 time periods analyzed, ~40 % of the trades are clustered around rounded values. This suggests that the majority of trades might be computer-generated."
127,"Our third investigation uses power laws to estimate the fat tails of the NFT prices. If detected, they could indicate the presence of herding behavior [65]. Prior works also attribute fat tails to inadequate information available to economic agents to value an asset [66]. Li et al. [67] have shown that for financial assets the tail exponents lie in the Pareto-Levy range, i.e.,where is the power law exponent. The results of the Power fitting law in Table 4 show that power exponents, on 21 out of 42 occasions, do not lie in the Pareto-Levy range, suggesting abnormal trading practices."
128,"The upshot of the three tests described above is this: the trading patterns suggest high probability of abnormal and computer-generated trading both symptoms of wash trading and price manipulation. However, since we apply multiple tests on the same dataset, concerns over type-1 error and p-hacking may surface. Hence, we perform a multiple hypothesis test using Fischer's method with the null hypothesis that NFT trades are consistent with universal patterns in traditional financial markets. The combined results in Table 5 show a rejection of the null hypothesis for all months alleviating the aforementioned concerns. Our results contradict traditional asset stylized facts. For instance, Corazza et al. [68] show that prices of S&P 500 stocks generally follow Benford's Law but not during extreme events; e.g. the September 11 attack in 2001 or the crash during the Global Financial Crisis. Within the digital asset sphere, our results are comparable to Cong et al.?s [58] report on cryptocurrencies traded on unregulated exchanges, but similarities do not extend to regulated exchanges. Overall, our results appear consistent with the prevalent reputation of NFTs."
129,"The second phase of this investigation studies both the first and second significant digits. As stated before, a comma or zero before the first natural number is ignored [61]. Benford's Law is used to attempt to detect anomalies in the datasets of the non-fungible tokens. Via this approach, an effort is made to inspect whether price manipulation is occurring in the non-fungible tokens markets. Most of the requirements that are stated above are met by the datasets in this research. However, for the volume data, the requirement of a large dataset is somewhat difficult. The benchmark for the required number of transactions for the price data was set at 1000. However, in the literature there is a discrepancy that a number of researchers use as the lower bound for the criteria of a large dataset. For example, Riccioni and Cerqueti [56] used 100 as the lower bound. Meanwhile, Vicic and To?ic [29] stated that the rule is at least 50?100 transactions, while they state that often thousands of observations are used. Some papers argue for 500 as the lower bound for a large dataset (Tables 6 and 7)."
130,"The second phase of this investigation studies both the first and second significant digits. As stated before, a comma or zero before the first natural number is ignored [61]. Benford's Law is used to attempt to detect anomalies in the datasets of the non-fungible tokens. Via this approach, an effort is made to inspect whether price manipulation is occurring in the non-fungible tokens markets. Most of the requirements that are stated above are met by the datasets in this research. However, for the volume data, the requirement of a large dataset is somewhat difficult. The benchmark for the required number of transactions for the price data was set at 1000. However, in the literature there is a discrepancy that a number of researchers use as the lower bound for the criteria of a large dataset. For example, Riccioni and Cerqueti [56] used 100 as the lower bound. Meanwhile, Vicic and To?ic [29] stated that the rule is at least 50?100 transactions, while they state that often thousands of observations are used. Some papers argue for 500 as the lower bound for a large dataset (Tables 6 and 7)."
131,"These categories are also mentioned in the descriptive data overview in Table 8, which stems from the Nadini dataset. In the selection of NFTs, there are 13 Art, 9 Collectibles, 20 Games, 4 Metaverses, 2 Others and 2 Utility NFTs. Some popular examples of NFTs in the Art category are CryptoKitties and CryptoPunks. Both CryptoKitties and CryptoPunks have thousands of different characters. Every cat or Punk is unique. CryptoKitties can even be used to breed a new CryptoKittie [74]. Bitverse, MLB Champion and Sorare are good examples of the category Collectibles. Bitverse is a digital universe where sets of cards can be collected. There are four types of cards, ranging from common to legendary (Bitverse Comics, 2021). MLB Champions and Sorare are quite similar NFTs. MLB Champions are virtual baseball players, while Sorare consists of player cards. In both MLB Champions and Sorare, the NFTs can be used to build teams and compete in a virtual game (Non-Fungible Corporation, n.d.). Some well-known NFTs, Axie Infinity, Gods Unchained and My Crypto Heroes, fall in the category of Games. Axie Infinity is a large gaming universe where cute pets, called Axies, live. The Axie universe is called Lunacia, which is the home for the Axies and the land there is tokenized. Axies? owners can collect, breed and battle with their pets (Non-Fungible Corporation, n.d.). Gods Unchained consists of six unique gods, who compete with each other in a virtual card game (Non-Fungible Corporation, n.d.). With the My Crypto Heroes NFTs, battles can be fought using all kinds of equipment (Non-Fungible Corporation, n.d.). Decentraland and Cryptovoxels are famous NFTs in the metaverse tribe. Users can choose what types of content they want to publish on their LAND, which is the NFT of Decentraland. The content can be static 3D scenes; however, it can also consist of any kind of interactive experience (Non-Fungible Corporation, n.d.). In the CryptoVoxels world, digital property can be bought and decorated with custom-designed monochrome blocks (Non-Fungible Corporation, n.d.). The two NFTs that are categorized as Others are CryptoAssault and Footbattle Card. CryptoAssault is one of the NFTs of which doubt can exist whether it is placed in the correct category. CryptoAssault is a 3D world in which territory can be battled for (Non-Fungible Corporation, n.d.). For Footbattle the same applies, as it is described as a footbattle management simulation (Non-Fungible Corporation, n.d.). The Utility NFTs are Unstoppable Domains and Urbit ID. Unstoppable Domains is an NFT that can be used to appoint simple names to cryptocurrency payments (Non-Fungible Corporation, n.d.). In contrast, Urbit ID can be used to send and receive cryptocurrency payments (Non-Fungible Corporation, n.d.). While there are NFTs in each of the six categories, it is very clear that the categories of Art, Collectibles and Games are the best represented in this subset (Table 9, Table 10, Table 11)."
132,"These categories are also mentioned in the descriptive data overview in Table 8, which stems from the Nadini dataset. In the selection of NFTs, there are 13 Art, 9 Collectibles, 20 Games, 4 Metaverses, 2 Others and 2 Utility NFTs. Some popular examples of NFTs in the Art category are CryptoKitties and CryptoPunks. Both CryptoKitties and CryptoPunks have thousands of different characters. Every cat or Punk is unique. CryptoKitties can even be used to breed a new CryptoKittie [74]. Bitverse, MLB Champion and Sorare are good examples of the category Collectibles. Bitverse is a digital universe where sets of cards can be collected. There are four types of cards, ranging from common to legendary (Bitverse Comics, 2021). MLB Champions and Sorare are quite similar NFTs. MLB Champions are virtual baseball players, while Sorare consists of player cards. In both MLB Champions and Sorare, the NFTs can be used to build teams and compete in a virtual game (Non-Fungible Corporation, n.d.). Some well-known NFTs, Axie Infinity, Gods Unchained and My Crypto Heroes, fall in the category of Games. Axie Infinity is a large gaming universe where cute pets, called Axies, live. The Axie universe is called Lunacia, which is the home for the Axies and the land there is tokenized. Axies? owners can collect, breed and battle with their pets (Non-Fungible Corporation, n.d.). Gods Unchained consists of six unique gods, who compete with each other in a virtual card game (Non-Fungible Corporation, n.d.). With the My Crypto Heroes NFTs, battles can be fought using all kinds of equipment (Non-Fungible Corporation, n.d.). Decentraland and Cryptovoxels are famous NFTs in the metaverse tribe. Users can choose what types of content they want to publish on their LAND, which is the NFT of Decentraland. The content can be static 3D scenes; however, it can also consist of any kind of interactive experience (Non-Fungible Corporation, n.d.). In the CryptoVoxels world, digital property can be bought and decorated with custom-designed monochrome blocks (Non-Fungible Corporation, n.d.). The two NFTs that are categorized as Others are CryptoAssault and Footbattle Card. CryptoAssault is one of the NFTs of which doubt can exist whether it is placed in the correct category. CryptoAssault is a 3D world in which territory can be battled for (Non-Fungible Corporation, n.d.). For Footbattle the same applies, as it is described as a footbattle management simulation (Non-Fungible Corporation, n.d.). The Utility NFTs are Unstoppable Domains and Urbit ID. Unstoppable Domains is an NFT that can be used to appoint simple names to cryptocurrency payments (Non-Fungible Corporation, n.d.). In contrast, Urbit ID can be used to send and receive cryptocurrency payments (Non-Fungible Corporation, n.d.). While there are NFTs in each of the six categories, it is very clear that the categories of Art, Collectibles and Games are the best represented in this subset (Table 9, Table 10, Table 11)."
133,"These categories are also mentioned in the descriptive data overview in Table 8, which stems from the Nadini dataset. In the selection of NFTs, there are 13 Art, 9 Collectibles, 20 Games, 4 Metaverses, 2 Others and 2 Utility NFTs. Some popular examples of NFTs in the Art category are CryptoKitties and CryptoPunks. Both CryptoKitties and CryptoPunks have thousands of different characters. Every cat or Punk is unique. CryptoKitties can even be used to breed a new CryptoKittie [74]. Bitverse, MLB Champion and Sorare are good examples of the category Collectibles. Bitverse is a digital universe where sets of cards can be collected. There are four types of cards, ranging from common to legendary (Bitverse Comics, 2021). MLB Champions and Sorare are quite similar NFTs. MLB Champions are virtual baseball players, while Sorare consists of player cards. In both MLB Champions and Sorare, the NFTs can be used to build teams and compete in a virtual game (Non-Fungible Corporation, n.d.). Some well-known NFTs, Axie Infinity, Gods Unchained and My Crypto Heroes, fall in the category of Games. Axie Infinity is a large gaming universe where cute pets, called Axies, live. The Axie universe is called Lunacia, which is the home for the Axies and the land there is tokenized. Axies? owners can collect, breed and battle with their pets (Non-Fungible Corporation, n.d.). Gods Unchained consists of six unique gods, who compete with each other in a virtual card game (Non-Fungible Corporation, n.d.). With the My Crypto Heroes NFTs, battles can be fought using all kinds of equipment (Non-Fungible Corporation, n.d.). Decentraland and Cryptovoxels are famous NFTs in the metaverse tribe. Users can choose what types of content they want to publish on their LAND, which is the NFT of Decentraland. The content can be static 3D scenes; however, it can also consist of any kind of interactive experience (Non-Fungible Corporation, n.d.). In the CryptoVoxels world, digital property can be bought and decorated with custom-designed monochrome blocks (Non-Fungible Corporation, n.d.). The two NFTs that are categorized as Others are CryptoAssault and Footbattle Card. CryptoAssault is one of the NFTs of which doubt can exist whether it is placed in the correct category. CryptoAssault is a 3D world in which territory can be battled for (Non-Fungible Corporation, n.d.). For Footbattle the same applies, as it is described as a footbattle management simulation (Non-Fungible Corporation, n.d.). The Utility NFTs are Unstoppable Domains and Urbit ID. Unstoppable Domains is an NFT that can be used to appoint simple names to cryptocurrency payments (Non-Fungible Corporation, n.d.). In contrast, Urbit ID can be used to send and receive cryptocurrency payments (Non-Fungible Corporation, n.d.). While there are NFTs in each of the six categories, it is very clear that the categories of Art, Collectibles and Games are the best represented in this subset (Table 9, Table 10, Table 11)."
134,"The results in the following tables are split into separate tables for the first and second digits and for the price and volume data. In total there are 8 tables with results. Conformity to Benford's Law is judged according to the Mean Absolute Deviation score while Pearson's chi-squared test can be unreliable for large datasets. In Table 12 the results are shown for the price data of the selection of 50 NFTs. For 16 out of the 50 NFTs the first digit distribution conforms to Benford's Law according to the Mean Absolute Deviation. Two of these conforming NFTs are also confirmed by a significant chi-squared statistic. It is noteworthy that, among others, the NFT collections Axie Infinity, CryptoKitties and Gods Unchained score an abnormally high chi-squared statistic."
135,"In Table 13 the results for the second digit distribution of the price data of the NFT selection are presented. Something outstanding here is that 22 out of 30 conforming NFTs score in close conformity. Eight out of the 30 NFTs that conform to Benford's Law also achieve a significant chi-squared statistic. Once again, the collections of Axie Infinity, CryptoKitties and Gods Unchained have high chi-squared statistics. For 0xuniverse and CyberKongz, these high values are observed as well."
136,"Table 14 reports the results of the first digit distribution of the volume data of the 50 NFTs. Eight NFTs score acceptable conformity, five score marginally acceptable conformity and the remaining 37 NFTs nonconformity. Eleven of 13 conforming NFTs also show significant chi-squared scores. However, out of the 37 nonconforming NFTs, six nonetheless have a significant chi-squared statistic, which would indicate conformity. Either way, the MAD score is deemed as the leading test statistic; therefore these NFTs remain classified as nonconforming."
137,"Table 16 moves on to the results of the yearly aggregated data, starting with the first digit distribution of the yearly aggregated price data. The years 2017 through 2019 scored acceptable conformity, 2020 scored close conformity and the first 117 days of 2021 scored nonconformity. Nonetheless, with a MAD score of 0.01567, it is still close to marginally acceptable conformity. The transactions that are included in the years that do conform to Benford's Law amount to 44.3 % of the total number of transactions (6062,744) that are examined in the results section. All years have a high chi-squared statistic. Regardless, the year 2021 has an extraordinarily high chi-squared statistic, namely over 140,000."
138,"Table 17 demonstrates the second digit distribution of the yearly aggregated price data of the complete Nadini dataset. All of the years 2017 through 2021 obtained close conformity to Benford's Law. Once more, all of the years show a high chi-squared statistic"
139,"A pattern can be observed in Tables 18 and 19. In total 16 NFTs conform to the first digit distribution according to Benford's Law. Fifteen out of these 16 NFTs also conform to the second digit distribution according to Benford's Law. Therefore, this might be a consistent pattern that can also be found in other transaction data. Economically this pattern seems to make sense as well. If price manipulation would take place, it would be logical that both digits or at least the first do(es) not conform to Benford's Law. It would not make sense if the first digit distribution does conform to Benford's Law while the second digit distribution does not conform to Benford's Law. However, this pattern is not as strong for the volume data. The findings indicate that merely seven NFTs out of the 13 that conform to Benford's first digit distribution also conform to Benford's second digit distribution. Additionally, it can be observed that the 50 NFTs that were selected conform more often to Benford's Law for the price data than for the volume data. There were four NFTs that conformed to Benford's Law in all four tables, namely Crypto Space Commanders, CryptoKitites, Decentraland and Gods Unchained. They conformed for both the price and the volume data to the first- and second-digit distributions of Benford's Law. No pattern is found regarding the different categories of the NFTs. The categories are dispersed relatively in the same manner in the results as in the NFT selection. It can be observed that there are more NFTs in Art, Collectible and Games that appear in the conforming results; however, these NFTs are also represented way more in the NFT selection. Therefore, no relative difference can be observed."
140,"Table 19 shows the first- and second-digit distribution of the yearly aggregated volume data of the entire market history as recorded by nonfungible.com. For both the first- and second-digit distribution, all years (2017 through 2022) score nonconformity according to the MAD statistic. However, for the first-digit distribution, the chi-squared statistic reports a significant value for the years 2017 and 2022. For the second-digit distribution, the same applies for all of the years. Again, this is probably due to the small N. A pattern can be observed in Tables 18 and 19. In total 16 NFTs conform to the first digit distribution according to Benford's Law. Fifteen out of these 16 NFTs also conform to the second digit distribution according to Benford's Law. Therefore, this might be a consistent pattern that can also be found in other transaction data. Economically this pattern seems to make sense as well. If price manipulation would take place, it would be logical that both digits or at least the first do(es) not conform to Benford's Law. It would not make sense if the first digit distribution does conform to Benford's Law while the second digit distribution does not conform to Benford's Law. However, this pattern is not as strong for the volume data. The findings indicate that merely seven NFTs out of the 13 that conform to Benford's first digit distribution also conform to Benford's second digit distribution. Additionally, it can be observed that the 50 NFTs that were selected conform more often to Benford's Law for the price data than for the volume data. There were four NFTs that conformed to Benford's Law in all four tables, namely Crypto Space Commanders, CryptoKitites, Decentraland and Gods Unchained. They conformed for both the price and the volume data to the first- and second-digit distributions of Benford's Law. No pattern is found regarding the different categories of the NFTs. The categories are dispersed relatively in the same manner in the results as in the NFT selection. It can be observed that there are more NFTs in Art, Collectible and Games that appear in the conforming results; however, these NFTs are also represented way more in the NFT selection. Therefore, no relative difference can be observed."
141,"We conducted nine semi-structured interviews with experts at the regional level, six at the intermediate level, and three at the national office level; these experts came from five different HNGOs. Most of our interviewees working at regional units were volunteers, as this is where most volunteers engage with HNGOs; our paid staff interviewees were mostly active in intermediate and national units (headquarters), where HNGO permanent operations are situated. Hence, our sample reflects these organizational structures. The interviews were conducted in German via Skype or by telephone in 2019 and 2020. All interviews were between 30 minutes and 2 1/2 hours in length, depending on how detailed responses were; interviews conducted later in the study tended to be longer as we refined our interview guide and protocols. Table 2 is an overview of the interview sample."
142,"Contribution intentions were regressed on crowdfunding platform type (1 = reward; 0 = donation), prosocial motivation, and their interaction (see Table 2 for the stepwise regression results). As expected, the results revealed a significant interaction between crowdfunding platform and prosocial motivation (B = 2.24, SE = 0.72, p < 0.01). As prosocial motivation is a continuous measure, the analyses were repeated using a spotlight analysis at one standard deviation below and above the mean (see Fig. 1; [63]). The analysis revealed a significant negative simple effect of crowdfunding platform type for participants low in prosocial motivation (B = -2.31, SE = 0.74, p < 0.01), indicating they were willing to contribute less money in the reward (vs. donation) condition. Conversely, there was no effect of crowdfunding platform type for those with high prosocial motivation (B = 0.93, SE = 0.71, p = 0.20)."
143,"Given that this study sampled the general population on MTurk rather than a more homogeneous undergraduate sample as in Study 1, we controlled for participants? gender, age, education level, and income. Contribution intentions were regressed on prosocial nature of the project description (1 = high; 0 = low), crowdfunding platform type (1 = reward; 0 = donation), prosocial motivation, their three-way interaction, and all lower-order interactions, while controlling for gender, age, education level, and income level (see Table 3 for the stepwise regression results). The results showed significant effects of the interaction between prosocial nature of the project description and crowdfunding platform type (B = -3.64, SE = 1.45, p = 0.01), the interaction between prosocial nature of the project description and prosocial motivation (B = -0.39, SE = 0.19, p = 0.04), and the three-way interaction between prosocial nature of the project description, crowdfunding platform type, and prosocial motivation (B = 0.56, SE = 0.26, p = 0.03). As prosocial motivation is a continuous measure, the analyses were repeated using a spotlight analysis at one standard deviation below and above the mean to probe the three-way interaction [63]. "
144,"Similar to Study 2, given that this study sampled a more general population on Prolific rather than a more homogeneous undergraduate sample, we controlled for participants? gender, age, education level, and income. We also controlled for nationality given that we collected data from both American and Chinese participants. Contribution intentions were regressed on prosocial nature of the project description (1 = high; 0 = low), crowdfunding platform type (1 = reward; 0 = donation), prosocial motivation, their three-way interaction, all lower-order interactions, and control variables (see Table 4 for the stepwise regression results). Results showed significant effects of the interaction between prosocial nature of the project description and prosocial motivation (B = -0.74, SE = 0.34, p = 0.03) and the interaction between crowdfunding platform type and prosocial motivation (B = -0.94, SE = 0.31, p < 0.01). There were also marginally significant effects of the interaction between prosocial nature of the project description and crowdfunding platform type (B = -5.09, SE = 2.62, p = 0.05) and importantly, the three-way interaction between prosocial nature of the project description, crowdfunding platform type, and prosocial motivation (B = 0.78, SE = 0.45, p = 0.08)."
145,"To address these research questions, we leveraged on a longitudinal dataset that allowed us to observe the effects of the marketing choices (price and flexible policies as functional attributes) and economic returns (occupation rates and revenues per active nights, as in line with Airbnb literature; [17]) at a single Airbnb property level in the city of Rome (i.e., the largest touristic submarket in Italy). The first evidence that emerged from these data is that the sharp market contraction due to the pandemic shock affected demand much more than supply: the negative change in revenues has in fact been about five times larger than the exit rates (see Table 1), thus depicting a novel market condition on the Airbnb platform. This circumstance suggests that competition must have increased substantially and, consequently, forced (at least some) entrepreneurs to react to the shock with renewed activism."
146,"With the aim of describing the impact of the shock in our sample, Table 2 reports the descriptive statistics of the two dependant variables for the considered three years, that is, 2018, 2019, and 2020. In line with Ghebreyesus [18], the descriptive statistics are computed for the months of March to Decemeber of each year. Consistent with the magnitude of the shock, Table 2 reports that the mean values of occupation rate and revenues per active nights declined significantly in 2020, compared to 2018 and 2019, years that were instead rather stable."
147,"Table 3 provides the number of properties (and the relative shares in brackets) that adopted a given cancellation policy (moderate, flexible, or strict) in 2018, 2019, and 2020, and also shows the year-over-year transitions. Table 3a shows data pertaining to the benchmark situation (i.e., 2018 to 2019), while Table 3b shows data for the Covid-19 shocked situation (i.e., 2019 to 2020)."
148,"Table 4 provides a comparison of the pricing adjustements between 2018 and 2019 and between 2019 and 2020, and it also shows the main descriptive indicators for the absolute price variation (i.e., the absolute value of PV(i,m)) as well as the results of a mean comparison test (i.e., the T-test). Fig. 2, which is complementary to Table 4, plots the distribution of PVy(i,m) in 2019 and in 2020."
149,"Table 5 shows the estimates of the econometric model that was used to predict the impact of the pricing adjustments, the impact of the flexible cancellation policies, and the effect of joint adoptions on the occupation rate. It is worth noting that the IV diagnostic statistics (i.e., Kleibergen-Paap weak identification tests) fully confirmed the validity of the instrument for our empirical setting.16 Models M1 and M2 include control variables only, Model M3 includes control variables and PV2020(i,m), Model M4 includes control variables and ModFlexPolicy(i), Model M5 includes control variables, PV2020(I,m), and ModFlexPolicy(i), while Model M6 includes all the variables as well as the interaction between PV2020(i,m) and ModFlexPolicy(i). Table A4 in the Online Appendix provides the estimation results when a pooled OLS estimation was employed, without instrumenting PV2020(i,m), and rather similar results can be observed."
150,"Table 6 shows the estimates of the econometric model when RevPAN in 2020 was considered as the dependant variable and tested on the sample of strict cancellation policy adopters in 2019. Again in this case, it is worth noticing that the Kleibergen-Paap weak identification tests fully confirmed the validity of the instrument for our empirical setting.18 Models M1 to M6 are defined as in Section 5.2.1. As for the analyses on the OccR, Table A9 in the Online Appendix provides the estimation results obtained when employing a pooled OLS estimation without instrumenting PV2020(i,m), and they show rather similar results."
151,"Sample companies were purposely selected to obtain information-rich data that were able to contribute to a deeper understanding of the perceptions, concerns, and behavior related to social media use [109]. The interviewees were all key informants at their respective companies, i.e., owner- or business-managers, or executives responsible for their firms? social media management (see Table 1). A snowball sampling procedure [122] was employed, initiated via the first author's acquaintances. The use of natural social ties for accessing the ?elite informants? [119,122] counterbalanced the often prevailing asymmetry in the power relationship between interviewer and interviewee. To represent the heterogeneity of the SME area, the interview participants varied along several dimensions, such as gender, education, social media experience levels, and age. The participants? ages spanned from 23 to 71 years, with a job tenure ranging from 1 year to 30 years and more. This long period of service for a company applied to the owner-managers and founders of a hotel (SME 9), a men's shoe fashion wholesale (SME 15), and a firm consulting entrepreneurial couples (SME 18). Valuable insights into the research topic also resulted from the respondents' various social media worlds and accounts thereof complementing each other. Particularly, young participants aged under 35 years, acting in car and fashion retail or online marketing (SME 7, 8, 14, and 16), seemed to feel superior in knowledge and experience with social media to members of other age groups within and beyond their companies. Apart from the 42-year-old, socially and politically highly engaged owner-manager of a book retail shop (SME 13), all firm leaders were male. Most of the female participants held positions of a business, marketing, or social media manager."
152,"Although previous investigations [22] found that regular social media activity remains challenging for firms regardless of their size, this study showed differences in companies? behavioral consistencies. As innovation adoption literature in general, and especially in the SME domain, mainly restricts its focus to mere adoption processes, which fail to account for a comprehensive, sustainable use [152], a better understanding of social media usage in terms of (dis)continuity [45] is needed. Initially, executives are equally exposed to a broad bundle of structural, i.e., material and informational, properties of social media [9]. Nevertheless, these features open up different, context-related journeys on which SME managers may embark in conditions triggering perceptions and behavior in terms of this technology as a whole. From a structuration perspective [40], our findings suggest that these structural properties of social media possibly fail to cause triggers unleashing a sensemaking and engagement process. Here, the encounter with few, negatively connotated features may not produce triggers, such as perceiving obligation or novelty [100] for driving sensemaking and steady use behavior. This tendency effect is reinforced by environmental influences, such as necessary protection against competitors or lacking regulatory and market requirements (for a tendential relation between perception of social media features and steadiness of use behavior derived from interview data, see Table 3)."
153,"Table 2 reports the key descriptive statistics and correlation matrix for the variables applied in this study, with Bonferroni-adjusted significance levels below 0.01. Multicollinearity does not represent a problem for any of the variables as the Variance Inflation Factor (VIF) is largely below the suggested threshold of ten [110]."
154,"Table 3 shows the distribution of the strategic role of IT in industry in our sample of 1769 firms (and 17,690 observations) operating in 382 four-digit industries from 2011 to 2020."
155,"Models 1a ? 12a in Table 4 report the comparative analysis among subsamples (i.e. Automate, Informate, Physical-Transform, and Digital-Transform) used to assess the best alignment between business strategy and the strategic role of IT in industry on labour productivity growth (Models 1a, 4a, 7a, 10a) and its value components ? output growth (Models 2a, 5a, 8a, 11a) and input reduction (Models 3a, 6a, 9a, 12a) ? in Automate, Informate, Physical-Transform and Digital-Transform industries, respectively."
156,"As a robustness check, we also used a dynamic panel data estimation to overcome any possible endogeneity issues arising from reverse causality due to the prior performance of a firm. The results are shown in Table 6 and are consistent with the results of the comparative analysis of the subsamples (Table 4) and with the results on the moderating effect of the strategic role of IT in industry (Table 5)."
157,"Reliability was tested using Cronbach's Alpha value (a) (see Table 4) with all variables exceeding the threshold of 0.7. Moreover, to avoid common method bias, we employed Harman's one-factor test [138], which reported about 25.2% of variances explained by extracting only one factor, meeting the thumb value within 50% of the variance among all variables. This implies that there was no bias when applying respondents? answers in the same questionnaire for both independent and dependent variables. A reflective measurement model was inspected by conducting confirmatory factor analysis (CFA) via AMOS 26. Given the adequate sample size of 349 responses, the model fitness indices were as follows: ?2 = 656.355, degree of freedom (df) = 409, CMIN/DF= 1.605 (<3), p < 0.001, GFI= 0.903 (>0.9), TLI= 0.944 (>0.9), CFI= 0.950 (>0.9), RMSEA= 0.042 (<0.07). Hence, all the GOF indices met acceptable requirements, indicating that the measurement model achieved a good fit. As shown in Table 4, each item (Con1, Con2) and the first-order indicators (CON, OSO) significantly relate to the second-order latent constructs, the so-called utilitarian gratifications. Similarly, satisfying results were achieved with respect to hedonic and social gratifications and consumer state anxiety. In addition, the dependent variable (in-store purchase intention) was measured through a single item by probing the extent to which consumers were willing to purchase products after using their smartphones in-store. Single item has been accepted in existing studies as respondents can easily interpret the question [139,140]. This variable is further examined in the SEM and mediation analysis."
158,"Apart from achieving scale reliability, examining construct validity is suggested to embrace both convergent and discriminant validity tests. Convergent validity is assessed according to three aspects. First, all factor loadings should be statistically significant, with a standardized parameter of 0.5 or higher [141]. According to the output in Table 4, all indicators (CON and OSO) are significantly related to the latent constructs, falling between 0.534 (product information seeking via branded mobile apps) and 0.927 (consumer engagement via online brand communities). Second, the average variance extracted (AVE) is considered as the mean variance extracted for the items loading on a construct and is a conclusive index of convergence [142], with a suggested adequate convergence of over 0.5. The third attribute evaluates composite reliability (CR), an acceptable value of good reliability, suggested as being higher than 0.7. Table 5 demonstrates the convergent and discriminant validity performance."
159,"When performing the structural model, smartphones? utilitarian, hedonic, and social gratifications were independent variables, the mediator being named as consumer state anxiety, and purchase intention was the dependent variable. In a similar vein, the model's fitness indices were exhibited first: ?2 = 860.589, degree of freedom (df) = 532, CMIN/DF= 1.618 (<3), p < 0.001, GFI= 0.910 (>0.9), TLI= 0.928 (>0.9), CFI= 0.936 (>0.9), RMSEA= 0.042 (<0.07). These indicators support a valid and reliable structural model leading to hypotheses testing (Table 6)."
160,"Mediation analysis was performed to test the fourth hypothesis via Hayes? PROCESS Macro [144]. The advantages of conducting mediation analysis beyond SEM are threefold in this study. First, the PROCESS can test moderator and mediator effects in one model and suggest conditional outcomes. Second, SEM inspects the entire model while PROCESS can perform each equation separately [145]. Third, PROCESS incorporates bootstrapping methods that further recommend reliable results by evaluating extra information. Table 7 presents the mediation analysis results, including total, indirect, and direct effects of the models."
161,"The constructs of interest were measured using archival data. We measured remote work firm's initiatives through the natural logarithm of the number of remote work firm's initiatives mentions in news published about these initiatives per firm in t1, t2, and t3, with information collected from MyNews database (https://www.mynews.es/). This database includes news from more than 700 online and print editions of the national, regional, and international press. We performed a structured content analysis following the well-established protocol used in leading prior studies (e.g., [43,44,47]). Based on the review of relevant academic literature, managerial reports, and news on IT-enabled remote work, a preliminary list of keywords on remote work firms? initiatives was created. One of the authors discussed this list with three IT executives and four HR (business) executives. According to their recommendations and by carefully using their feedback, 20 keywords were selected and used for the corporate news coding protocol (Table 4). We considered these tools to be crucial to deploy remote work initiatives.4 Two of the authors conducted the news coding protocol. For each period, the two coders carefully read the news where the keyword appeared to check that the news referred to any remote work firm's initiative. We collected and read 2778 news in t1, 7819 news in t2, and 6353 news in t3 where the keywords appeared (Table 4). Each news contained different keywords referring to different initiatives on remote work. In that case, we computed as one each of these initiatives on remote work. After being read and coded, 111, 1137, and 847 remote work firm's initiatives mentions were found in t1, t2, and t3, respectively."
162,"We empirically tested the proposed research model running a partial least squares path modeling (PLS-PM), a variance-based structural equation modeling (SEM) technique [46,50] that is suitable to test the proposed model for two reasons. First, PLS is a full-fledged estimator that enables the empirical test of conceptual models in both confirmatory and explanatory IS research (as in this study) by using an overall evaluation of the fit of the saturated and estimated models [46]. Second, all the constructs of the proposed research model were conceptualized and operationalized as composite constructs, and this estimator is suitable to test composite models [48,51]. Moreover, PLS has been used extensively in the IS research area (e.g., [[52], [53], [54], [55], [56], [57]]). We used the statistical software package Advanced Analysis for Composites (ADANCO) 2.1. Professional (e.g., [58,59]) because it provides consistent estimates, and it has been designed for confirmatory research, as our study [60]. We ran a bootstrapping of 4999 subsamples. The proposed model was specified as a composite model, and all the constructs were estimated using mode B [46]. Table 5 presents the results of the empirical analysis. "
163,"Table A1 (in the appendix) presents the correlation matrix. We find support for H1 (beta = 0.278, p < 0.01) and H2 (beta = 0.203, p < 0.01) which indicates the following. 1. Companies that designed and executed a leader remote work strategy have continued executing these initiatives, which has provided leaders with a competitive advantage in remote work over their competitors. 2. Leaders and agile companies which have previously worked deliberately (leaders) or emergently (agile) on these remote work initiatives can yield leaders and agile a competitive advantage over survival companies that work on remote work initiatives through improvisation. The R2 values for remote work firm's initiatives in t1, t2, and t3 were 0.587, 0.570, and 0.650, respectively. The adjusted R2 values for the remote work firm's initiatives in t1, t2, and t3 constructs were 0.579, 0.556, and 0.639, respectively. The effect size (f2) values for the supported hypotheses ranged from 0.096 to 0.168, which indicates the medium size of these effects [61]. In addition, we compared the empirical correlation matrix with the model-implied correlation matrix of the estimated model to estimate three discrepancies between these two matrixes [62]: standardized root-mean-squared residual (SRMR), unweighted least squares (ULS) discrepancy (dULS), and the geodesic discrepancy (dG) [46]. SRMR should be lower than 0.080, and all the HI95 values should be greater than the values of the three discrepancies [46]. This analysis suggests that neither model should be rejected based on an alpha level of 0.05 since all discrepancies are below the 95%-quantile of the bootstrap discrepancies, which indicates that with a 5% probability, our theoretical hypotheses and the research proposed model are correct. Related to the control variables, the effects of firm size were significant on remote work firm's initiatives in t1 (beta = 0.112??) and t3 (beta = 0.112*). The size of these effects was similar (0.030 and 0.034, respectively). The influence of the firm's RSE in remote work was significant and with a large effect size in the three periods. The beta coefficients ranged from 0.649??? (t2) to 0.748??? (t1). The effect sizes were large, ranging from 0.994 (t3) to 1.342 (t1). The results show that the largest influence of the firm's RSE in remote work on the deployment of pioneer remote work initiatives was in t1, which is consistent with the leader remote work strategy."
164," As we empirically show in the experiments, the multistage approach provides better results than a single-stage end-to-end approach using multiobjective optimization with a constraints-based approach. The overall PREM process and components are presented in Fig. 4. As an overview of Fig. 4, the three most critical problems are noise, sparsity, and imbalance. We tackle each of these problems through two components ? feature embeddings and cost-sensitive classification."
165,"The dataset used for PREM development consists of more than 64 million trip booking records of customers traveling between 2017 and 2019. The dataset contains information concerning the price of the upgrade offer, which customers were sent upgrade offers, and which customers did or did not accept the update offers. This data is valuable for analyzing customer upselling and price elasticity dynamics in a major and competitive industry, and findings have implications for other travel-related domains. More than 14 million customers received upgrade offers (with a reach rate of 22%), and over 194,000 customers accepted the upgrade (with a conversion rate of 1.43%), as shown in Table 1."
166,"We did evaluate other encoding approaches, including dimensionality reduction techniques such as PCA. As discussed below in Table 2 (Results of feature embedding analysis), our embedding algorithm outperforms other approaches. While we did not invent this embedding algorithm, we are the first, to our knowledge, to apply it to airline data to tackle noise and sparsity issues. This applied study draws from computer science to solve a problem with real-world impact."
167,"A key hyperparameter is embedding in size, which determines the vector outputted size by the autoencoder, representing the trip information as a fixed-length vector. We evaluate its impact in the next experiment. When using the autoencoder, one could set the size of the latent representation to an arbitrary number. Traditionally, this size is often set as a power of two. Table 3 shows the results of PREM for different embedding sizes. We can see that an embedding size of 256 represents a sweet spot. Reducing the size results in lesser accuracy and revenue capture, while increasing it could potentially result in overfitting the model."
168,"From Table 4, we can see that a DL model using embeddings provides the best results. However, one could also use other traditional classifiers, such as logistic regression, support vector machine, or random forest, and pay only a minor penalty in the F1 score and almost none in revenue capture. Using the original data without the embeddings shows a steep drop in the F1 score for both DL-based and non-DL-based methods. As shown in Table 4, we evaluated alternate approaches for handling imbalanced data [69], such as the Synthetic Minority Oversampling Technique (SMOTE), oversampling, and the use of generative models such as Generative Adversarial Networks (GANs). We used random forests as the downstream classifier. From Table 4, we can see that traditional approaches such as oversampling are outperformed by the GAN, where we generate synthetic data for the rare classes so that the training data is balanced. Our embedding-based approach outperforms each of these approaches."
169,"The personalized upgrade model uses a binary autoencoder to segment customer bookings into K segments so that similar customers have similar embeddings. Once the segmentation is obtained, PREM estimates the response rate for each upgrade offer bucket. We consider two other segmentation approaches that also result in K segments. The first is based on K-Means that cluster all bookings into K distinct clusters, with K = 7. Our other baseline is a decision tree that tries to partition bookings using the Gini criterion. As shown in Table 5, our approach gives the best results."
170,"Next, we evaluate the revenue maximizer component. Recalling that we use an integer programming approach to select the best customers and the corresponding offers, a natural alternative is to use a greedy baseline that works as follows. First, the greedy algorithm computes each customer's expected revenue for each offer. Then, the Revenue Maximizer picks the best among them. For example, if Customer A accepts an offer of $500 with a 0.5 probability and $1000 with a 0.2 probability, then the expected revenues are $250 and $200, respectively. So, the Revenue Maximizer identifies that the best offer for Customer A is $500, with expected revenue of $250. Suppose there is another customer, Customer B, whose expected revenue is $300, and the model needs to select one customer. Here, the greedy algorithm will pick Customer B. As shown in Table 6, the revenue maximization of PREM (ILP) outperforms the greedy algorithm baseline."
171,"We propose a novel multistage approach based on feature development, the offer acceptance model, a personalized upgrade model, and a revenue maximizer. It is worth investigating if one needs such a multistage model in the first place. Specifically, two questions are of interest: (a) What would have happened if PREM used a single-stage classifier? and (b) What would have happened if PREM skipped the offer cost classification component or the revenue maximizer? The results presented in Table 7 address these questions. As shown in Table 7, the proposed PREM approach containing separate and sequential stages provides the best results. If one squeezes all of these stages into a single stage (i.e., if one trains a single classifier that takes all the bookings of a flight as input and returns the list of users and upgrade offers as output), then that gives the worst result. Splitting tasks into the different stages of an ML system clearly improves the performance in this context. Instead of the classifier trying to handle multiple objectives, each classifier in the PREM approach is targeted and focused on a single task, resulting in superior overall performance. Table 7 also indicates that all three components contribute positively. If one skips the revenue maximizer, then the accuracy drops marginally, but there is a steeper drop in revenue capture. Similarly, if one skips the offer classification and runs the upgrade offer determination for every user on the flight, there is a steep drop in accuracy but a smaller drop in revenue capture."
172,"LMM requires data to be set up in the long format such that there were 17 rows per participant. We first examined the psychometric properties of the model by assessing the convergent and discriminant validity of conservatism and collectivism variables. As shown in Table 4, because of low factor loadings, CONS1, CONS7, and CONS8 were dropped from the conservative position scale, and COL5 was dropped from the collectivism scale. The items listed in Table 4 lead to distinct constructs that demonstrated excellent Cronbach's a (Hair Jr, Hult, Ringle, & Sarstedt, 2013). The conservatism scale had Cronbach's a = 0.851, and the collectivism scale had Cronbach's a = 0.849. Discriminant validity was further assessed by examining items? cross-loadings that were all smaller than their factor (of interest) loadings (Hair [113]). As such, the measurement model demonstrated sound psychometric properties. In addition, we gauged the degree of multicollinearity between items and constructs in our study by calculating variance inflation factors (VIFs). All VIF values were <3.3, indicating that multicollinearity was not a concern in this study. While the focus of this study is on individuals? conservative political beliefs and their espoused cultural beliefs, we also added the country variable to control for the participant's country of origin, which may play a part (given the data were collected in two different countries). However, the focus remains on individual-level beliefs ? both political and cultural."
173,"As shown in Table 5, both hypotheses were supported. With increasing degree of conservatism (? = 0.65; p < 0.0001) and collectivism (? = 0.21; p < 0.0001), individuals? fake news believability increased significantly, thereby providing support for both H1 and H2 and answering positively both associated research questions. Participants? gender (? = -0.02) was found not significant. Age (? = -0.004; P < .01) was significant such that with increasing age, the fake news believability decreased. Internet usage (? = 0.03; P < 0.05) was also significant such that with increasing daily Internet usage, individuals? fake news believability increased. Country variable was found significant (? = 0.36; P < 0 .001) such that American participants (mean = 3.12) in general were more likely than Indian participants (mean = 2.77) to lend credence to the fake news scenarios presented."
174,Table 1 presents the descriptive statistics and Pearson correlation coefficients of all variables.
175,"Table 2 displays tests of the hypotheses. Models 1?3 and 4?6 use resource utilization (seat utilization) and product concentration (concentration) as the dependent variables, respectively. Models 1 and 4 are baseline models. They only include control variables. Models 2 and 5 include the independent variables for testing Hypotheses 1a and 1b. Models 3 and 6 include interaction terms between demand-side usage of O2O digital platforms and the extent of vertical and horizontal inter-firm relationships to test Hypotheses 2a, 2b, 3a, and 3b. All models tested are statistically significant. Wald's chi-square values are reported."
176,"Table A1 in the Appendix presents the results of robustness checks when the total number of all movie theaters is used as the measure of chain size and the new measure of concentration. The results indicate that the online ratio remains a strong predictor for operational decisions made by theaters. The study also finds that vertical relationship and chain size remain significant moderators. Hence, the results are robust to new formulations of critical variables. "
177,"Table A2 in the Appendix shows the results. Models 7 and 9 contain control variables, while Models 8 and 10 include independent variables. In Model 8, the results show that both seat utilization (? = 0.592, p < 0.01) and concentration (? = 0.191, p < 0.01) have a positive and significant impact on revenues. In Model 10, the results show that both seat utilization (? = 0.418, p < 0.01) and concentration (? = 0.131, p < 0.01) have a positive and significant impact on the audience."
178,"Based on the above discussion, our theoretical framework is summarized in Fig. 1."
179,Table 1 summarizes the profiles of responding companies and respondents.
180,"All items in this paper were adapted from the tested scale and measured by a seven-point Likert scale, ranging from ?1? to ?7? (?1? = ?strongly disagree? and ?7 = ?strongly agree?)  as shown in Table 2. In particular  four items adapted from Bharadwaj et al. [6] were used to measure digitalization capabilities  and these items reflected the degree to which companies could access customer-related order-related production-related  and market-related data. """
181,The results in Table 3 thereby confirmed the effectiveness of discriminant validity.
182,"The estimated results based on the logic of stepwise regression are presented in Table 4. It can be seen that first, digitalization capabilities ( ) positively affect market capitalizing agility. Second, both digitalization capabilities ( ) and market capitalizing agility ( ) positively relate to operational adjustment agility. Third, without any mediators, digitalization capabilities ( ) pose a positive relationship with firm performance. Fourth, when considering the combined effect of digitalization capabilities, market capitalizing agility, and operational adjustment agility on firm performance, only market capitalizing agility ( ) and operational adjustment agility ( ) show significant coefficients, whereas the coefficient of digitalization capabilities is nonsignificant ( ). The above results thereby indicate that the full mediating role of market capitalizing agility and operational adjustment agility in influencing the relationship between digitalization capabilities and firm performance."
183,"Table 5 further presents the results based on the bootstrap method with 5000 samples and a 95% confidence interval (CI) [62]. In particular, when the 95% CI's upper and lower bounds do not include zero, such a path is statistically significant; in contrast, when the 95% CI's upper and lower bounds include zero, such a path is statistically nonsignificant. As Table 5 shows, the direct effect of digitalization capabilities on firm performance (direct effect = 0.052, SE = 0.078) is statistically nonsignificant; in contrast, the indirect effects of digitalization capabilities on firm performance through market capitalizing agility (indirect effect = 0.088, SE = 0.054), operational adjustment agility (indirect effect = 0.077, SE = 0.045), and the sequence of market capitalizing agility and operational adjustment agility (indirect effect = 0.046, SE = 0.023) all have significant coefficients. Hence, these results again support all of our hypotheses."
184,"We checked the reliability of the constructs in three ways, as reported in Table I.1. We computed Cronbach alpha values, which were all above the 0.70 acceptable threshold [83]. Composite factor reliability (CFR) values were above the 0.70 acceptable threshold [104]. Average variance extracted (AVE) values were above the acceptable threshold 0.50 [104]. As an additional check on discriminant validity, we computed the square root of AVE for each construct and compared it with the construct's correlations with other constructs [37]. "
185,"For each construct, the square root of AVE was desirably greater than the correlation values (Table I.2). These checks provided support for the reliability and validity of the measured constructs."
186,The participants had an average duration in the community of 8.70 years (standard deviation=5.33 years). Table 1 lists the demographic information of our participants.
187,"Consistent with the literature [1,117,[132], [133], [134]], we conducted an exploratory factor analysis (EFA) to test data validity. Table 3 lists our EFA results that do not show marked cross-loadings, that is, the EFA results offer preliminary support for our data validity. All factor loadings are larger than .82."
188,"Table 4 reports the correlations among our study concepts. These ranged from .09 and .59. Moreover, the square roots of the AVE values (on the diagonal of Table 4) exceeded the associated correlations, indicating sufficient discriminant validity [118,141]."
189,"All the hypotheses were supported. Community commitment is positively related to taking an administrator role (H1), which is further positively related to public space contribution, private space contribution, and OL (H2, H3, and H4). Taking an administrator role has a stronger impact on public space contributions than on private space contributions (H5) and on OL (H6). Table 5 lists the testing results of H5 and H6. Specifically, we followed Ray et al. [46] and therefore used the t tests to compare the influences of taking an administrator role on three positive community behaviors. More details can be found in Ray et al. [46]. Both H5 and H6 were supported."
190,"Thus, taking the initial sample size as a reference (i.e., 342 companies), the stratified sampling procedure ensured that different proportions of company types according to size (mid-sized vs. large-sized), industry (manufacturing vs. service), and technology intensity (high-techs vs. low-techs, as established by the OECD and Eurostat) were preserved as they exist in the population, thereby improving the precision and representativeness of the resulting sample. The final sample included 346 companies? 4 over the threshold of 342?that answered the provided questionnaire. Table 1 provides more details about the composition of the sample."
191,"As data was collected through a single method (i.e., survey), this presented the possibility of the occurrence of what is known as common-method bias [[115], [116]]. To determine the extent of the method variance in the dataset, we used the marker variable approach [117]. To that end, we included a two-item scale regarding competition intensity,2 based on Jaworski and Kohli [118]. Subsequent correlation analysis revealed that correlations between the marker variable and independent, mediating, and dependent variables were very low, the largest one being 0.191. Thus, it could be concluded that common method variance was not a likely problem in our dataset. Also, a full collinearity test specially conceived for PLS-SEM [119] was carried out. The above test includes both vertical (predictor?predictor) and lateral (predictor?criterion) collinearity analyses. According to Kock [119], if all the variance inflation factors (VIFs) resulting from a full collinearity test are equal to or lower than 3.3, the model can be considered free of common-method bias. The highest VIF in our model (see Table 2) was 2.023, well below the 3.3 threshold. Therefore, this provides further evidence for ruling out the potential for common-method bias."
192,"Once the quality of the measurement model was guaranteed and before evaluating the structural model, a collinearity test was carried out. This collinearity test was performed to rule out any potential bias in path coefficients due to critical levels of collinearity among the predictor constructs [137]. Analogous to the assessment of composite measurement models, VIF values should be lower than 3. Table 4 shows the results obtained. As can be observed, all VIFs are well below the established threshold, the highest one being 2.121. Therefore, collinearity in the structural model is not a problem in this research."
193,"To test the significance and strength of the proposed relations, we used a one-tailed 5000 subsample BCA bootstrap [137]. Fig. 2 and Table 5 show the results obtained. As can be observed, quality data shows a very strong and positive relationship with IT-enabled data analytics sensing (? = 0.689). Thus, hypothesis H1 is supported. Moreover, both quality data (? = 0.340) and IT-enabled data analytics sensing (? = 0.317) are positively and significantly related to marketing innovation. As the indirect effect of quality data on marketing innovation via IT-enabled data analytics sensing is positive and significant (?1 ? ?2 = 0.219), partial mediation applies. Hence, hypotheses H2a and H2b are supported."
194,"The coefficient of determination (R2 value) of the mediating and dependent variables was also examined, which represents a measure of in-sample predictive power that also indicates explanatory power [122, 137]. As can be observed in Table 6, the amount of variance explained for IT-enabled data analytics sensing reached 47.4%, while for marketing innovation, it scored 38.3% and for market performance 34.1%. Moreover, changes in R2 when a specified exogenous construct is omitted from the model were analyzed by means of the so-called ??2 effect size? [137]. According to Hair et al. [137], for a construct to be relevant when explaining another variable, its effect size should reach the minimum threshold of 0.02. This was the case for both the independent and mediating variables, except for quality data vis-?is market performance."
195,"This data collection approach generated a diverse pool of key informants with diverse professional backgrounds and at various stages of their career. Descriptive characteristics of the key informants as well as the identification of key informants (abbreviated with the letter ?I? for informant and numbered consecutively) are summarized in Table 1. Each of the target organizations tasked a relatively small team of people with blockchain knowledge to (potentially) develop and test a prototype and, thus, interviewed key informants are assumed to be representative of their organization given the very small team size. "
196, Table 2 below provides an overview of our primary and secondary data.
197," Table 4 lists the pairwise correlation among all variables, variance inflation factor (VIF) for independent variables, and relevant descriptive statistics. A positive and significant correlation exists between the two main explanatory variables: Capex and Staffex. Among the control variables, CP and Size are highly associated with other variables. VIF scores for the independent variables indicate that the regression models used in the study are not affected by multi-collinearity. Additional daily data related to FF3F and C4F are obtained from Kenneth French's data library. To ensure that the impact of the WHO's announcement is free from any bias induced by extreme observations, we also compute the CAAR of the outlier-adjusted sample firms. The outlier-adjusted sample comprises all sample firms except those that fall in the top 10% or bottom 10% in terms of the CAR generated from day -30 to day 50."
198,"Table 5 presents some descriptive statistics related to the sample firms for the pre-event and the post-event windows (including the event day). The pre-event period denotes the time interval from 30 days to 1 day prior to the event, and the post-event period includes the time period from the event date to 50 days after it. From Table 5, it is evident that the average daily unadjusted dollar-denominated price reduces from the pre-event ($34.46) to the post-event period ($27.53). In the pre-event period, the average daily return percentage (annualized) is recorded as a minor loss (-0.62%). However, the return decreases even further in the post-event period (-2.03%). The volatility of the return increases in the post-event period (6.32%) compared to the pre-event period (3.06%). The logarithm of the average daily volume of trades also increases after the event. Also, the average daily market capitalization reduces slightly from the pre- to the post-event period. However, there is no change recorded for average shares outstanding between the two-time windows."
199,"To investigate the effect of the WHO's announcement on SCF firms, we determine the CAAR as per Eq. (2) and present our findings in Table 6. We estimate the CAAR for two sets of firms (i.e., all sample firms and outlier-adjusted sample firms) over different event windows. From Table 6, we observe that our sample firms incur a significant loss in valuation close to the event date. According to the MM, MMEGE, FF3F, and C4F models, the firms on an average earn -2.8%, -2.1%, -3.2%, and -2.8%, respectively, around the event window [-1, ]. These significant valuation losses are consistently observed throughout the entire event window. In the longest window of our study, (i.e., [-30, ]), sample firms experience a negative and significant CAAR of -19.3%, -23.8%, -28.0%, and -22.3% as per the MM, MMEGE, FF3F, and C4F models, respectively. Therefore, it seems that there is a permanent valuation loss for all SCF firms due to the announcement. This negative impact is not immediate as we do not find a significant drop in the [0, ] event window. However, the loss is quite prominent in the [0, ] window. This significant loss can also be observed in the [-15, ] event window, as estimated by the C4F model. Fig. 3 provides a visual depiction of the valuation loss of firms. The valuation loss is persistent even for a long post-event time period (i.e., [, ]). In contrast, none of the models depict any significant valuation loss for the sample firms in the pre-event time period (i.e., [-30, -1])."
200,"We perform a sub-sample analysis and explore the impact of the WHO's announcement on BlockFirms and Non-BlockFirms, separately. We compute the CAAR for these two groups of firms using the same MM, MMEGE, FF3F, and C4F models across all event windows and report the results in Table 7. Interestingly, there is not a single event window where BlockFims incur a significant loss of valuation. On the contrary, Non-BlockFirms exhibit a significant valuation loss across all event windows. It seems that valuation loss encountered by all SCF firms in the sample is predominantly driven by abnormal losses for Non-BlockFirms. BlockFirms, on the other hand, show enough investor confidence during the turbulent time period."
201,"This negative and significant CAAR for Non-BlockFirms can be potentially caused by either the higher magnitude of losses of a few sample firms or a significantly large number of sample firms that move into the loss-making domain due to the announcement. We explore the same using a binomial sign test. This test measures whether the percentage of firms earning negative returns on a particular day in a specific time window is significantly different from 50% or not. We compute the AAR earned by BlockFirms and Non-BlockFirms and the percentage of firms from each group earning losses on a particular day in the [-15, ] event window. We show the results obtained from the MM and C4F models in Table 8. The columns ?Mean (%)? and ?Negative (%)? represent the AARs and the percentage of loss-earning firms on each day, respectively. It yields two important insights. First, the C4F model shows a lower impact of the announcement than the MM model. The C4F model includes traditional asset pricing factors that play an important role in explaining the AAR. Second, there are few days, i.e., Days 1, 9, and 12, when a higher number of firms among BlockFirms earn negative returns. In contrast, Non-BlockFirms earn losses on 7 out of 15 days in the post-event period. Even Non-BlockFirms start experiencing valuation loss from one day before the event day, probably due to some information leakage or anticipation of panic. These findings support Hypothesis 3."
202,"To determine the impact of the WHO's announcement on the trading volume, we compute the CAAV around the event date using Eq. (5). Table 9 presents the estimated CAAV for all sample SCF firms as well as for the sub-samples BlockFirms and Non-BlockFirms across different event windows. From Table 9, it is evident that all sample SCF firms generate abnormally high trading volume around the event day and in the post-event period. The significant increase in trading volume is evident immediately after the event. In the event window [0, ], sample firms on the whole experience a CAAV of 1.335, and the CAAV increases up to 12.454 surrounding the event window (i.e., [-30, ]). This insight is consistent with the low return and high volume relationship in the bear market reported by Chen [77]. Thus, it statistically supports Hypothesis 4 of this study. However, such a significant increase in abnormal trading volume is guided by Non-BlockFirms. Non-BlockFirms experience a much higher trading volume compared to BlockFirms. While a significant increase in the trading volume for BlockFirms is observed only within the first two days of the event day, it is consistently higher in case of Non-BlockFirms for most of the event windows. This finding supports Hypothesis 5."
203,"To explore whether the firm characteristics in our sample of SCF firms play an important role in our findings, we perform a sub-sample analysis. More specifically, we divide both BlockFirms and Non-BlockFirms into two groups: banking and non-banking. We compute the ARs earned by these two groups of firms in different event windows using the Carhart 4-factor model (C4F). The outcomes of the analysis are documented in Table 10."
204,"To identify the predictive factors explaining the valuation loss for SCF firms, we perform a cross-sectional regression analysis, following the description in Section 4.3. The CAR estimated by the C4F model for the [-15, ] time window is used as the dependent variable in the regression. The results for models 1 to 4 (as specified in Section 4.3) are reported in Table 11. In model 1, Block_Dummy is found to be positive and significant. This indicates that Non-BlockFirms earn higher valuation loss compared to BlockFirms. Models 2 and 3 in Table 11 show that the impact of the interaction between Block_Dummy and R&D on CAR is significant. It is also observed that the interaction of Block_Dummy and Capex has a positive and significant relationship with CAR. However, there is no significant relationship between CAR and the interaction term Block_Dummy*Staffex. Therefore, we infer that BlockFirms that make a higher investment in R&D and capital expenditure suffer significantly less valuation loss due to the event. Thus, we find support for Hypothesis 7a and 7b, but not for Hypothesis 7c. The control variables show a consistent association with CAR across all four regression models."
205,"So far, we find that the adoption of blockchain enables SCF firms (i.e., BlockFirms) to protect against the erosion of firm value during the pandemic. Moreover, R&D and capital expenditure play an important role in this regard. Next, we aim to identify specific predictive factors that guide BlockFirms to protect the market value. We again run a set of cross-sectional regressions where we use CAR of BlockFirms estimated by the C4F model for the [-15, ] time window as the dependent variable. More specifically, we run models 5 to 10 (as specified in Section 4.3) to explain the impact of consortium and implementation dummies on the CAR of BlockFirms and report the results in Table 12. Results of models 5 and 6 reveal that the interaction terms Consortium*R&D and Implementation*R&D are positive and significant. While interacting capital expenditure (Capex) of BlockFirms with consortium and implementation dummies, we find a similar positive and significant association as depicted in the results of models 7 and 8. However, no significant association is observed in case of the interactions between staff expenditure (Staffex) and consortium and implementation dummies in models 9 and 10."
206," Fractions of top ratings in all categories are provided in Table 1 in Section 4. One can only speculate why such good ratings are usually given. AirBnB does not provide monetary incentives for reviews, which have been shown to lead to more positive reviews [114]. Possible explanations could be an ex post rationalization of the decision made by the guest (?I have chosen this accommodation, so it must be good?), or reciprocity between guests and hosts [30], [80]. On AirBnB, guests are also rated by hosts and might hope for a reciprocal favorable evaluation of themselves if they evaluated the host and the accommodation very positively."
207,"Table 2 presents the results of this analysis. The F values and their significance refer to the comparison to the previous model. Although adding both types of information to the baseline model leads to a significant improvement of fit, the effect of premises information is much stronger. Adding premises-specific variables to the baseline model increases the by almost 0.08, whereas adding the host information increases it by less than 0.02, and the F-test also clearly indicates a much stronger increase in model fit due to the premises information. Consequently, adding the host information to the model already containing the premises information leads only to a marginal improvement. Thus premises information has a considerably stronger influence on price than host information. This result is in accordance with other results from the literature. Although they did not specifically test for differences between premises-specific and host-specific information,Chen and Xie [24] also used nested regression models in which they first added premises-specific and then host-specific variables. In their model, adding host-specific variables increased the from 0.538 to 0.673. "
208,"Table 3 shows the results of this analysis. The results confirm those of the analysis of all premises types. Again, the effect of adding the premises-specific characteristics is considerably stronger than the effect of adding host characteristics."
209,The following tables provide an overview of descriptive statistics of the data set used. Table 4 summarizes data according to country.
210,Table 5 according to the type of premises.
211,Table 6 gives an overview of host characteristics.
212,Table 7 provides the regression coefficients for the three models using all types of premises.
213,Table 8 contains the regression coefficients of the full model (including both premises-specific and host-specific information) for six selected types of premises.
