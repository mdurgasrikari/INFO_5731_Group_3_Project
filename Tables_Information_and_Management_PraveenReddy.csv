index,Image Name,AI generated Summary,Author Summary,Cosine_Similarity Score,ROUGE-WE,BertScore,BLEU Score,METEOR Score
0,01.jpg," The table shows the number of posts and comments on the Facebook pages of two public health organisations.

NSW Health has posted 431 times and received 13,990 comments.

The Victorian Department of Health has posted 334 times and received 247 comments.

In total, the two organisations have posted 765 times and received 14,237 comments.",We used a self-developed Python app and collected a random sample of 765 posts and their linked comments published from 1 January to the end of April 2020 on the NSW1 and VIC2 Department of Health Facebook page. Table 2 presents a summary of our initial Facebook dataset.,0.3646680511241154,0.78882873,0.8559837937355042,0.5185185185185185,0.7339901867679645
1,02.jpg, NSW Health has been made aware of a social media post that is being widely circulated warning people not to consume certain foods or visit certain locations in Sydney.,"To investigate official Facebook use against misinformation, we analysed 29 posts that directly addressed COVID-related uncertainties or misinformation. This targeted approach aimed to understand official strategies to counter misinformation during the pandemic. These posts aligned with the four major thematic areas of the COVID-19 infodemic identified by the ?Coronavirus Disease 2019 (COVID-19) Situation Report?85? (WHO, 2020). Table 3 showcases samples of these posts by Australian health agencies.",0.07423769343519653,0.79475445,0.8160008788108826,0.11471149595346299,0.8380131362889985
2,03.jpg," The table shows the role of interviewees and the number of participants. There are 18 participants in total. The roles of the participants are state public health COVID-19 communication director, state COVID-19 social media and design manager, multicultural health team leader, crisis management strategist, director of a local health district, public health assistant and community expert, members of the Aboriginal community working in the public health, nurse, general practitioner, and hospital scientist.","We conducted nineteen semi-structured interviews, averaging an hour each, with professionals from the health agencies whose Facebook activities we studied. These interviews, held online via Zoom, aimed to deepen our understanding of the topic, gauge the extent of the problem, comprehend the organisational approach to using Facebook against COVID-19 misinformation, and benefit from the experts' tactical knowledge. All interview participants held roles in the public health sector, as shown in Table 4. They were recognised for their exceptional academic and hands-on knowledge in the field, qualifying them as experts. Although our engagement with these experts significantly influenced our interpretation of the study's results, it's essential to clarify that only data from six informants were incorporated into this study. These six (rows i to vi in Table 4) were directly involved in managing and operating public health social media communication and were recognised as online community administrators.",0.40411953689185165,0.92897195,0.8437353372573853,0.20540438772582517,0.8538902455569123
3,04.jpg," The table shows the percentage of people in each category. The categories are gender, age, and marital status.

The majority of the people in the survey were female (85%), aged between 26 and 35 (36.7%), and single (35.8%).","A total of 120 participants (Mage = 30.98, SDage = 8.14) were recruited by Qualtrics (see Table 4). Participants were randomly assigned to one of the two priming conditions (maximisers = 60 and satisficers = 60). The priming task and shopping task were the same as in Study 1. In this study, participants were asked to shop and select a new footwear product using a real-world omnichannel retailer. Perceived omnichannel interaction quality and MTS were measured as advised in Study 1. Perceived content integration capability was measured using two items adapted from Sun et al. (2020), such as ?I trust my ability to process the information I gather from different channels?. Participants responded to all items using a seven-point Likert scale ranging from 1 (strongly disagree) to 7 (strongly agree).",0.24591595199012245,0.7558942,0.808329164981842,0.048310000265099705,0.7971804511278194
4,05.jpg," The table shows the results of a structural equation model. The model has three paths: SDMS -> CIC (a), SDMS -> OIQ (c'), and CIC -> OIQ (b). The path coefficients are shown in the column labeled ""Î²"". The standard errors of the path coefficients are shown in the column labeled ""SE"". The p-values of the path coefficients are shown in the column labeled ""p value"". The 95% confidence intervals of the path coefficients are shown in the columns labeled ""LLCI"" and ""ULCI"".

The path coefficient for the path SDMS -> CIC (a) is 0.600. The standard error of the path coefficient is 0.172. The p-value of the path coefficient is 0.01. The 95% confidence interval of the path coefficient is [0.260, 0.939].

The path coefficient for the path SDMS -> OIQ (c') is 0.312. The standard error of the path coefficient is 0.126. The p-value of the path coefficient is 0.014. The 95% confidence interval of the path coefficient is [0.062, 0.562].

The path coefficient for the path CIC -> OIQ (b) is 0.447. The standard error of the path coefficient is 0.064. The p-value of the path coefficient is 0.01. The 95% confidence interval of the path coefficient is [0.319, 0.575].

The index of the model is 0.268. The standard error of the index is 0.085. The 95% confidence interval of the index is [0.115, 0.445].","A one-way ANOVA was used for the manipulation check using the MTS measures. Results show that maximisers scored higher in the MTS compared to satisficers (Mmaximisers = 5.95, SD = 0.42, Msatisficers = 4.30, SD = 0.52, F[1,118] = 359.280, p < 0.001). Therefore, the significant results of the manipulation checks confirm the success of the priming method used in this study. To examine the proposed mediation pathway (H2), we used SPSS PROCESS macro model 4 (Hayes, 2017) with 5000 iterations. Shoppers? decision-making styles (coded as maximisers = 1 and satisficers = 0) served as the independent variable, while perceived content integration capability was the mediator variable, and perceived omnichannel interaction quality was the dependent variable. Results show that shoppers? decision-making styles had a positive effect on perceived content integration capability (? = 0.600, t = 3.497, p < .001), which in turn positively influenced perceived omnichannel interaction quality (? = 0.447, t = 6.945, p < .001). In line with H2, the indirect effect (ab) of shoppers? decision-making styles on perceived omnichannel interaction quality through perceived content integration capability was positive and significant. Thus, perceived content integration capability mediated the proposed relationship as the confidence interval excluded zero (? = 0.268, 95% CI = [0.115, 0.445]), as presented in Fig. 2 and Table 6.",0.3665021053410814,0.89867806,0.8045498132705688,0.4239766081871345,0.8644779519779515
5,06.jpg," The table shows the data for the variables used in the study. The sector is the services sector, the geographic location is Spain, the methodology is stratified random sampling, the universe of population is 3210 firms, the sample size is 950 firms (36.10% response), the sampling error is 5.0%, and the data collection period is June to October 2022.","Our study used stratified random sampling of 950 companies, establishing equal probability that any firm could be selected at any step during sampling. The companies were contacted by phone and e-mail to explain the study?s purpose and offer them the opportunity to receive the results once the study was finished. Analyzing the results in aggregate and promising confidentiality of responses increased the response rate (36.10%, 343 valid responses (see Table 4)) and reduced the possibility of desirability bias.",0.4529956424196279,0.9110577,0.8479355573654175,0.38076071806582323,0.8568304106439699
6,07.jpg," The table shows the mean, standard deviation, and p-value for each characteristic for early and late respondents. The p-value is used to test the null hypothesis that there is no difference between the means of the two groups. A p-value less than 0.05 is considered to be statistically significant.

For the characteristic ""Size"", the mean for early respondents is 1.18 and the mean for late respondents is 1.15. The p-value for this characteristic is 0.590, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

For the characteristic ""Sector"", the mean for early respondents is 1.86 and the mean for late respondents is 1.91. The p-value for this characteristic is 0.668, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

For the characteristic ""Annual Turnover"", the mean for early respondents is 1508.95 and the mean for late respondents is 1150.52. The p-value for this characteristic is 0.368, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

For the characteristic ""Growth of Sales"", the mean for early respondents is 4.85 and the mean for late respondents is 4.94. The p-value for this characteristic is 0.647, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

For the characteristic ""Market share"", the mean for early respondents is 4.71 and the mean for late respondents is 4.87. The p-value for this characteristic is 0.348, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

For the characteristic ""ROI"", the mean for early respondents is 4.29 and the mean for late respondents is 4.31. The p-value for this characteristic is 0.922, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

For the characteristic ""ROA"", the mean for early respondents is 4.21 and the mean for late respondents is 4.26. The p-value for this characteristic is 0.754, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

For the characteristic ""ROS"", the mean for early respondents is 4.36 and the mean for late respondents is 4.49. The p-value for this characteristic is 0.457, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

For the characteristic ""ROE"", the mean for early respondents is 4.89 and the mean for late respondents is 4.96. The p-value for this characteristic is 0.635, which is greater than 0.05. This means that there is no statistically significant difference between the means of the two groups for this characteristic.

In conclusion, there is no statistically significant difference between early and late respondents for any of the characteristics.","A comparative analysis of two groups of respondents was performed, the companies that returned the completed survey within three weeks of receiving it and the companies that returned the survey only after follow-up reminders. This test assumes that late respondents are similar to non-respondents (Armstrong & Overton, 1977). Comparing the characteristics of the firms with late vs. early respondents (Table 5) indicated no significant differences between early and late respondents.",0.3600112801234839,0.7548381,0.8003404140472412,0.37555982085732564,0.8273695913811079
7,08.jpg," | Designation | Type | No. of employees | Engagement in corporate sustainability |
|---|---|---|---|
| Company A | Industrial technology provider | +250 | Core activities related to the circular economy, anchored in the corporate culture |
| Company B | Industrial software provider | +400 | CO2 compensation, green power and electric vehicles |
| Company C | Glass manufacturer | +150 | Climate-friendly production and focus on recycling |
| Company D | Web design agency | +30 | Awareness of sustainability, but no action so far |","Table 3 shows the participating companies. Company A is an industrial technology provider with approximately 250 employees from various sectors, with a focus on engineering and software development. Their product relates to circular economy and recycling, and according to their own presentation, environmental sustainability is already embedded in their culture. Company B is an industrial software provider with approximately 400 employees who are mainly software developers due to their core B2B software product. Company B is making various sustainability efforts, such as offsetting its emissions, using green power, and switching to electric vehicles, but its employees have not been as involved in its sustainability strategy. Company C is a glass manufacturer with approximately 150 employees. The majority of these employees work in the production halls and often come from abroad or have little education. In administration, about 30 employees work in research and development, procurement, sales, marketing and process optimization. The company attaches great importance to the recycling and reuse of its glass products and environmentally compatible production, but is particularly interested in new approaches to creatively involve its employees and motivate them to adopt sustainable behavior. Finally, Company D is a web design agency with 30 employees, mainly software developers and UX designers. Environmental sustainability has gained importance for them as a key criterion of responsible and sustainable digitalization. However, the company is not yet engaged in efforts for sustainability.",0.4343697219925243,0.25826833,0.8433866500854492,0.12505156191329622,0.8869758019758021
8,09.jpg," The table shows the responses to three survey items. The items are:
- I am satisfied with Netflix's AI tool.
- I am happy with Netflix's AI tool.
- I think Netflix's AI tool did a good job.

The response options are:
- Strongly disagree
- Disagree
- Neither agree nor disagree
- Agree
- Strongly agree

The table shows that, for each item, the majority of respondents either agreed or strongly agreed. This suggests that the respondents were generally satisfied with Netflix's AI tool.",Survey Items for Satisfaction.,0.09255699998724932,0.6577749,0.830858051776886,0.34117647058823536,0.5924692190925958
9,10.jpg," The table shows the responses to a survey about the usefulness of Netflix's AI tool in deciding what to watch. The items in the survey are:
- ""I find this Netflix AI tool useful in deciding what to watch""
- ""Using this Netflix AI tool enables me to decide what to watch quickly""
- ""Using this Netflix AI tool increases my efficiency in deciding what to watch""

The respondents were asked to rate their agreement with each statement on a scale of 1 to 9, where 1 means ""Strongly Disagree"" and 9 means ""Strongly Agree"".

The results show that the majority of respondents find the Netflix AI tool useful in deciding what to watch. They also agree that the tool enables them to decide what to watch quickly and increases their efficiency in deciding what to watch.

Overall, the results of the survey suggest that the Netflix AI tool is a valuable tool for users in deciding what to watch.",Survey Items for Performance Expectancy.,0.047250510740500976,0.62271905,0.8206648826599121,0.3375,0.5475632117351862
10,100.jpg," The table shows the results of a study that tested the hypotheses about the effects of routine use, advanced use, and their interaction on individual performance and task complexity.

The results show that:

1. Routine use has a positive effect on individual performance. (H1a is supported)
2. Advanced use has a positive effect on individual performance. (H1b is supported)
3. The interaction between routine use and task complexity has a positive effect on individual performance. (H2a is supported)
4. The interaction between advanced use and task complexity has a positive effect on individual performance. (H2b is supported)

In conclusion, the results of the study support the hypotheses that routine use, advanced use, and their interaction have positive effects on individual performance and task complexity.","In total, we conducted 21 interviews. The data collection reached saturation when the interview data showed no new information (Jacobson & Harrison, 2022). Table 3 describes the participants? demographics. We elaborated an interview guide with 13 questions inspired by the theoretical model tested in the previous studies. The average time for each interview was 20 min. Interviews were conducted face-to-face and mediated by videoconferencing technology (Zoom) in Portuguese by the last author, who transcribed, anonymized, and translated the scripts into English.",0.20056006295131404,0.8772529,0.8128324747085571,0.3978494623655914,0.8005836009868266
11,101.jpg," The table shows the incidence and assigned statements for each category and factor. The category with the highest incidence is 'rational decision making', with 15 out of 24 statements. The category with the lowest incidence is 'psychological commitment', with 6 out of 24 statements. The factor with the highest incidence is 'control', with 16 out of 24 statements. The factor with the lowest incidence is 'regret avoidance', with 0 out of 24 statements.","After the data collection, panel A of Table 1 presents the characteristics of the sample firms. For instance, the mean of the sample firms' net income and total assets are $3292.382 million and $ 139,398 million, respectively. At the same time, the mean of sales, total liabilities and employee number of the sample firms are $ 24,361.830 million, $ 11,933.500 million, and 66,487, respectively. Panel B and C of Table 1 show the distribution of the sample firms by industry (via its two-digit SIC codes) and year. It illustrates that AI-enabled B2B marketing activities are most popular in the services industry (i.e., SIC 70?89), which takes 56.18% of the total sample. The distribution panel shows that most of the firms only started using AI for their B2B marketing practices during 2016?2020, with 2017 as the peak year.",0.37723192402843375,0.61355865,0.8168001770973206,0.19572296365523634,0.8281541137705519
12,102.jpg, Table 1. Descriptive statistics of the variables,"After performing the binary logistic regression model, we acquire the propensity score, which indicates the probability of implementing AI-enabled B2B marketing initiatives for all firms included in the model. Then, we use a nearest-neighbor one-on-one matching method to identify the control firms. To improve the matching quality, we set a predetermined caliper of 0.02, which measures the absolute distance between the control and treatment firms' propensity scores (Ye et al., 2020). As shown in Model 1 (pre-match model) of Table 2, the number of firms included in the regression model is 1423, consisting of 89 treatment firms collected from Factiva, 1334 potential control firms with the same 4-digit SIC codes as the treatment firms. 87 out of the 89 treatment firms are matched successfully through the above-mentioned matching procedures and criteria. Therefore, the total sample size for this research reached 174, including 87 treatment firms and 87 matched control firms. Model 1 shows that the coefficients of marketing efficiency are negatively significant, while the coefficients of firm size, liquidity and R&D intensity are positively significant. This result indicates that firms with lower marketing efficiency, larger firm size, higher firm liquidity and greater R&D intensity tend to be more likely to employ AI technology for their B2B marketing practices. Also, we further check the matching quality by comparing the results of pre-match and post-match logistic regressions. As shown in Model 2 (post-match model) in Table 2, there are no statistically significant predictors, thus indicating a satisfying matching quality is achieved.",0.24394035651917476,0.756577,0.8117899298667908,5.991608076094159e-16,0.8290043290043291
13,103.jpg," Table 1. Constructs, sample items, and Cronbach's alpha values.","Table 4 shows the descriptive statistics, including means and standard deviations, and the correlations of all variables in Eq. (1). ",0.12977181239551144,0.8763203,0.8726105690002441,0.14183232474190352,0.7740740740740741
14,104.jpg," The image shows the results of a mediation analysis using SPSS and AMOS. The analysis was conducted to examine the effect of privacy concerns on purchase intentions, with disclosure intentions as a mediator.

The results show that privacy concerns have a significant negative effect on purchase intentions (b = -0.02, p < 0.05). Disclosure intentions have a significant positive effect on purchase intentions (b = 0.04, p < 0.05). Privacy concerns have a significant positive effect on disclosure intentions (b = 0.67, p < 0.05).

The results of the mediation analysis show that disclosure intentions mediate the effect of privacy concerns on purchase intentions. The indirect effect of privacy concerns on purchase intentions through disclosure intentions is significant (b = 0.03, p < 0.05). The direct effect of privacy concerns on purchase intentions is not significant (b = -0.02, p > 0.05).

These results suggest that privacy concerns have a negative effect on purchase intentions, but this effect is mediated by disclosure intentions. This means that the negative effect of privacy concerns on purchase intentions is reduced when disclosure intentions are high.","Table 5 presents the results of cross-sectional regression analysis with CAR over the event window (-1, 0) as the dependent variable. More specifically, model 1 is the basic model and only includes all control variables. In model 2, the direct effect of AI-enabled B2B marketing is introduced. The interactions between AI-enabled B2B marketing and industry dynamism and customer complexity are sequentially included in models 3 and 4. The F-tests (p < 0.05) show that these four models are significant, with adjusted R-squared values between 0.071 and 0.141. To test for multicollinearity, we calculate the full model's variance inflation factor (VIF). The maximum and mean values of VIF are 1.93 and 1.40 (much lower than the threshold of 10), thus suggesting that multicollinearity is not a concern in our models (Kennedy, 1998).",0.24261983761071437,0.84467673,0.8284276127815247,0.43956043956043955,0.790306931440652
15,105.jpg," The table shows the results of a path analysis. The path analysis was used to test the relationships between government subsidies (GS), privacy concerns (PC), disclosure intentions (DI), and purchase intentions (PI). The results show that there is a significant positive relationship between GS and DI (Î² = 0.525, p < 0.001), a significant positive relationship between GS and PI (Î² = 0.318, p < 0.001), a significant negative relationship between PC and DI (Î² = -0.297, p < 0.001), and a significant positive relationship between DI and PI (Î² = 0.399, p < 0.001). The results also show that there is no significant relationship between PC and PI (Î² = -0.047, p = 0.296). These results support hypotheses H1, H3, H7, and H8 and do not support hypothesis H2.","To facilitate our focus group discussion, we meticulously framed our research objectives to provide clear guidance on the purpose of our study, as outlined in Table 6. These predefined objectives served as a framework for our inquiries during the workshop. The discussion revolved around the examination of the three hypotheses central to our research. For Hypothesis 1, participants engaged in conversations addressing questions such as ""Could you share your thoughts on why shareholders generally react positively to AI implementation in B2B marketing?"" and ""What specific benefits or expectations do you associate with AI adoption in B2B marketing?"" Hypothesis 2 prompted discussions with questions such as ""From your perspective, how do industry dynamics and concerns affect your perception of AI adoption in B2B marketing?"" and ""Do you believe that firms in more dynamic industries have unique considerations when it comes to AI implementation? Please elaborate."" Hypothesis 3 guided participants to respond to queries like ""What challenges or complexities do you perceive in firms with more complex customer bases when implementing AI in B2B marketing?"" and ""Could you provide examples of situations where shareholders may have concerns about AI adoption in such firms?"".",0.12453818453105654,0.48135132,0.7889808416366577,0.2566085022431339,0.7241815360565358
16,106.jpg," This table provides summary statistics of the variables used in the analysis. The variables are:

- **DailyInvestors:** Number of individual investors contributing to a campaign each day
- **LogDailyInvestors:** Logarithm of number of DailyInvestors
- **DailyInvestments:** Total monetary amount raised by a campaign each day
- **LogDailyRaised:** Logarithm of DailyRaised
- **DailyRaised:** Total monetary amount raised by a campaign from initial to the day
- **LogDailyRaised:** Logarithm of DailyRaised
- **Time-varying information:** 
 - **Discussions:** The accumulated number of discussions posted in platform
 - **Twitter:** The accumulated number of Twitter posts in campaign's official Twitter account
 - **Facebook:** The accumulated number of Facebook posts from campaign's official Facebook account
- **Campaign-specific controls:**
 - **Days Available:** Duration - Number of Day Passed/ Duration (%)
 - **Patent:** Dummy variable =1 if the campaign listing or documentation mentions a patent (pending)
 - **Management:** Dummy variable =1 if the nonexecutive managers or board members mentioned by name in the campaign listing
 - **Equity Offered:** the percentage of equity in the business offered by the campaign founders in return for the target sum (%)
 - **Fin Snapshot:** Dummy variable =1 if the campaign listing or documentation mentions a financial snapshot
 - **Tax:** Dummy variable =1 if the campaign listing or documentation refers to available for investors: 0 otherwise
 - **Dividend:** Dummy variable =1 if the campaign is listed in the technology category; 0 otherwise
 - **Sophisticated:** Dummy variable =1 if the campaign listing or documentation mentions the involvement of an angel or VC; 0 otherwise
 - **London:** Dummy variable =1 if the business is based in London; 0 otherwise
 - **IPO:** Dummy variable =1 if the campaign listing or documentation states an IPO as the target exit strategy; 0 otherwise
 - **Active Campaign:** The aggregate number of active campaigns hosted on the Crowdcube platform on a given date
- **FTSE Volatility:** The standard deviation of FTSE returns over a rolling 20-day period up to and including a given date","Following a similar strategy as Study 1, in Study 2, we obtained 508 [Females= 260] filled-in questionnaires from UK-based participants [Median Age= 33.78 years; Median Income= ?32,820]. In both studies, our final sample was skewed toward younger adults compared to the UK population. Table 1 presents the sample demographics of studies 1 and 2.",0.17885667365477947,0.5385968,0.7719557285308838,0.35190918472652216,0.7714633312375437
17,107.jpg," The correlation matrix shows the correlation coefficients between the different variables. The correlation coefficient is a measure of the strength of the linear relationship between two variables. It can range from -1 to 1, where -1 indicates a perfect negative correlation, 0 indicates no correlation, and 1 indicates a perfect positive correlation.

In this case, the correlation matrix shows that there are some strong positive correlations between some of the variables. For example, the correlation between LogDailyInvestors and Twitter is 0.58, which indicates that there is a strong positive relationship between the two variables. This means that as the number of daily investors increases, the number of tweets also increases.

There are also some strong negative correlations between some of the variables. For example, the correlation between LogDailyInvestors and Days Available is -0.53, which indicates that there is a strong negative relationship between the two variables. This means that as the number of days available decreases, the number of daily investors increases.

The correlation matrix can be used to identify relationships between different variables. This information can be used to make decisions about how to invest. For example, if an investor is looking for a stock that is positively correlated with the number of daily investors, then they may want to consider investing in Twitter.","In Table 2, we present the descriptive statistics of the variables in the study. There are positive and statistically significant correlations between the antecedents (i.e., perceived privacy concern, anthropomorphic chatbots, and perceived empathy) and the mediators [i.e., perceived ability (rprivacy concerns, perceived ability=-0.21, p < 0.001; ranthropomorphic chatbots, perceived ability =0.25, p < 0.001; rperceived empathy, perceived ability=0.34, p < 0.001), perceived benevolence (rprivacy concerns, perceived benevolence=-0.06, p < 0.10; ranthropomorphic chatbots, perceived benevolence =0.28, p < 0.001; rperceived empathy, perceived beenvolence=0.24, p < 0.001), and perceived integrity (rprivacy concern, perceived intergrity=-0.05, p < 0.10; ranthropomorphic chatbots, perceived integrity =0.33, p < 0.001; rperceived empathy, perceived integrity=0.28, p < 0.001).",0.13077673716975807,0.7457649,0.8003140687942505,0.3829457364341085,0.8234911144487063
18,108.jpg," Table 4 shows the results of the first-stage and second-stage regressions. In unreported results, we find that the first stage F-statistics are all significant, indicating that the instruments are relevant. The second-stage results show that the coefficient on LogDailyInvestors is negative and significant in all specifications, suggesting that retail investors trade less frequently than institutional investors. The coefficient on LogVolume is positive and significant in all specifications, suggesting that stocks with higher volume are more likely to be traded by retail investors. The coefficient on Twitter is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks that are discussed on Twitter. The coefficient on Facebook is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks that are discussed on Facebook. The coefficient on Discussion is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks that are discussed on online forums. The coefficient on Sentiment is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks that have positive sentiment. The coefficient on Management is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks with good management. The coefficient on Equity is negative and significant in all specifications, suggesting that retail investors are more likely to trade stocks with low equity. The coefficient on Snapshot is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks that have been featured in the financial press. The coefficient on Target is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks that have been targeted by analysts. The coefficient on Tech is positive and significant in all specifications, suggesting that retail investors are more likely to trade technology stocks. The coefficient on Dividends is negative and significant in all specifications, suggesting that retail investors are less likely to trade stocks that pay dividends. The coefficient on London is negative and significant in all specifications, suggesting that retail investors are less likely to trade stocks that are listed on the London Stock Exchange. The coefficient on Sophisticated is negative and significant in all specifications, suggesting that retail investors are less likely to trade stocks that are held by sophisticated investors. The coefficient on Positive Sales is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks that have positive sales growth. The coefficient on IPO is negative and significant in all specifications, suggesting that retail investors are less likely to trade stocks that are newly issued. The coefficient on Active Campaign is positive and significant in all specifications, suggesting that retail investors are more likely to trade stocks that are actively campaigned by the company. The coefficient on FTSE Volatility is negative and significant in all specifications, suggesting that retail investors are less likely to trade stocks that have high volatility. The coefficient on Constant is negative and significant in all specifications.",We tested hypotheses 1?6 using a structural equation model. We employed MPLUS 8.0 to test the structural model. Table 4 presents the results of the hypothesis tests.,0.11423902767034143,0.8071674,0.796745777130127,0.3437908496732026,0.6268304244774832
19,109.jpg," The table shows the descriptive statistics of the number of posts on Twitter, Facebook, and Discussion at the end of the first stage and at the end of the last stage, as well as the t-statistics and Wilcoxon p-value of the difference in means.

At the end of the first stage, the mean number of posts on Twitter was 29, with a median of 11 and a standard deviation of 59.85. The minimum number of posts was 0, while the maximum was 444.

At the end of the last stage, the mean number of posts on Twitter was 134.13, with a median of 45.5 and a standard deviation of 81.2. The minimum number of posts was 0, while the maximum was 652.

The t-statistics of the difference in means for Twitter was 4.09, which is significant at the 0.001 level. The Wilcoxon p-value for Twitter was also significant at the 0.001 level.

This indicates that there was a significant increase in the number of posts on Twitter from the end of the first stage to the end of the last stage.","We predicted through the sixth hypothesis that perceived ability, perceived benevolence, and perceived integrity act as mediators between the antecedents (perceived privacy concerns, anthropomorphism, and perceived empathy) and customer outcome (i.e., consumer forgiveness and nWOM). To test the mediation models, we employed Hayes? (2018) procedure and further employed a bootstrapping re-sample value of 5000. In Table 5, we present the results of the mediation analyses.",0.33016934480592497,0.7979491,0.8048356175422668,0.3885819521178637,0.8141033460094236
20,11.jpg," | Pseudonym | Gender | Age |
| :--- | :--- | :--- |
| 1. Manoel | Male | 22 |
| 2. Maria | Female | 28 |
| 3. Marcus | Male | 22 |
| 4. Paulo | Male | 43 |
| 5. Anne | Female | 41 |
| 6. John | Male | 24 |
| 7. Mary | Female | 41 |
| 8. Marcio | Male | 23 |
| 9. George | Male | 30 |
| 10. AndrÃ© | Male | 40 |
| 11. Bruna | Female | 25 |
| 12. Eduardo | Male | 22 |
| 13. Eduarda | Female | 30 |
| 14. Gabriela | Female | 22 |
| 15. Rafael | Male | 35 |
| 16. Tamara | Female | 22 |
| 17. Diogo | Male | 44 |
| 18. Isabela | Female | 22 |
| 19. JoÃ£o Pedro | Male | 23 |
| 20. Mario | Male | 41 |
| 21. Lucas | Male | 22 |","Next, from Table 6, we can observe that the correlations of the antecedents and the mediators are positive and statistically significant, and the correlations of the mediators and the two outcome variables: consumer forgiveness and nWOM, are in the expected directions. These encouraging findings provide preliminary evidence in support of the study hypotheses.",0.0,-0.008960623,0.7704321146011353,0.0,0.42782287157287174
21,110.jpg," Table 6 shows the results of the negative binomial and OLS regressions. Because the dependent variable in the negative binomial regression is a count variable, we exponentiate the coefficients to ease interpretation. Exponentiated coefficients greater than 1 indicate that the independent variable increases the number of daily investors, while exponentiated coefficients less than 1 indicate that the independent variable decreases the number of daily investors. For the OLS regression, we present the standardized coefficients, which allow us to compare the relative effects of the independent variables on the number of daily investors.","Next, we tested the measurement model using MPLUS 8.0. The Study 2 measurement model reported a good fit (Chi-square/df= 2.83; RMSEA= 0.042; CFI= 0.955; TLI= 0.963). We also assessed the constructs? convergent and discriminant validities (Fornell & Larcker, 1981) that we report in Table 7.",0.24434821260336623,0.6691122,0.8266727924346924,0.39855072463768115,0.7549785359567968
22,111.jpg, Table 6: First-stage and reduced-form estimates for the whole sample and subsamples.,"Finally, to test hypothesis six, we employed a strategy similar to Study 1, i.e., Hayes?s (2018) mediation procedure with a bootstrapping resample value 5000. We present the results of the mediation analyses in Table 8. The estimated path coefficient for the indirect effect of perceived privacy concerns on consumer forgiveness through perceived ability (Column 1 of Table 8) was statistically significant (? = -0.0089; LCI=-0.0122; UCI=-0.0056). Also, the estimated path coefficient for the indirect effect of perceived privacy concerns on nWOM through perceived ability (Column 2 of Table 8) was statistically significant (? = 0.0092; LCI=0.0044; UCI=0.0140). From Column 3 of Table 8, we observe that the estimated path coefficients for the indirect effects of chatbot anthropomorphism through perceived ability (? = 0.0125; LCI=0.0062; UCI=0.0188), perceived benevolence (? = 0.0208; LCI=0.0124; UCI=0.0292), and perceived integrity (? = 0.0298; LCI=0.0204; UCI=0.0392) on consumer forgiveness were statistically significant. Also, in Column 4 of Table 8, we observe that the estimated path coefficients for the indirect effects of anthropomorphism through perceived ability (? = -0.0127; LCI=-0.0178; UCI=-0.0076), perceived benevolence (? = -0.0175; LCI=-0.0246; UCI=-0.0104), and perceived integrity (? = -0.0352; LCI=-0.0481; UCI=-0.0223) on nWOM were statistically significant. Finally, in Column 5 of Table 8, we observe that the estimated path coefficients for the indirect effects of perceived empathy through perceived ability (? = 0.0193; LCI=0.0107; UCI=0.0279), perceived benevolence (? = 0.0261; LCI=0.0169; UCI=0.0353), and perceived integrity (? = 0.0292; LCI=0.0190; UCI=0.0394) on consumer forgiveness were statistically significant. Similarly, in Column 6 of Table 8, we observe that the estimated path coefficients for the indirect effects of perceived empathy through perceived ability (? = -0.0175; LCI=-0.0269; UCI=-0.0081), perceived benevolence (? = -0.0220; LCI=-0.0329; UCI=-0.0111), and perceived integrity (? = -0.0352; LCI=-0.0494; UCI=-0.0210) on nWOM were statistically significant.",0.1278682854499365,0.6907348,0.7795900702476501,4.134195997215927e-11,0.8025252525252525
23,112.jpg, Model 3 reports the results of a two-stage least squares (2SLS) regression where the first stage is a probit model and the second stage is a linear regression.,"We studied in detail the creative practices of ISD teams at the WealthTech headquarters in Switzerland and various subsidiaries worldwide. The style of involvement was that of an embedded researcher having in-depth access to the research site (Walsham, 2006), including meeting rooms, in-house workstations, and the intranet. For nearly three years, from February 2013 to December 2015, the lead author spent several days weekly onsite in the Swiss offices, having access to an in-house workstation and intranet. There, the author conducted 32 interviews to get an in-depth understanding of creativity in ISD teams from a participant?s perspective (Walsham, 2006). In addition, the author attended meetings to do participant observations, in which a researcher participates actively in discussions, as opposed to acting as a passive outside observer (Walsham, 2006). In April 2014, the author also visited the UK offices to conduct 30 interviews and observe how ISD teams collaborated virtually. Table 1 provides an overview.",0.15850084820678212,0.73644567,0.8104655742645264,0.005818998186698351,0.8670493197278911
24,113.jpg," Table 1. Descriptive statistics for the variables in the study (N = 299).

Item	Self-Oriented Affordances	Others-Oriented Affordances	
1	I try to give ""like"" to a post that I like.	When I make a decision whom to follow or unfollow on Instagram, it's important for me that I like that person's posts.	
2	If I see a post about something that I am interested in, I usually give it a ""like"".	I follow a person on Instagram because I like his/her posts.
3	I give ""like"" to posts by people I personally know.	I share a post that I like to show it to my friends and followers.
4	I like posts of people I follow.	I support an Instagram post that I like by giving it a ""like"".
5	I usually give ""like"" to posts that I just like.	I give ""like"" to a post when I want to say ""Thank you"".
6	I give ""like"" because people care about whether I hurt them or not.	I give ""like"" to a post of a person that I admire.
7	I give ""like"" to say ""like"".	I give ""like"" to posts that make a difference in my life.

Note. N/A denotes the number of missing values. OAA = others-oriented affordances; SAA = self-oriented affordances.","We conducted interviews at WealthTech with 62 different ISD team members, ranging from 19 to 100 min. We took care to select a broad sample of participants to capture diverse perspectives, relying on a combination of theoretical sampling (seeking out different ISD team members), purposive sampling (seeking out diverse views), and snowballing (following referrals from other participants). We audio recorded and transcribed all 62 interviews except two, where the participants did not give permission to record, in which case we took notes. Of the 62 interviews, 39 were in German, in which case we translated the quotations into English. The remaining 23 interviews were in English. Table 2 provides an overview.",0.12814197427933707,0.62245905,0.7926305532455444,0.3956386292834891,0.8096634934312655
25,114.jpg," The table shows the weights and variance inflation factors (VIFs) for the items in the others-oriented AA and self-oriented AA scales. The weights are used to calculate the scores for each scale, and the VIFs indicate the amount of collinearity between the items.

For the others-oriented AA scale, the items with the highest weights are OAA2 (weight = 0.415) and OAA7 (weight = 0.540). This indicates that these items are the most important in determining the overall score for the scale. The VIFs for the items in this scale are all below 2.0, which indicates that there is no significant collinearity between the items.

For the self-oriented AA scale, the items with the highest weights are SAA3 (weight = 0.478) and SAA5 (weight = 0.617). This indicates that these items are the most important in determining the overall score for the scale. The VIFs for the items in this scale are all below 2.0, which indicates that there is no significant collinearity between the items.

Overall, the weights and VIFs for the items in the others-oriented AA and self-oriented AA scales suggest that the scales are reliable and valid.","For the scenario-based experiment (Study 2), we selected and adapted four conversations with KIM representing a 2 ? 2 factorial design: two conversations were completed by KIM, while this was not the case for the other two. In the unsuccessful conversations, the chatbot responded twice with textual elements to restart the conversation. In addition, two conversations were short in terms of the length of the conversation itself and KIM?s responses presenting 2 correct recipes, while the other two conversations were long with a lengthy introduction by KIM, and a detailed textual presentation displaying 5?6 recipes (see Figure A1 in the appendix). The experiment was supported by a German market research institute and took place with 627 participants in February 2022. We asked the respondents to read one sample conversation with KIM thoroughly and to evaluate KIM in terms of the conversation ability score and the three item scales (perceived naturalness of KIM, performance of the chat, satisfaction with the interaction). To check manipulation, they were asked to indicate whether KIM made good recipe suggestions and answered straight to the point ? that is, short and concise. The participants were randomly assigned to one of the four scenarios (see Table 3).",0.47261533860450794,0.86348,0.7979951500892639,0.45425863308602665,0.8237652587652586
26,115.jpg, Table shows the demographic information of the survey respondents,"Both samples consist of more females than males. In the usability study (Study 1), the percentage of females was higher (60.2%) than males (39.0%, 0.8% diverse). In the experiment (Study 2), the gender distribution was more balanced with 51.0% females and 47.7% males (1.3% diverse). The respondents are young, most often 20?25 years (Study 1: 67.5%, Study 2: 62.3%) or 26?30 (Study 1: 16.3%, Study 2: 17.3%) old. The share of respondents under 20 was more than twice the size in Study 2 (14.7% vs. 5.7%) reflecting the aim to include a younger age group. Over time, the claim of familiarity with the term chatbot increased from about two-thirds to three-quarters of the respondents, more often males. In both samples, less than half of the respondents already had experience of chatbot usage. The percentage was higher compared to an earlier study on the acceptance of chatbots (Rese et al., 2020). About two-thirds of the sample in Study 1 use Facebook Messenger, and about half of the sample Study 2. However, the chatbot, KIM, is largely unfamiliar to respondents, in particular in Study 1. With regard to diet preferences, more than half of the respondents follow no special regimen, whilst about a quarter to a third are vegetarians, among them significantly greater numbers of females. Female respondents search for recipes more frequently on the internet in both samples. In general, the time spent searching for a recipe was short. In Study 1, half of the respondents take up to 5 min and another third up to 10 min, whilst in Study 2 about a quarter need longer with up to 20 min and more (see Table 4). While Study 1 relied on a student sample, participants of Study 2 included students (28.2%), employees (43.5%), self-employed (5.9%), pupils (9.3%), and trainees (8.9%).",0.3384066159402393,0.6082426,0.80385822057724,6.385598208374123e-15,0.7993265993265993
27,116.jpg," All items show good standardized loadings, ranging from 0.827 to 0.970. All items also show good outer VIF values, ranging from 1.551 to 6.444. All items show good AVE values, ranging from 0.763 to 0.950. All items show good composite reliability (CR) values, ranging from 0.906 to 0.970. All items show good Cronbach's alpha values, ranging from 0.826 to 0.954.

Overall, the measurement model shows good reliability and validity.","With regard to the dialogues, there were no significant differences between female and male participants. Most participants completed the recipe search, corresponding more or less to their food preferences. Often KIM asked two questions about recipe criteria (48.0%), including the ingredients. In 3.3% of the dialogues, KIM referred to all three criteria, whilst not mentioning them explicitly in 21.1% of the conversations. On average, KIM suggested 6 recipes to the user, of which a small number were inappropriate (18.2%). The search was quick, with KIM posting more messages and using more words. KIM?s messages usually included one emoji per dialogue. KIM had to restart the conversation once in almost every dialogue. This had a significantly greater frequency in dialogues with female users, who also received a lower percentage of correct recipes. In about a quarter of the cases, KIM failed to employ a correct greeting, either repeating the same message or omitting the greeting. In the evaluation by external reviewers, KIM received a mean conversational ability score above 0 = poor, machine-like, but still under 50. This score was termed as ?good conversationalist? and was achieved by 2 of the 6 chatbots evaluated (Shah et al., 2016). The users rated KIM slightly better on satisfaction, naturalness, and performance expectancy with a score above the average value of 4 (see Table 5; for a description of the variables, see Table A1 in the appendix).",0.09310733657470939,0.88456523,0.8035950660705566,0.03812522543671228,0.7393761632892067
28,117.jpg," The correlation matrix between the 10 variables is shown below. All the variables are highly correlated with each other, with the exception of USAF and CODI.","For hypotheses on task fulfilment, we relied on a comparison of users successfully and unsuccessfully completing the search for recipes with KIM in Study 1. We compared the mean values of task and conversation elements as well as evaluation criteria for the two groups. Since the group failing to complete the task was small, a non-parametric test ? the Mann-Whitney U Test ? was used (see Table 6).",0.2766592327610259,0.84580916,0.8352232575416565,0.09685819451342076,0.788838938838939
29,118.jpg," | USAF | TRAF | CODI |
|---|---|---|
| INOV | 1.151 |  |
| SOOV | 1.274 |  |
| SYOV | 1.342 |  |
| SUNC |  | 1.799 |
| TRAC |  | 1.799 |
| ALAT |  | 2.487 |
| PROC |  | 1.234 |
| USAF | 3.163 | 1.088 |","With regard to the perceived conversational ability of KIM, we transformed the independent variables with a box-cox transformation to compensate for the non-normal distribution of the data. We employed stepwise regression analysis to integrate into the model not only the independent variables concerning the hypotheses but also all available independent variables from Table A1. We chose this more exploratory approach because of the scarcity of research results on the human?chatbot conversation. We used the four internal and external dependent evaluation variables. Similar to the results from the mean comparison, the external evaluation with the conversational ability score and, to some extent, user satisfaction were shown to be suitable and provided higher R2. Taking the external evaluation ? the conversational ability score ? into account, H1b and H7b were confirmed, and a positive effect of a high percentage of correct recipe suggestions (0.212, p = 0.003) and a negative effect of the number of conversation restarts (-0.506, p = 0.000) were established. For user satisfaction, the positive effect of a high percentage of correct recipe suggestions (0.174, p = 0.043) was also found. Other hypotheses on the perceived conversational ability of KIM could not be proven. The internal evaluation criteria established negative effects for the number of messages, the number of words from the user, the number of greetings by KIM, and the number of wrong recipe suggestions. While the presence of a correct greeting did not show the hypothesized positive effect (H8b), additional greetings had a negative effect (Table 7).",0.0,-0.08213441,0.7632694840431213,0.0,0.6875
30,119.jpg," The table shows the results of a PLS path model analysis. The model has three formative constructs: intermittent discontinuance (INDI), short break discontinuance (SBDi), and suspended discontinuance (SUDi). The constructs are measured by multiple items. The table shows the weights, t-values, loadings, and VIF values for each item. The weights represent the strength of the relationship between the item and the construct. The t-values represent the significance of the relationship. The loadings represent the correlation between the item and the construct. The VIF values represent the amount of collinearity between the items.

All of the items have significant weights and loadings, and the VIF values are all below 3.3, which indicates that there is no collinearity between the items. This suggests that the model is valid and reliable.","This research has tried to identify a mix of instrumental (task-oriented) and social (small-talk) conversational elements that influence users? perception of a chatbot and their conversation with it. To investigate conversational ability, we used the task-based and text-based chatbot, KIM, by MAGGI Kochstudio to perform the task of finding an accurate recipe and to undertake an analysis of 123 unstructured chat records (Study 1). An overview of previous studies analysing text-based chatbot conversations supported the identification of relevant features and evaluation variables from usability research (Fr?j? et al., 2000). We focused on several task-based and text-based variables as well as two characteristics of conversational ability that potentially influence the success of KIM in this area. In addition, we relied on an external evaluation by three reviewers based on the conversational ability score (Shah et al., 2016) and a subjective user evaluation following the conversation with KIM using item scales describing user satisfaction (Hornb?, 2006, Shawar and Atwel, 2007, S?erlund, 2022, S?erlund and Oikarinen, 2021). A scenario-based experiment (Study 2) was used to gain further insights into user evaluation of selected conversational elements (see Table 8). The usability study (Study 1) provided insights into several task-based and text features as well as characteristics of conversational ability, and it was used as a source for example dialogues. While chatbot usage could be monitored, the implementation period was rather long with data collected in person. The scenario-based experiment (Study 2) was quickly implemented but was restricted to a few features and did not include real experience with KIM.",0.29800828703808213,0.904527,0.7961003184318542,0.18152024482576848,0.8327922077922079
31,12.jpg," Panel A: Characteristics of Sample Firms

The table shows the distribution of sample firms across different industries. The industry with the most sample firms is services, which accounts for 56.18% of the total sample. This is followed by manufacturing, which accounts for 21.34% of the total sample. The remaining industries account for less than 10% of the total sample each.

Panel B: Distribution of Samples Across Industries

The table shows the distribution of sample firms across different years. The year with the most sample firms is 2019, which accounts for 16.85% of the total sample. This is followed by 2017, which accounts for 14.61% of the total sample. The remaining years account for less than 10% of the total sample each.","In the U.S sample, 50.2% of the respondents were female, 43.4% in the age group of 26?41 years, 40.9% had earned a four-year degree, and 84.3% indicated that the trip was domestic. In the Chinese sample, 56.1% were female, 36.9% in the age group of 26?41, 65.6% had earned a four-year degree, and 97.3% indicated that the trip was domestic. Table 1 shows the demographic profiles of participants in both countries.",0.373433654057672,0.9156223,0.8280938267707825,0.4049586776859504,0.8082389832389829
32,120.jpg," **Hypothesis 1 (H1):** There is a positive relationship between perceived innovativeness and USAFs.
**Result:** Supported. The path coefficient between perceived innovativeness and USAFs is 0.504, which is significant (t-value = 8.940, p-value = 0.000). The effect size (f2) is 0.265, indicating that perceived innovativeness explains 26.5% of the variance in USAFs.

**Hypothesis 2 (H2):** There is a positive relationship between perceived service quality and USAFs.
**Result:** Supported. The path coefficient between perceived service quality and USAFs is 0.197, which is significant (t-value = 3.671, p-value = 0.000). The effect size (f2) is 0.044, indicating that perceived service quality explains 4.4% of the variance in USAFs.

**Hypothesis 3 (H3):** There is a positive relationship between perceived social support and USAFs.
**Result:** Not supported. The path coefficient between perceived social support and USAFs is 0.073, which is not significant (t-value = 1.498, p-value = 0.134). The effect size (f2) is 0.006, indicating that perceived social support explains only 0.6% of the variance in USAFs.

**Hypothesis 4 (H4):** There is a positive relationship between USAFs and INDI.
**Result:** Supported. The path coefficient between USAFs and INDI is 0.466, which is significant (t-value = 8.839, p-value = 0.000). The effect size (f2) is 0.295, indicating that USAFs explain 29.5% of the variance in INDI.

**Hypothesis 5 (H5):** There is a positive relationship between perceived proactiveness and INDI.
**Result:** Supported. The path coefficient between perceived proactiveness and INDI is 0.131, which is significant (t-value = 2.335, p-value = 0.020). The effect size (f2) is 0.020, indicating that perceived proactiveness explains 2.0% of the variance in INDI.

**Hypothesis 6 (H6):** There is a positive relationship between perceived altruism and INDI.
**Result:** Not supported. The path coefficient between perceived altruism and INDI is 0.117, which is not significant (t-value = 1.510, p-value = 0.131). The effect size (f2) is 0.008, indicating that perceived altruism explains only 0.8% of the variance in INDI.

**Hypothesis 7 (H7):** There is a positive relationship between perceived sunshine and TRAC.
**Result:** Supported. The path coefficient between perceived sunshine and TRAC is 0.277, which is significant (t-value = 5.529, p-value = 0.000). The effect size (f2) is 0.123, indicating that perceived sunshine explains 12.3% of the variance in TRAC.

**Hypothesis 8 (H8):** There is a positive relationship between TRAC and TRAF.
**Result:** Supported. The path coefficient between TRAC and TRAF is 0.596, which is significant (t-value = 13.932, p-value = 0.000). The effect size (f2) is 0.570, indicating that TRAC explains 57.0% of the variance in TRAF.

**Hypothesis 9 (H9):** There is a negative relationship between TRAF and INDI.
**Result:** Supported. The path coefficient between TRAF and INDI is -0.224, which is significant (t-value = 2.491, p-value = 0.013). The effect size (f2) is 0.023, indicating that TRAF explains 2.3% of the variance in INDI.","Establishing validity and reliability of the measures is essential prior to testing the structural model (Hair Jr et al., 2017; Henseler et al., 2009). We assessed the measurement models for the pooled data and then group 1 (U.S.) and group 2 (China). As displayed in Table 3, constructs were internally consistent since Cronbach?s alpha values were > the 0.70 threshold (Nunnally & Bernstein, 1994). The convergent validity criterion was verified, with average variance extracted (AVE) values all above 0.50 (Fornell & Bookstein, 1982).",0.2214958028447875,0.7643973,0.7687166929244995,0.354978354978355,0.7195335445335448
33,121.jpg," The table shows the results of a mediation analysis. The independent variables are sunk costs and transition costs. The mediating variable is transition fatigue. The dependent variable is intermittent discontinuance.

The results show that sunk costs have a significant positive indirect effect on intermittent discontinuance through transition fatigue (path coefficient = 0.062, p < 0.05). Sunk costs also have a significant positive direct effect on intermittent discontinuance (path coefficient = 0.184, p < 0.05). The total effect of sunk costs on intermittent discontinuance is 0.246 (p < 0.05).

Transition costs have a significant positive indirect effect on intermittent discontinuance through transition fatigue (path coefficient = -0.033, p < 0.05). Transition costs also have a significant positive direct effect on intermittent discontinuance (path coefficient = 0.241, p < 0.05). The total effect of transition costs on intermittent discontinuance is 0.208 (p < 0.05).

The results of the mediation analysis show that transition fatigue mediates the relationship between sunk costs and intermittent discontinuance and the relationship between transition costs and intermittent discontinuance.","As shown in Table 4, discriminant validity was assessed by heterotrait-monotrait criterion (HTMT). The results indicated good discriminant validity as all HTMT values were below the threshold value of 0.90 (Voorhees et al., 2016). A multicollinearity test was employed via the value inflation factor (VIF). VIF values were less than the 5.0 threshold. Hence, multicollinearity was not an issue. The Harman's single-factor test was utilized to control the threat of common method variance. The results of the exploratory factor analysis (unrotated) showed that no single construct explained more than 44.9% of the observed variance. Common method variance did not seem a concern in this study since it was below 50?60% (Fuller et al., 2016).",0.1679452360018094,0.8935295,0.8004575371742249,0.396078431372549,0.7744439935064935
34,122.jpg," The table shows the results of an experiment to measure the consistency and coverage of different machine learning algorithms. The algorithms are TEOV, ~TEOV, USAF, ~USAF, PRCO, ~PRCO, ALAT, ~ALAT, SUNC, ~SUNC, TRAC, ~TRAC, TRAF, and ~TRAF. The results show that the best algorithm for consistency is USAF, and the best algorithm for coverage is TEOV.","In the second stage, the structural models for group 1 and group 2 were gauged using SmartPLS 3 (Ringle et al., 2015). To assess the structural model, the R? of the endogenous variables was computed for the model?s explanatory power (Hair Jr et al., 2017). As reported in Table 5, consumption achieved R? value of 38.6% (pooled data), 32% (group 1), and 36.2% (group 2); contribution 44.3% (pooled), 38.5% (group 1), and 42.5% (group 2); creation 40.7% (pooled), 29.3% (group 1), and 43.8% (group 2); cold BRQ 27.7% (pooled), 17.9% (group 1), and 49.8% (group 2); hot BRQ 51.1% (pooled), 39.4% (group 1), and 49% (group 2); trip decision-making 23.9% (pooled), 20.2% (group 1), and 13.9% (group 2); and cross-buying 48.9% (pooled), 37.2% (group 1), and 54.9% (group 2). To assess the strength of the hypothesized relations, a bootstrapping test based on 5000 subsamples was performed. As hypothesized, brand involvement had a positive effect on ?consumption,? ?contribution? and ?creation? (H1a, ? = 0.612, p < 0.05; H1b, ? = 0.645, p < 0.05; H1c, ? = 0.603, p < 0.05, respectively). Accordingly, H1a, H1b, and H1c were verified. Additionally, perceived anonymity had a positive effect on ?consumption,? ?contribution? and ?creation? (H2a, ? = 0.038, p < 0.05; H2b, ? = 0.081, p < 0.05; H2c, ? = 0.119, p < 0.05, respectively). Hence, H2a, H2b, and H2c were confirmed. As hypothesized, consumption had a positive effect on both (H3a) cold and (H3b) hot BRQ (? = 0.272, p < 0.05; ? = 0.221, p < 0.05, respectively). Contribution had a positive effect on both (H4a) cold and (H4b) hot BRQ (? = 0.129, p < 0.05; ? = 0.281, p < 0.05, respectively). Additionally, creation had a positive effect on both (H5a) cold and (H5b) hot BRQ (? = 0.170, p < 0.05; ? = 0.269, p < 0.05, respectively). Therefore, H3a, H3b, H4a, H4b, H5a, and H5b were verified. Cold BRQ had a positive effect on trip-decision making (H6a) and cross-buying (H6b) (? = 0.057, p < 0.05; ? = 0.411, p < 0.05, respectively). Finally, hot BRQ had a significant positive effect on trip-decision making (H7a) and cross-buying (H7b) (? = 0.448, p < 0.05; ? = 0.350, p < 0.05, respectively). Thus, H6a, H6b, H7a, and H7b were confirmed.",0.16089067293710674,0.5108399,0.7680523991584778,0.0013758497700939063,0.8548701298701297
35,123.jpg," The table shows the results of the experiment. The first column is the configuration of the system. The second column is the outcome of the experiment. The third column is the number of times the outcome was observed. The fourth column is the percentage of times the outcome was observed. The fifth column is the standard deviation of the number of times the outcome was observed. The sixth column is the 95% confidence interval for the percentage of times the outcome was observed.

The results show that the configuration with the highest percentage of successful outcomes is HC3. This configuration has a percentage of successful outcomes of 90%. The configuration with the lowest percentage of successful outcomes is HC8. This configuration has a percentage of successful outcomes of 10%.","A multigroup analysis (MGA) was performed to compare the differences between the model for group 1 with the model for group 2. Differences in the path coefficients between the two data sets are shown in Table 6. In the first step, we tested the measurement invariance of composite models (MICOM) (Henseler et al., 2016). Thus, we followed the three-step process. These steps were computing the ?configural invariance,? ?compositional invariance? and ?the equality of means and variances.? . As displayed in Table 5, the full measurement invariance was partially achieved in the comparison between group 1 and group 2 as step (1) was fully established, and step (2) and step (3) were partially established. The following step was related to the employment of a multigroup analysis to test the path coefficients in both groups. Parametric and nonparametric procedures (PLS-MGA and permutation) were applied to investigate group differences (Hair et al., 2018). As shown in Table 5, the findings indicated that significant differences existed in path coefficients between group 1 and group 2. In the relationship between perceived anonymity and ?consumption,? ?contribution? and ?creation? the effects were stronger for group 1 (|??| = 0.113, p < 0.05, |??| = 0.106, p < 0.05, |??| = 0.088, p < 0.05, respectively).",0.38836531628781457,0.7130154,0.802320659160614,0.26191921120525297,0.8575446517306984
36,124.jpg," The table shows the results of the experiment. The first column is the configuration of the system. The second column is the condition of the system. The third column is the outcome of the experiment. The fourth column is the number of times the experiment was repeated. The fifth column is the percentage of times the experiment resulted in the outcome.

The results show that the system is most likely to be in the ALAT configuration when the outcome is intermittent discontinuance. The system is least likely to be in the USAF configuration when the outcome is intermittent discontinuance.","The two goals of Study1 were to contrast the accuracy of effectiveness prediction (the difference between actual and predicted effectiveness) for email and FtF requests (H1) and to verify whether this overestimation is moderated by the closeness level between the requesters and the targets (H1a). To test these hypotheses, a new variable (Prediction accuracy) was calculated by subtracting Actual effectiveness from Predicted effectiveness. The data was submitted to a univariate ANOVA1 with factors of Media (email vs. FtF ? Between-subjects) and Closeness (Strangers vs. Friends ? Between-subjects), and Prediction accuracy as the DV. We looked at the main effect of Media which was highly significant [F (1, 109) = 22.105, p < 0.001,  = 0.169] showing that the magnitude of inaccuracy was significantly larger in email compared to FtF when Closeness levels are collapsed (H1 supported). However, neither the interaction [F (1, 109) = 0.321, p = 0.572,   = 0.003] nor the main effect of Closeness (F (1, 109) = 0.028, p = 0.867,   <0.001) was significant. Hence, the pattern of overestimation is not different among Friends and Strangers groups, that is the closeness between requesters and targets does not improve the accuracy of predicted effectiveness (H1a is not supported). We also asked participants to report their own feeling about the task (Table 1). We looked at the ANOVAs to see if there are any differences across conditions in terms of participants? feelings about the task. As expected, we found that the Friends group perceive requesting to be easier and feel less awkward approaching a target individual compared to the Strangers group. However, the two groups do not predict any difference in the embarrassment after being rejected. No significant interaction emerged between Media and Closeness nor any main effect for Media was observed (see Table 1).",0.5094782841886498,0.659822,0.7965719699859619,0.08147317971652915,0.8460067710067709
37,125.jpg," Note: This table chronicles the summary statistics of the dataset employed in this study disaggregated on a monthly basis. The observations refer to the number of trades, while the mean value reflects the average price of token-changing hands denominated in US Dollars. The remaining columns are standard statistical moments used to describe data.","We asked our participants one open-ended and several Likert scale questions (Appendix E) to justify their choice of medium. A content analysis of the open-ended question revealed that our Likert questions covered all the reasons provided by participants. Then, a factor analysis was conducted on the reasoning data leading to two factors and two single items (Table 2).",0.23099303700761772,0.8627039,0.8223471641540527,0.40634044030711225,0.7350223675695374
38,126.jpg," The table shows the results of the Mantyla's Arc Test for randomness on the residuals of the fitted models. The results show that the residuals are not significantly different from a random distribution, which indicates that the models are adequate.","To test hypotheses 2 through 4, an omnibus logistic regression was conducted (Table 3). All the variables were mean-centred and logistic regression was conducted using the bootstrap method with 5000 resampling. Although we have already observed that a substantial portion of requesters chose email, which is the suboptimal medium according to Study1, the expectation was that their reasons would be different when approaching Strangers vs. Friends. Hence, in the following analysis, we included the interaction terms between Closeness and each of the reasons in Table 2. As seen in Table 3, two significant interactions emerged supporting H3a and H4a but not H2a. Please note that the main effects of factors involved in these significant interaction terms (i.e., Closeness, AwkEmbar, and Convenience) are not interpretable at this stage.",0.37786799170567303,0.8752853,0.8266770243644714,0.0662714229746122,0.8288499694749696
39,127.jpg, Note: This table reports the results of statistical significance of the trade size-clustering analysis for the five exchanges covered under Nadini et al.'s [30] dataset.,"However, we can conclude that Effectiveness does not play a significant role in media selection decision (H2 was not supported) as further confirmed in Table 4. To unpack the significant interaction terms of Closeness, data was split on Closeness levels (Friends vs. Strangers) and separate logistic regressions (bootstrap method with 5000 resampling) were performed for each subset of data (Table 4) with the decision outcome as the dependent variable and reasoning items explained above as independent variables. Although no predictor reached the significance level for the Friends group (H3 and H4 not supported for Friends), the biggest coefficient emerged for Effectiveness. On the other hand, email was more attractive for the Strangers group due to less awkwardness, less embarrassment, and the convenience of an email request (H3 and H4 supported for Strangers). A minority within this group picked the more effective medium for the right reason as shown by the marginally significant coefficient of Effectiveness.",0.2989176247087085,0.7449053,0.818072497844696,0.0028686134987956015,0.8157532467532469
40,128.jpg," The table shows the results of fitting the alpha-stable distribution to the daily closing prices of the S&P 500 index from January 2017 to March 2021. The alpha-MLE column shows the estimated value of the alpha parameter, and the p-value column shows the corresponding p-value of the goodness-of-fit test. The alpha-Levy range column indicates whether the estimated alpha value falls within the alpha-stable Levy range, which is between 1 and 2.

As we can see from the table, the alpha-stable distribution provides a good fit to the data, as the p-values are all very small. The estimated alpha values are all within the alpha-stable Levy range, except for a few months in 2018 and 2019. This suggests that the S&P 500 index returns are heavy-tailed and exhibit long-range dependence, which is consistent with the findings of previous studies.","First, we contrasted the media decision by Male and Female participants by running a logistic regression (bootstrap with 5000 resampling) analysis with Closeness, Gender, and the interaction term of the two variables as the IVs and, the media decision outcome as the dependent variable. As shown in Table G1, no significant interaction effect emerged nor any main effect of Gender on media selection was detected.",0.3763198302184821,0.8227047,0.8148823380470276,0.4106280193236715,0.7501478996044215
41,129.jpg, Note: This table pools the p-values of the statistical tests conducted in this study and applies a combination of p-value tests to account for the possibility of a Type II error.,"Second, we looked at the gender effect of reasoning by running an ANOVA analysis which was explained in the main text. Lastly, we excluded the female participants from the data set and ran another logistic regression. The significant interaction terms in Table 3 were also significant in this analysis.",0.2830152284485814,0.7768153,0.852020800113678,0.27074383466701846,0.7930922124470512
42,13.jpg," **Table 4** reports the results of the propensity score matching. Model 1 shows the results of the probit regression used to estimate the propensity score. The results show that marketing efficiency, firm profitability, firm size, R&D intensity, and the control firms are all significant predictors of the likelihood of a firm being acquired. Model 2 shows the results of the matching procedure. The results show that the matching procedure was successful in creating two groups of firms that are similar in terms of their propensity to be acquired. The two groups of firms are also similar in terms of their other characteristics, such as firm age, firm leverage, and firm cash holdings.","We asked our participants to contrast requesters? perspectives when they are approached FtF and via email. Two separate factor analyses were conducted on FtF and email perspective-taking measures with similar emerging factors as shown in Table A1. Cronbach?s alphas are reported separately for FtF questions and email questions. Separate repeated measure ANOVAs, Closeness (Cls vs. Str ? between-subject) ? perspective-taking index (FtF vs. eml ? within-subject), were conducted for each of the three emerged indices and none of them resulted in a significant interaction between Closeness and the perspective-taking index. It suggests that Participants in both Closeness conditions predicted the same magnitude of change in targets? perspectives when moving from FtF to email. As shown in the last column of Table H1, participants, regardless of their closeness level to the target (main effect of media), acknowledged differences between FtF and email requests for some of the indices and Single measures. We tested whether requesters consider any of the significant indices/measures when predicting the effectiveness of each medium. Index 3 was positively correlated with requesters? prediction of both FtF effectiveness (r(106)= 0.401, p < .0001) and Email effectiveness (r(107)= 0.398, p < 0.001). Index 1 was correlated with Email prediction only (r(106)= 0.246, p = 0.011) but it wasn?t strong and vanished when data was split on the Closeness factor. Single1 was correlated both with Email (r(48)= 0.366, p = 0.010) and FtF (r(48)= 0.475, p = <0.001) predictions but Single2 was only correlated with FtF predictions (r(48)= 0.539, p = <0.001). These significant correlations offer possible causes that make requesters to perceive FtF as a more effective channel for reaching out to targets. However, as shown in Study 1, requesters? perception is not even nearly close to the real extent of the difference between the two channels.",0.3440982039986716,0.81563467,0.800549328327179,0.10726478111469569,0.869454925035282
43,130.jpg," The critical values for the mean absolute deviation statistic for the first digit distribution are shown in the table. 

- If the mean absolute deviation is less than 0.006, then the distribution is considered to be in close conformity. 

- If the mean absolute deviation is between 0.006 and 0.012, then the distribution is considered to be in acceptable conformity. 

- If the mean absolute deviation is between 0.012 and 0.015, then the distribution is considered to be in marginally acceptable conformity. 

- If the mean absolute deviation is greater than 0.015, then the distribution is considered to be in nonconformity.","Next, we selected those items with high and distinct loadings on this one factor (= .80). In addition, we sorted out items that did not clearly load on the feeling of creepiness factor. The final item set included seven items (see Table 1).",0.11558733733923915,0.81136584,0.8178393840789795,0.35313531353135313,0.6829522424883249
44,131.jpg," The table shows the critical values for the Mean Absolute Deviation test for the second digit distribution. The critical values are used to determine whether a sample of data is close to, acceptable, marginally acceptable, or nonconforming.

The critical values are as follows:

* 0.000-0.008: Close conformity
* 0.008-0.010: Acceptable conformity
* 0.010-0.012: Marginally acceptable conformity
* Above 0.012: Nonconformity

To use the table, first calculate the mean absolute deviation (MAD) of your sample of data. Then, compare the MAD to the critical values in the table. If the MAD is less than or equal to the critical value for close conformity, then your sample of data is close to the expected distribution. If the MAD is greater than the critical value for close conformity but less than or equal to the critical value for acceptable conformity, then your sample of data is acceptable. If the MAD is greater than the critical value for acceptable conformity but less than or equal to the critical value for marginally acceptable conformity, then your sample of data is marginally acceptable. If the MAD is greater than the critical value for marginally acceptable conformity, then your sample of data is nonconforming.","Next, we examined the effect of perceived creepiness on resistance. This analysis showed that the creepier participants perceived the SHA, the higher their resistance to using the SHA, supporting H3 (OLS regression including all conditions: B = 0.57, SE =.03, p < .001, d = 1.11). Considering the downstream effects of resistance, we find that all regression paths were significant at p < .001, except for the relationship between ease of use and usage intention (p = .316). In support of H4, resistance exerted a direct negative effect on usage intentions (B = -0.22, SE =.05) and negatively affected perceived usefulness (H5; B = -0.60, SE =.03) and ease of use (H6; B = -0.20, SE =.03). In line with H7, perceived usefulness exerted a positive effect on usage intention (B = 0.71, SE =.03). However, since ease of use did not significantly affect usage intention (B = -0.03, SE =.03), H8 had to be rejected. Finally, we tested the significance of the indirect effects of transparency and tangibility on usage intention through the proposed mediators ? creepiness, resistance, perceived usefulness, and perceived ease of use. Except for the path through perceived ease of use, all indirect effects reached significance at 95% CI. Table 2 provides a detailed overview of all results.",0.23172513556973087,0.8156054,0.7900301218032837,0.38415854314055026,0.8052009590869692
45,132.jpg," | NFT | Mean Volume | Median Volume | Mean Std. Dev. | Minimum | Maximum | Begin Date | End Date |
| - | - | - | - | - | - | - | - |
| Axie Infinity | 16,108,439 | 16,084,359 | 55,852 | 0 | 180,232 | 7-2-2020 | 11-5-2022 |
| Art Blocks | 281,350 | 261,300 | 3,576 | 0 | 8477 | 11-5-2020 | 11-5-2022 |
| Avatar | 534 | 534 | 11,500 | 5 | 34,570 | 7-2-2020 | 11-5-2022 |
| Bastard Gas Punks V2 | 460,070 | 323,000 | 3,783 | 0 | 15,785 | 3-3-2021 | 11-5-2022 |
| Blitverse | 865 | 838 | 105,566 | 0 | 3665 | 11-7-2021 | 11-5-2022 |
| Blockchain Cuties | 317 | 315.1 | 10,566 | 0 | 1115 | 11-7-2021 | 11-5-2022 |
| Brave Frontier Heroes | 1,848 | 1,848 | 0 | 0 | 18,484 | 28-1-2018 | 11-5-2022 |
| ChainGuardians | 1094 | 1094 | 0 | 0 | 5669 | 24-1-2022 | 11-5-2022 |
| Chiliz | 13,382 | 2,936 | 22,952 | 0 | 337 | 7-7-2019 | 11-5-2022 |
| Coinbase Wizards | 454 | 442 | 171.27 | 0 | 5337 | 18-5-2021 | 11-5-2022 |
| Crypto Space Commanders | 1526 | 1513 | 7,866 | 0 | 417 | 24-2-2018 | 11-5-2022 |
| Crypto Stamp Edition | 1074 | 1074 | 0 | 0 | 20,950 | 21-11-2018 | 11-5-2022 |
| Cryptovoxels | 1440 | 1300 | 2,821 | 0 | 11,890 | 5-6-2019 | 11-5-2022 |
| CryptoPunks | 1988 | 328.5 | 2,545 | 0 | 52,451 | 22-6-2017 | 11-5-2022 |
| CyberKongz | 979 | 916 | 1,287 | 0 | 100 | 15-4-2021 | 11-5-2022 |
| Dark Country | 230 | 230 | 0 | 0 | 678 | 24-3-2018 | 11-5-2022 |
| Decentraland | 1688 | 608.914 | 6,904 | 0 | 815 | 29-9-2017 | 11-5-2022 |
| DeF1 Time | 200 | 0","Table 2 showed the demographic information. Specifically, we ranked respondents by the interval between responses to the two rounds of questionnaires, then we compared the demographic information of the early and late 25% of respondents (Armstrong and Overton, 1977, Sivo et al., 2006). The results (Table 2) showed no significant differences in gender, age, education, and usage experience. Therefore, in line with prior literature (Benlian, 2020, Ke et al., 2021, Laumer et al., 2017), we find that, even with a relatively low response rate, the comparative analysis revealed that nonresponse bias was not problematic for the present research.",0.011077246348898026,0.14564805,0.7426888942718506,0.0,0.46527906617192344
46,133.jpg," The table shows the number of transactions (N), mean, median, mean-median, skewness, minimum, maximum, begin date, and end date for each year from 2017 to 2021. The mean-median is a measure of the difference between the mean and the median. The skewness is a measure of the asymmetry of the distribution. The minimum and maximum are the smallest and largest values in the distribution, respectively. The begin date and end date are the dates on which the data was collected.

The number of transactions increased from 2017 to 2021. The mean transaction value also increased from 2017 to 2021. The median transaction value remained relatively stable from 2017 to 2021. The mean-median increased from 2017 to 2021. The skewness of the distribution also increased from 2017 to 2021. The minimum transaction value remained relatively stable from 2017 to 2021. The maximum transaction value increased from 2017 to 2021.","The longitudinal two-wave design with a time lag between the independent and dependent variables ensured that common method bias (CMB) was alleviated (Sykes, 2015). We also applied the Harmon single-factor test (Podsakoff et al., 2003). We found 10 factors with eigenvalues over 1, and the first factor accounted for 26.75%, lower than the threshold of 40%. In addition, we conducted a fit comparison between the one-factor model and the measurement model (Flynn et al., 2010). The one-factor model fit (?2/df=11231.312/560 =20.06, RMSEA=0.226, SRMR=0.332, CFI=0.182, TLI=0.131) indicated a worse result than the fit of our measurement model (?2/df=1849.975/539 =3.43, RMSEA=0.0072, SRMR=0.051, CFI=0.900, TLI=0.918). Finally, we adopted the marker variable technique to further examine CMB (Malhotra et al., 2006). In particular, the selected marker variable should be unrelated to any other variable in the measurement model (Acharya et al., 2022). We chose the vision of continuity as the marker variable. It refers to the organizational vision of maintaining continuity amidst internal and external changes (Venus et al., 2019), which was an irrelevant variable with two items. Table 3 showed that the correlations between the marker variable and other latent variables were irrelevant. Then, we utilized the lowest positive correlation (r = 0.02) to adjust the correlations among constructs. The results indicated that the difference between unadjusted correlations and adjusted correlations was not significant. Hence, CMB might not be a concern.",0.40988162001301937,0.7969715,0.7857572436332703,0.2885930956225289,0.8425592800592799
47,134.jpg," The table shows the yearly statistics of nonfungible.com transactions from 2017 to 2022. The number of transactions increased from 193 in 2017 to 956,917 in 2022. The total value of transactions also increased from $763,808 in 2017 to $28,280,899 in 2021. The mean transaction value increased from $3,957.55 in 2017 to $63,323.46 in 2022. The median transaction value increased from $4,000 in 2017 to $45,875.00 in 2022. The skewness of the distribution of transaction values increased from 3.003 in 2017 to 0.648 in 2022, indicating that the distribution became less skewed over time. The minimum transaction value decreased from 0 in 2017 to $18,982 in 2022. The maximum transaction value increased from $52,457 in 2017 to $224,768 in 2021.","We strategically selected 20 respondents from four subsidiaries of the electric company, all of whom had completed both phases of the questionnaires (as indicated in Table 4). Due to the constraints imposed by the COVID-19 pandemic, we conducted telephone interviews as the most practical and safe means of data collection. Each interview, on average, had a duration of approximately 10 min. Within the timeframe, we allocated around 7 min for specific questions tailored to each participant, while the remaining time was dedicated to providing a comprehensive introduction to the research background. While the interviews were relatively short, they were designed to be concise and focused, ensuring that participants? responses provided in-depth insights into their experiences and perspectives related to ES use, particularly in the context of TDS and support structures.",0.3686822086094393,0.5575321,0.7961133122444153,0.3958390302437389,0.6808044429893171
48,135.jpg," | NFT | N | Chi-squared | P-value | MAD | MAD conformity |
| - | - | - | - | - | - |
| SuperRare | 16,469 | 34.07 | 0.00% | 0.0034 | Close |
| Brave Frontier Heroes | 8410 | 106.54 | 0.00% | 0.0100 | Acceptable |
| Crypto Space Commanders | 15,581 | 134.60 | 0.00% | 0.0089 | Acceptable |
| Gods Unchained | 640946 | 640.46 | 0.00% | 0.0075 | Acceptable |
| Footballkitties | 1640 | 34.01 | 0.00% | 0.0075 | Acceptable |
| Known Origin | 1603 | 103.92 | 0.00% | 0.0092 | Acceptable |
| Makers Place | 851 | 42.69 | 0.00% | 0.0100 | Acceptable |
| My Crypto Heroes | 4238 | 68.32 | 0.00% | 0.0065 | Acceptable |
| PixelChain | 17142 | 299.42 | 0.00% | 0.0126 | Acceptable |
| Art Blocks | 5524 | 220.22 | 0.00% | 0.0138 | Marginally acc. |
| Decentravids | 3616 | 56.16 | 0.00% | 0.0128 | Marginally acc. |
| F1 Delta Time | 2331 | 45.09 | 0.00% | 0.0212 | Marginally acc. |
| Axie Infinity | 26282 | 1,991.27 | 0.00% | 0.0142 | Marginally acc. |
| Universe | 4813 | 84.57 | 0.00% | 0.0185 | Marginally acc. |
| War Riders | 1663 | 27.34 | 0.00% | 0.0227 | Nonconformity |
| Avataars | 3105 | 66.40 | 0.00% | 0.0250 | Nonconformity |
| Bastard Gas Punks V2 | 12922 | 222.28 | 0.00% | 0.0227 | Nonconformity |
| Blockchain Cuties | 29493 | 366.25 | 0.00% | 0.0221 | Nonconformity |
| ChainGuardians | 8645 | 156.96 | 0.00% | 0.0351 | Nonconformity |
| Cheese Wizards | 1254 | 23.15 | 0.00% | 0.0226 | Nonconformity |
| Chibi | 2799 | 165.98 | 0.00% | 0.0156 | Nonconformity |
| Crypto Assault | 2392 | 10.38 | 0.00% | 0.0198 | Nonconformity |
| Crypto Stamps Edition | 2815 | 61.28 | 0.00% | 0.0212 | Nonconformity |
| Cryptovoxels | 2662 | 1136.80 | 0.00% | 0.0338 | Nonconformity |
| CryptoPunks | 7262 | 1724.62 | 0.00% | 0.0233 | Nonconformity |
| CryptoSkulls | 2231 | 117.41 | 0.00% | 0.0282 |","This study used data from the University of Queensland, Australia, to explore the cyber resilience of organizations (Tsen et al., 2020). The dataset consisted of various features of 1473 organizations belonging to the critical and non-critical sectors in Australia, the USA, Canada, and Japan and their associated breaches due to ransomware attacks from 2004 to 2022. The dataset included firms with varying digital intensity, organizational size, network segmentation, EVSS, and CSR. We referred to Statista for data on the average financial losses (Lj) (Statista, 2022) from 2004 to 2022, which are derived from cyber-crime cases reported by the Internet Crime Complaint Center (IC3), which is a part of the FBI. Table 5 summarizes the statistics of the data.",0.0,0.12086991,0.7403626441955566,0.0,0.4262471508503256
49,136.jpg," | NFT | N | Chi-squared | P-value | MAD | MAD conformity |
| - | - | - | - | - | - |
| Art Blocks | 8743 | 23.26 | 0.56% | 0.0045 | Close |
| Axie Infinity | 171127 | 1130.71 | 0.00% | 0.0075 | Close |
| Battle Infinity | 8645 | 62.47 | 0.08% | 0.0089 | Close |
| Brave Frontiers | 2145 | 21.45 | 1.00% | 0.0037 | Close |
| Crypto Space Commanders | 15581 | 76.25 | 0.05% | 0.0056 | Close |
| CryptoKitties | 1091521 | 1616.08 | 0.00% | 0.0029 | Close |
| CryptoPunks | 7262 | 50.47 | 8.24% | 0.0052 | Close |
| CryptoSpells | 2645 | 15.33 | 0.05% | 0.0056 | Close |
| Decentraland | 3345 | 47.39 | 0.00% | 0.0056 | Close |
| Enjin | 10218 | 128.20 | 0.00% | 0.0028 | Close |
| Gods Unchained | 69464 | 226.69 | 0.11% | 0.0042 | Close |
| Illuvium | 1603 | 11.91 | 18.54% | 0.0077 | Close |
| Knights of Origin | 18743 | 128.20 | 0.00% | 0.0028 | Close |
| MegaCryptoPolis | 8591 | 36.43 | 2.83% | 0.0054 | Close |
| Makers Place | 3105 | 30.66 | 0.03% | 0.0071 | Close |
| My Crypto Heroes | 3735 | 27.34 | 0.00% | 0.0059 | Close |
| NBA Top Shot | 290485 | 168.93 | 0.30% | 0.0019 | Close |
| Sorare | 19003 | 169.37 | 0.00% | 0.0027 | Close |
| Splinterlands | 290048 | 128.15 | 0.00% | 0.0027 | Close |
| SuperRare | 2231 | 18.15 | 6.38% | 0.0090 | Close |
| The Sandbox | 16469 | 155.36 | 0.00% | 0.0027 | Close |
| Chiliz | 5616 | 148.86 | 0.00% | 0.0081 | Acceptable |
| FIFA World Cup Qatar 2022 | 10965 | 19.94 | 3.59% | 0.00998 | Acceptable |
| Dark Country | 1663 | 33.26 | 0.81% | 0.0053 | Acceptable |
| Pixies Official | 1648 | 327.43 | 0.00% | 0.0114 | Marginally acc. |
| Avastar | 48713 | 274.82 | 0.00% | 0.0071 | Marginally acc. |
| Axie Infinity: Land | 1814 | 102.28 |",Table 6 shows the relationship between the dependent and independent variables.,0.010838326891529172,0.05085326,0.7517373561859131,0.0,0.2883412108542998
50,137.jpg," The table shows the results of a study that measured the conformity of different NFT projects to the MAD Conformity Index. The index is a measure of how well an NFT project conforms to the standards of the market. The higher the index, the more conformed the project is.

The study found that the most conformed NFT projects were those that had a high degree of community engagement, a clear and concise roadmap, and a strong team of developers. The least conformed projects were those that had a low degree of community engagement, a vague or nonexistent roadmap, and a weak team of developers.

The study also found that there was a positive correlation between the MAD Conformity Index and the price of an NFT project. This suggests that investors are more likely to invest in NFT projects that are conformed to the standards of the market.","We used generalized linear models such as LR (Son et al., 2020) in the RRA module to test the hypotheses. Based on the chi-squared test, the goodness of fit of the model was revealed to be significant (p < 0.001) with a small deviance of 66.68. Table 8 reports the parameters of the M1 (LR) model that were significant at the 1% level. Substituting the values from Table 8 into Equation (1), Eq. (3) is determined, as follows (3) Table 8 and Eq. (3) indicate that larger organizations are 6.786 times more likely to face R attacks than NR attacks (p = 0.001), thereby supporting hypothesis H1a. Moreover, if organizations belong to a critical industry, their chances of facing ransomware attacks increase by 5.229 times compared to NR attacks (p = 0.001). This finding supports hypothesis H1b. Similarly, for each unit increase in digital intensity, the odds of R attacks are 13.573 times greater than those of NR attacks (p = 0.001). This result aligns with hypothesis H2a. However, if the network is segmented, the probability of occurrence of R attacks decreases to 0.042 times that of NR attacks (p = 0.001), thereby supporting hypotheses H2b. Table 8 also indicates that for each unit increase in vulnerabilities in the organizational environment, the odds of ransomware attacks increase by 2.734 times compared to other cyberattacks (p = 0.098). This finding supports hypothesis H3. In contrast, if information security governance is properly implemented in an organization, for an increase in every cybersecurity role, the probability of ransomware attacks decreases to 0.421 times that of non-ransomware attacks (p = 0.100), thereby supporting hypothesis H4.",0.4475801730262166,0.6730008,0.8013356924057007,0.2370413105135252,0.8548917258100931
51,138.jpg," The table shows the results of the Pearson's Chi-squared test for the years 2017 to 2021. The test is used to determine whether there is a significant difference between the observed and expected frequencies of a categorical variable. In this case, the categorical variable is the conformity of NFT transactions to the power law distribution. The results show that for the years 2017 to 2020, the p-value is 0.00%, which means that there is a significant difference between the observed and expected frequencies of conformity. This suggests that the power law distribution is not a good fit for the data. However, for the year 2021, the p-value is 0.157, which means that there is no significant difference between the observed and expected frequencies of conformity. This suggests that the power law distribution is a good fit for the data.","Next, in the RRA module, we used the M1, M2, and M3 models to classify attacks as R or NR. The performances of the three models were measured and compared on the test dataset using the accuracy, precision, recall, and F1-score, as shown in Table 9. It is evident from Table 9 that M1 was better than M2 and M3 because its accuracy, precision, recall, and F1-score were better than those of the other two models. Hence, this study further elaborates on the results of M1 (the LR model). Figs. 3(a) and 3(b) show that M1 could correctly classify or predict 27 out of 29 R and 293 out of 314 NR data points of the test dataset.",0.4410874250290839,0.8087745,0.8189940452575684,0.4628297362110312,0.7600973766441391
52,139.jpg," The table shows the results of a Pearson's chi-squared test for the years 2017 to 2021. The test was conducted to determine whether there is a relationship between the number of NFT transactions and the US dollar value of those transactions. The results show that there is a significant relationship between the two variables, as the p-value for each year is 0.00. This means that the null hypothesis, which states that there is no relationship between the two variables, can be rejected. The MAD (mean absolute deviation) and MAD conformity values are also shown in the table. The MAD value represents the average difference between the actual value of a transaction and the predicted value of the transaction. The MAD conformity value represents the percentage of transactions that have a MAD value of less than 1%. The results show that the MAD value is close to 0 for each year, which indicates that the model is able to accurately predict the value of NFT transactions. The MAD conformity value is also high for each year, which indicates that the model is able to accurately predict the value of most NFT transactions.","Consistent with the literature (Islam et al., 2022, Sun et al., 2020, Sun et al., 2021), Table 2 lists the loadings and cross-loadings of the measurement items. The items loaded in our assumed factors provide preliminary evidence of our data validity.",0.2755242432118208,0.7268647,0.8145291209220886,0.36125654450261785,0.7880886274865334
53,14.jpg," Table 1 presents the correlation matrix and descriptive statistics of the variables used in the study. All variables are measured at the firm level. The correlation matrix shows that most of the variables are significantly correlated with each other, suggesting that there is a complex relationship between the variables. The descriptive statistics show that the mean values of the variables are all within a reasonable range. The standard deviations of the variables are also relatively small, suggesting that the data is not too noisy.","All the Cronbach?s a values are.76 or larger, indicating sufficient reliability (Nunnally & Bernstein, 1994). All the composite reliability (CR) values are.81 or larger, and all the average variance extracted (AVE) values are.55 or larger. These results indicate acceptable reliability (Bagozzi & Yi, 1988). As shown in Appendix A, all the indicator loadings are.65 or higher, suggesting good convergent validity (Hair et al., 1998). As shown in Table 3, all the positive square roots of the AVE values exceed the associated correlations, indicating discriminant validity (Fornell & Larcker, 1981). To offer enhanced evidence of discriminant validity, we tested and found that all the 95% confidence intervals of the correlations are smaller than all the positive square roots of the AVE values. Psychometric properties may include reliability, validity, and model fit performance. Our measurement model has sufficiently good performance in model fit, i.e., CFI= .97, IFI= .97, NNFI= .96, SRMR= .05 (Bagozzi, 2010).",0.41938882604996075,0.80792725,0.8249366283416748,0.23313188058430412,0.8457333341261914
54,140.jpg," The Pearson's Chi-squared test is a statistical test that is used to determine whether the distribution of a set of data fits a particular distribution. In this case, the data is the distribution of the first digits of NFT prices. The null hypothesis is that the distribution of the first digits of NFT prices follows Benford's law. The alternative hypothesis is that the distribution of the first digits of NFT prices does not follow Benford's law.

The results of the Pearson's Chi-squared test show that the p-value for each year is less than 0.05, which means that the null hypothesis is rejected. This means that the distribution of the first digits of NFT prices does not follow Benford's law.

This finding is consistent with the findings of other studies that have found that the distribution of the first digits of prices in financial markets does not follow Benford's law. This suggests that there may be some underlying factors that are causing the distribution of prices in financial markets to deviate from Benford's law.","We obtained 546 complete responses through a two-wave data collection process. The data indicate that most of our participants were male (86.7%). This proportion is similar to that of the local player population, in which 83% of players are male (GNN, 2016). Most participants were aged = 30 years (82.1%), had a college/university level education or higher (91.4%), and had an income = NT $600,000.00 (79.5%). Most participants had played the focal game for = 5 years (91.1%), showed weekly gameplay hours of < 21 h (87.7%), and had a skill level of gold or below (91.7%). Table 4 shows the demographic profile of the participants. However, the total numbers shown in Table 4 are not always equal to the total collected sample size due to some missing values in the profile data.",0.3965413557067954,0.5323947,0.8003648519515991,0.45664739884393063,0.8219494699263487
55,141.jpg,Error: Invalid response from model,"As shown in Fig. 2 and Table 5, our structural model explains significant variances in the endogenous constructs: 57% in competence satisfaction, 49% in autonomy satisfaction, 26% in relatedness satisfaction, 49% in game continuance, and 11% in game usage. We suppose that 11% may be adequate, as game usage may be easily affected by schoolwork or workplace and family responsibilities. Moreover, the well-known phenomenon of the intentionsingle bondbehavior gap predicts a high discount in transforming intention to behavior (Fennis et al., 2011).",0.018210108981827563,0.42363194,0.8035814166069031,9.569114686189008e-08,0.8128571428571428
56,142.jpg, The table shows the interview participants' profiles. Interviews were conducted with 18 participants from three different units of an international humanitarian NGO. The participants were from different hierarchical levels within the organization and had varying lengths of experience in social media management.,"We performed the usual bootstrapping process, i.e., 5000 resamplings at the typical significance level of.05 (Nusair et al., 2024). Although not all the path coefficients in our structural model have significant coefficients, the bootstrapping results indicate that all the mediations are significant. This is reasonable, as the bootstrapping method is designed to test the interactions of the path coefficients. Therefore, a single large path coefficient can result in a significant interaction among path coefficients. All the mediation coefficients are significant, justifying the importance of the chosen mediators in our model. Moreover, our model shows that most (but not all) paths have significant coefficients, giving game makers useful insights into game achievability and game immersibility, but not focusing on game creatability.",0.21710180609041294,0.8419513,0.8199757933616638,0.06938579791820935,0.734023780452352
57,143.jpg," The table shows the results of a two-step hierarchical regression analysis. In the first step, the main effects of crowdfunding platform type and prosocial motivation were entered into the model. In the second step, the interaction between crowdfunding platform type and prosocial motivation was added to the model. The results show that the interaction between crowdfunding platform type and prosocial motivation was significant, indicating that the relationship between crowdfunding platform type and prosocial motivation depended on the level of prosocial motivation.","In total, we received 213 complete responses, which were screened in multiple steps, resulting in 206 valid responses. We excluded 1 response from South Africa, as it was from outside of Europe, and removed 6 responses for inattentive responding (< 0.5 sd in the responses) or for responding at a speed that would be impossible to do attentively (< 5 min). The sample was then examined for missing data. We found two missing values for USE_3 (see Appendix C, Table C1), which were imputed with the median value of the item. Finally, we screened the remaining responses that failed the attention-trap question. We found sufficient variance in their answers, and the respondents took a sufficiently long enough time (> 10 min) to complete the survey. Demographic information about the respondents (n = 206) can be found in Table 1. As can be seen from the table, the survey responses were collected from top management (61), middle management (65), lower management (51), and experts (29). Table 2 depicts information about the companies of the respondents.",0.3490342454289567,0.69092214,0.8211988210678101,0.1710135872065935,0.7827494521938966
58,144.jpg," From the results of the hierarchical regression analysis, we can see that in Step 1, gender, age, income, and crowdfunding platform type were entered into the model. The model was significant, F(4, 265) = 3.16, p = .016, and explained 3% of the variance in the dependent variable, project description. In Step 2, prosocial motivation was added to the model. The model was significant, F(5, 264) = 3.56, p = .004, and explained 5% of the variance in the dependent variable, project description. In Step 3, the interaction between crowdfunding platform type and prosocial motivation was added to the model. The model was significant, F(6, 263) = 3.67, p = .002, and explained 7% of the variance in the dependent variable, project description. In Step 4, the interaction between project type and prosocial motivation was added to the model. The model was significant, F(7, 262) = 3.89, p = .001, and explained 10% of the variance in the dependent variable, project description.

From the results, we can see that prosocial motivation was a significant predictor of project description, even after controlling for the effects of gender, age, income, and crowdfunding platform type. This suggests that people who are motivated by prosocial concerns are more likely to write project descriptions that are informative and engaging. Additionally, the interaction between crowdfunding platform type and prosocial motivation was significant, suggesting that the effect of prosocial motivation on project description is different for different types of crowdfunding platforms. Finally, the interaction between project type and prosocial motivation was significant, suggesting that the effect of prosocial motivation on project description is different for different types of projects.","In total, we received 213 complete responses, which were screened in multiple steps, resulting in 206 valid responses. We excluded 1 response from South Africa, as it was from outside of Europe, and removed 6 responses for inattentive responding (< 0.5 sd in the responses) or for responding at a speed that would be impossible to do attentively (< 5 min). The sample was then examined for missing data. We found two missing values for USE_3 (see Appendix C, Table C1), which were imputed with the median value of the item. Finally, we screened the remaining responses that failed the attention-trap question. We found sufficient variance in their answers, and the respondents took a sufficiently long enough time (> 10 min) to complete the survey. Demographic information about the respondents (n = 206) can be found in Table 1. As can be seen from the table, the survey responses were collected from top management (61), middle management (65), lower management (51), and experts (29). Table 2 depicts information about the companies of the respondents.",0.4040689549967145,0.87814814,0.8005380034446716,0.4387254901960784,0.7878121037211938
59,145.jpg, Table 3. Results of the hierarchical regression analyses predicting intention to contribute.,"We then proceeded with the CFA by evaluating the fully correlated measurement model. As the first step in assessing the indicator and construct validities, we examined the standardized item loadings for the constructs. All loadings were statistically significant (p < 0.001) and above the recommended 0.707 threshold (Fornell & Larcker, 1981), except for one RESI item, which had a loading of 0.689. Thus, this item was dropped from subsequent analyses. The constructs, items, and their means, standard deviations, and standardized factor loadings are presented in Appendix C (Table C1). Next, we used the Master Validity plug-in of Gaskin et al. (2019) to analyze the discriminant validity of our measurement model (Table 3). According to Fornell and Larcker (1981), the composite reliability (CR) value of all constructs should be above 0.7, the average variance extracted (AVE) should be above 0.5 and larger than the maximum shared variance (MSV), and the square root of each AVE should be larger than all other correlations with the other variables. The CR, AVE, MSV, and square root of the AVE (bolded in diagonal) are reported in Table 3. As can be seen, our data fit all the aforementioned criteria, indicating sufficient convergent and discriminant validity for our model.",0.21658978072454105,0.7424872,0.8283252120018005,7.474801712640877e-08,0.7849867724867723
60,146.jpg," The table shows the perkembangan of Airbnb in Romania from 2018 to 2020. The number of active listings decreased from 42,028 in 2018 to 36,012 in 2020. The total revenue decreased from $439,323,137.22 in 2018 to $121,072,214.67 in 2020. The number of nights booked decreased from 3,650,895 in 2018 to 1,162,574 in 2020. The occupancy rate decreased from 41.35% in 2018 to 16.34% in 2020. The revenue per available night decreased from $49.75 in 2018 to $17.02 in 2020.

The decrease in the number of active listings, total revenue, number of nights booked, occupancy rate, and revenue per available night from 2018 to 2020 can be attributed to the COVID-19 pandemic. The pandemic caused a significant decrease in the number of people traveling, which led to a decrease in the demand for Airbnb listings.","We opted to evaluate the model fit for the measurement and path models using the CFI, SRMR, and RMSEA measures. This is in line with the recommendations of Hair et al. (2014), who suggested that model fit should be evaluated with at least one absolute fit measure (e.g., SRMR and RMSEA) and one incremental fit index (e.g., CFI). The suggested cutoffs for these fit measures are = 0.95 for CFI, = 0.08 for SRMR, and = 0.08 for RMSEA, along with > 0.05 for its PClose (Hair et al., 2014). As shown in Table 4, the measurement model?s values were excellent for all of these fit indices. The model?s normed chi-square (?2/df) was 1.515, which falls within the suggested range of 1?3 (Hair et al., 2014). The chi-square test was statistically significant (p < 0.05), indicating poor fit with the data; however, this is common with complex models and larger sample sizes (Schermelleh-Engel et al., 2003). Moreover, Hair et al. (2014) recommend that this measure should not be examined independently but in the context of other model fit measures. As all the other model fit indices were excellent, we can conclude that the measurement model fit the data well. After we moved on to the hypothesis-testing phase, we also evaluated the path model?s fit. Again, the measures were still excellent except for CFI (0.946), which was still close to excellent fit, but within acceptable range (= 0.9) nonetheless.",0.25209315734677257,0.5223066,0.7833763957023621,0.2083439822276784,0.785861547242144
61,147.jpg," The table shows the descriptive statistics of Airbnb listings in the United States from 2018 to 2020. The occupation rate is the percentage of nights that a listing is booked. The revenue per active night is the average amount of money that a listing earns per night that it is booked.

The occupation rate and revenue per active night both decreased from 2018 to 2020. This is likely due to the COVID-19 pandemic, which caused a sharp decline in travel and tourism. The occupation rate fell from 51.09% in 2018 to 17.77% in 2020. The revenue per active night fell from $61.83 in 2018 to $14.47 in 2020.

The decline in the occupation rate and revenue per active night was likely caused by a number of factors, including:

* A decrease in the number of travelers
* An increase in the supply of Airbnb listings
* A decrease in the average length of stay
* A decrease in the average daily rate

The COVID-19 pandemic had a significant impact on the Airbnb industry. The decline in the occupation rate and revenue per active night is likely to continue in the short term, as the pandemic continues to weigh on the travel and tourism industry. However, the long-term impact of the pandemic on the Airbnb industry is uncertain.","Four out of twelve of the paths were significant at the p < 0.001 level, two at the p < 0.01 level, and one at the p < 0.05 level. Seven out of the twelve hypotheses were thus supported (see Table 5). For the statistically significant paths, the effect directions (positive or negative) were as hypothesized in the research model (Fig. 1). Thus, the research model had overall empirical support.",0.4149569231179522,0.6283908,0.7925683856010437,0.38556067588325654,0.786294196153351
62,148.jpg," The table shows the results of the credit portfolio stress test. The stress test was conducted on a portfolio of loans that were originated in 2018 and 2019. The portfolio was divided into three risk categories: flexible, moderate, and strict. The stress test was conducted under two scenarios: a benchmark scenario and a shock scenario.

In the benchmark scenario, the unemployment rate was assumed to increase from 3.9% in 2018 to 10% in 2019. In the shock scenario, the unemployment rate was assumed to increase from 3.9% in 2018 to 15% in 2019.

The results of the stress test showed that the portfolio was most sensitive to the shock scenario. In this scenario, the portfolio's loss rate increased from 0.29% in 2018 to 7.39% in 2020. The portfolio's capital ratio also declined from 10.49% in 2018 to 3.42% in 2020.

The results of the stress test also showed that the portfolio was more sensitive to the flexible risk category. In the shock scenario, the loss rate for the flexible risk category increased from 2.81% in 2019 to 12.50% in 2020. The capital ratio for the flexible risk category also declined from 8.56% in 2019 to 1.56% in 2020.

The results of the stress test suggest that the portfolio is vulnerable to economic downturns. The portfolio is particularly sensitive to the flexible risk category. The results of the stress test also suggest that the portfolio's capital ratio is not sufficient to absorb losses in a severe economic downturn.","Besides testing for the direct effects of each antecedent, we also carried out additional mediation analysis by testing for the indirect effects of the six TOE-based antecedents on organizational XR adoption intention via the perceived organizational value of XR and expected employee resistance to XR constructs. In addition, we tested whether the effect of expected employee resistance to XR on organizational XR adoption intention was mediated via the perceived organizational value of XR. This analysis was carried out using the latent mediation estimand and the Indirect Effects plugin created by Gaskin et al. (2020). The statistically significant paths are presented in Table 6. Mimetic pressure?s effect on organizational XR adoption intention was strongly mediated via the perceived organizational value of XR (? = 0.206; p < 0.001). Organizational support (? = 0.088; p < 0.01), employee technology use skills (? = 0.069; p < 0.05), and trialability (? = 0.047; p < 0.05) had a positive mediated effect on organizational XR adoption intention via expected employee resistance to XR. Other indirect effects were statistically insignificant (p > 0.05).",0.292847188406235,0.6720348,0.7931517958641052,0.4224021592442645,0.7826408971145813
63,149.jpg," Note: Descriptive statistics for the absolute value of PV2020 and PV2019 are displayed. The absolute value was chosen since the purpose of the table is to show the mean and observed PV2020 (chosen according to [18], to analyze the effects of Covid-19); Column on the right: Airbnb listings employing strict policies in 2019 and observed in March-December 2020 (chosen according to [18], to act as a benchmark situation); Last two columns: Column on the left: universe of 10,498 Airbnb listings observed in March-December 2020 (chosen according to [18], to act as a benchmark situation); d) The T-Stat (Mean Comparison) compares the mean value in 2020 with that of 2019, and tests whether the former is significantly larger than the latter. *** p < 0.001; ** p < 0.01; * p < 0.05; + p < 0.10.","Table 1 displays socially accepted risk profiles (for sources, see S.I.2. Comparison data). In food safety, the U.S. Food and Drug Administration (FDA) maintains a Food Defect Levels Handbook, which specifies that it accepts around 7% of defect samples (mainly mold and insect-infestations). About 15% of U.S. citizens contract foodborne illnesses annually, while severe harm is much less common (some 3000 die each year). The U.S. Food Safety and Inspection Service (FSIS) accepts 7.5% of salmonella-positive chicken carcasses and ground beef samples, with harm levels below 0.5% and around 420 U.S. deaths annually. General consumer goods have a different profile. Tracking the number of faulty products sold per year, the U.S. Dept. of Commerce only recalls 0.1%. Their accumulation and frequent use hurts 2%- 4% of U.S. citizens annually. In between these extremes is the risk profile of sports. In soccer, 1 in 32 ball possessions leads to a potentially dangerous foul (3.1%), and 1.5% of U.S. players end up injured. Another extreme is the risk profile of cigarettes. While each cigarette is risky and severe harm levels are notably higher (some 10% die from lung cancer or cardiovascular disease), it is surprising to many that these trackable risks are not life-threatening to some 90% of smokers.",0.334361953249172,0.71675646,0.7881332039833069,0.2733823169474204,0.7920921309593181
64,15.jpg," Table 4 reports the results of the hypotheses tests for the hypothesized relationships. In Model 1, we examine the main effects of the four AI-enabled B2B marketing capabilities. The results show that AI-enabled marketing analytics (Î² = 0.227, p < 0.05) and AI-enabled marketing automation (Î² = 0.202, p < 0.05) are positively related to firm performance. However, AI-enabled customer experience (Î² = -0.056, p > 0.10) and AI-enabled dynamic pricing (Î² = -0.090, p > 0.10) are not significantly related to firm performance. Therefore, H1a and H1b are supported, but H1c and H1d are not supported.

In Model 2, we examine the interaction effects of the four AI-enabled B2B marketing capabilities. The results show that the interaction of AI-enabled marketing analytics and AI-enabled marketing automation is positively related to firm performance (Î² = 0.141, p < 0.05). The interaction of AI-enabled marketing analytics and AI-enabled customer experience is also positively related to firm performance (Î² = 0.150, p < 0.05). However, the interaction of AI-enabled marketing analytics and AI-enabled dynamic pricing is not significantly related to firm performance (Î² = -0.030, p > 0.10). The interaction of AI-enabled marketing automation and AI-enabled customer experience is positively related to firm performance (Î² = 0.117, p < 0.05). The interaction of AI-enabled marketing automation and AI-enabled dynamic pricing is not significantly related to firm performance (Î² = -0.016, p > 0.10). The interaction of AI-enabled customer experience and AI-enabled dynamic pricing is not significantly related to firm performance (Î² = 0.069, p > 0.10). Therefore, H2a, H2b, and H2d are supported, but H2c and H2e are not supported.

In Model 3, we examine the moderating effects of industry dynamism. The results show that the positive relationship between AI-enabled marketing analytics and firm performance is stronger in industries with high dynamism (Î² = 0.334, p < 0.05). The positive relationship between AI-enabled marketing automation and firm performance is also stronger in industries with high dynamism (Î² = 0.290, p < 0.05). However, the positive relationship between AI-enabled customer experience and firm performance is weaker in industries with high dynamism (Î² = -0.182, p < 0.05). The positive relationship between AI-enabled dynamic pricing and firm performance is not significantly different between industries with high and low dynamism (Î² = 0.056, p > 0.10). Therefore, H3a and H3b are supported, but H3c and H3d are not supported.

In Model 4, we examine the moderating effects of firm size. The results show that the positive relationship between AI-enabled marketing analytics and firm performance is stronger in large firms (Î² = 0.355, p < 0.05). The positive relationship between AI-enabled marketing automation and firm performance is also stronger in large firms (Î² = 0.312, p < 0.05). However, the positive relationship between AI-enabled customer experience and firm performance is weaker in large firms (Î² = -0.203, p < 0.05). The positive relationship between AI-enabled dynamic pricing and firm performance is not significantly different between large and small firms (Î² = 0.061, p > 0.10). Therefore, H4a and H4b are supported, but H4c and H4d are not supported.","As our analysis aims at bridging measures from computer science, information science, medicine, and the psychological and social sciences, we prioritized expected values and simple conditional probabilities over higher-order meta-analytic statistics (Higgins et al., 2019, Petticrew and Roberts, 2008, Uman, 2011). We still achieve the meta-analytic goal of systematically synthesizing independent studies to calculate an overall effect (Egger and Smith, 1997, Shorten and Shorten, 2013). Table 2 presents the simple framework that conditions algorithmic recommendation output on different kinds of input. While all included studies (N = 151) report the percentage of ?bad? recommendations (first column: X%, Y%, or Z%), we only obtain data on ?good? recommendations for 62 studies (see Table 3). This means that we can distinguish between ?bad? and ?not bad? recommendations for all 151 audits (which is what we will do for most of our analyses), and distinguish between ?good?, ?other/neutral?, and ?bad? for a subgroup of studies (see section ?Recommending utility content?).",0.22942362063699667,0.824097,0.7724632620811462,0.3750815394651011,0.7512977665609243
65,150.jpg, Table 4: Regression Results - Robust,"As our analysis aims at bridging measures from computer science, information science, medicine, and the psychological and social sciences, we prioritized expected values and simple conditional probabilities over higher-order meta-analytic statistics (Higgins et al., 2019, Petticrew and Roberts, 2008, Uman, 2011). We still achieve the meta-analytic goal of systematically synthesizing independent studies to calculate an overall effect (Egger and Smith, 1997, Shorten and Shorten, 2013). Table 2 presents the simple framework that conditions algorithmic recommendation output on different kinds of input. While all included studies (N = 151) report the percentage of ?bad? recommendations (first column: X%, Y%, or Z%), we only obtain data on ?good? recommendations for 62 studies (see Table 3). This means that we can distinguish between ?bad? and ?not bad? recommendations for all 151 audits (which is what we will do for most of our analyses), and distinguish between ?good?, ?other/neutral?, and ?bad? for a subgroup of studies (see section ?Recommending utility content?).",0.029026082597858407,0.5421114,0.7973432540893555,5.224840301332778e-12,0.6295238095238096
66,151.jpg, Table 4: Regression Results - Robustness Checks,"Drawing from the research questions, a range of keywords were identified for the database searches, including ?mobile phone,? ?smart phone,? ?augmented reality,? ?distraction,? and ?multi-tasking.? In line with prior studies (Agarwal et al., 2019, Borges et al., 2021, Yan et al., 2021), Web of Science (WoS) and Scopus were identified as appropriate databases to obtain relevant and reliable journal articles across disciplines (see Table 1). To determine the eligibility of articles, inclusion and exclusion criteria were created in line with PRISMA guidelines (Massaro et al., 2016, Moher et al., 2009, Tranfield et al., 2003), see Fig. 2. Inclusion criteria included i) journal articles investigated mobile or AR technologies, and distraction or multi-tasking, involving customers (i.e., consumption context), ii) journal articles published in English, iii) journal articles published in high-ranking outlets (Scimago Q1 or Q2), iv) journal articles published since 2016 (to ensure the technology studied is up to date), v) journal articles empirical in nature, and vi) full-text versions accessible. The full exclusion criteria included i) publications merely mentioning distraction or multi-tasking, ii) publications where the focus was not on a customer-related experience, iii) publications in other than high-ranking journal articles, and iv) non-empirical research articles.",0.009889522472668813,0.57391256,0.7824459671974182,8.055123499453214e-13,0.6206349206349207
67,152.jpg," The table shows information about 20 firm owners or managers who were interviewed as part of a research project. For each person, the table provides their position, age, education, gender, the industry sector of their firm, the year their firm was founded, and the number of employees in their firm.

The youngest interviewee was 28 years old, and the oldest was 71 years old. The majority of the interviewees were male (16), with only four female interviewees. In terms of education, the majority of the interviewees had a college degree (7), followed by those with a high school diploma (6). Only three interviewees had a postgraduate degree.

The most common industry sector for the firms was services, which accounted for 8 of the 20 interviews. This was followed by manufacturing (4), retail (3), and construction (2). The remaining three firms were in the agriculture, mining, and transportation industries.

The majority of the firms were founded in the 1990s (7), followed by the 2000s (6). Only three firms were founded in the 1980s, and two were founded in the 2010s.

In terms of firm size, the majority of the firms had fewer than 20 employees (11). Only four firms had more than 50 employees, and two firms had more than 100 employees.

Overall, the table provides a snapshot of the characteristics of the firm owners or managers who were interviewed as part of the research project. The interviewees were predominantly male, with a college degree, and in their 40s or 50s. They were most likely to be in the services industry and to have founded their firm in the 1990s. The majority of the firms were small, with fewer than 20 employees.","Three focus groups were conducted (between 5 and 8 participants per session) to examine specific issues (Krueger, 2014). The sessions lasted between 60 and 90 min. The participants were recruited in Spain, following a non-probabilistic, purposive approach. The composition of a focus group should have a certain degree of homogeneity to avoid huge differences in opinion emerging, but it should also be diverse enough to promote discussion and generate useful information (Phillippi & Lauderdale, 2018). As prior knowledge of cultural events can influence participants? perceptions and evaluation of an experience (Lobuono et al., 2016), we selected people with similar levels of knowledge about the cultural event under consideration, but with different characteristics in terms of age, gender, and willingness to adopt new technologies. The focus groups were run until the saturation criterion was met (Malterud et al., 2016). The composition of the focus groups is shown in Table 1.",0.4622122424582198,0.9181514,0.8052665591239929,0.4400948991696323,0.830134248906491
68,153.jpg," The table shows the different social media features and how they are perceived by users. The features are: range of influence, similarity to face-to-face, convenience, transparency, work and time intensity, informational content, risk potential, communication, up-to-dateness, variety of formats, customizability, measurability, professional appearance, and personal availability.

For each feature, the table shows whether it is perceived positively or negatively by users who use social media sporadically or regularly. For example, the range of influence is perceived positively by users who use social media regularly, but it is perceived negatively by users who use social media sporadically.

The table also shows that some features are perceived differently by users who use social media sporadically and those who use it regularly. For example, the convenience of social media is perceived positively by both groups of users, but it is perceived more positively by users who use social media regularly.

Overall, the table shows that there are some social media features that are perceived positively by users who use social media sporadically or regularly. However, there are also some features that are perceived differently by these two groups of users.","Analyses of the reliability and convergent validity of the scales were conducted using SmartPLS 4.0 software. The factorial loadings of the indicators exceeded the minimum recommended level of 0.70 (except one, see Appendix B; Hair et al., 2011). The composite reliability of the constructs and the average variance extracted (AVE) values were also higher than the recommended minimum levels (Hair et al., 2011) (see Appendix B). Discriminant validity was assessed based on the criteria of Fornell and Larcker (1981) and heterotrait-monotrait ratios (Kline, 2011), with both approaches returning satisfactory values (see Table 3).",0.17672692574355814,0.53082514,0.7901646494865417,0.40106951871657753,0.7714601797489493
69,154.jpg," Table 1 reports the descriptive statistics and correlation matrix for the variables used in the analysis. All continuous variables are winsorized at the 1% and 99% levels to mitigate the influence of outliers. The correlation matrix shows that most of the variables are significantly correlated with each other, with the exception of the differentiation strategy, which is not significantly correlated with any of the other variables.","In this study, exploratory factor analysis and confirmatory factor analysis were used to test the dimensions and items of the evaluation index system for structural validity, convergent validity and discriminant validity. The KMO value of the indicator system is 0.922 > 0.7, Bartlett's test: X2 is 2817.8, p < 0.001, which shows that the indicator system has good structural validity. Table 2 demonstrates the rotated factor loading coefficients after adjustment and deletion in this study. The four factors extracted were named by combining the connotation of each variable; factor 1 was the value of health information content, factor 2 was the reliability of mobile social media, factor 3 was the trustworthiness of health information content, and factor 4 was the interactivity of mobile social media. From the results of principal component extraction, it can be seen that the cumulative explained variance of the extracted 19 question items is 77.31 %, which indicates that the four factors extracted from the 19 question items have a better explanation for the original data.",0.49738091227006875,0.9140541,0.834134578704834,0.1253641140397589,0.8396042089223906
70,155.jpg," From the table, we can see that the frequency of the physical-transform industry is 1250. The percentage of the physical-transform industry is 7.07%. The cum percentage of the physical-transform industry is 95.99%.","According to the four-factor model derived from the exploratory factor analysis, the validated factor analysis of the mobile social media health information quality evaluation scale was conducted on the survey questionnaire data using Amos23 software. The results showed (see Table 3) that the factor loadings of the dimensions of interactivity of mobile social media, reliability of mobile social media, the trustworthiness of health information content, and value of health information content ranged from 0.748 to 0.883, 0.781 to 0.908, 0.771 to 0.858, and 0.693 to 0.911, respectively, which were all greater than 0.6, indicating that each of their latent variables corresponding to the AVEs of each dimension were 0.6987, 0.7162, 0.6686, and 0.7118, all of which were greater than 0.6; the combined reliability CRs were 0.8737, 0.9095, 0.8896, and 0.9516, all of which were greater than 0.8, indicating ideal convergent validity.",0.3400911673840893,0.7106768,0.8161641955375671,0.017964557806493073,0.8089971405228759
71,156.jpg, Table 4. Regression results,"The final weight and the scores of the four dimensions of the WeChat official accounts' health information quality evaluation system were derived to give a quantitative evaluation of the current situation of WeChat official accounts' health information quality; see Table 5. The total average score of WeChat official accounts health information quality in this empirical study was 48.24, among which the score of the WeChat official accounts subject interaction dimension was 45.20, the score of the WeChat official accounts reliability dimension was 59.95, the score of the content credibility dimension was 28.32, and the score of the information content value dimension was 53.55. It is clear that the quality of health information on WeChat official accounts is generally low, especially the lowest score of content credibility, and the future improvement of health information quality on WeChat official accounts should be promoted from the aspect of content credibility.",0.010662182198433751,0.6524588,0.8241170644760132,1.4891631343101143e-16,0.7678571428571428
72,157.jpg," Table 4 reports the estimation results of the effects of digital transformation on firm performance. Model (1) shows that digital transformation has a significantly positive effect on labour productivity. A one-unit increase in the digital transformation index leads to a 0.065% increase in labour productivity. Model (2) shows that digital transformation has a significantly positive effect on value added per employee. A one-unit increase in the digital transformation index leads to a 0.169% increase in value added per employee. Model (3) shows that digital transformation has a significantly positive effect on value added growth. A one-unit increase in the digital transformation index leads to a 0.123% increase in value added growth.

Model (4) shows that digital transformation has a significantly positive effect on labour productivity growth. A one-unit increase in the digital transformation index leads to a 0.195% increase in labour productivity growth. Model (5) shows that digital transformation has a significantly positive effect on employment growth. A one-unit increase in the digital transformation index leads to a 1.977% increase in employment growth.

Model (6) shows that digital transformation has a significantly negative effect on physical-transform industry. A one-unit increase in the digital transformation index leads to a 0.098% decrease in physical-transform industry. Model (7) shows that digital transformation has a significantly negative effect on employment in the physical-transform industry. A one-unit increase in the digital transformation index leads to a 0.564% decrease in employment in the physical-transform industry. Model (8) shows that digital transformation has a significantly negative effect on value added growth in the physical-transform industry. A one-unit increase in the digital transformation index leads to a 0.674% decrease in value added growth in the physical-transform industry.

Model (9) shows that digital transformation has a significantly positive effect on the digital-transform industry. A one-unit increase in the digital transformation index leads to a 0.032% increase in the digital-transform industry. Model (10) shows that digital transformation has a significantly positive effect on employment in the digital-transform industry. A one-unit increase in the digital transformation index leads to a 2.453% increase in employment in the digital-transform industry. Model (11) shows that digital transformation has a significantly positive effect on value added growth in the digital-transform industry. A one-unit increase in the digital transformation index leads to a 1.587% increase in value added growth in the digital-transform industry.

Model (12) shows that digital transformation has a significantly negative effect on employment in the non-digital-transform industry. A one-unit increase in the digital transformation index leads to a 0.249% decrease in employment in the non-digital-transform industry.

Overall, the results show that digital transformation has a positive effect on firm performance. Digital transformation can improve labour productivity, value added per employee, value added growth, labour productivity growth, and employment growth. However, digital transformation also has a negative effect on physical-transform industry and employment in the physical-transform industry.","To minimise the drop-out rate, we included information about the purpose of the research in the survey, together with a statement guaranteeing the anonymity of the respondents. In addition, we offered some small incentives, such as mugs and umbrellas featuring the university logo, and, at the end of the survey, awarded these to randomly selected participants. To reduce the occurrence of missing values, the participants were required to give their responses to all questions/statements before they could progress to the next page/end of the survey (otherwise, a notification would pop up). Regarding the sample characteristics, 51.5 % were women, 76 % of the total were under 45 years of age, 46.5 % had studied at the higher education level and 63.8 % were in employed work. Table 4 presents the sample characteristics.",0.23364673699531652,0.89392954,0.775044858455658,0.3770260747004933,0.7699166739787507
73,158.jpg," Table 1. CFA results and standardized regression weights

Latent Variables/Indicators	Cronbach's Alpha	Standardized Regression Weights	
	Utilitarian gratifications	0.839	
	(a)	Considered more options	0.651***	
	(b)	Bargain hunting	0.623***	
	(c)	Compare prices	0.811***	
	(d)	Shop around	0.704***	
	(e)	Seeking second opinions via CON	0.634***	
	(f)	Seeking second opinions via OBS	0.521***	
	(g)	Informed by related reviews	0.691***	
	Hedonic gratifications	0.836	
	(a)	mp1	0.755***	
	(b)	mp2	0.680***	
	(c)	mp3	0.826***	
	(d)	mp4	0.784***	
	(e)	mp5	0.622***	
	(f)	mp6	0.564***	
	(g)	mp7	0.839***	
	Social gratifications	0.859	
	(a)	Re1	0.776***	
	(b)	Re2	0.687***	
	(c)	Re3	0.851***	
	(d)	Re4	0.733***	
	(e)	Re5	0.634***	
	(f)	Re6	0.727***	
	(g)	Re7	0.821***	
	Passing time	0.711	
	(a)	Pt1	0.856***	
	(b)	Pt2	0.753***	
	(c)	Pt3	0.529***	
	Convenience	0.856	
	(a)	Con1	0.709***	
	(b)	Con2	0.865***	
	(c)	Con3	0.780***	
	(d)	Con4	0.741***	
	(e)	Con5	0.636***	
	(f)	Con6	0.814***	
	(g)	Con7	0.924***	
	Control variables	
	(a)	Internet Anxiety	0.838	
	(b)	Computer Self-efficacy	0.752	
	Note: *p < 0.05; **p < 0.01; ***p < 0.001.
*** indicates a P value less than 0.001.","Prior to conducting further data analyses, we assessed the multivariate assumptions of normality, linearity, multicollinearity and homoscedasticity [98]. The results of the one-sample Kolmogorov-Smirnov test [99], presented in Table 5, indicate the absence of normal distribution [99], since all 2-tailed asymptotic significance values were 0.000?that is, less than 0.05 [82,96]. Hence, we opted for PLS-SEM in this study because it has been shown to be robust under conditions of non-normality [100].",0.023810466286304892,0.32418817,0.7494254112243652,0.3534136546184739,0.7015126199336726
74,159.jpg," The table shows the results of a study that examined the relationship between consumer state anxiety (CSA) and three types of consumer behavior: hedonic, utilitarian, and social. The results show that CSA is positively related to hedonic and utilitarian consumption, but negatively related to social consumption. This suggests that when consumers are feeling anxious, they are more likely to engage in activities that are focused on their own pleasure or that are practical and useful, but less likely to engage in activities that involve interacting with others.

The study was conducted using a survey of 200 consumers. The survey measured CSA using a 10-item scale. The three types of consumer behavior were measured using 10-item scales for each type of behavior. The results were analyzed using structural equation modeling.

The findings of this study have implications for marketers. Marketers should be aware of the relationship between CSA and consumer behavior. They should also be aware of the different ways that consumers cope with anxiety. This information can be used to develop marketing strategies that are more effective at reaching and engaging consumers who are feeling anxious.","We performed an ANOVA to test the linearity of the relationships between variables [100,82], the results of which are presented in Table 6. The results show that there are linear relationships between the dependent (use intention) and independent variables, since all p-values are below 0.05. However, seven out of the eight relationships reveal a statistically significant deviation from linearity, which justified the use of the ANN model?a nonlinear artificial intelligence technique that reflects the structure and operation of the human brain. The only exception was the relationship between price value and use intention, albeit its p-value (0.054) was very close to the significance threshold (0.05).",0.4371607208578411,0.8604864,0.8286636471748352,0.44086021505376344,0.8050099691228723
75,16.jpg," The table shows the objectives of the study, which are:

- To explore the specific reasons and emotions behind shareholders' positive reactions to AI implementation in B2B marketing.
- To investigate whether there are common themes or differences among participants' responses.
- To probe into shareholders' perceptions of industry dynamics and how these dynamics influence their reactions to AI implementation.
- To identify key industry concerns and their impact on shareholder sentiment.
- To investigate why shareholders of firms with more complex customer bases might react less positively to AI implementation.
- To explore their concerns, expectations, and factors that contribute to this reaction.","Multicollinearity is a problem of high correlation between independent variables [101]. The results of the multicollinearity test performed on our model (see Table 7) indicate that there were no issues of multicollinearity, since all the Variance Inflation Factor (VIF) values were in the range of 1.065?3.562 (i.e., less than 10), and the tolerances were all higher than 0.10 [93,99].",0.1517786613649279,0.5893926,0.8029290437698364,0.4166666666666667,0.7599953617810759
76,160.jpg," The table shows the relationship between constructs, correlations, and regression.

The relationship between constructs is as follows:
* Utilitarian gratifications and hedonic gratifications have a positive relationship.
* Utilitarian gratifications and social gratifications have a positive relationship.
* Hedonic gratifications and social gratifications have a positive relationship.
* Utilitarian gratifications have a negative relationship with consumer state anxiety.
* Hedonic gratifications have a negative relationship with consumer state anxiety.
* Social gratifications have a negative relationship with consumer state anxiety.
* Consumer state anxiety has a negative relationship with in-store purchase intention.

The correlations between constructs are as follows:
* Utilitarian gratifications and hedonic gratifications have a correlation of 0.694.
* Utilitarian gratifications and social gratifications have a correlation of 0.689.
* Hedonic gratifications and social gratifications have a correlation of 0.637.
* Utilitarian gratifications and consumer state anxiety have a correlation of -0.204.
* Hedonic gratifications and consumer state anxiety have a correlation of -0.074.
* Social gratifications and consumer state anxiety have a correlation of -0.024.
* Consumer state anxiety and in-store purchase intention have a correlation of -0.125.

The regression results show that:
* Utilitarian gratifications have a significant negative effect on consumer state anxiety (p = 0.028).
* Hedonic gratifications have a significant negative effect on consumer state anxiety (p = 0.046).
* Social gratifications have a significant negative effect on consumer state anxiety (p = 0.087).
* Consumer state anxiety has a significant negative effect on in-store purchase intention (p = 0.032).","We evaluated the measurement model by analysing its reliability and convergent and discriminant validity. The reliability analysis included three indicators of internal consistency: Cronbach's alpha (CA; [102]), the Rho coefficient and composite reliability (CR; [103]). The values for all three tests were above the recommended minimum value of 0.7. We assessed CR using average variance extracted (AVE). The AVE indicates the amount of variance a variable obtains from its indicators relative to the amount of variance caused by measurement error. All the AVE values were above the recommended minimum value of 0.5 [104]. Table 8 lists these values for each variable, along with the mean of each item and the outer loadings (i.e., the loads estimated for the relationships in reflective measurement models).",0.11874568989029291,0.8403655,0.7890686392784119,0.3765182186234818,0.7428273208273204
77,161.jpg," The table shows the results of the mediation analysis. The direct effect of UG on PI is 0.348, and the direct effect of HG on PI is 0.254. The direct effect of SG on PI is 0.243. The indirect effect of UG on PI through CSA is 0.022, and the indirect effect of HG on PI through CSA is 0.032. The indirect effect of SG on PI through CSA is 0.011. The total effect of UG on PI is 0.362, and the total effect of HG on PI is 0.295. The total effect of SG on PI is 0.254.","In this study, the presence of nonresponse bias was detected. To address this issue, we conducted a multigroup analysis, following the approach outlined by Hair et al. [105]. We compared the group of respondents who completed the survey promptly (within the first 5 days of issue) with the group of respondents who completed it later. The results indicated that there were no statistically significant differences between these two groups in terms of all variables (p > 0.05). Consequently, it can be concluded that the potential impact of nonresponse bias on the sample data is likely to be minimal or negligible [106]. Next, we assessed discriminant validity by comparing the squared AVE with the intercorrelation scores. Discriminant validity is achieved if the squared AVE of a variable is greater than the intercorrelation with other variables [107]. We further checked discriminant validity by applying the heterotrait-monotrait (HTMT) ratio. Henseler et al. [108] suggest that a HTMT ratio score above 0.90 indicates a discriminant validity issue. The HTMT ratio scores were all below the threshold, indicating that discriminant validity was achieved (see Table 9).",0.3364463679888877,0.7819489,0.815687358379364,0.20148626951993417,0.8260381593714926
78,162.jpg, Table 4. Correlation between remote work and COVID-19,"First, we tested the research hypotheses by comparative analysis of the coefficients obtained by OLS, using IBM SPSS v20 as a simulation tool. The results, presented in Table 10, confirm that none of the initial eight hypotheses derived from the extended UTAUT2 model could be rejected?that is, that all eight predictors have a statistically significant influence on the dependent variable (use intention). The most influential predictors according to the OLS findings are performance expectancy (?PE?UI=0.321, p-value=0.000), effort expectancy (?EE?UI=0.177, p-value=0.000) and facilitating conditions (?FC?UI=0.150, p-value=0.000), followed by hedonic motivation (?HM?UI=0.120, p-value=0.000), subjective norms (?SN?UI=0.100, p-value=0.000) and habit (?HAB?UI=0.112, p-value=0.000). The least influential predictors as per OLS are risk (?PRISK?UI= -0.084, p-value=0.000) and price value (?PRI-VAL?UI=0.065, p-value=0.006). We assessed the quality of the OLS model using the values of adjusted R2 (which was 0.724) and normalised root mean squared error (RMSE), which was 0.1292. Both values are acceptable, meaning that OLS can be accepted as a valid baseline model.",0.039703364644542036,0.60046357,0.7949592471122742,3.5970665151626917e-09,0.764069264069264
79,163.jpg," Table 2. Results of the conditional process models testing the moderated-mediation hypotheses.

Note. All models control for the firm-level time-invariant variables (i.e., firm size, firm age, and industry type). All models include a random intercept for firm. The significance of the indirect effect was tested using the bias-corrected percentile bootstrap method with 5,000 resamples.
*p < .05. **p < .01. ***p < .001.","We also assessed the predictive ability of the model by determining the squared multiple correlation coefficient (R2). The R2 value for use intention was 0.708, meaning that it explains a high proportion of the variance of the model. Furthermore, we examined the standardised root mean square residual (SRMR) value [108] to test the difference between the observed correlation and the predicted correlation as an indicator of model fit. A value of less than 0.08 is considered acceptable. The model proposed in this study yielded a value below this threshold (0.046). We also evaluated effect size (f2) after reviewing research from Chin [109], who indicated that f2 values of 0.02?0.15, 0.15?0.35 and 0.35 or higher suggest that an independent or exogenous latent variable has a small, moderate or large effect, respectively, on a dependent latent variable. The relationship between the variables in the present study was found to exert a significant effect, and the lowest value with regard to f2 pertained to the relationship between perceived value and use intention. Finally, we assessed the predictive relevance of the model using Stone-Geisser's Q2 value. According to Chin [109], a model demonstrates good predictive relevance when its Q2 value is greater than zero. Thus, the present value can be considered adequate. Table 10 summarises all of these results.",0.3321868640888359,0.8484519,0.8130132555961609,0.045971462784504535,0.8292456617456616
80,164.jpg," The table shows the correlation matrix of the variables used in the analysis. The variables are:

1. Remote work firm's initiatives in t1
2. Remote work firm's initiatives in t2
3. Remote work firm's initiatives in t3
4. Firm size
5. Firm's RSE in remote work in t1
6. Firm's RSE in remote work in t2
7. Firm's RSE in remote work in t3
8. Industry's average RSE in t1
9. Industry's average RSE in t2
10. Industry's average RSE in t3
11. Industry

The correlation matrix shows that there is a strong positive correlation between the firm's remote work initiatives in t1 and t2 (r = 0.411) and between the firm's remote work initiatives in t2 and t3 (r = 0.506). This suggests that firms that are more proactive in implementing remote work initiatives in one year are more likely to continue to do so in subsequent years.

There is also a strong positive correlation between the firm's RSE in remote work in t1 and t2 (r = 0.705) and between the firm's RSE in remote work in t2 and t3 (r = 0.775). This suggests that firms that have a higher level of RSE in remote work in one year are more likely to have a higher level of RSE in remote work in subsequent years.

There is a negative correlation between the firm's remote work initiatives in t1 and the firm's RSE in remote work in t1 (r = -0.233). This suggests that firms that are more proactive in implementing remote work initiatives are less likely to have a high level of RSE in remote work.

There is also a negative correlation between the firm's remote work initiatives in t2 and the firm's RSE in remote work in t2 (r = -0.164) and between the firm's remote work initiatives in t3 and the firm's RSE in remote work in t3 (r = -0.211). This suggests that firms that are more proactive in implementing remote work initiatives are less likely to have a high level of RSE in remote work in subsequent years.

These findings suggest that firms that are more proactive in implementing remote work initiatives are more likely to have a lower level of RSE in remote work. This is because remote work initiatives can help to reduce the costs associated with RSE, such as the costs of recruiting and training new employees, and the costs of providing employees with the necessary equipment and support to work remotely.","One of the potential problems associated with ANNs is overfitting [86], which occurs when the model ?memorises? data from the training sample and loses the ability to generalise when used with previously unseen data. To avoid this problem, we performed 10-fold cross validation [[95], [115]]. A common measure of the prediction accuracy of ANN models is RMSE [91,99] (Table 11). The low RMSE values presented in Table 11 indicate good reliability and high prediction accuracy for the proposed model [101,50]. Finally, we further evaluated the performance of the ANN model by determining its goodness-of-fit coefficient R2 [116,100], using the following formula: where   is the variance of the desired output. The value R2 = 0.957 indicates that the ANN acceptance model explains 95.7 % of the variance of use intention (model output), which is a significant improvement on the PLS-SEM results.",0.2241387104563217,0.74921453,0.7850008606910706,0.39805825242718446,0.788835177168511
81,165.jpg," The above image shows the architecture of the PREM (Price Elasticity Model). The model consists of four main components:
1. Data Input
2. Feature Engineering
3. Cost-Sensitive Classification
4. Revenue Maximizer

The Data Input component ingests data from various sources, including customer data, flight data, offer data, third-party data, and generated data. 

The Feature Engineering component then extracts features from the raw data. These features are used to train the cost-sensitive classification model. 

The Cost-Sensitive Classification component predicts the probability that a customer will accept an upgrade offer. This model is trained using a three-layer deep learning model. 

The Revenue Maximizer component then uses the predicted probabilities to assign customers to different upgrade offers. The goal of this component is to maximize the revenue generated from upgrade offers.","Finally, we performed a sensitivity analysis of the ANN model to determine the importance of each predictor. The importance of a predictor measures the significance of the changes in the output caused by changes in different predictors [62]. The normalised importance is calculated by dividing the importance values of each predictor by the largest importance value [91]. Values for the relative and normalised importance of the ANN model are presented in Table 12.",0.3636120883802759,0.8415134,0.8180610537528992,0.4427083333333333,0.743674728049728
82,166.jpg," | Year | Bookings | Offers sent | Offers accepted | Reach rate | Conversion rate |
|---|---|---|---|---|---|
| 2017 | 15.2 M | 2.5 M | 42 K | 16% | 1.67% |
| 2018 | 30.9 M | 7.5 M | 99 K | 24% | 1.32% |
| 2019 | 18.2 M | 4.1 M | 53 K | 23% | 1.29% |
| All | 64.3 M | 14.1 M | 194 K | 22% | 1.43% |","The most significant predictor of use intention is PE (average importance: 0.256), followed by EE (0.175), FC (0.134) and HM (0.104), which is in line with SEM-PLS findings. Next, the ANN model predicts that SN (0.099) has a more significant impact than HAB (0.089), which differs from SEM-PLS results. Finally, the two least influential predictors were PRISK (0.087) and PRI-VAL (0.057), which was also predicted by SEM-PLS findings. These minor differences between the ANN and SEM-PLS findings can be explained by the higher prediction accuracy of the ANN model and its capacity to consider any nonlinear relationships among the variables [[50], [62]]. A detailed comparison of OLS, SEM-PLS and ANN findings is presented in Table 13 [117].",0.0,0.28739965,0.7796154618263245,0.0,0.7577898550724638
83,167.jpg," From the table, we can see that the best feature embedding technique is the Denoising AutoEncoder, which achieves an F1 score of 83.9 and a revenue capture of 100%.","Table 14 presents a comparison of similar research studies related to m-payment that have employed the UTAUT2 model as a theoretical framework. As can be seen, the results are aligned with the recent proposals of Al-Okaily et al. [120] and Migliore et al. (2020), which reinforces the generalisability of the findings obtained.",0.30712518782017306,0.6253034,0.8345322012901306,0.2548216809534708,0.7908531124048366
84,168.jpg," The table shows the F1 score and revenue capture for different embedding sizes. The F1 score is a measure of the accuracy of the model, and the revenue capture is the percentage of revenue that the model is able to capture. The results show that the model with the highest embedding size (256) has the highest F1 score and the highest revenue capture. This suggests that a larger embedding size results in a more accurate model that is able to capture more revenue.","In the experiment, participants were presented with a recommendation provided by DA and were asked to make a decision regarding the promotion of a candidate to a sales manager position. The decision specifically focused on choosing between a female candidate and a male candidate. This scenario aimed to simulate the use of algorithms in real-world promotion decisions, which have significant implications for individuals? lives and careers [108]. To ensure that the sample met the requirements of our study, we included a screening question asking participants about their roles in their respective firms. Participants who did not have managerial roles were excluded from the analysis. This decision was based on the understanding that managers are typically the primary users of DA tools and are responsible for accepting or rejecting the recommendations provided by such tools. The characteristics of the final sample are presented in Table 2.",0.40460635676586126,0.81977874,0.8265306353569031,0.2682915657616884,0.8223608720596672
85,169.jpg," The table shows the F1 score and revenue capture for different classifiers and feature sets. The best F1 score is achieved by the DL/Embeddings model, which also has the highest revenue capture. The worst F1 score is achieved by the Random Forest/Original data model, which also has the lowest revenue capture.","SPSS 26 was used to conduct the analyses. Cronbach's alphas, composite reliabilities, correlations, descriptive statistics, and the square roots of average variance extracted (diagonal values) are provided in Table 3. The item loadings associated with the constructs are presented in Table 4. To evaluate the presence of common method bias, we performed a marker-variable analysis [110]. We used extraversion as the marker variable, as it is theoretically not related to the variables in the research model. The average correlation between the marker variable and the main variables in the research model was 0.018, suggesting that common method bias was unlikely to exist in the data. To examine the manipulation check for ?just recommendation? versus ?unjust recommendation against women,? we used ANOVA. The results showed that participants in the ?just recommendation? treatment group reported a mean score of 4.35 (SD = 1.53), whereas participants in the ?unjust recommendation? treatment group reported a mean score of 5.31 (SD = 1.45) for the manipulation check question assessing the perception of unjust treatment toward the female candidate. The difference between the two groups was statistically significant (P < 0.05). Therefore, the manipulation of algorithmic injustice was successful.",0.4027920975456774,0.8119241,0.815783679485321,0.031895071026180936,0.8087428910958324
86,17.jpg," The table shows the demographic information of the participants in two studies. Study 1 had 586 participants, while Study 2 had 508 participants. The participants in both studies were from the United Kingdom.

In Study 1, the majority of the participants were female (58%), with a mean age of 31 years. The majority of the participants were in the 25-34 age group (35%), followed by the 18-24 age group (26%). The majority of the participants had a university degree (57%), followed by those with a college degree (24%). The majority of the participants were employed full-time (41%), followed by those who were employed part-time (22%). The majority of the participants had a household income of less than Â£25,000 (44%).

In Study 2, the majority of the participants were also female (51%), with a mean age of 30 years. The majority of the participants were in the 25-34 age group (35%), followed by the 18-24 age group (27%). The majority of the participants had a university degree (56%), followed by those with a college degree (22%). The majority of the participants were employed full-time (40%), followed by those who were employed part-time (21%). The majority of the participants had a household income of less than Â£25,000 (41%).

Overall, the two studies had similar participant demographics. The majority of the participants in both studies were female, young, and had a university degree. The majority of the participants in both studies were also employed full-time and had a household income of less than Â£25,000.","SPSS 26 was used to conduct the analyses. Cronbach's alphas, composite reliabilities, correlations, descriptive statistics, and the square roots of average variance extracted (diagonal values) are provided in Table 3. The item loadings associated with the constructs are presented in Table 4. To evaluate the presence of common method bias, we performed a marker-variable analysis [110]. We used extraversion as the marker variable, as it is theoretically not related to the variables in the research model. The average correlation between the marker variable and the main variables in the research model was 0.018, suggesting that common method bias was unlikely to exist in the data. To examine the manipulation check for ?just recommendation? versus ?unjust recommendation against women,? we used ANOVA. The results showed that participants in the ?just recommendation? treatment group reported a mean score of 4.35 (SD = 1.53), whereas participants in the ?unjust recommendation? treatment group reported a mean score of 5.31 (SD = 1.45) for the manipulation check question assessing the perception of unjust treatment toward the female candidate. The difference between the two groups was statistically significant (P < 0.05). Therefore, the manipulation of algorithmic injustice was successful.",0.5133287545573182,0.6302411,0.7912766337394714,0.4634794156706507,0.7962435970404097
87,170.jpg," The table shows the F1 score and revenue capture for three different customer segmentation models. The best model is the Binary AutoEncoder, which has an F1 score of 83.9 and a revenue capture of 100%. The K-Means model has an F1 score of 64.9 and a revenue capture of 79%. The Decision Tree model has an F1 score of 53.6 and a revenue capture of 73%.","We performed a hierarchical logistic regression analysis in SPSS 26 to examine (1) the impact of algorithmic injustice on making a discriminatory decision and (2) the moderating role of displacement of responsibility and trust in DA outcomes on that association. The results, presented in Table 5, indicated that the impact of algorithmic injustice on discrimination (H1) was statistically significant (P < 0.001). While the moderating effect of displacement of responsibility on the relationship between algorithmic injustice and discrimination (H3) was not significant, trust in DA outcomes showed a significant moderating effect on the impact of algorithmic injustice on discrimination (P < 0.05) (H5). The findings also demonstrated that the control variables did not have a significant impact on making algorithmically informed, discriminatory decisions. Next, we ran an analysis of covariance (ANCOVA) to examine the effect of discrimination on the perception of guilt (H2). The results indicated that the effect was not significant (P = 0.19), supporting H2. We then added two interaction terms to the ANCOVA model to test the moderating effect of displacement of responsibility on the relation between discrimination and guilt (H4) as well as the moderating impact of trust in DA outcomes on that association (H6). The results showed that while H4 was not significant (P = 0.87), H6 was marginally significant (P = 0.08). In summary, while H1, H2, and H5 were supported, H3 and H4 were not supported, and H6 was partially supported.",0.3056698947148835,0.6061267,0.8027264475822449,0.040268070891233666,0.8196346582710219
88,171.jpg," The table shows the F1 score and revenue capture of two methods for maximizing revenue. The first method, ILP, has an F1 score of 83.9 and a revenue capture of 100%. The second method, Greedy, has an F1 score of 49.2 and a revenue capture of 56%.","Second, we performed a confirmatory factor analysis (CFA). We examined the reliability, convergent validity, and discriminant validity of the latent reflective constructs. The composite reliability (CR) was above the recommended 0.70 threshold [91]. The average variance extracted (AVE) for all constructs exceeded the suggested 0.50 threshold [28], thereby demonstrating good reliability and internal consistency (Table 4), except for our control variable, social desirability (AVE = 0.475). Because social desirability slightly falls below the 0.50 threshold but has a CR of 0.729, we kept social desirability in our model (cf. [28]). All indicators loaded significantly on their latent constructs, and standardized loadings exceeded the required minimum of 0.700, indicating good convergent validity, except for social desirability (Appendix D). In addition, we tested the discriminant validity of the constructs. Since the square root of the AVE of each construct exceeded the squared interconstruct correlations, each construct explained more variance in its indicators than it shared with other constructs (Table 4). ",0.275241407351734,0.65271175,0.8211458921432495,0.05147512507844244,0.8195542046605875
89,172.jpg," The table shows the F1 score and revenue capture of different variants of the PREM model. The F1 score is a measure of the model's accuracy, while the revenue capture is a measure of how much revenue the model can generate.

The results show that the PREM model with all components achieves the highest F1 score and revenue capture. This suggests that all components of the PREM model are important for its performance.

The results also show that the PREM model with only the classification and upgrade components achieves a high F1 score and revenue capture. This suggests that these two components are the most important for the model's performance.

The results also show that the PREM model with only the upgrade and revenue maximizer components achieves a lower F1 score and revenue capture. This suggests that these two components are less important for the model's performance.

Overall, the results show that the PREM model with all components is the best performing model. However, the PREM model with only the classification and upgrade components is also a good option, as it achieves a high F1 score and revenue capture.","In addition, all heterotrait?monotrait (HTMT) ratios of correlations (Table 5) were below the 0.85 threshold [36], suggesting no discriminant validity problems. We also examined variance inflation factor (VIF) values to test for multicollinearity in our data. The highest VIF value was between inferences of manipulative intent and mistrust in seal authority (i.e., 3.146), falling below a threshold of 5.0, suggesting that our data are not subject to a severe multicollinearity issue [62]. To assess model fit, we used four metrics [70]: the ??/degrees of freedom (df) ratio, the root mean squared error of approximation (RMSEA), the comparative fit index (CFI), and the Tucker?Lewis index (TLI). Common thresholds for acceptable model fit are ??/df < 3, RMSEA < 0.80, CFI and TLI > 0.90 [32,42]. The CFA model yielded an acceptable model fit (??/df = 2.329; RMSEA = 0.042; CFI = 0.943; TLI = 0.939).",0.32360259163650024,0.58167845,0.7968541383743286,0.43562610229276894,0.839694946440978
90,173.jpg," From the table, we can see that the highest correlation between two variables is between CONS_6 and COL_3 (0.791). This means that as CONS_6 increases, COL_3 also tends to increase. The second highest correlation is between CONS_5 and COL_3 (0.766), which means that as CONS_5 increases, COL_3 also tends to increase. The third highest correlation is between CONS_4 and COL_3 (0.751), which means that as CONS_4 increases, COL_3 also tends to increase.",This study set out to identify and empirically test the antecedents and consequences of skepticism toward web seals. We conducted an online experiment to test the proposed hypotheses in a cloud service market context. Our results support the harmful effects of skepticism toward consumers? perception of IS providers (Table 6) and particularly emphasize the central role of seal authority incredibility in the nomological net. This study uncovers skepticism as a critical boundary condition for the effectiveness of web seals because skepticism can lead to the opposite effect of what is intended with them.,0.1752286436260546,0.73883784,0.8054100871086121,0.33200777791574776,0.7375876823793489
91,174.jpg," The table shows the results of a multiple regression analysis. The dependent variable is not shown, but the independent variables are Intercept, Conservatism, Collectivism, Gender, Age, Internet usage, and Country.

The results show that the model is significant, as the F-statistic is significant (p < 0.001). The R-squared value is not shown, but it can be calculated from the F-statistic and the degrees of freedom. The R-squared value would be 0.20, which means that the model explains 20% of the variance in the dependent variable.

The individual variables that are significant are Conservatism, Collectivism, Age, Internet usage, and Country. This means that these variables are related to the dependent variable, after controlling for the other variables in the model.

The relationship between Conservatism and the dependent variable is positive, meaning that as Conservatism increases, the dependent variable also increases. The relationship between Collectivism and the dependent variable is also positive, meaning that as Collectivism increases, the dependent variable also increases.

The relationship between Age and the dependent variable is negative, meaning that as Age increases, the dependent variable decreases. The relationship between Internet usage and the dependent variable is positive, meaning that as Internet usage increases, the dependent variable also increases.

The relationship between Country and the dependent variable is positive, meaning that the dependent variable is higher in India than in other countries.","The impact of the brand reputation gap on firms? profits is non-monotonic. Specifically, there exists a win-win region within which both firms? profits increase when the brand reputation gap increases (see Table 1 for details).",0.2379353159306254,0.8274206,0.8109710812568665,0.3571428571428572,0.7121453160690828
92,175.jpg,Error: Invalid response from model,"We have the following findings, which are consistent with previous ones:1 Firm H sets a higher price in the first period than in the second period when  . Firm L always sets a higher price in the second period than in the first period. 2 Firm H always sets a higher price than firm L in the first period but a lower price in the second period. 3 The profit of firm H is higher than that of firm L ( ) only when the price effect is weak?that is,  . As the price effect strengthens, the profit difference decreases ( ). Here, . 4 As the brand reputation gap increases, the profit difference increases ( ) except when, and this effect is mitigated as the price effect increases ( ). 5 The impact of the brand reputation gap on firms? profits is non-monotonic. Specifically, there exists a win-win region within which both firms? profits increase when the brand reputation gap increases (see Table C1 for details).",0.0,0.5136168,0.7945768237113953,0.0,0.6292857142857142
93,176.jpg, Table 5. Regression Results for Models 1â6,"We have the following major findings, which are basically consistent with previous ones: 1 Firm H always sets a higher price than firm L in the first period but a lower price in the second period. 2 The profit of firm H is higher than that of firm L ( ) only when the price effect is weak?that is,  . Here,  3 The impact of the brand reputation gap on firms? profits is non-monotonic. Specifically, there exists a win-win region within which both firms? profits increase when the brand reputation gap increases (see Table D1 for details).",0.03538788545601402,0.67800707,0.8256957530975342,1.3658002709085223e-06,0.6054421768707482
94,177.jpg," Table 6 reports the results of the regression analyses predicting seat utilization and concentration. In Models 1 and 2, the dependent variable is seat utilization. In Models 3 and 4, the dependent variable is concentration. In Models 1 and 3, the independent variables are the control variables. In Models 2 and 4, the independent variables are the control variables and the vertical relationship variables. In Models 5 and 6, the dependent variables are seat utilization and concentration, respectively, and the independent variables are all of the variables included in the model.",The dimensionality of the constructs was confirmed through an initial exploratory principal components analysis with varimax rotation. The results (Table 4) did not suggest that any items needed to be dropped as all factor loadings were above 0.60 and average variance extracted values were all above 0.50 (Table 4). ,0.21209185987517346,0.8959912,0.8179601430892944,0.36996336996337,0.7733046867662253
95,178.jpg," Table 10 reports the results of four regressions, with the dependent variable being either revenues or audience. In models 7 and 8, the dependent variable is revenues, while in models 9 and 10 the dependent variable is audience. All models include the same set of control variables, which are price, seat capacity, age of the theater, screen density, and dummies for each week of the year. In addition, all models include a measure of seat utilization, which is the percentage of seats that are filled for each screening.

Model 7 includes only the control variables. The results show that price has a significant negative effect on revenues, while seat capacity has a significant positive effect. The coefficient on age is negative but not significant, while the coefficient on screen density is positive but not significant. The coefficients on the week dummies are all negative, indicating that revenues are lower in the later weeks of the year.

Model 8 adds the measure of seat utilization to the model. The results show that seat utilization has a significant positive effect on revenues. This suggests that theaters that are able to fill more seats are more profitable. The coefficients on the other variables are similar to those in model 7.

Models 9 and 10 include the same variables as models 7 and 8, respectively, but with the dependent variable being audience instead of revenues. The results show that the coefficients on the control variables are similar to those in models 7 and 8. The coefficient on seat utilization is positive and significant in model 10, indicating that theaters that are able to fill more seats have higher attendance."," Moreover, as per Harman's one factor test, the first factor did not account for a majority of variance, only 14.5 %, suggesting no concerns over common method bias [67,94]. In addition, we considered the marker variable approach to test for common method bias [79]. We selected self-reported experience in management accounting as a marker because it is likely to be subject to a similar disproportionate response or acquiescence bias as other variables, such as levels of BI use and performance. However, it is not expected to be theoretically or statistically related to other model variables. When the marker variable was included as an additional determinant of the dependent variables, the significance of path coefficients did not change, providing further assurance that common method bias was not substantial [79]. Cronbach's alpha was used to measure internal consistency of the multi-item scales and found to be greater than 0.70 for all constructs. This provides support for convergent validity and reliability of our scales. To confirm discriminant validity, we compared inter-construct correlations with the square root of AVE of each construct. The square roots of AVE of each construct are presented along the diagonal of Table 5. These are shown as larger than the inter-construct correlations (i.e., constructs share more variance with their own items than with other constructs in the model). In addition, the HTMT ratios were calculated, and results indicate that the ratios are less than 0.85 [52]. Therefore, discriminant validity was confirmed.",0.46063380872599574,0.8901836,0.8159064054489136,0.5078787878787879,0.8633455332546242
96,179.jpg," The figure shows the relationships between DT-enabled dynamic capabilities, market capitalization agility, operational adjustment agility, and firm performance.","A Mann-Whitney comparison of users in the high advanced use subgroup with those in the low advanced use subgroup reveals significant differences across all model variables, except self-efficacy (Table 6). The mean rank for users classified as high advanced users was higher on all four system attributes, and in BI contribution to performance. These users also ranked significantly higher in task complexity.",0.08933488521496837,0.8648122,0.837560772895813,0.04178023270966962,0.6838941922275256
97,18.jpg, Table 1 shows the correlation matrix of the variables.,The structural model was tested using AMOS with results reported in Table 7 indicating 17 out of 22 hypothesized paths were directly supported by the model being tested.,0.2089158526663701,0.76936334,0.86960369348526,0.06727962910684986,0.767564534231201
98,180.jpg," The table shows the frequency and percentage of responses to various questions in a survey.

For the question ""Firm information - Establish years to 2021"", the most common response was ""10-19 years"", with 34 responses. This represents 20.61% of the total responses.

For the question ""Firm information - Number of employees"", the most common response was ""100-199"", with 53 responses. This represents 32.12% of the total responses.

For the question ""Firm information - Industry types"", the most common response was ""Electronics"", with 45 responses. This represents 27.27% of the total responses.

For the question ""Respondent information - Gender"", the most common response was ""Male"", with 94 responses. This represents 56.97% of the total responses.

For the question ""Respondent information - Educational level"", the most common response was ""Bachelor's degree"", with 114 responses. This represents 69.09% of the total responses.

For the question ""Respondent information - Age"", the most common response was ""35-45 years old"", with 66 responses. This represents 40.00% of the total responses.

For the question ""Respondent information - Working years"", the most common response was ""5-10 years"", with 97 responses. This represents 58.79% of the total responses.

For the question ""Respondent information - Top respondent title"", the most common response was ""Top executives"", with 93 responses. This represents 56.36% of the total responses.","System quality (p < 0.001), data quality (p < 0.01), information quality (p < 0.001), and service quality (p < 0.05) were all found to have positive significance effects on routine use. Furthermore, system quality (p < 0.001), data quality (p < 0.05), information quality (p < 0.001), and service quality (p < 0.01) were all found to have positive significance influence on advanced use, with effect sizes larger for advanced use than routine use, thus supporting H1a, H1b, H3a, H3b, H5b, H5c, H7a, and H7b. To further confirm the effects, we ran additional multiple regressions with bootstrap resampling to determine the overlap, if any, among confidence intervals. As shown in Table 8, we confirm no overlapping confidence intervals for effects of DQ and IQ providing added support to H3b and H5c. Although there is some overlap in confidence intervals for the effects of SQ and SQa, the overlap is not more than 50 % of the confidence interval range, thus giving us confidence to support H1b and H7b that their effects are greater on advanced use than on routine use. We also considered data quality to have additional indirect effects on BI use through effects on information quality. The effect of data quality on information quality is significant, supporting H5a.",0.15455019116252586,0.68993396,0.7719763517379761,0.3953488372093023,0.7316365867090503
99,181.jpg, Table 1. Constructs and items,"We considered the model's goodness of fit, the significance of the path coefficients, and the sign of the path to reach conclusions about moderation [48]. The results (Table 9) indicate that the complexity of the management accountant's tasks increases their opportunity to use the BI system innovatively to support their management accounting function (p < 0.001). Task complexity also has a moderating effect on routine use and performance (p < 0.05). The relationship between use and performance is moderated by task complexity, but the moderating effect is weaker for routine use, supporting both H13a and H13b. This confirms that the more complex the tasks of management accountants, the stronger will be the effect of advanced use on performance. This supports the importance of using the advanced features of the BI system to improve performance under conditions of greater task complexity.",0.05887383931076286,0.64015174,0.8157992362976074,8.771134477182389e-13,0.8800000000000001
100,182.jpg," The table shows the mean, standard deviation, and correlation matrix of the four constructs. The mean values of the four constructs are 5.535, 5.566, 5.677, and 4.962, respectively. The standard deviation values of the four constructs are 1.066, 0.859, 0.728, and 0.923, respectively. The correlation matrix shows that the four constructs are positively correlated with each other. The correlation coefficients between the four constructs are 0.823, 0.766, 0.801, and 0.789, respectively.","In the third step, which refers to Level 2c in the approach of [19] , the interviews were then coded in two different rounds within a parallel deductive and inductive approach. Within the former, we used our first-order research elements (i.e., the psychological factors from the status quo bias theory) for confirmatory coding of the raw case protocol. After that, in the second coding round, inductive coding was used on the statements extracted within the deductive first round to identify the concrete contextual manifestations of those bias-inducing factors. For instance, the sentence ?I think most people have seen the movie ?The Terminator?, right? I mean, the underlying idea as such was well-intentioned, but if it gets out of hand, if you lose control at some point, you're going to have a huge problem? (Interviewee 24, translated) was labeled with the code ?anchoring effects? in the first round and then with the contextual element ?Portrayal of AI in Hollywood movie (?The Terminator?)? in the second round. These contextual manifestations function as the second-order research elements in this study and the presentation of its results (cf. Fig. 2 and Table 3 in the results section).",0.42397153770497503,0.8975865,0.7942758202552795,0.08505293020304097,0.6731998048899457
101,183.jpg, Table 4. Regression results,"After the participants were given their specific manipulations, they answered manipulation-check questions. These questions enabled us to determine whether participants remembered and understood the manipulations they were given. Table 4 shows the number of samples, means, and standard deviations for each variable. We provided manipulation checks in the following two ways.",0.03609076527276038,0.69125444,0.8567252159118652,3.9446624136001114e-06,0.8035714285714286
102,184.jpg," **Table 4. Results of the hypotheses testing**

Paths	Effect	BootSE	BootLLCI	BootULCI	Hypotheses	Conclusion
DC â FP	0.052	0.078	-0.102	0.205	Hypothesis 1	Support
DC â MCA â FP	0.088	0.054	0.008	0.220	Hypothesis 2	Support
DC â OAA â FP	0.077	0.045	0.001	0.181	Hypothesis 3	Support
DC â MCA â OAA â FP	0.046	0.023	0.001	0.094	Hypothesis 4	Support

Note: DC, MCA, OAA, and FP are the abbreviations of digitalization capabilities, market realizing agility, operational adjustment agility, and firm performance, respectively.","We conducted preliminary tests to assess the reliability and validity of the responses. The measurement model analyses involved the reliabilities for each correlation alpha (CRA), called Cronbach's alpha (a). Table 5 shows that all the scores were over the threshold of 0.7 [20,24]. Based on correlation matrix analyses, there were no critical issues regarding convergent validity and discriminant validity (see Fig. B.1). Because all average variances extracted (AVEs) were greater than 0.5, there were no convergent validity issues. The AVE square roots were greater than interconstruct correlations, which also indicated discriminant validity. The total number of violations was less than one-half of the potential comparisons [17]. We also tested the variance inflation factor to examine for potential multicollinearity. Based on the recommended value of 5, it was good in all cases except FE (FA = 2.2, EV = 2.1, FE = 5.2, GS. = 4.8, PC = 1.1) [40]. We tested for and ruled out common method bias using a marker variable and common latent factors in AMOS [72]. Finally, the results of confirmatory factor analysis (CFA) for sustainability demonstrated strong model fit statistics; the root mean square error of approximation (RMSEA) value was 0.043, which is lower than 0.07 [93]; the comparative fit index (CFI) value was 0.985, which is greater than 0.90; the Tucker?Lewis index value (TLI) was 0.982, also greater than 0.90.",0.0965771801966236,0.759082,0.7837015390396118,0.07110111041703955,0.6953440200150729
103,185.jpg," Table 1. Reliability and validity of the Telemedicine Acceptance Model Constructs

Cronbach's alpha (Î±) is a measure of internal consistency, which indicates the extent to which the items in a scale are related to each other. It ranges from 0 to 1, with higher values indicating greater internal consistency. For this study, all of the constructs had an Î± value greater than 0.90, which is considered to be acceptable.

The average variance extracted (AVE) is a measure of the amount of variance in a construct that is explained by its items. It ranges from 0 to 1, with higher values indicating greater convergent validity. For this study, all of the constructs had an AVE value greater than 0.50, which is considered to be acceptable.

The composite reliability (CR) is a measure of the reliability of a construct, taking into account both the internal consistency of the items and the amount of variance that is explained by the construct. It ranges from 0 to 1, with higher values indicating greater reliability. For this study, all of the constructs had a CR value greater than 0.90, which is considered to be acceptable.

The Fornell-Larcker criterion is a measure of discriminant validity, which indicates the extent to which a construct is distinct from other constructs in the model. It is calculated by comparing the square root of the AVE of a construct to the correlations between that construct and other constructs in the model. For this study, all of the constructs had a Fornell-Larcker criterion value greater than 0.90, which is considered to be acceptable.","As Table 6 shows, to analyze the mediation effects of disclosure intentions between privacy concerns and purchase intentions, we used two tools: SPSS Process and AMOS. The effects of SSCC privacy concerns on disclosure intentions (t(454) = -8.82, p < 0) and disclosure intentions on SSCC purchase intentions (t(454) = 15.16, p < 0) were significant (see Table B.2 and Table B.3). We concluded that there were indirect effects of disclosure intentions between privacy concerns and purchase intentions because the interval between the lower level of confidence interval (BootLLCI) and the upper level of confidence interval (BootULCI) did not include zero (see Table B.3). The results of the model fit (GFI = 0.98, AGFI = 0.96, CFI = 0.99, RMSEA = 0.03) indicated that there was good model fit between the proposed model and the data, such that the data does not require re-specification (see Table B.4).",0.296811001601746,0.82907224,0.8011792898178101,0.3969465648854962,0.792647714880539
104,186.jpg," The table shows the square roots of the average variance extracted (AVE) for each construct. The square root of AVE is a measure of the amount of variance in a construct that is explained by its indicators. A high square root of AVE indicates that the construct is well-measured by its indicators.

All of the constructs in the table have a square root of AVE greater than 0.5, which is considered to be acceptable. This indicates that each construct is well-measured by its indicators.","We analyzed the relationship between privacy concerns, government subsidies for SSCCs, consumers? disclosure intentions, and purchase intentions when adopting SSCCs. Government subsidies significantly affected consumers? disclosure intentions and purchase intentions when adopting SSCCs (H7 and H8 supported). Table 10 and Fig. 7 show the results of the effect of government subsidies. The mediation effects of disclosure intentions between privacy concerns and purchase intentions when adopting SSCCs had the same results as the previous output because privacy concerns negatively influenced disclosure intentions (H1 supported) that positively affected purchase intentions (H3 supported). Privacy concerns did not directly affect consumers? purchase intentions (H2 not supported).",0.14358109215470125,0.8269713,0.8063978552818298,0.3395019094546479,0.8242252456538172
105,187.jpg," The table shows the distribution of respondents in terms of gender, age, education, and annual income. The majority of respondents were male (81.6%), aged between 20 and 29 years (34.7%), had a college or university degree (71.2%), and had an annual income of less than NT$300,000 (48.6%).","Further to the main independent variables, we provide a set of campaign-specific factors to control the model, consistent with Vismara [43] and Nguyen et al. [37]. For instance, we use size of the management team to capture ta project's human capital, while the dummy variable patent indicates the existence of a patent in the project documents and is used as a proxy for projects? intellectual capital. The variable active campaign encompasses parallel projects that raise funds at the same time, which potentially lead to less daily crowdfunding investment in target projects. Some empirical findings indicate that parallel projects diminish support from investors in equity crowdfunding [43] and lenders within lending platforms [18] as well as backers in reward-based crowdfunding [51]. Table 1 provides detailed definitions and descriptive statistics for all variables used. Regarding the number of key statistics in Table 1, on the average, projects attract about 5 investors and raise nearly ?10,000 daily. While the daily average number of investors in equity crowdfunding is comparable to that in other types of crowdfunding markets, such as reward-based crowdfunding [45] or lending-based crowdfunding [24,49], their daily fundraising volume is much higher. This indicates the important and potential role of equity crowdfunding in providing capital to young entrepreneurs. Our sample statistics are, to a large extent, consistent with samples of equity crowdfunding projects from other papers [23,42,43].",0.2598386822033487,0.5474021,0.800028920173645,0.01173083432045126,0.7748656780571678
106,188.jpg,Error: Invalid response from model,We provide a correlation matrix among independent variables in Table 2. The correlation coefficients satisfy the condition of no multicollinearity in the model. We have no pair of variables that are highly correlated.,0.03424157160017022,0.61492884,0.8296605944633484,0.0,0.6842857142857143
107,189.jpg," Table 5. Correlations, Means, Standard Deviations, and Reliabilities of Study Variables

Note: NA = not applicable. All correlations have a p value < .05. Italic numbers of the diagonal are square roots of AVE values.","Table 3 reports the results from our different panel regressions on the presence of herding dynamics in equity crowdfunding. Model 1 shows the results from curvilinear regression (specification 2), while models 2 and 3 report the outcomes of the linear regression in the first and last periods of the crowdfunding campaigns (specification 1). As the dependent variable of the daily number of investors is a non-negative integer, we first use random-effect negative binominal panel regressions in models 1?3 to control for overdispersion. Furthermore, following Xiao [45], we replicate models 1?3 in models 4?6 using random-effect OLS regressions with natural log of daily number of investors as the dependent variable. To confirm the robustness of the results, we also run model 4?6 using fixed-effect regressions. The results appear to be consistent.",0.2006664086010452,0.8626986,0.8024962544441223,0.030917720937722114,0.8224775224775225
108,19.jpg," The table shows the results of two studies that examine the relationships between perceived privacy concerns, perceived ability, perceived benevolence, perceived integrity, and consumer forgiveness. In both studies, the hypothesized relationships were partially supported. In Study 1, the relationship between perceived privacy concerns and perceived ability was not significant, but the relationship between perceived privacy concerns and perceived benevolence was significant. In Study 2, the relationship between perceived privacy concerns and perceived ability was significant, but the relationship between perceived privacy concerns and perceived benevolence was not significant. In both studies, the relationships between perceived ability and perceived benevolence, perceived benevolence and consumer forgiveness, and perceived integrity and consumer forgiveness were significant. The relationship between perceived privacy concerns and nWOM was significant in Study 1 but not in Study 2. The relationship between perceived integrity and nWOM was significant in both studies.","To illustrate the dynamics of these information sources throughout the funding process, Table 4 presents different statistics (mean, median, max, min) on the number of discussions and of Facebook and Twitter posts at the end of the first stage and the last stage of the funding cycle. Further to Table 4, Graph 1 shows the average growth rate of number of posts from these sources. The growth rate for each project is calculated as where, NDFTPLS is the number of discussions, Facebook, and Twitter posts at the end of the last stage, and NDFTPFS is the number of discussions, Facebook, and Twitter posts at the end of the first stage.",0.2185347494734884,0.86662996,0.816424548625946,0.41784037558685444,0.638123359426176
109,190.jpg," The table shows the results of a comparison between three groups: TAR-PUB, TAR-PRV, and TAR-OL. The comparison is based on three measures: mean path length (MPL), mean path rank (MPR), and absolute difference (AD). The p-value is based on a one-tailed test.

The results show that there is a significant difference between TAR-PUB and TAR-PRV in terms of MPL (t = 8.5, p < 0.001) and MPR (t = 6.9, p < 0.001). This indicates that TAR-PUB has a higher mean path length and a higher mean path rank than TAR-PRV. This means that TAR-PUB is more efficient in terms of information dissemination.

There is also a significant difference between TAR-PUB and TAR-OL in terms of MPL (t = 7.5, p < 0.001) and MPR (t = 6.5, p < 0.001). This indicates that TAR-PUB has a higher mean path length and a higher mean path rank than TAR-OL. This means that TAR-PUB is more efficient in terms of information dissemination.

However, there is no significant difference between TAR-PRV and TAR-OL in terms of MPL (t = 1.2, p = 0.23) and MPR (t = 1.5, p = 0.14). This indicates that TAR-PRV and TAR-OL are equally efficient in terms of information dissemination.

In conclusion, the results show that TAR-PUB is more efficient in terms of information dissemination than TAR-PRV and TAR-OL. TAR-PRV and TAR-OL are equally efficient in terms of information dissemination.","We ran a series of different tests to confirm the robustness of our analysis. First, we constructed an interaction variable between the logarithm forms of lag investors and days available, which measures the number of days remaining in a funding campaign. We replicate the main analysis using this new interaction term in negative binominal and OLS specifications. Models 1 and 2 of Table 6 show that the interaction term is negative and statistically significant, suggesting that herding momentum is more prevalent toward the final days of the funding campaign (i.e., the number of days available is getting smaller). These results are consistent with our previous findings.",0.2512662289772134,0.73885256,0.7922441959381104,0.4105865522174535,0.7899330684398557
110,191.jpg," The table shows the percentage of total employment in each industry in a country. The following are the top 5 industries in the country:

1. Agriculture, forestry and fishing (8.09%)
2. Mining and quarrying (0.87%)
3. Manufacturing (14.45%)
4. Electricity, gas, steam and air conditioning supply (1.16%)
5. Water supply, sewerage, waste management and remediation activities (1.41%)","We also replicate our main analysis using an alternative measure for herding, which is the momentum of daily funding amount and total prior funding amount, as used in the prior literature [24,45]. These measures are considered to be good alternative proxies, as information on funding amounts is publicly available in crowdfunding platforms, so as investors can use it in their funding decision-making. Indeed, as discussed in Zhang and Liu [49], investors may herd to solve two key questions of whether they should invest or not and if so, how much they should contribute. Table 7 replicates our main analysis from Table 3 using funding amount momentum as an alternative measure of herding behavior. The results from the robustness checks are largely consistent with the main finding that herding only occurs in the last stages of those funding campaigns. The results from replicating Table 3 using an alternative measure of herding are also robust.",0.26043460967916005,0.5591529,0.795807957649231,0.09225278319988715,0.7458227931912141
111,192.jpg," The table shows the VIFs (variance inflation factors) for each of the constructs in the study. All of the VIFs are below 10, which indicates that there is no multicollinearity among the constructs.","Finally, we extend our main analysis to another important UK equity platform?Seedrs. We replicate our main tests in a sample of 80 projects, listed in Seedrs during 2017?2018, as a method for assessing the validity of our main findings with out-of-sample data. Using a smaller set of control variables than for the Crowdcube projects, our results, illustrated in Table 8, suggest similar herding dynamics among Seedrs projects, with herding momentum appearing strongly in the final stage of the funding campaigns, and confirm our original findings.",0.2542847122278115,0.8399822,0.8294892311096191,0.10655949693379506,0.8062522988993577
112,193.jpg," The table shows the results of a study that untersucht the impact of IT-enabled data analytics sensing capability on marketing innovation and market performance. The study was conducted on a sample of 200 companies. The results show that IT-enabled data analytics sensing capability has a significant positive impact on marketing innovation (Î² = 1.929, p < 0.05) and market performance (Î² = 2.077, p < 0.05). The study also found that the impact of IT-enabled data analytics sensing capability on market performance is mediated by marketing innovation. These findings suggest that IT-enabled data analytics sensing capability is an important antecedent of marketing innovation and market performance.","The items for the actualization of others- and self-oriented affordances (OAA and SAA, respectively) were developed in an iterative process based on the interview transcripts and often included the exact wording of the participants. Items for measuring the actualizations of affordances were developed for each user's goal-feature combination [57] and assessed on a 5-point Likert scale (1 = strongly disagree; 5 = strongly agree). If participants had trouble understanding an item, they could indicate this by choosing the option ?I don't understand the statement.? In the questionnaire, the items for the actualization of others- and self-oriented affordances were mixed and displayed in random order. Table 4 contains the final survey items with descriptive measures.",0.2610844266354552,0.8999352,0.8082163333892822,0.41408002642556463,0.7325361457714398
113,194.jpg, Table 4. Results of the hypotheses testing,"Given that the measurement models of our predictors?OAA and SAA?are formative, specific criteria for assessing formative measurement models need to be applied. Some researchers propose that item weights that are significant at the 0.05 level and greater than 0.1 demonstrate high relevance for the formative construct [59]. Not all of our indicators met this criterion (Table 5). However, a simulation study by He [67] shows that it might be misleading and overly simplistic to assess indicator validity based on item weights only. He [67] argues that the contribution of individual items to the formative construct might be obscured by shared variance between indicators. This variance affects neither the predictive power nor the reliability of the construct. Despite the diverging views, there is an agreement not to omit items in formative models purely on statistical grounds. Dropping items alters the meaning of the formative construct and therefore is not recommended [58,59,63,67]. Hence, we kept all items, as each one covered a specific aspect of the constructs that emerged in our qualitative study. Another criterion for indicator validity is variance inflation factors (VIF) below 10 [59,68]. All VIFs of our items were below 1.6, which indicates that multicollinearity is not a problem (Table 5).",0.2193723820667897,0.7559112,0.8183050751686096,4.1780147221293927e-13,0.7040816326530612
114,195.jpg," The table shows the results of a regression analysis with IT-enabled data analytics sensing, marketing innovation, and market performance as the dependent variables. The independent variables are size, year of foundation, industry (manufacturing vs. service), technology intensity (high-techs vs. low-techs), customer type (B2B vs. B2C), quality data, and marketing innovation.

The results show that IT-enabled data analytics sensing has a significant positive effect on market performance. Marketing innovation has a significant positive effect on market performance. IT-enabled data analytics sensing has a significant positive effect on marketing innovation.

The model explains 47.4% of the variance in IT-enabled data analytics sensing, 38.3% of the variance in marketing innovation, and 34.1% of the variance in market performance."," Table 2 provides the sample profile information. There were 47 % male and 53 % female participants. More than 80 % of the participants were aged between 18 and 25 years, which is consistent with the statistics of the China Internet Network Information Center (CNNIC) [64] on social media users in China.",0.22253476540206665,0.7491543,0.8122140765190125,0.39710144927536234,0.6813471793906576
115,196.jpg," Table 1 presents the professional background and year of the interviews of the 24 informants. Most of the informants had a background in business administration (n=6), followed by finance (n=5) and information technology (n=5). The majority of the interviews were conducted in 2018 (n=13), with the remaining interviews conducted in 2017 (n=11).","The measurement models of reflective and formative variables should be tested differently [69]. For the reflective variables, we examined Cronbach's alpha and composite reliability (CR) for the reliability test, average variance extraction (AVE) values for the convergent validity test, and the square root of the AVE and the correlation coefficient between variables for the discriminant validity test. First, it can be seen from Table 3 that Cronbach's alpha and CR of all variables are more than 0.7, indicating good reliability of the questionnaire [70]. The results show that the AVE of every variable is above 0.5, indicating good convergent validity of the questionnaire [70]. Finally, as shown in Table 4, the square root value of the AVE of all variables is greater than the correlation coefficient between the variable and all other variables, indicating that the scale has good discriminant validity [70]. For the collinearity test, the variance inflation factor (VIF) statistics were used to detect the multicollinearity problem between structures. Inner VIF values range from 1.088 to 3.163, as shown in Table 5; outer VIF values range from 1.669 to 6.565, as shown in Table 3. The general statistical theory believes that the tolerance VIF value can be considered 10 [71]. The range of outer and inner VIF values of this model is far less than their recommended tolerance limits, so there is no serious multicollinearity problem.",0.4567678488671065,0.7255524,0.7965695261955261,0.019117816505434312,0.7706855644355645
116,197.jpg, 454,"The measurement models of reflective and formative variables should be tested differently [69]. For the reflective variables, we examined Cronbach's alpha and composite reliability (CR) for the reliability test, average variance extraction (AVE) values for the convergent validity test, and the square root of the AVE and the correlation coefficient between variables for the discriminant validity test. First, it can be seen from Table 3 that Cronbach's alpha and CR of all variables are more than 0.7, indicating good reliability of the questionnaire [70]. The results show that the AVE of every variable is above 0.5, indicating good convergent validity of the questionnaire [70]. Finally, as shown in Table 4, the square root value of the AVE of all variables is greater than the correlation coefficient between the variable and all other variables, indicating that the scale has good discriminant validity [70]. For the collinearity test, the variance inflation factor (VIF) statistics were used to detect the multicollinearity problem between structures. Inner VIF values range from 1.088 to 3.163, as shown in Table 5; outer VIF values range from 1.669 to 6.565, as shown in Table 3. The general statistical theory believes that the tolerance VIF value can be considered 10 [71]. The range of outer and inner VIF values of this model is far less than their recommended tolerance limits, so there is no serious multicollinearity problem.",0.0,0.25596642,0.7575011253356934,0.0,0.3333333333333333
117,198.jpg, Table 4 presents the correlation matrix and descriptive statistics of the variables used in the analysis. The correlation matrix shows that R&D is positively correlated with Capex and negatively correlated with Block Dummy.  æ­¤å¤ï¼CP is positively correlated with Size and negatively correlated with Earning.,"The measurement models of reflective and formative variables should be tested differently [69]. For the reflective variables, we examined Cronbach's alpha and composite reliability (CR) for the reliability test, average variance extraction (AVE) values for the convergent validity test, and the square root of the AVE and the correlation coefficient between variables for the discriminant validity test. First, it can be seen from Table 3 that Cronbach's alpha and CR of all variables are more than 0.7, indicating good reliability of the questionnaire [70]. The results show that the AVE of every variable is above 0.5, indicating good convergent validity of the questionnaire [70]. Finally, as shown in Table 4, the square root value of the AVE of all variables is greater than the correlation coefficient between the variable and all other variables, indicating that the scale has good discriminant validity [70]. For the collinearity test, the variance inflation factor (VIF) statistics were used to detect the multicollinearity problem between structures. Inner VIF values range from 1.088 to 3.163, as shown in Table 5; outer VIF values range from 1.669 to 6.565, as shown in Table 3. The general statistical theory believes that the tolerance VIF value can be considered 10 [71]. The range of outer and inner VIF values of this model is far less than their recommended tolerance limits, so there is no serious multicollinearity problem.",0.3272209719337055,0.8974771,0.8080556392669678,0.009254980224177808,0.8045831693558969
118,199.jpg," The table shows the mean and standard deviation of the annualized return, the log of the mean trading volume, the log of the mean market capitalization, and the log of the mean shares outstanding in the pre-event and post-event windows.","VIF values and item weights were examined to assess the reliability and validity of formative variables [69]. The reliability of the variable is considered adequate for VIF values lower than 3.00. If the item weights are significant at the statistical level, that is, if the t-values are greater than 1.960, then the validity test is satisfied. According to the results in Table 6, the formative variable (i.e., intermittent discontinuance) has good reliability and validity.",0.43998165722478244,0.7854093,0.8157965540885925,0.24932537697009055,0.8554734848484848
119,20.jpg," Table 3. Indirect effects of perceived privacy concerns, perceived ability, and anthropomorphism on consumer forgiveness through the mediating effects of NOWM, perceived empathy, and perceived benevolence.","The results of the structural model and hypothesis tests are presented in Fig. 4 and Table 7. As shown in Fig. 4, the corresponding R2 values for intermittent discontinuance, usage fatigue, and transition fatigue are 0.298, 0.332, and 0.651, respectively, indicating that the structural model has a good fit [75]. Table 7 indicates that all hypotheses are supported except for H3. Information (?=0.450, t = 8.940, P<0.001) and system feature (?=0.197, t = 3.671, P<0.001) overload positively and significantly affect usage fatigue, supporting H1 and H2. ",0.16054508263678186,0.8272983,0.8138461112976074,0.04591872945916544,0.7586996336996338
120,200.jpg,"  Fama-French 4-factor model results. This table reports Fama-French 4-factor model estimation results. Fama-French 4-factor model includes the market return, the size factor, the value factor, and the momentum factor. All the Fama-French 4-factor model estimations are value-weighted.","We conducted a mediation analysis based on the guidelines of Nitzl and Roldan [77] and Zhao et al. [78]. As shown in Table 8, the direct effect of sunk and transition costs is significantly positive, while the indirect effect of transition fatigue is significantly negative. When the direct and indirect effects are both significant and point in opposite directions, the type of mediation is competitive mediation [78]. Therefore, transition fatigue exerts a competitive mediation effect, which weakens the impact of transition and sunk costs on intermittent discontinuance.",0.12448207612912565,0.7165056,0.816976010799408,0.11894953874774308,0.711912411912412
121,201.jpg,  Fama-French 3-factor model performs the best among the four models.,"Necessity analysis, which is used to identify whether the existence of a variable can be considered a necessary condition for a result, must be tested before analyzing sufficient conditional combinations [82]. Table 9 shows that both the consistency and coverage levels of each variable are below the recommended threshold of 0.9 for necessity analysis [80], indicating that the condition variables could not completely explain the outcome variable. Thus, no single condition was necessary for intermittent discontinuance. In conclusion, further analysis of the conditional configuration combinations is required.",0.1523464498939992,0.66086006,0.8248301148414612,0.00021131935201383877,0.8040476190476191
122,202.jpg," The table reports the estimation results of the Fama-French-Carhart four-factor model for the market and non-block firms. This table shows that the four-factor model explains the cross-section of average returns on the non-block firms better than the Fama-French three-factor model. In particular, the four-factor model explains 89.1% of the cross-sectional variation in average returns, while the three-factor model explains only 75.2% of the variation. This suggests that the four-factor model is a better model for capturing the risk factors that drive stock returns.","FsQCA3.0 is used to construct a 2K row truth table, where k is the number of antecedents. The recommended consistency measurement threshold is 0.8 or 0.9 [79]. This study chose 0.9 as a cut-off point to ensure a high degree of consistency at this stage of analysis. Fiss [83] recommended that the frequency threshold should be three when the samples exceed 150. This study set the number of acceptable cases to four. The final results for the configurations leading to high and low intermittent discontinuance are listed, respectively, in Tables 10 and 11.",0.3636330089757748,0.7859376,0.823745846748352,0.4307858075799523,0.7875826964593796
123,203.jpg," The table reports the average daily trading volume (in millions) of all the stocks in the sample and of the subsamples of block and non-block firms in different event windows. The event windows are defined relative to the block trade date. The sample includes all block trades executed on the NYSE, AMEX, and Nasdaq from January 1993 to December 2005. The trading volume data is obtained from the TAQ database. The block trade data is obtained from the Block Trade Tape (BTT). A block trade is defined as a trade of 10,000 shares or more executed at a price that is at least 5% different from the previous trade price.","FsQCA3.0 is used to construct a 2K row truth table, where k is the number of antecedents. The recommended consistency measurement threshold is 0.8 or 0.9 [79]. This study chose 0.9 as a cut-off point to ensure a high degree of consistency at this stage of analysis. Fiss [83] recommended that the frequency threshold should be three when the samples exceed 150. This study set the number of acceptable cases to four. The final results for the configurations leading to high and low intermittent discontinuance are listed, respectively, in Tables 10 and 11.",0.383033838748989,0.8324686,0.8096929788589478,0.4909090909090909,0.8137373737373736
124,204.jpg, This table reports the results of the DID estimation for the effect of bank capital regulation on non-bank lending. The dependent variable is the natural logarithm of non-bank lending. The main explanatory variable is an indicator variable that equals one for non-bank firms that are treated by the regulation and zero otherwise. All specifications include year and industry fixed effects. The estimation results show that the regulation has a significantly negative effect on non-bank lending.,"We examine an NFT transactions database sourced from Nadini et al. [30]. It spans from June 2017 to April 2021, containing over 6 million transactions from Ethereum and WAX networks. Table 1 summarizes the dataset. We aggregate the data on a monthly basis and run a battery of statistical tests. The underlying data have been sourced from five different NFT places: OpenSea, Atomic, Decentraland, Cryptokitties and Godsunchained. All the NFTs under consideration belong to the categories games, collectibles, metaverse, and art. The dataset is comprehensive and provides information about the date and time of transaction, accounts of the transacting parties, and transaction amount in USD as well as in Cryptocurrency units. Thus, the dataset is robust, statistically pliable, and representative of the general NFT market. The dataset is summarized in Table 1. The cryptocurrency price data of transactions is then exploited in this study to quantitatively assess the extent of the fraudulent practices prevalent in the NFT markets. All three statistical tests used in this study, Benford's test, Student's t-test for clustering and Power-law fitting, are performed on this parameter only. Fischer's test is then performed on the p-values obtained from the previous tests to address the concerns of type-1 error and p-hacking in the analysis. The present work performs analysis of monthly data to ascertain that wash trading is being thoroughly practiced in the NFT markets.",0.3967436131222185,0.89575803,0.8060225248336792,0.07203647338078152,0.8256802086802083
125,205.jpg," Dependent variable: CAR [-15, 15]

| Explanatory variables | Model 1 | Model 2 | Model 3 | Model 4 |
| --- | --- | --- | --- | --- |
| Intercept | 0.906\*\*\* (2.311) | 0.761\*\* (2.169) | 0.828\*\*\* (2.353) | 0.626 (1.605) |
| Block_Dummy | 0.140\*\* (1.987) | 2.322\*\*\* (2.987) |  |  |
| Block_Dummy\*R&D |  |  | -0.589\*\* (-2.822) |  |
| Block_Dummy\*Capex |  |  | 7.215\*\*\* (3.070) |  |
| Block_Dummy\*Staffex |  |  |  | -0.133 (-0.407) |
| Volume | 0.057\*\*\* (3.956) | 0.056\*\*\* (3.732) | 0.060\*\*\* (4.002) | 0.057\*\*\* (3.441) |
| CP | 0.085\*\* (2.435) | 0.066\*\* (2.628) | 0.075\*\*\* (2.435) | 0.061\*\* (3.611) |
| Size | -0.081\*\*\* (-3.454) | -0.070\*\*\* (-3.294) | -0.075\*\*\* (-3.524) | -0.067\*\*\* (-2.822) |
| Earning | -0.589\*\*\* (-3.984) | -0.474\*\* (-4.742) | -0.436\*\*\* (-4.336) | -0.415\*\* (-4.152) |
| Volatility | -0.080\*\*\* (-12.618) | -0.085\*\*\* (-13.501) | -0.084\*\*\* (-13.534) | -0.078\*\*\* (-11.735) |
| Adjusted R\^2 | 0.906 | 0.916 | 0.917 | 0.897 |
| F-statistic | 79.269\*\*\* | 79.555\*\*\* | 80.495\*\*\* | 63.207\*\*\* |

Note: \*, \*\*, and \*\*\* indicate significance at 10%, 5%, and 1% levels, respectively. t-statistics are reported in ().","Meanwhile, MAD conformity deals with the average divergence from an actual digit distribution. As per Nigrini and Miller [63], . We use the same author's decision criteria where values between 0.0012 and 0.0018 are acceptable, between 0.0018 and 0.0022 are marginally acceptable, and beyond 0.0022 are labeled as nonconformity. Results from Table 2 show that and scores from Chi-squared and Mantissa Arc tests necessitate rejection of the null hypothesis for all months. As a robustness check, we run a Distortion Factor Model, which is capable of revealing overstatement and understatement in data. We report the magnitude of the distortion of actual values against what Benford's Law expects. Conformity tests on mean absolute deviation (MAD) register positive results for only two months: September and October 2020. Otherwise, overall evidence overwhelmingly suggests violation of Benford's Law.",0.06608421482424477,0.051127356,0.7535443902015686,0.3498349834983499,0.48260555703216246
126,206.jpg," Table 4 reports the results of the second-stage regressions. The dependent variable is the cumulative abnormal return over the event window (â15, +15). All models include year and month fixed effects. The results show that the coefficient on the interaction between the implementation dummy and R&D intensity is positive and significant, suggesting that firms with higher R&D intensity benefit more from implementing the consortium. This finding is consistent with the idea that R&D intensity is a measure of a firm's technological sophistication, and that firms with higher technological sophistication are better able to exploit the benefits of collaboration. 
The coefficient on the interaction between the implementation dummy and advertising intensity is also positive and significant, suggesting that firms with higher advertising intensity also benefit more from implementing the consortium. This finding is consistent with the idea that advertising intensity is a measure of a firm's marketing capabilities, and that firms with stronger marketing capabilities are better able to exploit the benefits of collaboration. 
The coefficient on the interaction between the implementation dummy and the number of patents is positive and significant, suggesting that firms with more patents also benefit more from implementing the consortium. This finding is consistent with the idea that the number of patents is a measure of a firm's innovative capabilities, and that firms with stronger innovative capabilities are better able to exploit the benefits of collaboration. 
Overall, the results of the second-stage regressions provide evidence that firms with higher R&D intensity, higher advertising intensity, and more patents benefit more from implementing the consortium. This suggests that firms with stronger technological sophistication, marketing capabilities, and innovative capabilities are better able to exploit the benefits of collaboration.","Next, we investigate whether clustering takes place in NFT sales prices. Since human traders use round numbers as a mental heuristic to save time, such a test is well-suited to identify potential automatic trades, which often manifest in clusters. For each period, we divide the data into two groups: one with prices that are exact multiples of 1000 base units and another with prices within a 500 unit radius from multiples of 1000 base units. The base for the analysis is 4?10 units. The results of the clustering test in Table 3 show that, for 33 out of the 42 time periods analyzed, ~40 % of the trades are clustered around rounded values. This suggests that the majority of trades might be computer-generated.",0.40227253707745725,0.91999274,0.8074728846549988,0.4145758661887694,0.7962938196809164
127,207.jpg," The table shows the mean, standard deviation, and correlation matrix of the seven hotel attributes. The mean of the overall stars is 94.321, with a standard deviation of 7.650. The mean of the accuracy is 9.655, with a standard deviation of 0.757. The mean of the checkin is 9.764, with a standard deviation of 0.662. The mean of the cleanliness is 9.496, with a standard deviation of 0.684. The mean of the communication is 9.767, with a standard deviation of 0.669. The mean of the location is 9.628, with a standard deviation of 0.691. The mean of the value is 9.397, with a standard deviation of 0.846.

The correlation matrix shows that all the attributes are positively correlated with each other. The strongest correlation is between the overall stars and the accuracy (0.74). The second strongest correlation is between the overall stars and the checkin (0.59). The third strongest correlation is between the overall stars and the cleanliness (0.58). The fourth strongest correlation is between the overall stars and the communication (0.56). The fifth strongest correlation is between the overall stars and the location (0.45). The sixth strongest correlation is between the overall stars and the value (0.45).","Our third investigation uses power laws to estimate the fat tails of the NFT prices. If detected, they could indicate the presence of herding behavior [65]. Prior works also attribute fat tails to inadequate information available to economic agents to value an asset [66]. Li et al. [67] have shown that for financial assets the tail exponents lie in the Pareto-Levy range, i.e.,where is the power law exponent. The results of the Power fitting law in Table 4 show that power exponents, on 21 out of 42 occasions, do not lie in the Pareto-Levy range, suggesting abnormal trading practices.",0.4009504607687242,0.829959,0.7922706007957458,0.39057239057239057,0.741305383729626
128,208.jpg," The table shows the results of a mediation analysis. The first column shows the model, the second column shows the R^2 value, the third column shows the path 1 robust F value, and the fourth column shows the path 2 robust F value.

The baseline model has an R^2 value of 0.173. Adding only the premises increases the R^2 value to 0.252, and the path 1 robust F value is significant (p < 0.001). Adding only the host increases the R^2 value to 0.190, and the path 2 robust F value is significant (p < 0.001). Adding both the premises and the host increases the R^2 value to 0.255, and both the path 1 and path 2 robust F values are significant (p < 0.001).

This suggests that both the premises and the host are significant mediators of the relationship between the independent variable and the dependent variable.","The upshot of the three tests described above is this: the trading patterns suggest high probability of abnormal and computer-generated trading both symptoms of wash trading and price manipulation. However, since we apply multiple tests on the same dataset, concerns over type-1 error and p-hacking may surface. Hence, we perform a multiple hypothesis test using Fischer's method with the null hypothesis that NFT trades are consistent with universal patterns in traditional financial markets. The combined results in Table 5 show a rejection of the null hypothesis for all months alleviating the aforementioned concerns. Our results contradict traditional asset stylized facts. For instance, Corazza et al. [68] show that prices of S&P 500 stocks generally follow Benford's Law but not during extreme events; e.g. the September 11 attack in 2001 or the crash during the Global Financial Crisis. Within the digital asset sphere, our results are comparable to Cong et al.?s [58] report on cryptocurrencies traded on unregulated exchanges, but similarities do not extend to regulated exchanges. Overall, our results appear consistent with the prevalent reputation of NFTs.",0.43145765793099705,0.8262253,0.8035136461257935,0.37770171277131814,0.8500582176444246
129,209.jpg," Table 4 shows the results of the spatial regression models for each property type, with the full model including premises, host, and full models. The baseline model includes only a constant. All models are significant (p < 0.01). The full model explains between 2% and 6% of the variance in property values. The host model explains less than 1% of the variance in property values for apartments and houses, and is not significant for condominiums. The premises model explains between 1% and 4% of the variance in property values.","The second phase of this investigation studies both the first and second significant digits. As stated before, a comma or zero before the first natural number is ignored [61]. Benford's Law is used to attempt to detect anomalies in the datasets of the non-fungible tokens. Via this approach, an effort is made to inspect whether price manipulation is occurring in the non-fungible tokens markets. Most of the requirements that are stated above are met by the datasets in this research. However, for the volume data, the requirement of a large dataset is somewhat difficult. The benchmark for the required number of transactions for the price data was set at 1000. However, in the literature there is a discrepancy that a number of researchers use as the lower bound for the criteria of a large dataset. For example, Riccioni and Cerqueti [56] used 100 as the lower bound. Meanwhile, Vicic and To?ic [29] stated that the rule is at least 50?100 transactions, while they state that often thousands of observations are used. Some papers argue for 500 as the lower bound for a large dataset (Tables 6 and 7).",0.4447132050747299,0.7614207,0.8107671737670898,0.17362659029486915,0.8153204119113209
130,21.jpg," **Table 1.** Correlation matrix among study variables (nâ=â250)

| Variable |	1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 | 13 |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1. Consumer forgiveness | 1 |
| 2. nWOM | -0.41 | 1 |
| 3. Perceived privacy concerns | -0.15 | 0.24 | 1 |
| 4. Anthropomorphism | -0.25 | -0.17 | -0.21 | 1 |
| 5. Perceived empathy | -0.20 | -0.14 | 0.10 | 0.16 | 1 |
| 6. Perceived ability | 0.02 | -0.23 | -0.22 | 0.32 | 0.05 | 1 |
| 7. Perceived benevolence | -0.21 | -0.05 | -0.09 | 0.25 | 0.26 | 0.39 | 1 |
| 8. Perceived integrity | -0.22 | -0.06 | 0.13 | 0.27 | 0.22 | 0.44 | 0.49 | 1 |
| 9. Ln Age | 0.17 | 0.16 | 0.08 | 0.08 | 0.09 | 0.06 | 0.12 | 0.27 | 1 |
| 10. Education | -0.09 | 0.18 | 0.09 | 0.11 | 0.07 | -0.02 | 0.04 | -0.05 | -0.07 | 1 |
| 11. Dispositional anger | -0.22 | 0.21 | 0.06 | 0.13 | -0.12 | -0.07 | -0.05 | -0.09 | -0.04 | -0.13 | 1 |
| 12. Dispositional compassion | 0.26 | 0.11 | 0.08 | 0.16 | 0.11 | 0.12 | 0.08 | 0.11 | 0.05 | 0.14 | -0.23 | 1 |
| 13. Mean | 5.71 | 5.94 | 5.34 | 5.06 | 5.19 | 5.61 | 5.91 | 4.91 | 3.35 | 4.51 | 4.62 | 4.51 |  |

Note. **r > .15**, p < .05; **r > .12**, p < .01; **r > .088**, p < .05.","The second phase of this investigation studies both the first and second significant digits. As stated before, a comma or zero before the first natural number is ignored [61]. Benford's Law is used to attempt to detect anomalies in the datasets of the non-fungible tokens. Via this approach, an effort is made to inspect whether price manipulation is occurring in the non-fungible tokens markets. Most of the requirements that are stated above are met by the datasets in this research. However, for the volume data, the requirement of a large dataset is somewhat difficult. The benchmark for the required number of transactions for the price data was set at 1000. However, in the literature there is a discrepancy that a number of researchers use as the lower bound for the criteria of a large dataset. For example, Riccioni and Cerqueti [56] used 100 as the lower bound. Meanwhile, Vicic and To?ic [29] stated that the rule is at least 50?100 transactions, while they state that often thousands of observations are used. Some papers argue for 500 as the lower bound for a large dataset (Tables 6 and 7).",0.0009279285069458978,0.021696923,0.7512001991271973,0.33535353535353535,0.6359405769127994
131,210.jpg," The table shows the number of millionaires in different countries. The country with the most millionaires is the United States, with 114,353 millionaires. The country with the fewest millionaires is Belize, with 1,268 millionaires. The index column shows the number of millionaires per 100,000 people. The country with the highest index is Switzerland, with 12.9 millionaires per 100,000 people. The country with the lowest index is India, with 0.06 millionaires per 100,000 people.","These categories are also mentioned in the descriptive data overview in Table 8, which stems from the Nadini dataset. In the selection of NFTs, there are 13 Art, 9 Collectibles, 20 Games, 4 Metaverses, 2 Others and 2 Utility NFTs. Some popular examples of NFTs in the Art category are CryptoKitties and CryptoPunks. Both CryptoKitties and CryptoPunks have thousands of different characters. Every cat or Punk is unique. CryptoKitties can even be used to breed a new CryptoKittie [74]. Bitverse, MLB Champion and Sorare are good examples of the category Collectibles. Bitverse is a digital universe where sets of cards can be collected. There are four types of cards, ranging from common to legendary (Bitverse Comics, 2021). MLB Champions and Sorare are quite similar NFTs. MLB Champions are virtual baseball players, while Sorare consists of player cards. In both MLB Champions and Sorare, the NFTs can be used to build teams and compete in a virtual game (Non-Fungible Corporation, n.d.). Some well-known NFTs, Axie Infinity, Gods Unchained and My Crypto Heroes, fall in the category of Games. Axie Infinity is a large gaming universe where cute pets, called Axies, live. The Axie universe is called Lunacia, which is the home for the Axies and the land there is tokenized. Axies? owners can collect, breed and battle with their pets (Non-Fungible Corporation, n.d.). Gods Unchained consists of six unique gods, who compete with each other in a virtual card game (Non-Fungible Corporation, n.d.). With the My Crypto Heroes NFTs, battles can be fought using all kinds of equipment (Non-Fungible Corporation, n.d.). Decentraland and Cryptovoxels are famous NFTs in the metaverse tribe. Users can choose what types of content they want to publish on their LAND, which is the NFT of Decentraland. The content can be static 3D scenes; however, it can also consist of any kind of interactive experience (Non-Fungible Corporation, n.d.). In the CryptoVoxels world, digital property can be bought and decorated with custom-designed monochrome blocks (Non-Fungible Corporation, n.d.). The two NFTs that are categorized as Others are CryptoAssault and Footbattle Card. CryptoAssault is one of the NFTs of which doubt can exist whether it is placed in the correct category. CryptoAssault is a 3D world in which territory can be battled for (Non-Fungible Corporation, n.d.). For Footbattle the same applies, as it is described as a footbattle management simulation (Non-Fungible Corporation, n.d.). The Utility NFTs are Unstoppable Domains and Urbit ID. Unstoppable Domains is an NFT that can be used to appoint simple names to cryptocurrency payments (Non-Fungible Corporation, n.d.). In contrast, Urbit ID can be used to send and receive cryptocurrency payments (Non-Fungible Corporation, n.d.). While there are NFTs in each of the six categories, it is very clear that the categories of Art, Collectibles and Games are the best represented in this subset (Table 9, Table 10, Table 11).",0.2796153874369353,0.74062884,0.7908921837806702,0.002259410772833962,0.7911047856253334
132,211.jpg," The table shows the distribution of Airbnb listings in New York City by property type. The most common property type is an entire apartment, which accounts for 43% of all listings. This is followed by private rooms in apartments, which account for 12% of listings. The third most common property type is entire houses, which account for 11% of listings. The fourth most common property type is private rooms in houses, which account for 6% of listings. The fifth most common property type is entire condominiums, which account for 5% of listings.","These categories are also mentioned in the descriptive data overview in Table 8, which stems from the Nadini dataset. In the selection of NFTs, there are 13 Art, 9 Collectibles, 20 Games, 4 Metaverses, 2 Others and 2 Utility NFTs. Some popular examples of NFTs in the Art category are CryptoKitties and CryptoPunks. Both CryptoKitties and CryptoPunks have thousands of different characters. Every cat or Punk is unique. CryptoKitties can even be used to breed a new CryptoKittie [74]. Bitverse, MLB Champion and Sorare are good examples of the category Collectibles. Bitverse is a digital universe where sets of cards can be collected. There are four types of cards, ranging from common to legendary (Bitverse Comics, 2021). MLB Champions and Sorare are quite similar NFTs. MLB Champions are virtual baseball players, while Sorare consists of player cards. In both MLB Champions and Sorare, the NFTs can be used to build teams and compete in a virtual game (Non-Fungible Corporation, n.d.). Some well-known NFTs, Axie Infinity, Gods Unchained and My Crypto Heroes, fall in the category of Games. Axie Infinity is a large gaming universe where cute pets, called Axies, live. The Axie universe is called Lunacia, which is the home for the Axies and the land there is tokenized. Axies? owners can collect, breed and battle with their pets (Non-Fungible Corporation, n.d.). Gods Unchained consists of six unique gods, who compete with each other in a virtual card game (Non-Fungible Corporation, n.d.). With the My Crypto Heroes NFTs, battles can be fought using all kinds of equipment (Non-Fungible Corporation, n.d.). Decentraland and Cryptovoxels are famous NFTs in the metaverse tribe. Users can choose what types of content they want to publish on their LAND, which is the NFT of Decentraland. The content can be static 3D scenes; however, it can also consist of any kind of interactive experience (Non-Fungible Corporation, n.d.). In the CryptoVoxels world, digital property can be bought and decorated with custom-designed monochrome blocks (Non-Fungible Corporation, n.d.). The two NFTs that are categorized as Others are CryptoAssault and Footbattle Card. CryptoAssault is one of the NFTs of which doubt can exist whether it is placed in the correct category. CryptoAssault is a 3D world in which territory can be battled for (Non-Fungible Corporation, n.d.). For Footbattle the same applies, as it is described as a footbattle management simulation (Non-Fungible Corporation, n.d.). The Utility NFTs are Unstoppable Domains and Urbit ID. Unstoppable Domains is an NFT that can be used to appoint simple names to cryptocurrency payments (Non-Fungible Corporation, n.d.). In contrast, Urbit ID can be used to send and receive cryptocurrency payments (Non-Fungible Corporation, n.d.). While there are NFTs in each of the six categories, it is very clear that the categories of Art, Collectibles and Games are the best represented in this subset (Table 9, Table 10, Table 11).",0.28313425718033286,0.7065758,0.789084255695343,0.008853387476611733,0.8108005521048998
133,212.jpg," The table shows the distribution of Airbnb hosts by host type, response time, and whether they have a picture.

The majority of hosts are individuals, accounting for 93.72% of all hosts. 74.38% of hosts respond within a few hours, and 67.47% of hosts have a picture.","These categories are also mentioned in the descriptive data overview in Table 8, which stems from the Nadini dataset. In the selection of NFTs, there are 13 Art, 9 Collectibles, 20 Games, 4 Metaverses, 2 Others and 2 Utility NFTs. Some popular examples of NFTs in the Art category are CryptoKitties and CryptoPunks. Both CryptoKitties and CryptoPunks have thousands of different characters. Every cat or Punk is unique. CryptoKitties can even be used to breed a new CryptoKittie [74]. Bitverse, MLB Champion and Sorare are good examples of the category Collectibles. Bitverse is a digital universe where sets of cards can be collected. There are four types of cards, ranging from common to legendary (Bitverse Comics, 2021). MLB Champions and Sorare are quite similar NFTs. MLB Champions are virtual baseball players, while Sorare consists of player cards. In both MLB Champions and Sorare, the NFTs can be used to build teams and compete in a virtual game (Non-Fungible Corporation, n.d.). Some well-known NFTs, Axie Infinity, Gods Unchained and My Crypto Heroes, fall in the category of Games. Axie Infinity is a large gaming universe where cute pets, called Axies, live. The Axie universe is called Lunacia, which is the home for the Axies and the land there is tokenized. Axies? owners can collect, breed and battle with their pets (Non-Fungible Corporation, n.d.). Gods Unchained consists of six unique gods, who compete with each other in a virtual card game (Non-Fungible Corporation, n.d.). With the My Crypto Heroes NFTs, battles can be fought using all kinds of equipment (Non-Fungible Corporation, n.d.). Decentraland and Cryptovoxels are famous NFTs in the metaverse tribe. Users can choose what types of content they want to publish on their LAND, which is the NFT of Decentraland. The content can be static 3D scenes; however, it can also consist of any kind of interactive experience (Non-Fungible Corporation, n.d.). In the CryptoVoxels world, digital property can be bought and decorated with custom-designed monochrome blocks (Non-Fungible Corporation, n.d.). The two NFTs that are categorized as Others are CryptoAssault and Footbattle Card. CryptoAssault is one of the NFTs of which doubt can exist whether it is placed in the correct category. CryptoAssault is a 3D world in which territory can be battled for (Non-Fungible Corporation, n.d.). For Footbattle the same applies, as it is described as a footbattle management simulation (Non-Fungible Corporation, n.d.). The Utility NFTs are Unstoppable Domains and Urbit ID. Unstoppable Domains is an NFT that can be used to appoint simple names to cryptocurrency payments (Non-Fungible Corporation, n.d.). In contrast, Urbit ID can be used to send and receive cryptocurrency payments (Non-Fungible Corporation, n.d.). While there are NFTs in each of the six categories, it is very clear that the categories of Art, Collectibles and Games are the best represented in this subset (Table 9, Table 10, Table 11).",0.26518043253031676,0.6472735,0.7924949526786804,5.78702888210508e-05,0.8026868059476755
134,213.jpg," | | Premises | Host | Both |
| :--- | :--- | :--- | :--- |
| Max. guests | ***3.200 |  | ***3.199 |
| Log reviews | ***-1.872 |  | ***-1.673 |
| Accuracy | ***3.307 |  | ***3.310 |
| Communication | ***-0.670 |  | ***-0.557 |
| Cleanliness | ***6.025 |  | ***6.064 |
| Location | ***10.941 |  | ***10.861 |
| Value | ***-2.761 |  | ***-2.734 |
| Check-in | ***8.521 |  | ***8.340 |
| No. amenities | 0.005 |  | 0.008 |
| No. bathrooms | ***5.719 |  | ***5.389 |
| No. bedrooms | ***13.276 |  | ***13.251 |
| Host type generic |  | ***-18.080 | ***-21.677 |
| Host type individual |  | ***-8.325 | ***-7.494 |
| Host type multi-person |  | ***-6.929 | ***-6.041 |
| Identity verification | ***0.367 |  | ***0.544 |
| Host log reviews | ***2.273 |  | ***1.976 |
| All respond | ***0.970 |  | ***1.877 |
| Response: a day | ***-2.005 |  | ***-0.988 |
| Response: an hour | ***-4.903 |  | ***-4.902 |
| Picture | ***1.355 |  | ***1.202 |
| RÂ² | 0.252 | 0.190 | 0.255 |","The results in the following tables are split into separate tables for the first and second digits and for the price and volume data. In total there are 8 tables with results. Conformity to Benford's Law is judged according to the Mean Absolute Deviation score while Pearson's chi-squared test can be unreliable for large datasets. In Table 12 the results are shown for the price data of the selection of 50 NFTs. For 16 out of the 50 NFTs the first digit distribution conforms to Benford's Law according to the Mean Absolute Deviation. Two of these conforming NFTs are also confirmed by a significant chi-squared statistic. It is noteworthy that, among others, the NFT collections Axie Infinity, CryptoKitties and Gods Unchained score an abnormally high chi-squared statistic.",0.008848402772953708,-0.090943106,0.7477049827575684,0.33983739837398375,0.384918634337239
135,214.jpg," The table shows the results of a regression analysis with the dependent variable of price per night. The independent variables are all of the variables that were included in the hedonic price model. The results show that the coefficients for the variables are all significant at the 0.05 level or better, with the exception of the variables for number of bathrooms and number of bedrooms. This indicates that all of the variables, with the exception of number of bathrooms and number of bedrooms, have a significant impact on the price per night of a rental unit.","In Table 13 the results for the second digit distribution of the price data of the NFT selection are presented. Something outstanding here is that 22 out of 30 conforming NFTs score in close conformity. Eight out of the 30 NFTs that conform to Benford's Law also achieve a significant chi-squared statistic. Once again, the collections of Axie Infinity, CryptoKitties and Gods Unchained have high chi-squared statistics. For 0xuniverse and CyberKongz, these high values are observed as well.",0.48986118014913477,0.86831045,0.8330128788948059,0.5,0.8277852934102935
136,22.jpg," Table 4. Convergent and Discriminant Validity

Note: *Italics* values are square root of AVE.","Table 14 reports the results of the first digit distribution of the volume data of the 50 NFTs. Eight NFTs score acceptable conformity, five score marginally acceptable conformity and the remaining 37 NFTs nonconformity. Eleven of 13 conforming NFTs also show significant chi-squared scores. However, out of the 37 nonconforming NFTs, six nonetheless have a significant chi-squared statistic, which would indicate conformity. Either way, the MAD score is deemed as the leading test statistic; therefore these NFTs remain classified as nonconforming.",0.07334362110790339,0.62655747,0.807610034942627,0.003975313641590977,0.8307823129251701
137,23.jpg, Table 3. Indirect effects.,"Table 16 moves on to the results of the yearly aggregated data, starting with the first digit distribution of the yearly aggregated price data. The years 2017 through 2019 scored acceptable conformity, 2020 scored close conformity and the first 117 days of 2021 scored nonconformity. Nonetheless, with a MAD score of 0.01567, it is still close to marginally acceptable conformity. The transactions that are included in the years that do conform to Benford's Law amount to 44.3 % of the total number of transactions (6062,744) that are examined in the results section. All years have a high chi-squared statistic. Regardless, the year 2021 has an extraordinarily high chi-squared statistic, namely over 140,000.",0.017861994176767315,0.69239587,0.8290754556655884,9.397644082695416e-13,0.8303571428571428
138,24.jpg," The table summarizes the data collection and analysis methods used in the study. A total of 62 interviews were conducted, with a total duration of 3529 minutes (average = 56.92 minutes, minimum = 19 minutes, maximum = 100 minutes). In addition, 196 days of participant observation were conducted, including passive observations of workplace interactions, attendance at meetings, and informal contacts, as well as active participation in talks, workshops, steering meetings, and collaborations. The data were analyzed using Gioia et al.'s (2013) denaturalization, transcription, coding, and memoing techniques.","Table 17 demonstrates the second digit distribution of the yearly aggregated price data of the complete Nadini dataset. All of the years 2017 through 2021 obtained close conformity to Benford's Law. Once more, all of the years show a high chi-squared statistic",0.2257547965597186,0.8423571,0.8160518407821655,0.3946360153256705,0.6853888670852957
139,25.jpg," The table shows the roles, employment lengths, places of work, and highest qualifications of employees in a company. The company has 37 employees in its headquarters, 22 in its subsidiary, and 3 external employees. The employees in the headquarters have an average employment length of 5.5 years, while the employees in the subsidiary have an average employment length of 6.8 years. The external employees have an average employment length of 10 years. The majority of the employees in the company have a bachelor's degree, followed by a master's degree and a diploma.","A pattern can be observed in Tables 18 and 19. In total 16 NFTs conform to the first digit distribution according to Benford's Law. Fifteen out of these 16 NFTs also conform to the second digit distribution according to Benford's Law. Therefore, this might be a consistent pattern that can also be found in other transaction data. Economically this pattern seems to make sense as well. If price manipulation would take place, it would be logical that both digits or at least the first do(es) not conform to Benford's Law. It would not make sense if the first digit distribution does conform to Benford's Law while the second digit distribution does not conform to Benford's Law. However, this pattern is not as strong for the volume data. The findings indicate that merely seven NFTs out of the 13 that conform to Benford's first digit distribution also conform to Benford's second digit distribution. Additionally, it can be observed that the 50 NFTs that were selected conform more often to Benford's Law for the price data than for the volume data. There were four NFTs that conformed to Benford's Law in all four tables, namely Crypto Space Commanders, CryptoKitites, Decentraland and Gods Unchained. They conformed for both the price and the volume data to the first- and second-digit distributions of Benford's Law. No pattern is found regarding the different categories of the NFTs. The categories are dispersed relatively in the same manner in the results as in the NFT selection. It can be observed that there are more NFTs in Art, Collectible and Games that appear in the conforming results; however, these NFTs are also represented way more in the NFT selection. Therefore, no relative difference can be observed.",0.28311287464624607,0.87119764,0.8017088770866394,0.06004191376140791,0.7823197032436163
140,26.jpg," The table shows the number of successful and unsuccessful conversations between the user and the system, as well as the percentage of successful conversations for each type of conversation. 

For short conversations, 57.1% of female users and 42.9% of male users obtained a recipe, while for long conversations, 47.2% of female users and 52.8% of male users obtained a recipe. 

Overall, female users were more successful in obtaining a recipe than male users, with 51.9% of female users obtaining a recipe compared to 48.1% of male users.","Table 19 shows the first- and second-digit distribution of the yearly aggregated volume data of the entire market history as recorded by nonfungible.com. For both the first- and second-digit distribution, all years (2017 through 2022) score nonconformity according to the MAD statistic. However, for the first-digit distribution, the chi-squared statistic reports a significant value for the years 2017 and 2022. For the second-digit distribution, the same applies for all of the years. Again, this is probably due to the small N. A pattern can be observed in Tables 18 and 19. In total 16 NFTs conform to the first digit distribution according to Benford's Law. Fifteen out of these 16 NFTs also conform to the second digit distribution according to Benford's Law. Therefore, this might be a consistent pattern that can also be found in other transaction data. Economically this pattern seems to make sense as well. If price manipulation would take place, it would be logical that both digits or at least the first do(es) not conform to Benford's Law. It would not make sense if the first digit distribution does conform to Benford's Law while the second digit distribution does not conform to Benford's Law. However, this pattern is not as strong for the volume data. The findings indicate that merely seven NFTs out of the 13 that conform to Benford's first digit distribution also conform to Benford's second digit distribution. Additionally, it can be observed that the 50 NFTs that were selected conform more often to Benford's Law for the price data than for the volume data. There were four NFTs that conformed to Benford's Law in all four tables, namely Crypto Space Commanders, CryptoKitites, Decentraland and Gods Unchained. They conformed for both the price and the volume data to the first- and second-digit distributions of Benford's Law. No pattern is found regarding the different categories of the NFTs. The categories are dispersed relatively in the same manner in the results as in the NFT selection. It can be observed that there are more NFTs in Art, Collectible and Games that appear in the conforming results; however, these NFTs are also represented way more in the NFT selection. Therefore, no relative difference can be observed.",0.2427177148643436,0.6854337,0.8009741902351379,0.022282071822350147,0.8227909702047632
141,27.jpg, Table 1. Sample characteristics,"We conducted nine semi-structured interviews with experts at the regional level, six at the intermediate level, and three at the national office level; these experts came from five different HNGOs. Most of our interviewees working at regional units were volunteers, as this is where most volunteers engage with HNGOs; our paid staff interviewees were mostly active in intermediate and national units (headquarters), where HNGO permanent operations are situated. Hence, our sample reflects these organizational structures. The interviews were conducted in German via Skype or by telephone in 2019 and 2020. All interviews were between 30 minutes and 2 1/2 hours in length, depending on how detailed responses were; interviews conducted later in the study tended to be longer as we refined our interview guide and protocols. Table 2 is an overview of the interview sample.",0.061347739349902425,0.6853072,0.8431690335273743,2.9910641118835677e-15,0.8333333333333334
142,28.jpg, Table 2. Comparison of characteristics of female and male participants,"Contribution intentions were regressed on crowdfunding platform type (1 = reward; 0 = donation), prosocial motivation, and their interaction (see Table 2 for the stepwise regression results). As expected, the results revealed a significant interaction between crowdfunding platform and prosocial motivation (B = 2.24, SE = 0.72, p < 0.01). As prosocial motivation is a continuous measure, the analyses were repeated using a spotlight analysis at one standard deviation below and above the mean (see Fig. 1; [63]). The analysis revealed a significant negative simple effect of crowdfunding platform type for participants low in prosocial motivation (B = -2.31, SE = 0.74, p < 0.01), indicating they were willing to contribute less money in the reward (vs. donation) condition. Conversely, there was no effect of crowdfunding platform type for those with high prosocial motivation (B = 0.93, SE = 0.71, p = 0.20).",0.10276092896417258,0.70993584,0.8249064087867737,1.1163288062895107e-06,0.7983333333333335
143,29.jpg," | Task-related features | Task completed | Task not completed | P |
|---|---|---|---|
| No. recipe suggestions (mean Â± std.) | 5.85 (4.431) | 7.33 (5.743) | 0.525 |
| No. correct recipe suggestions (mean Â± std.) | 4.19 (3.511) | 5.33 (5.433) | 0.863 |
| Percentage of correct recipe suggestions (mean Â± std.) | 79.87 (32.145) | 71.86 (43.721) | 0.362 |
| Recipe criteria: narrativeness of KIM (mean Â± std.) | 4.251 (28.643) | 59.52 (19.298) | 0.041 |
| Recipe criteria: ingredients (mean Â± std.) | 0.35 (0.497) | 0.64 (0.497) | 0.034 |
| Recipe criteria: difficulty level (mean Â± std.) | 0.55 (0.500) | 0.64 (0.497) | 0.514 |
| Time spent in conversation in minutes (mean Â± std.) | 2.69 (1.338) | 3.00 (1.240) | 0.304 |
| Text features |  |  |  |
| No. messages from KIM (mean Â± std.) | 14.16 (5.637) | 17.57 (7.272) | 0.051 |
| No. messages from the user (mean Â± std.) | 9.21 (3.452) | 10.93 (4.552) | 0.047 |
| No. messages from KIM * user (mean Â± std.) | 23.37 (8.917) | 28.50 (10.219) | 0.035 |
| No. words from KIM (mean Â± std.) | 148.21 (136.762) | 210.43 (143.872) | 0.038 |
| No. words from the user (mean Â± std.) | 362.16 (195.704) | 400.43 (279.203) | 0.988 |
| No. words from KIM * user (mean Â± std.) | 22.51 (13.975) | 22.51 (13.975) | 1.000 |
| No. words from KIM/user (mean Â± std.) | 384.67 (202.237) | 960.87 (1386.526) | 0.789 |
| No. emojis used by KIM (mean Â± std.) | 1.47 (1.488) | 0.61 (1.488) | 0.173 |
| No. emojis used by the user (mean Â± std.) | 1.47 (1.488) | 1.57 (1.828) | 0.828 |
| Characteristics of conversation ability |  |  |  |
| No. conversation restarts by KIM (mean Â± std.) | 1.21 (0.426) | 1.22 (0.516) | 0.983 |
| Correct greeting by KIM (mean Â± std.) | 0.98 (0.142) | 0.79 (0.426) | 0.731 |
| Evaluation |  |  |  |
| Satisfaction of the user (mean Â± std.) | 4.34 (1.477) | 3.31 (2.288) | 0.047 |
| Perceived naturalness of KIM (mean Â± std.) | 4.48 (1.359) | 4.26 (1.359) | 0.","Given that this study sampled the general population on MTurk rather than a more homogeneous undergraduate sample as in Study 1, we controlled for participants? gender, age, education level, and income. Contribution intentions were regressed on prosocial nature of the project description (1 = high; 0 = low), crowdfunding platform type (1 = reward; 0 = donation), prosocial motivation, their three-way interaction, and all lower-order interactions, while controlling for gender, age, education level, and income level (see Table 3 for the stepwise regression results). The results showed significant effects of the interaction between prosocial nature of the project description and crowdfunding platform type (B = -3.64, SE = 1.45, p = 0.01), the interaction between prosocial nature of the project description and prosocial motivation (B = -0.39, SE = 0.19, p = 0.04), and the three-way interaction between prosocial nature of the project description, crowdfunding platform type, and prosocial motivation (B = 0.56, SE = 0.26, p = 0.03). As prosocial motivation is a continuous measure, the analyses were repeated using a spotlight analysis at one standard deviation below and above the mean to probe the three-way interaction [63]. ",0.06750322122106275,0.44720882,0.7906244993209839,0.35228251507321273,0.6182059437161477
144,30.jpg, Table 4. Results of the regression analyses.,"Similar to Study 2, given that this study sampled a more general population on Prolific rather than a more homogeneous undergraduate sample, we controlled for participants? gender, age, education level, and income. We also controlled for nationality given that we collected data from both American and Chinese participants. Contribution intentions were regressed on prosocial nature of the project description (1 = high; 0 = low), crowdfunding platform type (1 = reward; 0 = donation), prosocial motivation, their three-way interaction, all lower-order interactions, and control variables (see Table 4 for the stepwise regression results). Results showed significant effects of the interaction between prosocial nature of the project description and prosocial motivation (B = -0.74, SE = 0.34, p = 0.03) and the interaction between crowdfunding platform type and prosocial motivation (B = -0.94, SE = 0.31, p < 0.01). There were also marginally significant effects of the interaction between prosocial nature of the project description and crowdfunding platform type (B = -5.09, SE = 2.62, p = 0.05) and importantly, the three-way interaction between prosocial nature of the project description, crowdfunding platform type, and prosocial motivation (B = 0.78, SE = 0.45, p = 0.08).",0.22839328299826686,0.70026654,0.834089994430542,2.0247096508371306e-12,0.8653061224489796
145,31.jpg," The table shows the results of two studies that tested hypotheses about the effects of task-related features, text features, and characteristics of conversational ability on perceived conversational ability.

In Study 1, the results showed that:
- There was no significant effect of the proportion of correct responses to requests on perceived conversational ability.
- There was a significant effect of the proportion of conversational ability questions about request criteria on perceived conversational ability.
- There was a significant effect of the proportion of correct questions about request criteria on perceived conversational ability.
- There was no significant effect of the time spent in conversation on perceived conversational ability.
- There was a significant effect of the time spent in conversation on perceived task completion time.
- There was no significant effect of the number of messages sent by the user on perceived conversational ability.
- There was a significant effect of the number of messages sent by the chatbot on perceived conversational ability.
- There was a significant effect of the number of words sent by the user on perceived conversational ability.
- There was a significant effect of the number of words sent by the chatbot on perceived conversational ability.
- There was a significant effect of the number of emojis sent by the user on perceived conversational ability.
- There was a significant effect of the number of emojis sent by the chatbot on perceived conversational ability.
- There was a significant effect of the number of conversation restarts on perceived conversational ability.
- There was a significant effect of the presence of a correct greeting on perceived conversational ability.
- There was no significant effect of the presence of a correct greeting on perceived task completion time.

In Study 2, the results showed that:
- There was no significant effect of the proportion of correct responses to requests on perceived conversational ability.
- There was a significant effect of the proportion of conversational ability questions about request criteria on perceived conversational ability.
- There was a significant effect of the proportion of correct questions about request criteria on perceived conversational ability.
- There was no significant effect of the time spent in conversation on perceived conversational ability.
- There was a significant effect of the time spent in conversation on perceived task completion time.
- There was no significant effect of the number of messages sent by the user on perceived conversational ability.
- There was a significant effect of the number of messages sent by the chatbot on perceived conversational ability.
- There was a significant effect of the number of words sent by the user on perceived conversational ability.
- There was a significant effect of the number of words sent by the chatbot on perceived conversational ability.
- There was a significant effect of the number of emojis sent by the user on perceived conversational ability.
- There was a significant effect of the number of emojis sent by the chatbot on perceived conversational ability.
- There was a significant effect of the number of conversation restarts on perceived conversational ability.
- There was a significant effect of the presence of a correct greeting on perceived conversational ability.
- There was no significant effect of the presence of a correct greeting on perceived task completion time.

Overall, the results of the two studies provide evidence that task-related features, text features, and characteristics of conversational ability can affect perceived conversational ability.","To address these research questions, we leveraged on a longitudinal dataset that allowed us to observe the effects of the marketing choices (price and flexible policies as functional attributes) and economic returns (occupation rates and revenues per active nights, as in line with Airbnb literature; [17]) at a single Airbnb property level in the city of Rome (i.e., the largest touristic submarket in Italy). The first evidence that emerged from these data is that the sharp market contraction due to the pandemic shock affected demand much more than supply: the negative change in revenues has in fact been about five times larger than the exit rates (see Table 1), thus depicting a novel market condition on the Airbnb platform. This circumstance suggests that competition must have increased substantially and, consequently, forced (at least some) entrepreneurs to react to the shock with renewed activism.",0.2515631337070638,0.80789155,0.7792419195175171,0.36921296296296297,0.7882228173286568
146,32.jpg," The table shows the frequency and percentage of respondents in the US and China for different variables.

For the variable ""Gender"", there are 352 males and 355 females in the US, and 352 males and 450 females in China. The percentage of males in the US is 49.8%, and the percentage of females in the US is 50.2%. The percentage of males in China is 43.9%, and the percentage of females in China is 56.1%.

For the variable ""Age"", there are 120 respondents under the age of 26 in the US, and 171 respondents under the age of 26 in China. The percentage of respondents under the age of 26 in the US is 16.6%, and the percentage of respondents under the age of 26 in China is 21.3%. There are 313 respondents aged 26-41 in the US, and 296 respondents aged 26-41 in China. The percentage of respondents aged 26-41 in the US is 43.4%, and the percentage of respondents aged 26-41 in China is 36.9%. There are 175 respondents aged 42-56 in the US, and 222 respondents aged 42-56 in China. The percentage of respondents aged 42-56 in the US is 24.2%, and the percentage of respondents aged 42-56 in China is 27.7%. There are 113 respondents aged 57-76 in the US, and 111 respondents aged 57-76 in China. The percentage of respondents aged 57-76 in the US is 15.7%, and the percentage of respondents aged 57-76 in China is 13.8%. There is 1 respondent over the age of 76 in the US, and 2 respondents over the age of 76 in China. The percentage of respondents over the age of 76 in the US is 0.1%, and the percentage of respondents over the age of 76 in China is 0.2%.

For the variable ""Education"", there are 174 respondents with a high school education in the US, and 70 respondents with a high school education in China. The percentage of respondents with a high school education in the US is 24.1%, and the percentage of respondents with a high school education in China is 8.7%. There are 88 respondents with a two-year college education in the US, and 131 respondents with a two-year college education in China. The percentage of respondents with a two-year college education in the US is 12.2%, and the percentage of respondents with a two-year college education in China is 16.3%. There are 295 respondents with a four-year college education in the US, and 526 respondents with a four-year college education in China. The percentage of respondents with a four-year college education in the US is 40.9%, and the percentage of respondents with a four-year college education in China is 65.6%. There are 155 respondents with a graduate degree in the US, and 71 respondents with a graduate degree in China. The percentage of respondents with a graduate degree in the US is 21.5%, and the percentage of respondents with a graduate degree in China is 8.9%. There are 10 respondents with other types of education in the US, and 4 respondents with other types of education in China. The percentage of respondents with other types of education in the US is 1.4%, and the percentage of respondents with other types of education in China is 0.5%.

For the variable ""Type of Trip"", there are 609 respondents who took domestic trips in the US, and 780 respondents who took domestic trips in China. The percentage of respondents who took domestic trips in the US is 84.3%, and the percentage of respondents who took domestic trips in China is 97.3%. There are 113 respondents who took international trips in the US, and 22 respondents who took international trips in China. The percentage of respondents who took international trips in the US is 15.7%, and the percentage of respondents who took international trips in China is 2.7%.","With the aim of describing the impact of the shock in our sample, Table 2 reports the descriptive statistics of the two dependant variables for the considered three years, that is, 2018, 2019, and 2020. In line with Ghebreyesus [18], the descriptive statistics are computed for the months of March to Decemeber of each year. Consistent with the magnitude of the shock, Table 2 reports that the mean values of occupation rate and revenues per active nights declined significantly in 2020, compared to 2018 and 2019, years that were instead rather stable.",0.4870570814240781,0.749886,0.7755090594291687,0.3624544981799272,0.8057952015050311
147,33.jpg, All items show adequate to good convergent validity with all items loading above 0.70 on their respective constructs. All items also show good discriminant validity with the AVE of each construct being greater than the squared correlation between that construct and any other construct.,"Table 3 provides the number of properties (and the relative shares in brackets) that adopted a given cancellation policy (moderate, flexible, or strict) in 2018, 2019, and 2020, and also shows the year-over-year transitions. Table 3a shows data pertaining to the benchmark situation (i.e., 2018 to 2019), while Table 3b shows data for the Covid-19 shocked situation (i.e., 2019 to 2020).",0.11744490757988299,0.5874584,0.8099183440208435,0.29857845543565315,0.7315722156631249
148,34.jpg, **Table 1.** Correlation matrix for all variables.,"Table 4 provides a comparison of the pricing adjustements between 2018 and 2019 and between 2019 and 2020, and it also shows the main descriptive indicators for the absolute price variation (i.e., the absolute value of PV(i,m)) as well as the results of a mean comparison test (i.e., the T-test). Fig. 2, which is complementary to Table 4, plots the distribution of PVy(i,m) in 2019 and in 2020.",0.05456904221929315,0.5071484,0.8392024636268616,7.03812563925996e-05,0.8023088023088024
149,35.jpg," Table 4 shows the results of the hypotheses testing. All the hypotheses were supported, except for H4a, H4b, and H7b. The results indicate that there are significant differences between the two groups in terms of their consumption engagement, customer engagement, and brand loyalty. The results also indicate that there are significant differences between the two groups in terms of their perceived anonymity and hot brand relationship quality. However, there are no significant differences between the two groups in terms of their attitudes toward risk and their intention to revisit the website.","Table 5 shows the estimates of the econometric model that was used to predict the impact of the pricing adjustments, the impact of the flexible cancellation policies, and the effect of joint adoptions on the occupation rate. It is worth noting that the IV diagnostic statistics (i.e., Kleibergen-Paap weak identification tests) fully confirmed the validity of the instrument for our empirical setting.16 Models M1 and M2 include control variables only, Model M3 includes control variables and PV2020(i,m), Model M4 includes control variables and ModFlexPolicy(i), Model M5 includes control variables, PV2020(I,m), and ModFlexPolicy(i), while Model M6 includes all the variables as well as the interaction between PV2020(i,m) and ModFlexPolicy(i). Table A4 in the Online Appendix provides the estimation results when a pooled OLS estimation was employed, without instrumenting PV2020(i,m), and rather similar results can be observed.",0.4004245110888867,0.7898498,0.8268463015556335,0.3184695578383765,0.7939465296608152
150,36.jpg," The table shows the results of a series of t-tests comparing the means of two groups. The first group is the control group, and the second group is the treatment group. The treatment group received a marketing campaign, and the control group did not.

The results show that the marketing campaign had a significant effect on three of the seven outcomes: customer engagement, contribution customer engagement, and perceived anonymity. For customer engagement, the mean difference between the two groups was 0.1091, with a 95% confidence interval (CI) of [0.0252, 0.1930]. This means that the marketing campaign led to a statistically significant increase in customer engagement.

For contribution customer engagement, the mean difference between the two groups was 0.1907, with a 95% CI of [0.0965, 0.2849]. This means that the marketing campaign led to a statistically significant increase in contribution customer engagement.

For perceived anonymity, the mean difference between the two groups was -0.1299, with a 95% CI of [-0.2236, -0.0362]. This means that the marketing campaign led to a statistically significant decrease in perceived anonymity.

The other four outcomes were consumption customer engagement, creation customer engagement, cross-buying, and trip-planning. The results for these outcomes were not statistically significant.","Table 6 shows the estimates of the econometric model when RevPAN in 2020 was considered as the dependant variable and tested on the sample of strict cancellation policy adopters in 2019. Again in this case, it is worth noticing that the Kleibergen-Paap weak identification tests fully confirmed the validity of the instrument for our empirical setting.18 Models M1 to M6 are defined as in Section 5.2.1. As for the analyses on the OccR, Table A9 in the Online Appendix provides the estimation results obtained when employing a pooled OLS estimation without instrumenting PV2020(i,m), and they show rather similar results.",0.4667235363391336,0.88411397,0.798439085483551,0.43097643097643096,0.7802436200163473
151,37.jpg," The table shows the results of a study that compared how easy it is for people to seek help from friends versus strangers. The study also compared how awkward and embarrassed people feel when they are rejected by friends versus strangers.

The results show that people find it easier to seek help from friends than from strangers. They also feel less awkward and embarrassed when they are rejected by friends than by strangers.

These findings suggest that friends provide a more supportive environment for people who are seeking help. Friends are more likely to be understanding and helpful, and they are less likely to reject someone who is in need.","Sample companies were purposely selected to obtain information-rich data that were able to contribute to a deeper understanding of the perceptions, concerns, and behavior related to social media use [109]. The interviewees were all key informants at their respective companies, i.e., owner- or business-managers, or executives responsible for their firms? social media management (see Table 1). A snowball sampling procedure [122] was employed, initiated via the first author's acquaintances. The use of natural social ties for accessing the ?elite informants? [119,122] counterbalanced the often prevailing asymmetry in the power relationship between interviewer and interviewee. To represent the heterogeneity of the SME area, the interview participants varied along several dimensions, such as gender, education, social media experience levels, and age. The participants? ages spanned from 23 to 71 years, with a job tenure ranging from 1 year to 30 years and more. This long period of service for a company applied to the owner-managers and founders of a hotel (SME 9), a men's shoe fashion wholesale (SME 15), and a firm consulting entrepreneurial couples (SME 18). Valuable insights into the research topic also resulted from the respondents' various social media worlds and accounts thereof complementing each other. Particularly, young participants aged under 35 years, acting in car and fashion retail or online marketing (SME 7, 8, 14, and 16), seemed to feel superior in knowledge and experience with social media to members of other age groups within and beyond their companies. Apart from the 42-year-old, socially and politically highly engaged owner-manager of a book retail shop (SME 13), all firm leaders were male. Most of the female participants held positions of a business, marketing, or social media manager.",0.23049014677690513,0.6742583,0.8049298524856567,0.10623510625693945,0.8516778423596604
152,38.jpg," The Cronbach's alpha values for the three constructs are 0.817, 0.655, and N/A, respectively. The values for AwkEmbar and Money (Effectiveness in terms of earning money) are above the recommended threshold of 0.7, indicating good internal consistency. The low Cronbach's alpha value for Effectiveness (in terms of success) suggests that the items in this construct are not measuring the same underlying concept and should be revised or removed. The Convenience construct has only one item, so a Cronbach's alpha value cannot be calculated.","Although previous investigations [22] found that regular social media activity remains challenging for firms regardless of their size, this study showed differences in companies? behavioral consistencies. As innovation adoption literature in general, and especially in the SME domain, mainly restricts its focus to mere adoption processes, which fail to account for a comprehensive, sustainable use [152], a better understanding of social media usage in terms of (dis)continuity [45] is needed. Initially, executives are equally exposed to a broad bundle of structural, i.e., material and informational, properties of social media [9]. Nevertheless, these features open up different, context-related journeys on which SME managers may embark in conditions triggering perceptions and behavior in terms of this technology as a whole. From a structuration perspective [40], our findings suggest that these structural properties of social media possibly fail to cause triggers unleashing a sensemaking and engagement process. Here, the encounter with few, negatively connotated features may not produce triggers, such as perceiving obligation or novelty [100] for driving sensemaking and steady use behavior. This tendency effect is reinforced by environmental influences, such as necessary protection against competitors or lacking regulatory and market requirements (for a tendential relation between perception of social media features and steadiness of use behavior derived from interview data, see Table 3).",0.2447106326458341,0.8723278,0.804452657699585,0.10610182564975054,0.8268162225993548
153,39.jpg," The table shows the results of a bootstrap analysis. The analysis was conducted to determine the effect of various independent variables on the dependent variable, which is the medium selected. The independent variables are closeness, awkwardness, effectiveness, convenience, money, and the interaction of money and closeness.

The results show that the interaction of money and closeness has a significant effect on the medium selected. This means that the effect of money on the medium selected depends on the level of closeness. Specifically, the results show that as the level of closeness increases, the effect of money on the medium selected decreases. This means that when people are close to each other, they are less likely to be influenced by money when making decisions about which medium to use.

The results also show that the main effects of closeness, awkwardness, effectiveness, and convenience are not significant. This means that these variables do not have a significant effect on the medium selected.","Table 2 reports the key descriptive statistics and correlation matrix for the variables applied in this study, with Bonferroni-adjusted significance levels below 0.01. Multicollinearity does not represent a problem for any of the variables as the Variance Inflation Factor (VIF) is largely below the suggested threshold of ten [110].",0.36912468748209626,0.753205,0.8146592974662781,0.39166666666666666,0.7916850857475858
154,40.jpg," **. Table 3.** Results of the Bootstrap Analysis for the Structural Model (n = 200)

***
DV: Selected medium
***

| Independent Variable | B | Bias | Std. Error | Sig. (2-tailed) | 95% Confidence Interval | VIF |
|---|---|---|---|---|---|---|
| Friends | 
| AwkEmbar | 0.31 | 0.089 | 0.965 | 0.228 | -0.245 | 1.35 | 1.17 |
| Effectiveness | -0.474 | -0.278 | 2.581 | 0.097 | -2.111 | 0.027 | 1.041 |
| Convenience | 0.25 | 0.218 | 2.124 | 0.348 | -0.149 | 1.521 | 1.169 |
| Money | 0.296 | 0.122 | 0.914 | 0.195 | -0.151 | 1.184 | 1.042 |
| Constant | 0.156 | 0.077 | 1.101 | 0.698 | -0.647 | 1.357 |  |
| Strangers | 
| AwkEmbar | 1.616 | 19.318 | 64.328 | <.001 | 1.105 | 262.888 | 1.134 |
| Effectiveness | -0.597 | -11.276 | 35.012 | 0.055 | -131.387 | 326.431 | 1.12 |
| Convenience | 1.645 | 2.201 | 48.375 | 0.447 | 1.177 | 50.814 | 1.181 |
| Money | 0.348 | 2.201 | 40.826 | 0.447 | -49.493 | 50.814 | 1.066 |
| Constant | 1.79 | 22.705 | 82.739 | 0.008 | 0.461 | 312.185 |  |","Table 3 shows the distribution of the strategic role of IT in industry in our sample of 1769 firms (and 17,690 observations) operating in 382 four-digit industries from 2011 to 2020.",0.06186409849657341,0.19767939,0.7664133906364441,0.3457364341085271,0.5772513751680418
155,41.jpg," The table shows the results of a bootstrap analysis. The analysis was conducted to determine the effect of closeness and gender on the selection of medium. The results show that closeness has a significant positive effect on the selection of medium, while gender has no significant effect. The interaction between closeness and gender is also not significant.

The results of the bootstrap analysis are consistent with the results of the ordinary least squares (OLS) regression analysis. The OLS regression analysis showed that closeness has a significant positive effect on the selection of medium, while gender has no significant effect. The interaction between closeness and gender is also not significant.

The bootstrap analysis provides a more robust estimate of the standard errors of the coefficients than the OLS regression analysis. This is because the bootstrap analysis takes into account the sampling error in the data. The OLS regression analysis does not take into account the sampling error, which can lead to biased estimates of the standard errors.

Overall, the results of the bootstrap analysis and the OLS regression analysis are consistent. The results show that closeness has a significant positive effect on the selection of medium, while gender has no significant effect. The interaction between closeness and gender is also not significant.","Models 1a ? 12a in Table 4 report the comparative analysis among subsamples (i.e. Automate, Informate, Physical-Transform, and Digital-Transform) used to assess the best alignment between business strategy and the strategic role of IT in industry on labour productivity growth (Models 1a, 4a, 7a, 10a) and its value components ? output growth (Models 2a, 5a, 8a, 11a) and input reduction (Models 3a, 6a, 9a, 12a) ? in Automate, Informate, Physical-Transform and Digital-Transform industries, respectively.",0.2060473802849937,0.76840913,0.7793053388595581,0.37756714060031593,0.8177022424652749
156,42.jpg," The table shows the results of a bootstrap analysis. The analysis was conducted to determine the 95% confidence intervals for the coefficients in a linear regression model. The model was used to predict the DV: Selected medium.

The results show that the coefficients for Closeness, AwkEmb, Effectiveness, Convenience, Money, AwkEmb*Closeness, Effectiveness*Closeness, Convenience*Closeness, and Money*Closeness are all significant at the .05 level. The 95% confidence intervals for these coefficients are also shown in the table.","As a robustness check, we also used a dynamic panel data estimation to overcome any possible endogeneity issues arising from reverse causality due to the prior performance of a firm. The results are shown in Table 6 and are consistent with the results of the comparative analysis of the subsamples (Table 4) and with the results on the moderating effect of the strategic role of IT in industry (Table 5).",0.49360772599318337,0.8359822,0.8245797157287598,0.5495495495495496,0.7282569532569533
157,43.jpg, Results of the Mixed Model ANOVA and Cronbachâs alpha for each of the indices and single items.,"Reliability was tested using Cronbach's Alpha value (a) (see Table 4) with all variables exceeding the threshold of 0.7. Moreover, to avoid common method bias, we employed Harman's one-factor test [138], which reported about 25.2% of variances explained by extracting only one factor, meeting the thumb value within 50% of the variance among all variables. This implies that there was no bias when applying respondents? answers in the same questionnaire for both independent and dependent variables. A reflective measurement model was inspected by conducting confirmatory factor analysis (CFA) via AMOS 26. Given the adequate sample size of 349 responses, the model fitness indices were as follows: ?2 = 656.355, degree of freedom (df) = 409, CMIN/DF= 1.605 (<3), p < 0.001, GFI= 0.903 (>0.9), TLI= 0.944 (>0.9), CFI= 0.950 (>0.9), RMSEA= 0.042 (<0.07). Hence, all the GOF indices met acceptable requirements, indicating that the measurement model achieved a good fit. As shown in Table 4, each item (Con1, Con2) and the first-order indicators (CON, OSO) significantly relate to the second-order latent constructs, the so-called utilitarian gratifications. Similarly, satisfying results were achieved with respect to hedonic and social gratifications and consumer state anxiety. In addition, the dependent variable (in-store purchase intention) was measured through a single item by probing the extent to which consumers were willing to purchase products after using their smartphones in-store. Single item has been accepted in existing studies as respondents can easily interpret the question [139,140]. This variable is further examined in the SEM and mediation analysis.",0.3827530251408236,0.7625758,0.815957248210907,8.095477544671495e-07,0.9413632119514475
158,44.jpg," All the items have high factor loadings, greater than 0.80, which indicates that they are all good measures of the latent variable.","Apart from achieving scale reliability, examining construct validity is suggested to embrace both convergent and discriminant validity tests. Convergent validity is assessed according to three aspects. First, all factor loadings should be statistically significant, with a standardized parameter of 0.5 or higher [141]. According to the output in Table 4, all indicators (CON and OSO) are significantly related to the latent constructs, falling between 0.534 (product information seeking via branded mobile apps) and 0.927 (consumer engagement via online brand communities). Second, the average variance extracted (AVE) is considered as the mean variance extracted for the items loading on a construct and is a conclusive index of convergence [142], with a suggested adequate convergence of over 0.5. The third attribute evaluates composite reliability (CR), an acceptable value of good reliability, suggested as being higher than 0.7. Table 5 demonstrates the convergent and discriminant validity performance.",0.2184774481298784,0.8290304,0.8435326814651489,0.002485106733628416,0.8101911976911975
159,45.jpg, Table 2. Results of the structural equation model.,"When performing the structural model, smartphones? utilitarian, hedonic, and social gratifications were independent variables, the mediator being named as consumer state anxiety, and purchase intention was the dependent variable. In a similar vein, the model's fitness indices were exhibited first: ?2 = 860.589, degree of freedom (df) = 532, CMIN/DF= 1.618 (<3), p < 0.001, GFI= 0.910 (>0.9), TLI= 0.928 (>0.9), CFI= 0.936 (>0.9), RMSEA= 0.042 (<0.07). These indicators support a valid and reliable structural model leading to hypotheses testing (Table 6).",0.28096456791696967,0.6901957,0.8340247869491577,5.606513036914691e-05,0.8799107142857143
160,46.jpg," The table shows the frequency and percentage of each category, as well as the non-response bias tests (early vs. late 25% of respondents). The T-value and P-value are also shown.

For gender, the T-value is 0.87 and the P-value is 0.32. This means that there is no significant difference between the early and late respondents in terms of gender.

For age, the T-value is 0.96 and the P-value is 0.40. This means that there is no significant difference between the early and late respondents in terms of age.

For education, the T-value is 1.33 and the P-value is 0.22. This means that there is no significant difference between the early and late respondents in terms of education.

For usage experience, the T-value is -1.20 and the P-value is 0.19. This means that there is no significant difference between the early and late respondents in terms of usage experience.

Overall, there is no significant difference between the early and late respondents in terms of gender, age, education, or usage experience. This suggests that the non-response bias is not a major concern in this study.","Mediation analysis was performed to test the fourth hypothesis via Hayes? PROCESS Macro [144]. The advantages of conducting mediation analysis beyond SEM are threefold in this study. First, the PROCESS can test moderator and mediator effects in one model and suggest conditional outcomes. Second, SEM inspects the entire model while PROCESS can perform each equation separately [145]. Third, PROCESS incorporates bootstrapping methods that further recommend reliable results by evaluating extra information. Table 7 presents the mediation analysis results, including total, indirect, and direct effects of the models.",0.25635347752798954,0.8379038,0.8022674322128296,0.3989071038251366,0.833566736845425
161,47.jpg," Table 1 shows the descriptive statistics, reliability coefficients, and correlations among the study variables. All of the variables were normally distributed, and the reliability coefficients were all above 0.70, indicating good reliability. The correlations between the variables were all significant, indicating that the variables are all related to each other.","The constructs of interest were measured using archival data. We measured remote work firm's initiatives through the natural logarithm of the number of remote work firm's initiatives mentions in news published about these initiatives per firm in t1, t2, and t3, with information collected from MyNews database (https://www.mynews.es/). This database includes news from more than 700 online and print editions of the national, regional, and international press. We performed a structured content analysis following the well-established protocol used in leading prior studies (e.g., [43,44,47]). Based on the review of relevant academic literature, managerial reports, and news on IT-enabled remote work, a preliminary list of keywords on remote work firms? initiatives was created. One of the authors discussed this list with three IT executives and four HR (business) executives. According to their recommendations and by carefully using their feedback, 20 keywords were selected and used for the corporate news coding protocol (Table 4). We considered these tools to be crucial to deploy remote work initiatives.4 Two of the authors conducted the news coding protocol. For each period, the two coders carefully read the news where the keyword appeared to check that the news referred to any remote work firm's initiative. We collected and read 2778 news in t1, 7819 news in t2, and 6353 news in t3 where the keywords appeared (Table 4). Each news contained different keywords referring to different initiatives on remote work. In that case, we computed as one each of these initiatives on remote work. After being read and coded, 111, 1137, and 847 remote work firm's initiatives mentions were found in t1, t2, and t3, respectively.",0.25382133309365573,0.8998348,0.8055232763290405,0.0067116124803440775,0.7641385281385282
162,48.jpg," The table shows the frequency of members in each department. The departments are marketing, logistics, development planning, finance, and human resources. The members are M11, M12, M13, F11, F12, F13, M21, M22, M23, M24, F21, M31, M32, F31, F32, F33, M41, M42, M43, and F41. The frequency is the number of times that a member is in a department. For example, M11 is in the marketing department 6 times.","We empirically tested the proposed research model running a partial least squares path modeling (PLS-PM), a variance-based structural equation modeling (SEM) technique [46,50] that is suitable to test the proposed model for two reasons. First, PLS is a full-fledged estimator that enables the empirical test of conceptual models in both confirmatory and explanatory IS research (as in this study) by using an overall evaluation of the fit of the saturated and estimated models [46]. Second, all the constructs of the proposed research model were conceptualized and operationalized as composite constructs, and this estimator is suitable to test composite models [48,51]. Moreover, PLS has been used extensively in the IS research area (e.g., [[52], [53], [54], [55], [56], [57]]). We used the statistical software package Advanced Analysis for Composites (ADANCO) 2.1. Professional (e.g., [58,59]) because it provides consistent estimates, and it has been designed for confirmatory research, as our study [60]. We ran a bootstrapping of 4999 subsamples. The proposed model was specified as a composite model, and all the constructs were estimated using mode B [46]. Table 5 presents the results of the empirical analysis. ",0.3486651833869535,0.6304785,0.7836816310882568,0.09262935070215811,0.6943194888847062
163,49.jpg," | Variable | Values | Count | Min | Max | Mean | Std Dev |
| --- | --- | --- | --- | --- | --- | --- |
| Critical Industry (CI) | Yes | 604 | 0 | 137 | 27 | 25 |
|  | No | 869 | 2 | 89 | 41 | 22 |
| Organization Size (Size) | Small | 619 | 0 | 95 | 22 | 23 |
|  | Medium | 854 | 2 | 137 | 49 | 29 |
|  | Large | 732 | 0 | 86 | 27 | 25 |
| Digital Intensity (DI) | High | 731 | 0 | 57 | 17 | 17 |
|  | Low | 741 | 0 | 63 | 19 | 19 |
| Network Segmentation (NS) | Yes | 474 | 0 | 161 | 51 | 47 |
|  | No | 999 | 1 | 69 | 32 | 27 |
| Vulnerability Assessment (EVSS) |  | 279 | 0 | 39 | 8 | 13 |
| Attack Vector (AV) | Local | 223 | 0 | 181 | 61 | 53 |
|  | Network | 1164 | 1 | 5 | 66 | 57 |
|  | Physical | 152 | 0 | 181 | 73 | 60 |
| Privileges Required (PR) | High | 1321 | 0 | 9 | 73 | 2 |
|  | Low | 107 | 1 | 221 | 60 | 63 |
| Attack Complexity (AC) | High | 1451 | 0 | 219 | 69 | 63 |
|  | Low | 998 | 2 | 177 | 59 | 54 |
| User Interaction (UI) | Required | 375 | 0 | 45 | 12 | 12 |
|  | Not Required | 1264 | 2 | 223 | 63 | 55 |
|  | Not Changed | 209 | 0 | 7 | 69 | 32 |
| Scope (S) | Confidential | 1224 | 2 | 223 | 66 | 57 |
|  | Integrity | 1203 | 0 | 5 | 66 | 1 |
|  | Availability | 1337 | 0 | 34 | 7 | 8 |
| Information Security Governance (ISR) | Yes | 1156 | 1 | 203 | 57 | 57 |
|  | No | 1317 | 1 | 18 | 65 | 61 |
| Cyber-security Role (CSR) | Ransomware | 203 | 1 | 19 | 68 | 51 |
|  | In Million US$ | 266 | 0 | 32 | 65 | 26 |
| Losses (L) |  | 1473 | 0 | 4219 | 1254 | 797 |","Table A1 (in the appendix) presents the correlation matrix. We find support for H1 (beta = 0.278, p < 0.01) and H2 (beta = 0.203, p < 0.01) which indicates the following. 1. Companies that designed and executed a leader remote work strategy have continued executing these initiatives, which has provided leaders with a competitive advantage in remote work over their competitors. 2. Leaders and agile companies which have previously worked deliberately (leaders) or emergently (agile) on these remote work initiatives can yield leaders and agile a competitive advantage over survival companies that work on remote work initiatives through improvisation. The R2 values for remote work firm's initiatives in t1, t2, and t3 were 0.587, 0.570, and 0.650, respectively. The adjusted R2 values for the remote work firm's initiatives in t1, t2, and t3 constructs were 0.579, 0.556, and 0.639, respectively. The effect size (f2) values for the supported hypotheses ranged from 0.096 to 0.168, which indicates the medium size of these effects [61]. In addition, we compared the empirical correlation matrix with the model-implied correlation matrix of the estimated model to estimate three discrepancies between these two matrixes [62]: standardized root-mean-squared residual (SRMR), unweighted least squares (ULS) discrepancy (dULS), and the geodesic discrepancy (dG) [46]. SRMR should be lower than 0.080, and all the HI95 values should be greater than the values of the three discrepancies [46]. This analysis suggests that neither model should be rejected based on an alpha level of 0.05 since all discrepancies are below the 95%-quantile of the bootstrap discrepancies, which indicates that with a 5% probability, our theoretical hypotheses and the research proposed model are correct. Related to the control variables, the effects of firm size were significant on remote work firm's initiatives in t1 (beta = 0.112??) and t3 (beta = 0.112*). The size of these effects was similar (0.030 and 0.034, respectively). The influence of the firm's RSE in remote work was significant and with a large effect size in the three periods. The beta coefficients ranged from 0.649??? (t2) to 0.748??? (t1). The effect sizes were large, ranging from 0.994 (t3) to 1.342 (t1). The results show that the largest influence of the firm's RSE in remote work on the deployment of pioneer remote work initiatives was in t1, which is consistent with the leader remote work strategy.",0.02031311182807972,0.12913166,0.7488442063331604,0.3347732181425486,0.8227134105606326
164,50.jpg," **Correlation Matrix**

|  | CI | Size | DI | NS | EVSS | CSR | Type of Attack |
|---|---|---|---|---|---|---|---|
| CI | 1 | -.042 | -.121** | -.096** | .009 | .000 | .170 |
| Size |  | 1 | -.074 | -.048 | -.055 | .215** | .204** |
| DI |  |  | 1 | .070* | -.049 | .034 | .143** |
| NS |  |  |  | 1 | .048 | .004 | -.141** |
| EVSS |  |  |  |  | 1 | -.070* | .052 |
| CSR |  |  |  |  |  | 1 | -.024 |
| Type of Attack |  |  |  |  |  |  | 1 |"," As we empirically show in the experiments, the multistage approach provides better results than a single-stage end-to-end approach using multiobjective optimization with a constraints-based approach. The overall PREM process and components are presented in Fig. 4. As an overview of Fig. 4, the three most critical problems are noise, sparsity, and imbalance. We tackle each of these problems through two components ? feature embeddings and cost-sensitive classification.",0.025056677143406696,-0.1047665,0.7493282556533813,0.34435261707988984,0.3623737373737374
165,51.jpg," The table shows the results of a multiple regression analysis. The dependent variable is EVSS. The independent variables are Size, CI, DI, NS, CSR.

The results show that Size, CI, DI, and NS are all significant predictors of EVSS. CSR is not a significant predictor of EVSS.

The hypotheses are:

H1: Size is positively related to EVSS.
H2: CI is positively related to EVSS.
H3: DI is positively related to EVSS.
H4: NS is positively related to EVSS.
H5: CSR is positively related to EVSS.

The results support hypotheses H1, H2, H3, and H4. The results do not support hypothesis H5.","The dataset used for PREM development consists of more than 64 million trip booking records of customers traveling between 2017 and 2019. The dataset contains information concerning the price of the upgrade offer, which customers were sent upgrade offers, and which customers did or did not accept the update offers. This data is valuable for analyzing customer upselling and price elasticity dynamics in a major and competitive industry, and findings have implications for other travel-related domains. More than 14 million customers received upgrade offers (with a reach rate of 22%), and over 194,000 customers accepted the upgrade (with a conversion rate of 1.43%), as shown in Table 1.",0.18292914487880657,0.7730583,0.8013615012168884,0.3849175979503402,0.8116083036875114
166,52.jpg," | Model | Algorithms | Accuracy (p) | Misclassification rate (q = 1-p) | Precision | Recall | F1 score |
|---|---|---|---|---|---|---|
| M1 | LR | 0.93 | 0.07 | 0.97 | 0.89 | 0.93 |
| M2 | NB | 0.90 | 0.10 | 0.66 | 0.81 | 0.66 |
| M3 | DT | 0.92 | 0.08 | 0.86 | 0.45 | 0.66 |","We did evaluate other encoding approaches, including dimensionality reduction techniques such as PCA. As discussed below in Table 2 (Results of feature embedding analysis), our embedding algorithm outperforms other approaches. While we did not invent this embedding algorithm, we are the first, to our knowledge, to apply it to airline data to tackle noise and sparsity issues. This applied study draws from computer science to solve a problem with real-world impact.",0.0,0.021949453,0.7883583903312683,0.0,0.4031045751633987
167,53.jpg," The table shows the correlation matrix of 16 variables. The variables are:
Game Creativity 1
Game Creativity 2
Game Achievability 1
Game Achievability 2
Game Immersibility 1
Game Immersibility 2
Game Immersibility 3
Competence Satisfaction 1
Competence Satisfaction 2
Competence Satisfaction 3
Autonomy Satisfaction 1
Autonomy Satisfaction 2
Autonomy Satisfaction 3
Autonomy Satisfaction 4
Relatedness Satisfaction 1
Relatedness Satisfaction 2
Relatedness Satisfaction 3
Relatedness Satisfaction 4
Game Continuance 1
Game Continuance 2
Game Usage 1

The correlation matrix shows the relationships between the variables. For example, the correlation between Game Creativity 1 and Game Creativity 2 is 0.76. This means that there is a strong positive relationship between the two variables. The correlation between Game Achievability 1 and Game Achievability 2 is 0.16. This means that there is a weak positive relationship between the two variables.","A key hyperparameter is embedding in size, which determines the vector outputted size by the autoencoder, representing the trip information as a fixed-length vector. We evaluate its impact in the next experiment. When using the autoencoder, one could set the size of the latent representation to an arbitrary number. Traditionally, this size is often set as a power of two. Table 3 shows the results of PREM for different embedding sizes. We can see that an embedding size of 256 represents a sweet spot. Reducing the size results in lesser accuracy and revenue capture, while increasing it could potentially result in overfitting the model.",0.1834496773436893,0.5049278,0.7906368970870972,0.4068627450980392,0.6628187172304818
168,54.jpg," Table 1 shows the correlations among the study variables and descriptive statistics. All of the correlations between the variables were significant (p < .05), except for the correlation between relatedness satisfaction and game usage (r = .09, p > .05). All of the variables had acceptable composite reliabilities and average variance extracted values, indicating good convergent and discriminant validity.","From Table 4, we can see that a DL model using embeddings provides the best results. However, one could also use other traditional classifiers, such as logistic regression, support vector machine, or random forest, and pay only a minor penalty in the F1 score and almost none in revenue capture. Using the original data without the embeddings shows a steep drop in the F1 score for both DL-based and non-DL-based methods. As shown in Table 4, we evaluated alternate approaches for handling imbalanced data [69], such as the Synthetic Minority Oversampling Technique (SMOTE), oversampling, and the use of generative models such as Generative Adversarial Networks (GANs). We used random forests as the downstream classifier. From Table 4, we can see that traditional approaches such as oversampling are outperformed by the GAN, where we generate synthetic data for the rare classes so that the training data is balanced. Our embedding-based approach outperforms each of these approaches.",0.2798465636965297,0.81438357,0.8060768246650696,0.09880253596364585,0.7390618805797379
169,55.jpg, Table 1. Demographics of the participants (N = 550).,"The personalized upgrade model uses a binary autoencoder to segment customer bookings into K segments so that similar customers have similar embeddings. Once the segmentation is obtained, PREM estimates the response rate for each upgrade offer bucket. We consider two other segmentation approaches that also result in K segments. The first is based on K-Means that cluster all bookings into K distinct clusters, with K = 7. Our other baseline is a decision tree that tries to partition bookings using the Gini criterion. As shown in Table 5, our approach gives the best results.",0.13438303104513846,0.5740924,0.826738715171814,4.395997006686765e-05,0.6458333333333333
170,56.jpg," From the table, we can see that:

- H1a is not supported since the p-value (0.56) > 0.05.
- H1b is not supported since the p-value (0.58) > 0.05.
- H2a is supported since the p-value (< 0.01) < 0.05.
- H2b is supported since the p-value (< 0.01) < 0.05.
- H2c is supported since the p-value (< 0.01) < 0.05.
- H3a is supported since the p-value (< 0.01) < 0.05.
- H3b is supported since the p-value (0.01) < 0.05.
- H4a is supported since the p-value (< 0.01) < 0.05.
- H4b is supported since the p-value (< 0.01) < 0.05.
- H4c is not supported since the p-value (0.83) > 0.05.
- H5 is supported since the p-value (< 0.01) < 0.05.","Next, we evaluate the revenue maximizer component. Recalling that we use an integer programming approach to select the best customers and the corresponding offers, a natural alternative is to use a greedy baseline that works as follows. First, the greedy algorithm computes each customer's expected revenue for each offer. Then, the Revenue Maximizer picks the best among them. For example, if Customer A accepts an offer of $500 with a 0.5 probability and $1000 with a 0.2 probability, then the expected revenues are $250 and $200, respectively. So, the Revenue Maximizer identifies that the best offer for Customer A is $500, with expected revenue of $250. Suppose there is another customer, Customer B, whose expected revenue is $300, and the model needs to select one customer. Here, the greedy algorithm will pick Customer B. As shown in Table 6, the revenue maximization of PREM (ILP) outperforms the greedy algorithm baseline.",0.19458456738450677,0.4663451,0.8029024004936218,0.3525730753183796,0.8228458049886621
171,57.jpg, Moderator and mediation effects on the relationships between independent variables and continuance intention and usage intention.,"We propose a novel multistage approach based on feature development, the offer acceptance model, a personalized upgrade model, and a revenue maximizer. It is worth investigating if one needs such a multistage model in the first place. Specifically, two questions are of interest: (a) What would have happened if PREM used a single-stage classifier? and (b) What would have happened if PREM skipped the offer cost classification component or the revenue maximizer? The results presented in Table 7 address these questions. As shown in Table 7, the proposed PREM approach containing separate and sequential stages provides the best results. If one squeezes all of these stages into a single stage (i.e., if one trains a single classifier that takes all the bookings of a flight as input and returns the list of users and upgrade offers as output), then that gives the worst result. Splitting tasks into the different stages of an ML system clearly improves the performance in this context. Instead of the classifier trying to handle multiple objectives, each classifier in the PREM approach is targeted and focused on a single task, resulting in superior overall performance. Table 7 also indicates that all three components contribute positively. If one skips the revenue maximizer, then the accuracy drops marginally, but there is a steeper drop in revenue capture. Similarly, if one skips the offer classification and runs the upgrade offer determination for every user on the flight, there is a steep drop in accuracy but a smaller drop in revenue capture.",0.1832304967579292,0.8815603,0.8048293590545654,2.1275927538022295e-07,0.7626678876678876
172,58.jpg," The table shows the frequency and percentage of respondents in a survey. The survey has five categories: gender, age, education, organizational position, and industry.

For gender, there are 165 male respondents (80.1%) and 41 female respondents (19.9%).

For age, the majority of respondents are aged between 35 and 44 (25.7%), followed by those aged between 45 and 54 (26.2%).

For education, most respondents have a bachelor's degree (62.1%), followed by those with a high school diploma or less (24.8%).

For organizational position, the majority of respondents are in middle management (31.6%), followed by those in top management (29.6%).

For industry, the majority of respondents are in the manufacturing industry (28.4%), followed by those in the service industry (25.9%).","LMM requires data to be set up in the long format such that there were 17 rows per participant. We first examined the psychometric properties of the model by assessing the convergent and discriminant validity of conservatism and collectivism variables. As shown in Table 4, because of low factor loadings, CONS1, CONS7, and CONS8 were dropped from the conservative position scale, and COL5 was dropped from the collectivism scale. The items listed in Table 4 lead to distinct constructs that demonstrated excellent Cronbach's a (Hair Jr, Hult, Ringle, & Sarstedt, 2013). The conservatism scale had Cronbach's a = 0.851, and the collectivism scale had Cronbach's a = 0.849. Discriminant validity was further assessed by examining items? cross-loadings that were all smaller than their factor (of interest) loadings (Hair [113]). As such, the measurement model demonstrated sound psychometric properties. In addition, we gauged the degree of multicollinearity between items and constructs in our study by calculating variance inflation factors (VIFs). All VIF values were <3.3, indicating that multicollinearity was not a concern in this study. While the focus of this study is on individuals? conservative political beliefs and their espoused cultural beliefs, we also added the country variable to control for the participant's country of origin, which may play a part (given the data were collected in two different countries). However, the focus remains on individual-level beliefs ? both political and cultural.",0.33086848917321876,0.68949586,0.7942835688591003,0.19515382584940877,0.8029702171651325
173,59.jpg," The table shows the frequency and percentage of companies in different industries and countries. The data is based on a survey of 120 companies.

The most common industry is automotive, which accounts for 25.1% of the companies. This is followed by aerospace and defence (18.4%), and construction (12.6%).

The most common country is Germany, which accounts for 29.2% of the companies. This is followed by the United States (16.7%), and the United Kingdom (12.5%).

The table shows that the majority of companies are located in Europe (58.3%). This is followed by North America (25.8%), and Asia (15.8%).","As shown in Table 5, both hypotheses were supported. With increasing degree of conservatism (? = 0.65; p < 0.0001) and collectivism (? = 0.21; p < 0.0001), individuals? fake news believability increased significantly, thereby providing support for both H1 and H2 and answering positively both associated research questions. Participants? gender (? = -0.02) was found not significant. Age (? = -0.004; P < .01) was significant such that with increasing age, the fake news believability decreased. Internet usage (? = 0.03; P < 0.05) was also significant such that with increasing daily Internet usage, individuals? fake news believability increased. Country variable was found significant (? = 0.36; P < 0 .001) such that American participants (mean = 3.12) in general were more likely than Indian participants (mean = 2.77) to lend credence to the fake news scenarios presented.",0.1287425153786507,0.7154713,0.7995430827140808,0.2607641231254954,0.8130338733431514
174,60.jpg, Table shows the correlations between variables. All correlations are significant at the 0.01 level (2-tailed).,Table 1 presents the descriptive statistics and Pearson correlation coefficients of all variables.,0.20277335544414993,0.8629776,0.8940659165382385,0.4666666666666667,0.7051467051467051
175,61.jpg," The table shows the fit indices for the measurement model and the path model. The measurement model has a good fit, with a CFI of 0.959 and a SRMR of 0.050. The path model also has a good fit, with a CFI of 0.946 and a SRMR of 0.071. The RMSEA is 0.050 for both models, which is also within the acceptable range. Overall, the fit indices suggest that the measurement model and the path model are both good fitting.","Table 2 displays tests of the hypotheses. Models 1?3 and 4?6 use resource utilization (seat utilization) and product concentration (concentration) as the dependent variables, respectively. Models 1 and 4 are baseline models. They only include control variables. Models 2 and 5 include the independent variables for testing Hypotheses 1a and 1b. Models 3 and 6 include interaction terms between demand-side usage of O2O digital platforms and the extent of vertical and horizontal inter-firm relationships to test Hypotheses 2a, 2b, 3a, and 3b. All models tested are statistically significant. Wald's chi-square values are reported.",0.2884041764001302,0.75524265,0.8108855485916138,0.3754237731828841,0.8347700216450216
176,62.jpg," The table shows the results of a study that examined the relationships between various factors and employee resistance to XR adoption. The hypotheses tested in the study are listed in the first column, followed by the relationship between the variables in the second column. The third column shows the effect size of the relationship, and the fourth column indicates whether the hypothesis was supported or not.

The results show that there is a significant negative relationship between expected employee resistance and XR adoption intention, as well as between expected employee resistance and perceived organizational value of XR. This means that as expected employee resistance increases, XR adoption intention and perceived organizational value of XR decrease.

There is also a significant positive relationship between perceived organizational value of XR and organizational XR adoption intention. This means that as perceived organizational value of XR increases, organizational XR adoption intention also increases.

Additionally, the results show that there is a significant negative relationship between employee technology use skills and expected employee resistance to XR. This means that as employee technology use skills increase, expected employee resistance to XR decreases.

There is also a significant negative relationship between organizational support and expected employee resistance to XR, as well as between organizational support and perceived organizational value of XR. This means that as organizational support increases, expected employee resistance to XR and perceived organizational value of XR decrease.

However, the results did not support the hypotheses that there would be a significant relationship between external support and expected employee resistance to XR, between mimetic pressure and perceived organizational value of XR, between compatibility and expected employee resistance to XR, between compatibility and perceived organizational value of XR, between triability and expected employee resistance to XR, or between triability and perceived organizational value of XR.

Overall, the results of the study provide some evidence to support the idea that employee resistance to XR adoption is influenced by a variety of factors, including expected employee resistance, perceived organizational value of XR, employee technology use skills, and organizational support.","Table A1 in the Appendix presents the results of robustness checks when the total number of all movie theaters is used as the measure of chain size and the new measure of concentration. The results indicate that the online ratio remains a strong predictor for operational decisions made by theaters. The study also finds that vertical relationship and chain size remain significant moderators. Hence, the results are robust to new formulations of critical variables. ",0.34040648371247884,0.92876685,0.8117870688438416,0.3978494623655914,0.7572831534708373
177,63.jpg," **Mediation Path	Effect**
Mimetic pressure â Perceived organizational value of XR â Organizational XR adoption intention	0.206**
Organizational support â Expected employee resistance to XR â Organizational XR adoption intention	0.088**
Employee technology use skills â Expected employee resistance to XR â Organizational XR adoption intention	0.069*
Triability â Expected employee resistance to XR â Organizational XR adoption intention	0.047*

Note: *** p < 0.001, ** p < 0.01, * p < 0.05","Table A2 in the Appendix shows the results. Models 7 and 9 contain control variables, while Models 8 and 10 include independent variables. In Model 8, the results show that both seat utilization (? = 0.592, p < 0.01) and concentration (? = 0.191, p < 0.01) have a positive and significant impact on revenues. In Model 10, the results show that both seat utilization (? = 0.418, p < 0.01) and concentration (? = 0.131, p < 0.01) have a positive and significant impact on the audience.",0.01137491500843324,0.65344715,0.8205376863479614,0.31603575426708275,0.5847861178369652
178,64.jpg," The table shows the ballpark risk of different activities. The risk is expressed in terms of the number of people harmed, hospitalized, or killed per year in the United States. The activities are food safety, consumer goods, sports, and health.

The highest risk activity is food safety, with an estimated 7% of food samples containing harmful bacteria. This results in 15% of US citizens being harmed, 0.04% being hospitalized, and 0.0009% dying each year.

The second highest risk activity is health, with an estimated 22% of the global population being harmed by smoking. This results in 3-19% of smokers being hospitalized and 8.7-11.7% of smokers dying each year.","Based on the above discussion, our theoretical framework is summarized in Fig. 1.",0.149075561084734,0.6282312,0.8248903751373291,0.3518518518518519,0.6717666078777188
179,65.jpg," This is a confusion matrix. It is used to evaluate the performance of a classification model. The matrix shows the number of correct and incorrect predictions made by the model.

In this case, the model is trying to classify inputs into three categories: 'bad', 'good', and 'other/neutral'. The output of the model is a probability distribution over these three categories. The model's prediction is the category with the highest probability.

The confusion matrix shows that the model made 90% correct predictions on the 'bad' category, 80% correct predictions on the 'good' category, and 70% correct predictions on the 'other/neutral' category. Overall, the model made 80% correct predictions.

The confusion matrix can be used to identify the types of errors that the model is making. In this case, the model is making more errors on the 'other/neutral' category than on the other two categories. This suggests that the model is having difficulty distinguishing between the 'other/neutral' category and the other two categories.",Table 1 summarizes the profiles of responding companies and respondents.,0.21229644951152046,0.681976,0.814300537109375,0.3457556935817806,0.7094937843385047
180,66.jpg," This is a table that shows the number of recommendations that were good, bad, or neutral. The table also shows the number of recommendations that were made by each platform and the type of content that was recommended.

In total, there were 151 bad recommendations, 151 recommendations that were not good or bad, and 62 good recommendations.

YouTube made the most recommendations, followed by search engines, Twitter, Facebook, TikTok, Amazon, and Instagram.

The most common type of content that was recommended was misinformation, followed by political radicalization, child harm, bias/discrimination, and mental health.

The most common way that recommendations were made was through search results, followed by autoplay, API graphs, newsfeed, side panels, channels, and homepage.","All items in this paper were adapted from the tested scale and measured by a seven-point Likert scale, ranging from ?1? to ?7? (?1? = ?strongly disagree? and ?7 = ?strongly agree?)  as shown in Table 2. In particular  four items adapted from Bharadwaj et al. [6] were used to measure digitalization capabilities  and these items reflected the degree to which companies could access customer-related order-related production-related  and market-related data. """,0.15107244763147373,0.6504887,0.798644483089447,0.39655172413793105,0.7578820843907049
181,67.jpg," The structural model of the relationships between perceived gamification, negative affect, ease of imagination, existential authenticity, lack of focused attention, and behavioral intention. *pâ<â0.05.",The results in Table 3 thereby confirmed the effectiveness of discriminant validity.,0.2159028365353705,0.6872306,0.833971381187439,0.41025641025641024,0.5875736485736486
182,68.jpg, Table 1. Discriminant and convergent validity.,"The estimated results based on the logic of stepwise regression are presented in Table 4. It can be seen that first, digitalization capabilities ( ) positively affect market capitalizing agility. Second, both digitalization capabilities ( ) and market capitalizing agility ( ) positively relate to operational adjustment agility. Third, without any mediators, digitalization capabilities ( ) pose a positive relationship with firm performance. Fourth, when considering the combined effect of digitalization capabilities, market capitalizing agility, and operational adjustment agility on firm performance, only market capitalizing agility ( ) and operational adjustment agility ( ) show significant coefficients, whereas the coefficient of digitalization capabilities is nonsignificant ( ). The above results thereby indicate that the full mediating role of market capitalizing agility and operational adjustment agility in influencing the relationship between digitalization capabilities and firm performance.",0.07580295482513846,0.7067282,0.8158807158470154,2.555030765917954e-10,0.6208333333333333
183,69.jpg," A total of 920 records were identified through the database searching. After removing duplicates, 563 records were screened by title and abstract, of which 117 were assessed for eligibility. Of these, 49 full-text articles were excluded, and 68 studies were included in the qualitative synthesis.","Table 5 further presents the results based on the bootstrap method with 5000 samples and a 95% confidence interval (CI) [62]. In particular, when the 95% CI's upper and lower bounds do not include zero, such a path is statistically significant; in contrast, when the 95% CI's upper and lower bounds include zero, such a path is statistically nonsignificant. As Table 5 shows, the direct effect of digitalization capabilities on firm performance (direct effect = 0.052, SE = 0.078) is statistically nonsignificant; in contrast, the indirect effects of digitalization capabilities on firm performance through market capitalizing agility (indirect effect = 0.088, SE = 0.054), operational adjustment agility (indirect effect = 0.077, SE = 0.045), and the sequence of market capitalizing agility and operational adjustment agility (indirect effect = 0.046, SE = 0.023) all have significant coefficients. Hence, these results again support all of our hypotheses.",0.14771745822465923,0.7253128,0.8031026721000671,0.048966291974338126,0.7073096039762706
184,70.jpg," As shown in Table 1, the KMO value of the scale is 0.922, and the Bartlett's test result is 187.1 (df = 171, p < 0.001), indicating that the data are suitable for factor analysis. The results of the maximum variance rotation of the four factors are shown in the table. The cumulative contribution rate of the four common factors is 64.754%, which can explain most of the information of the original variables.","We checked the reliability of the constructs in three ways, as reported in Table I.1. We computed Cronbach alpha values, which were all above the 0.70 acceptable threshold [83]. Composite factor reliability (CFR) values were above the 0.70 acceptable threshold [104]. Average variance extracted (AVE) values were above the acceptable threshold 0.50 [104]. As an additional check on discriminant validity, we computed the square root of AVE for each construct and compared it with the construct's correlations with other constructs [37]. ",0.3665980954597194,0.8075989,0.8381190299987793,0.4460550568703489,0.8096274617401377
185,71.jpg, All the items show good convergent validity with the AVE values ranging from 0.668 to 0.718 and CR values ranging from 0.889 to 0.951. All the items also show good discriminant validity since the square root of the AVE for each construct is greater than the correlations between the constructs.,"For each construct, the square root of AVE was desirably greater than the correlation values (Table I.2). These checks provided support for the reliability and validity of the measured constructs.",0.5042513406015358,0.85877293,0.8791884779930115,0.5466666666666666,0.7306031746031748
186,72.jpg," Section 2: Primary Indicators and Ratings
8. Secondary Indicators
9. Rating
10. Observations",The participants had an average duration in the community of 8.70 years (standard deviation=5.33 years). Table 1 lists the demographic information of our participants.,0.0,0.756513,0.8164481520652771,0.0,0.636080586080586
187,73.jpg," The table shows the distribution of the sample in terms of gender, age, education, employment status, and net monthly household income.

The sample is fairly evenly split in terms of gender, with 48.5% male and 51.5% female. The majority of the sample is aged between 25 and 44 (32.2%), followed by those aged between 45 and 64 (19.2%). The majority of the sample has a secondary education (47.3%), followed by those with a higher education (46.5%). The majority of the sample is employed (63.8%), followed by those who are actively seeking work (14.9%). The majority of the sample has a net monthly household income of less than 1100 Euros (25.1%).","Consistent with the literature [1,117,[132], [133], [134]], we conducted an exploratory factor analysis (EFA) to test data validity. Table 3 lists our EFA results that do not show marked cross-loadings, that is, the EFA results offer preliminary support for our data validity. All factor loadings are larger than .82.",0.10949779923249894,0.5709454,0.7885570526123047,0.36363636363636365,0.7685281385281384
188,74.jpg," The table shows the normality test results of the data. The p-values of all the items are less than 0.05, which means that the data is not normally distributed.","Table 4 reports the correlations among our study concepts. These ranged from .09 and .59. Moreover, the square roots of the AVE values (on the diagonal of Table 4) exceeded the associated correlations, indicating sufficient discriminant validity [118,141].",0.42384447696287586,0.73117733,0.8670592904090881,0.34552824793491144,0.7793986664676319
189,75.jpg," The table shows the results of a multiple regression analysis. The dependent variable is Use Intention and the independent variables are Performance Expectancy, Effort Expectancy, Subjective Norms, Facilitating Conditions, Hedonic Motivation, Price Value, Habit and Perceived Risk. The results show that all of the independent variables are significant predictors of Use Intention.","All the hypotheses were supported. Community commitment is positively related to taking an administrator role (H1), which is further positively related to public space contribution, private space contribution, and OL (H2, H3, and H4). Taking an administrator role has a stronger impact on public space contributions than on private space contributions (H5) and on OL (H6). Table 5 lists the testing results of H5 and H6. Specifically, we followed Ray et al. [46] and therefore used the t tests to compare the influences of taking an administrator role on three positive community behaviors. More details can be found in Ray et al. [46]. Both H5 and H6 were supported.",0.19096287174774065,0.8061276,0.8211502432823181,0.15422484107108164,0.7593684093684095
190,76.jpg," The table shows the results of a multiple regression analysis. The dependent variable is Use Intention. The independent variables are Performance expectancy, Effort expectancy, Subjective norms, Facilitating conditions, Hedonic motivation, Price value, Habit and Perceived risk.

The results show that all of the independent variables are significant predictors of Use Intention. The strongest predictor is Performance expectancy, followed by Effort expectancy and Subjective norms. The least significant predictor is Perceived risk.

The collinearity statistics show that there is no significant collinearity between the independent variables. The tolerance values are all above 0.10 and the VIF values are all below 10. This indicates that the independent variables are not highly correlated and that they are all contributing unique information to the model.","Thus, taking the initial sample size as a reference (i.e., 342 companies), the stratified sampling procedure ensured that different proportions of company types according to size (mid-sized vs. large-sized), industry (manufacturing vs. service), and technology intensity (high-techs vs. low-techs, as established by the OECD and Eurostat) were preserved as they exist in the population, thereby improving the precision and representativeness of the resulting sample. The final sample included 346 companies? 4 over the threshold of 342?that answered the provided questionnaire. Table 1 provides more details about the composition of the sample.",0.3905759831978462,0.8063079,0.8112242817878723,0.4325068870523416,0.759394118278416
191,77.jpg," Table 1. Measurement Model Results

Note: CA = Cronbach's alpha; AVE = average variance extracted; CR = composite reliability; PRI = perceived risk intention; HAB = habit; FCI = facilitating conditions; SN = subjective norm; EE = effort expectancy; PE = performance expectancy. All factor loadings are significant at p < 0.05.","As data was collected through a single method (i.e., survey), this presented the possibility of the occurrence of what is known as common-method bias [[115], [116]]. To determine the extent of the method variance in the dataset, we used the marker variable approach [117]. To that end, we included a two-item scale regarding competition intensity,2 based on Jaworski and Kohli [118]. Subsequent correlation analysis revealed that correlations between the marker variable and independent, mediating, and dependent variables were very low, the largest one being 0.191. Thus, it could be concluded that common method variance was not a likely problem in our dataset. Also, a full collinearity test specially conceived for PLS-SEM [119] was carried out. The above test includes both vertical (predictor?predictor) and lateral (predictor?criterion) collinearity analyses. According to Kock [119], if all the variance inflation factors (VIFs) resulting from a full collinearity test are equal to or lower than 3.3, the model can be considered free of common-method bias. The highest VIF in our model (see Table 2) was 2.023, well below the 3.3 threshold. Therefore, this provides further evidence for ruling out the potential for common-method bias.",0.028163551677344936,0.7110951,0.7804845571517944,0.026675002680192572,0.7610758950044667
192,78.jpg, **. Correlation Matrix.**,"Once the quality of the measurement model was guaranteed and before evaluating the structural model, a collinearity test was carried out. This collinearity test was performed to rule out any potential bias in path coefficients due to critical levels of collinearity among the predictor constructs [137]. Analogous to the assessment of composite measurement models, VIF values should be lower than 3. Table 4 shows the results obtained. As can be observed, all VIFs are well below the established threshold, the highest one being 2.121. Therefore, collinearity in the structural model is not a problem in this research.",0.0,0.32623926,0.8256349563598633,0.0,0.7424242424242424
193,79.jpg," The table shows the results of a multiple regression analysis. The dependent variable is Use Intention. The independent variables are Performance Expectancy, Effort Expectancy, Subjective Norms, Facilitating Conditions, Hedonic Motivation, Price Value, Habit, and Perceived Risk.

The results show that all of the independent variables are significant predictors of Use Intention. The strongest predictor is Performance Expectancy, followed by Effort Expectancy and Subjective Norms. The other variables are also significant, but they have a smaller effect on Use Intention.

The table also shows the standardized coefficients for each independent variable. These coefficients show the relative strength of each predictor, taking into account the different scales of the variables. The strongest predictor is Performance Expectancy, followed by Effort Expectancy and Subjective Norms. The other variables are also significant, but they have a smaller effect on Use Intention.","To test the significance and strength of the proposed relations, we used a one-tailed 5000 subsample BCA bootstrap [137]. Fig. 2 and Table 5 show the results obtained. As can be observed, quality data shows a very strong and positive relationship with IT-enabled data analytics sensing (? = 0.689). Thus, hypothesis H1 is supported. Moreover, both quality data (? = 0.340) and IT-enabled data analytics sensing (? = 0.317) are positively and significantly related to marketing innovation. As the indirect effect of quality data on marketing innovation via IT-enabled data analytics sensing is positive and significant (?1 ? ?2 = 0.219), partial mediation applies. Hence, hypotheses H2a and H2b are supported.",0.22558388199978563,0.8368424,0.8211122155189514,0.4411764705882353,0.7772822765469827
194,80.jpg," The table shows the results of a structural equation model (SEM) analysis. The model has eight hypotheses, and the results show that all of the hypotheses are supported. The path coefficients are all significant, and the t-values are all greater than 1.96. The p-values are all less than 0.05, and the R-squared values are all greater than 0.02. This indicates that the model has a good fit to the data.","The coefficient of determination (R2 value) of the mediating and dependent variables was also examined, which represents a measure of in-sample predictive power that also indicates explanatory power [122, 137]. As can be observed in Table 6, the amount of variance explained for IT-enabled data analytics sensing reached 47.4%, while for marketing innovation, it scored 38.3% and for market performance 34.1%. Moreover, changes in R2 when a specified exogenous construct is omitted from the model were analyzed by means of the so-called ??2 effect size? [137]. According to Hair et al. [137], for a construct to be relevant when explaining another variable, its effect size should reach the minimum threshold of 0.02. This was the case for both the independent and mediating variables, except for quality data vis-?is market performance.",0.30078243793797405,0.8903529,0.8297300934791565,0.22633218436103997,0.8335116470830757
195,81.jpg," The table shows the training and testing results of a neural network with 10 inputs and 1 output. The inputs are: performance expectancy, effort expectancy, subjective norms, facilitating conditions, hedonic motivation, perceived risk, habit, and price value. The output is use intention. The training and testing results show that the neural network is able to learn the relationship between the inputs and the output.","This data collection approach generated a diverse pool of key informants with diverse professional backgrounds and at various stages of their career. Descriptive characteristics of the key informants as well as the identification of key informants (abbreviated with the letter ?I? for informant and numbered consecutively) are summarized in Table 1. Each of the target organizations tasked a relatively small team of people with blockchain knowledge to (potentially) develop and test a prototype and, thus, interviewed key informants are assumed to be representative of their organization given the very small team size. ",0.29390272829320685,0.8923244,0.8178383708000183,0.2959222412794505,0.810426812770563
196,82.jpg," The table shows the relative importance of each of the ten criteria in the decision-making process. The criteria are listed in the first column, and the relative importance is shown in the second column. The relative importance is a measure of how important each criterion is in the decision-making process. The higher the relative importance, the more important the criterion is.

The most important criterion is Performance expectancy, followed by Effort expectancy and Facilitating conditions. The least important criterion is Perceived risk.

The table also shows the average relative importance of each criterion. The average relative importance is a measure of how important each criterion is on average across all of the decision-making processes. The higher the average relative importance, the more important the criterion is on average.

The most important criterion on average is Performance expectancy, followed by Effort expectancy and Facilitating conditions. The least important criterion on average is Perceived risk.", Table 2 below provides an overview of our primary and secondary data.,0.050492927021323,0.7271315,0.8186803460121155,0.3420479302832244,0.6336568297352614
197,83.jpg," The table shows the result of the PLS-SEM and ANN analysis. The first column shows the relationship between constructs, the second and third columns show the path coefficients and the relative importance of the PLS-SEM, respectively. The fourth and fifth columns show the ranking of the relationships based on the standardized coefficients and path coefficients, respectively. The sixth and seventh columns show the ranking of the relationships based on the normalized relative importance of the ANN. As can be seen from the table, the most important relationships identified by the PLS-SEM analysis are:
- PE -> UI
- EE -> UI
- FC -> UI

The most important relationships identified by the ANN analysis are:
- PE -> UI
- EE -> UI
- FC -> UI

The results of the PLS-SEM and ANN analyses are consistent with each other. Both methods identified the same three relationships as the most important."," Table 4 lists the pairwise correlation among all variables, variance inflation factor (VIF) for independent variables, and relevant descriptive statistics. A positive and significant correlation exists between the two main explanatory variables: Capex and Staffex. Among the control variables, CP and Size are highly associated with other variables. VIF scores for the independent variables indicate that the regression models used in the study are not affected by multi-collinearity. Additional daily data related to FF3F and C4F are obtained from Kenneth French's data library. To ensure that the impact of the WHO's announcement is free from any bias induced by extreme observations, we also compute the CAAR of the outlier-adjusted sample firms. The outlier-adjusted sample comprises all sample firms except those that fall in the top 10% or bottom 10% in terms of the CAR generated from day -30 to day 50.",0.4787491877911265,0.8188688,0.8106594681739807,0.45253863134657835,0.852095027274883
198,84.jpg," The table shows the results of a meta-analysis of studies on the relationships between perceived risk, facilitating conditions, subjective norms, effort expectancy, performance expectancy, and behavioral intention to use mobile payment. The results show that perceived risk has a significant negative relationship with behavioral intention to use mobile payment, while facilitating conditions, subjective norms, effort expectancy, and performance expectancy have significant positive relationships with behavioral intention to use mobile payment. The results also show that the moderating effect of perceived risk on the relationship between facilitating conditions and behavioral intention to use mobile payment is significant.","Table 5 presents some descriptive statistics related to the sample firms for the pre-event and the post-event windows (including the event day). The pre-event period denotes the time interval from 30 days to 1 day prior to the event, and the post-event period includes the time period from the event date to 50 days after it. From Table 5, it is evident that the average daily unadjusted dollar-denominated price reduces from the pre-event ($34.46) to the post-event period ($27.53). In the pre-event period, the average daily return percentage (annualized) is recorded as a minor loss (-0.62%). However, the return decreases even further in the post-event period (-2.03%). The volatility of the return increases in the post-event period (6.32%) compared to the pre-event period (3.06%). The logarithm of the average daily volume of trades also increases after the event. Also, the average daily market capitalization reduces slightly from the pre- to the post-event period. However, there is no change recorded for average shares outstanding between the two-time windows.",0.2560483696317098,0.6336257,0.8079628944396973,0.22871236148703547,0.7636585058460058
199,85.jpg," The table shows the descriptive statistics of the sample. The sample size is 122. The mean age of the respondents is 53.83 years old with a standard deviation of 11.72 years. 42 of the respondents are female and 80 are male. In terms of education, 7.4% of the respondents have a high school diploma, 9.8% have a college degree, 41.8% have a bachelor's degree, 34.4% have a master's degree, and 6.6% have a Ph.D. The mean firm size is 30,443 employees with a standard deviation of 14,822 employees. In terms of industry, 7.4% of the respondents are in the consumer goods industry, 4.1% are in the producer goods industry, 47.5% are in the services industry, 10.7% are in the finance industry, 3.3% are in the utilities industry, and 27% are in other industries.","To investigate the effect of the WHO's announcement on SCF firms, we determine the CAAR as per Eq. (2) and present our findings in Table 6. We estimate the CAAR for two sets of firms (i.e., all sample firms and outlier-adjusted sample firms) over different event windows. From Table 6, we observe that our sample firms incur a significant loss in valuation close to the event date. According to the MM, MMEGE, FF3F, and C4F models, the firms on an average earn -2.8%, -2.1%, -3.2%, and -2.8%, respectively, around the event window [-1, ]. These significant valuation losses are consistently observed throughout the entire event window. In the longest window of our study, (i.e., [-30, ]), sample firms experience a negative and significant CAAR of -19.3%, -23.8%, -28.0%, and -22.3% as per the MM, MMEGE, FF3F, and C4F models, respectively. Therefore, it seems that there is a permanent valuation loss for all SCF firms due to the announcement. This negative impact is not immediate as we do not find a significant drop in the [0, ] event window. However, the loss is quite prominent in the [0, ] window. This significant loss can also be observed in the [-15, ] event window, as estimated by the C4F model. Fig. 3 provides a visual depiction of the valuation loss of firms. The valuation loss is persistent even for a long post-event time period (i.e., [, ]). In contrast, none of the models depict any significant valuation loss for the sample firms in the pre-event time period (i.e., [-30, -1]).",0.43444909338710685,0.818742,0.7997720241546631,0.21052033802680561,0.7851172845533747
200,86.jpg," Table 1 shows the correlation matrix and descriptive statistics for the study variables. All of the variables were significantly correlated with each other, with the exception of age and trust in DDA outcomes. The strongest correlations were between algorithmic injustice and discrimination (r = .40), algorithmic injustice and displacement of responsibility (r = .36), and discrimination and displacement of responsibility (r = .23).","We perform a sub-sample analysis and explore the impact of the WHO's announcement on BlockFirms and Non-BlockFirms, separately. We compute the CAAR for these two groups of firms using the same MM, MMEGE, FF3F, and C4F models across all event windows and report the results in Table 7. Interestingly, there is not a single event window where BlockFims incur a significant loss of valuation. On the contrary, Non-BlockFirms exhibit a significant valuation loss across all event windows. It seems that valuation loss encountered by all SCF firms in the sample is predominantly driven by abnormal losses for Non-BlockFirms. BlockFirms, on the other hand, show enough investor confidence during the turbulent time period.",0.32111925245111417,0.71093106,0.8243429064750671,0.22120502638766837,0.7592292892292892
201,87.jpg," From the table, we can see that all the items have high loadings on their respective constructs, and the cross-loadings are relatively low. This suggests that the items are measuring what they are supposed to measure and that there is no significant issue with discriminant validity.","This negative and significant CAAR for Non-BlockFirms can be potentially caused by either the higher magnitude of losses of a few sample firms or a significantly large number of sample firms that move into the loss-making domain due to the announcement. We explore the same using a binomial sign test. This test measures whether the percentage of firms earning negative returns on a particular day in a specific time window is significantly different from 50% or not. We compute the AAR earned by BlockFirms and Non-BlockFirms and the percentage of firms from each group earning losses on a particular day in the [-15, ] event window. We show the results obtained from the MM and C4F models in Table 8. The columns ?Mean (%)? and ?Negative (%)? represent the AARs and the percentage of loss-earning firms on each day, respectively. It yields two important insights. First, the C4F model shows a lower impact of the announcement than the MM model. The C4F model includes traditional asset pricing factors that play an important role in explaining the AAR. Second, there are few days, i.e., Days 1, 9, and 12, when a higher number of firms among BlockFirms earn negative returns. In contrast, Non-BlockFirms earn losses on 7 out of 15 days in the post-event period. Even Non-BlockFirms start experiencing valuation loss from one day before the event day, probably due to some information leakage or anticipation of panic. These findings support Hypothesis 3.",0.31078173330235553,0.87308306,0.8177148103713989,0.007975232926245615,0.840956265956266
202,88.jpg," Logistic Regression Model (DV: Discrimination)

Main effects
Constant -9.673 (0.001)
Gender -0.791 (0.299)
Age -0.03 (0.265)
Stereotypic Beliefs 0.413 (0.127)
Algorithmic Injustice (0 = Just; 1 = Unjust) 3.867 (<0.001)
Displacement of Responsibility -0.064 (0.819)
Trust in DA Outcomes 1.431 (<0.001)

Main and interaction effects
-0.032 (0.995)
-0.499 (0.556)
-0.034 (0.246)
0.433 (0.142)
5.675 (0.092)
0.459 (0.512)
-0.880 (0.424)
-0.688 (0.364)
2.821 (0.021)

Omnibus Test of Model Coefficients Ï2 = 46.45 (<0.001) Ï2 = 53.16 (<0.001)
Cox and Snell R2 0.321 0.358
Nagelkerke R2 0.540 0.603
Goodness of fit (Hosmer and Lemeshow Test) Ï2 = 10.733 Ï2 = 1.383

Note: P-values are shown in parentheses.","To determine the impact of the WHO's announcement on the trading volume, we compute the CAAV around the event date using Eq. (5). Table 9 presents the estimated CAAV for all sample SCF firms as well as for the sub-samples BlockFirms and Non-BlockFirms across different event windows. From Table 9, it is evident that all sample SCF firms generate abnormally high trading volume around the event day and in the post-event period. The significant increase in trading volume is evident immediately after the event. In the event window [0, ], sample firms on the whole experience a CAAV of 1.335, and the CAAV increases up to 12.454 surrounding the event window (i.e., [-30, ]). This insight is consistent with the low return and high volume relationship in the bear market reported by Chen [77]. Thus, it statistically supports Hypothesis 4 of this study. However, such a significant increase in abnormal trading volume is guided by Non-BlockFirms. Non-BlockFirms experience a much higher trading volume compared to BlockFirms. While a significant increase in the trading volume for BlockFirms is observed only within the first two days of the event day, it is consistently higher in case of Non-BlockFirms for most of the event windows. This finding supports Hypothesis 5.",0.05902819451290452,0.38097778,0.783980667591095,0.14540814978574448,0.5856366697275788
203,89.jpg," The table shows the reliability and validity of a 15-item scale measuring trust in financial advisors. The scale was developed using a sample of 300 investors. The results show that the scale has good reliability, with a Cronbach's alpha of 0.93. The scale also has good validity, with all items loading significantly on the latent factor of trust in financial advisors.","To explore whether the firm characteristics in our sample of SCF firms play an important role in our findings, we perform a sub-sample analysis. More specifically, we divide both BlockFirms and Non-BlockFirms into two groups: banking and non-banking. We compute the ARs earned by these two groups of firms in different event windows using the Carhart 4-factor model (C4F). The outcomes of the analysis are documented in Table 10.",0.29703386547999944,0.84356666,0.8411962985992432,0.4169764326653713,0.7567524460967083
204,90.jpg," | Construct | HTMT value |
|---|---|
| (1) Mistrust provider | - |
| (2) Seal costs | 0.847 |
| (3) Seal unreliability | 0.117 |
| (4) Seal incredibility | 0.492 |
| (5) Auth. incredibility | 0.385 |
| (6) Per. assurance | 0.450 |
| (7) Disbelief in seal | 0.765 |
| (8) Mistrust authority | 0.676 |
| (9) Disposition to trust | 0.087 |
| (10) Privacy concerns | 0.368 |
| (11) Pers. knowledge | 0.188 |
| (12) Cynicism | 0.227 |
| (13) Seal involvement | 0.117 |
| (14) Social desirability | 0.099 |
| (15) Dis. skepticism | 0.292 |","To identify the predictive factors explaining the valuation loss for SCF firms, we perform a cross-sectional regression analysis, following the description in Section 4.3. The CAR estimated by the C4F model for the [-15, ] time window is used as the dependent variable in the regression. The results for models 1 to 4 (as specified in Section 4.3) are reported in Table 11. In model 1, Block_Dummy is found to be positive and significant. This indicates that Non-BlockFirms earn higher valuation loss compared to BlockFirms. Models 2 and 3 in Table 11 show that the impact of the interaction between Block_Dummy and R&D on CAR is significant. It is also observed that the interaction of Block_Dummy and Capex has a positive and significant relationship with CAR. However, there is no significant relationship between CAR and the interaction term Block_Dummy*Staffex. Therefore, we infer that BlockFirms that make a higher investment in R&D and capital expenditure suffer significantly less valuation loss due to the event. Thus, we find support for Hypothesis 7a and 7b, but not for Hypothesis 7c. The control variables show a consistent association with CAR across all four regression models.",0.03395529944154725,0.13632764,0.7664822936058044,0.17306437232876906,0.559926625402816
205,91.jpg," The table shows the results of the hypotheses testing. The first column shows the hypothesis number, the second column shows the hypothesis direction, the third column shows the path, the fourth column shows the p-value, and the fifth column shows the support for the hypothesis.

The results show that all of the hypotheses are supported except for H4. H4 states that there is a positive relationship between perceived assurance and distrust in IS. The p-value for H4 is 0.507, which is greater than the significance level of 0.05. This means that there is not enough evidence to support H4.

The other hypotheses are all supported by the data. This means that there is a positive relationship between web seal unreliability and distrust in IS (H1), a positive relationship between web seal unreliability and perceived assurance (H2), a positive relationship between authority and distrust in IS (H3), a positive relationship between authority and perceived assurance (H5), a positive relationship between perceived assurance and manipulative intent (H6), and a positive relationship between distrust in IS and manipulative intent (H7).","So far, we find that the adoption of blockchain enables SCF firms (i.e., BlockFirms) to protect against the erosion of firm value during the pandemic. Moreover, R&D and capital expenditure play an important role in this regard. Next, we aim to identify specific predictive factors that guide BlockFirms to protect the market value. We again run a set of cross-sectional regressions where we use CAR of BlockFirms estimated by the C4F model for the [-15, ] time window as the dependent variable. More specifically, we run models 5 to 10 (as specified in Section 4.3) to explain the impact of consortium and implementation dummies on the CAR of BlockFirms and report the results in Table 12. Results of models 5 and 6 reveal that the interaction terms Consortium*R&D and Implementation*R&D are positive and significant. While interacting capital expenditure (Capex) of BlockFirms with consortium and implementation dummies, we find a similar positive and significant association as depicted in the results of models 7 and 8. However, no significant association is observed in case of the interactions between staff expenditure (Staffex) and consortium and implementation dummies in models 9 and 10.",0.4386091374884581,0.89807916,0.8124054670333862,0.466345359086997,0.7950001034746792
206,92.jpg," The table summarizes the results for the Cournot competition. The first column shows the different conditions on the parameters, the second column shows the corresponding region in the Figure, and the third and fourth columns show the signs of the derivatives of the profits of firms H and L with respect to the parameter B."," Fractions of top ratings in all categories are provided in Table 1 in Section 4. One can only speculate why such good ratings are usually given. AirBnB does not provide monetary incentives for reviews, which have been shown to lead to more positive reviews [114]. Possible explanations could be an ex post rationalization of the decision made by the guest (?I have chosen this accommodation, so it must be good?), or reciprocity between guests and hosts [30], [80]. On AirBnB, guests are also rated by hosts and might hope for a reciprocal favorable evaluation of themselves if they evaluated the host and the accommodation very positively.",0.30268943876388005,0.7531709,0.8154205083847046,0.19421896972682356,0.8473826173826173
207,93.jpg," The table shows the conditions for which firm H and firm L will choose to produce a high-quality product in a mixed duopoly. The conditions are based on the values of the parameters $\beta$, $\beta_1$, and $\beta_3$. The table is divided into three regions, and the conditions for each region are shown in the table. In Region I, both firms will choose to produce a high-quality product if $\beta < \beta_1$ and $\beta < B_3(\beta)$. In Region II, both firms will choose to produce a high-quality product if $\beta > \beta_1$ and $\beta > B_3(\beta)$. In Region III, neither firm will choose to produce a high-quality product.","Table 2 presents the results of this analysis. The F values and their significance refer to the comparison to the previous model. Although adding both types of information to the baseline model leads to a significant improvement of fit, the effect of premises information is much stronger. Adding premises-specific variables to the baseline model increases the by almost 0.08, whereas adding the host information increases it by less than 0.02, and the F-test also clearly indicates a much stronger increase in model fit due to the premises information. Consequently, adding the host information to the model already containing the premises information leads only to a marginal improvement. Thus premises information has a considerably stronger influence on price than host information. This result is in accordance with other results from the literature. Although they did not specifically test for differences between premises-specific and host-specific information,Chen and Xie [24] also used nested regression models in which they first added premises-specific and then host-specific variables. In their model, adding host-specific variables increased the from 0.538 to 0.673. ",0.2699652842226363,0.636214,0.8000925183296204,0.2748131481495103,0.840213508174673
208,94.jpg," The table summarizes the conditions for which firm H and firm L will locate in each of the three regions in Figure D1. The conditions are based on the values of the parameters $\beta$, $\beta_1$, and $\beta_3$. The table also provides the values of the derivatives of the firms' profits with respect to $\beta$ in each region. These derivatives are used to determine the direction of the arrows in Figure D1.

In Region I, both firms H and L locate in the same region. This is because both firms have a higher marginal cost of production than the marginal revenue in this region. As a result, both firms are making losses in this region.

In Region II, firm H locates in a different region than firm L. This is because firm H has a lower marginal cost of production than firm L in this region. As a result, firm H is making a profit while firm L is still making a loss.

In Region III, both firms H and L locate in the same region. This is because both firms have a lower marginal cost of production than the marginal revenue in this region. As a result, both firms are making profits in this region.","Table 3 shows the results of this analysis. The results confirm those of the analysis of all premises types. Again, the effect of adding the premises-specific characteristics is considerably stronger than the effect of adding host characteristics.",0.31203444266943786,0.78413725,0.8243038058280945,0.37886178861788616,0.8709525569281666
209,95.jpg, All items show adequate communalities and are above the recommended threshold of 0.50. All items also have a Cronbach's alpha value that is above the recommended threshold of 0.70. This indicates that the items are all measuring the same underlying construct and that the scale is reliable.,The following tables provide an overview of descriptive statistics of the data set used. Table 4 summarizes data according to country.,0.1649948738305144,0.7996152,0.8366769552230835,0.375886524822695,0.6848637768850535
210,96.jpg," **Correlation Matrix**

|  | Mean (S.D.) | SQ | DQ | IQ | SQa | US | IP | SE | TC | RU | AU |
|---|---|---|---|---|---|---|---|---|---|---|---|
| SQ | 5.32 | 1.000 |  |  |  |  |  |  |  |  |  | 
| DQ | 5.40 (1.14) | .800** | 1.000 |  |  |  |  |  |  |  |  | 
| IQ | 5.65 (1.36) | .137** | .078 | 1.000 |  |  |  |  |  |  |  | 
| SQa | 5.29 (1.13) | .150** | -.022 | .044 | 1.000 |  |  |  |  |  |  | 
| US | 3.24 (1.42) | .122** | .138** | .065 | -.085 | 1.000 |  |  |  |  |  | 
| IP | 5.65 (0.98) | .277** | .081 | .160** | .084 | .155** | 1.000 |  |  |  |  | 
| SE | 5.25 (1.36) | -.016 | -.028 | -.095 | -.034 | -.082 | -.003 | 1.000 |  |  |  | 
| TC | 5.09 (1.64) | .165** | .141** | -.038 | -.001 | .119** | .015 | -.007 | 1.000 |  |  | 
| RU | 4.13 (1.13) | .197** | .147** | .177** | .137** | .068 | .271** | .045 | .047 | 1.000 |  | 
| AU | 5.08 (0.98) | .234** | .163** | .255** | .139** | .130** | .279** | .011** | .115** | .138** | 1.000 | 

**Note.** Correlation is significant at the 0.01 level (2-tailed).",Table 5 according to the type of premises.,0.012988094566970056,0.10286931,0.7502717971801758,0.33598937583001326,0.17285269247886068
211,97.jpg," The table shows the mean, standard deviation, and rank of the two groups on each of the variables. The significance of the difference between the two groups is also shown.

The results show that the high advanced use group had significantly higher means than the low advanced use group on all of the variables except for self-efficacy and performance. This suggests that the high advanced use group had a better perception of the system, data quality, information quality, service quality, user satisfaction, and task complexity than the low advanced use group.",Table 6 gives an overview of host characteristics.,0.0665800464128583,0.6564913,0.842736542224884,0.34065934065934067,0.6432188995375808
212,98.jpg," From the table, we can see that:

- H1a and H1b are supported.
- H2 is supported.
- H3a and H3b are supported.
- H4 is supported.
- H5a, H5b, and H5c are supported.
- H6a is not supported.
- H7a and H7b are not supported.
- H8 is not supported.
- H9a and H9b are not supported.
- H10a is supported.
- H11 is supported.
- H12a is supported.
- H13 is not supported.
- H14a and H14b are supported.",Table 7 provides the regression coefficients for the three models using all types of premises.,0.02106880817402624,0.62832206,0.8037609457969666,0.3415637860082305,0.5787728026533998
213,99.jpg," The table shows the 95% confidence intervals for the standardized total effects of the independent variables (IVs) on the dependent variables (DVs). The CIs show that all of the IVs have a significant effect on the DVs, except for DQ on AU.",Table 8 contains the regression coefficients of the full model (including both premises-specific and host-specific information) for six selected types of premises.,0.2599916853403551,0.8104035,0.8462658524513245,0.4126984126984127,0.7389163746306605
