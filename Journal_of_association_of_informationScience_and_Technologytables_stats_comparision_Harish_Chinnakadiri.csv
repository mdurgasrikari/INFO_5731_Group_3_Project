index,Image Name,AI generated Summary,Author Summary,Cosine_Similarity Score,ROUGE-WE,BertScore,BLEU Score,METEOR Score
0,Tables_5731/h103.png," Table 1 shows the descriptive statistics for the five constructs. The mean values for telepresence, attitude, imagination, and instrumental need for touch were above the midpoint of the scale (4), indicating that, on average, participants agreed with the statements for these constructs. However, the mean value for autotelic need for touch was below the midpoint, indicating that, on average, participants disagreed with the statements for this construct. The standard deviations for all constructs were less than 2, indicating that the data were relatively normally distributed.","0,""Despite the contribution of the IS/IT industry toward the economic and social welfare of society, IS/IT has often been criticized for having a negative environmental impact. Concerns surrounding the adverse effects both hardware and software have on the environment date back to the Y2K era which led to the massive adoption of enterprise systems (Miyamoto, Harada, & Fujimoto, 2001). These negative impacts include high levels of energy consumption, greenhouse gas emissions and toxic disposal of IS/IT systems (Muregesan, 2008). The disposal of electronic waste (e-waste) while following recycling processes has been widely viewed as not being environmentally friendly, especially the impact of fossil fuels or respiratory inorganics (Barba-Gutiérrez, Adenso-Diaz, & Hopp, 2008). Refurbished ICTs are often used in developing countries where devices tend to have a short life-span and subsequently create environmental damage during disposal (Osibanjo & Nnorom, 2007). Studies have argued that electricity is a major cause of climate change, as many power stations throughout the world still rely on fossil fuels to generate electricity (Asongu et al., 2020, Tamburini et al., 2015). Energy hungry technologies such as applications of blockchain in the form of bitcoin, has been widely criticized for producing over 22–29 million metric tonnes of carbon dioxide emission each year. These figures are comparable to the carbon dioxide production of entire countries such as Jordan and Sri Lanka (Marr, 2018, Stoll et al., 2019). Technologies such as the Internet of Things (IoT), sensors and actuators have a shorter lifespan which leads to increased waste in the environment (Chakraborty and Gupta, 2016, Chakraborty et al., 2014, Nižetić et al., 2020). Digital transformation initiatives such as smart cities have concerns surrounding ICT waste management, energy management and emission management which needs to be addressed for achieving long term sustainability and viability (Ismagilova, Hughes, Dwivedi, & Raman, 2019).From an IS/IT perspective, IoT and Artificial Intelligence (AI) could potentially offer solutions for reducing the impact of technology projects (Salam, 2020). High ICT-driven initiatives need to plan for sustainability by thinking from",0.2990337669190202,0.8641537,0.7817739248275757,0.027565394766203948,0.7983469145233849
1,Tables_5731/h104.png," Table 2 shows the frequency and percentage of respondents for each of the respondent characteristics. There were slightly more male (53.4%) respondents than female (46.6%). The majority of respondents were aged between 18 and 29 (19.8%), followed by those aged between 50 and 59 (22.1%). Most respondents (66.7%) had no previous experience of using a 360-virtual store.","1,""After the assessment of the measurement model, we examined the path coefficients and the coefficient of determination (R2) to determine the significance of the relationships proposed in the structural model. Following best practices, we use the SmartPLS® bootstrapping procedure using 5000 subsamples and a parallel process technique (Hair et al., 2017). Results show that both KMS (β = 0.482; t = 10.986) and KS (β = 0.128; t = 2.202) have a positive influence on the quality of care provided to patients (H1, H3). By extension, findings also suggest that the existence of KMS positively influence KS (β = 0.168; t = 2.035) (H2). Similarly, a competitive culture also positively influences the quality of care provided to patients (β = 0.105; t = 2.154) (H5). However, results show no statistically significant relationship between competitive culture and KS (H4). Therefore, H1, H2, H3 and H5 were supported. H4 was not supported. Table 7 presents the main structural model results."",International journal of information Management,Table 7. Structural model results.,,",0.2907114313528422,0.68848443,0.8041777014732361,0.07516751373250252,0.7927704361914889
2,Tables_5731/h105.png," Table 3 shows the discriminant validity of the five constructs. The discriminant validity is assessed by examining the cross-loadings of the items on the constructs. As can be seen from the table, the cross-loadings are all below the threshold of 0.40, which indicates that the constructs are discriminant.","2,""FsQCA requires the calibration of conditions and outcomes. Thus, datasets are transformed into fuzzy-set membership scores based on the theoretical and empirical knowledge of the researchers. All the conditions and the outcomes were measured using a 7-point Likert scale based on the average values of each latent variable (Ragin, 2008). This technique allows us to resize data based on thresholds defined in the literature (Fiss, 2011) into full non-membership, crossover point of maximum ambiguity in membership, and full membership (Ragin, 2008). We transformed variables that were measured on a Likert scale into fuzzy sets (Woodside et al., 2011) by applying the three levels from best practices in fsQCA, establishing the cuts at 0.95, 0.5, and 0.05, considering the range and distribution of each scale (Ragin, 2008, Pappas and Woodside, 2021). FsQCA uncovers how conditions combine into configurations that produce the outcome of interest by exploring how set memberships intersect (Renkema et al., 2016). Table 8 presents the descriptive statistics and calibration of the research conditions and outcomes."",,,,",0.3864817865467442,0.84171563,0.8308467268943787,0.048890940407814436,0.8071225071225072
3,Tables_5731/h107.png," Table 2 shows the frequency and percentage of each demographic characteristic in the sample. The sample is composed of 795 participants. The majority of the sample is between the ages of 18 and 24 (46%), female (51.2%), and has a bachelor's degree or equivalent (47.5%).","3,""After the calibration procedure and following best practices (Greckhamer et al., 2018), we examined the conditions for necessity and sufficiency. The analysis of the necessity indicates the degree of the effect of a condition on achieving a specific result. The necessity analysis shows that there are no necessary conditions for quality of care (consistency levels below the recommended threshold of 0.9 (Ragin, 2008)). Such results are aligned with the literature, suggesting that to generate quality of care, an interplay of several conditions is needed (Desveaux et al., 2019, Hannawa et al., 2021). When the distributions for membership of either the conditions, the outcome, or both, have a skew, the presence (or the absence) of necessary conditions might have flaws (Schneider & Wagemann, 2012). To overcome this problem, and since the set of the KS condition in this study has a skew toward high membership, we followed Schneider and Wagemann’s (2012) suggestion of reporting the relevance of necessity (RoN). The analysis shows that there are no necessary conditions for the outcome (Table 9)."",,,,",0.5151428006338071,0.701914,0.8036404252052307,0.037446360967393705,0.7723328523328523
4,Tables_5731/h108.png," The table shows the online streaming platforms used by the participants. The most popular platform is YouTube, which is used by 568 respondents. This is followed by Instagram (462 respondents), Facebook (Meta) (374 respondents), and TikTok (242 respondents). The other platforms are used by less than 100 respondents each.","4,""The sufficiency analysis indicates the degree of relation between the configuration of conditions as an explanation of a specific result or outcome (Fiss, Sharapov, & Conqvist, 2013). We adopted the 0.8 threshold for the sufficiency analysis, which is high enough to conclude the level of care is sufficient for the outcome (in this case, quality of care) (Ragin, 2006). The analysis identified limited diversity (no rows with no cases - truth table in Appendix A displaying symmetric consistency and proportional reduction in inconsistency analysis), resulting from no difference between the number of manifested versus hypothetical configurations (Pappas & Woodside, 2021). Such evidence reflects competitive pressures from the context that are likely to discourage undesirable configurations (Miller, 1986). Considering the setting and the outcome of this study, this result is more than comprehensible, and is desirable. FsQCA delivers three solutions. The core conditions are the ones that are both present in the intermediate and parsimonious solutions. In this study, all conditions are core conditions. Table 10 reports the intermediate solution for quality of care as recommended by best practices (Greckhamer et al., 2018, Ragin, 2008). The symbol “∼” prior to the conditions’ name represents its absence."",,,,",0.2917726854916455,0.83318627,0.8024246096611023,0.02661663183424242,0.7986777394940661
5,Tables_5731/h109.png," Table 5 shows the discriminant validity of the Fornell-Larcker criterion. The square root of the AVE of each construct is shown in bold on the diagonal, and the correlations between constructs are shown off the diagonal. As can be seen, the square root of the AVE of each construct is greater than the correlations between constructs, indicating that the constructs are discriminantly valid.","5,""The exploration of successive product generations within marketing and economics literature began with a primary focus on non-digital goods. Initial research delved into the cannibalization effect, emphasizing the negative impact of new product introductions on legacy models. Stokey (1979) identified a detrimental influence on the sales of previous versions of physical products, leading to subsequent studies revealing intricate pricing and positioning strategies for managing generational transitions. However, the realm of digital goods, marked by unique facets, has received limited scholarly attention. Feature intensity, characterized by the breadth and complexity of product features (Rathore and Ilavarasan, 2020, Sheng and Teo, 2012), has witnessed exponential growth with each new generation of digital devices. For instance, contemporary smartwatches now incorporate thousands of apps, biometric tracking capabilities, and a myriad of productivity features that were unimaginable even five years ago (Joung & Kim, 2023). Despite this surge in information intensity, research has yet to directly examine the impacts on consumer decisions and sales.The accelerated cadence at which new product generations are introduced, especially in categories like smartphones and laptops, poses challenges that warrant deeper investigation. This is particularly relevant for information-laden digital devices where capability layers expand exponentially each year (X. Fu et al., 2020, Fu et al., 2020). Leading brands adopt agile development approaches, rapidly acquiring user input to fulfill feature requests (Santos et al., 2022). However, variations across brands and products in terms of agility and responsiveness introduce uncertainty (Hollebeek et al., 2021). Unpacking these variations represents a gap needing empirical examination. Hence, key digital product attributes like exponentially growing features and accelerated release cycles require greater scholarly attention (Rauschnabel, 2021). As each new generation introduction intensifies complexity and change, it remains unclear how these facets affect navigation and purchase choices. For instance, despite exponential growth in capability layers, no study has directly investigated how information",0.2929296316797575,0.87976193,0.7919922471046448,0.01211654396630927,0.8624905517762662
6,Tables_5731/h11.png," The table shows the results of a study that examined the relationship between knowledge management (KMS) and competitive culture (KS) on quality of care. The results show that there is a positive relationship between KMS and KS, and that both KMS and KS are positively related to quality of care. The study also found that the relationship between KMS and quality of care is moderated by KS. Specifically, the results show that the positive relationship between KMS and quality of care is stronger when KS is high.

In terms of practical implications, the results of this study suggest that healthcare organizations should focus on creating a competitive culture and implementing KMS in order to improve quality of care. The results also suggest that healthcare organizations should focus on creating a culture that values and supports KMS in order to maximize the benefits of KMS on quality of care.","6,""The descriptive statistics for variables used in the study are given in Table 3 below. Additionally, we included dummy variables to indicate type of wearable band (1 for fitness band and 0 for smartwatch), type of connectivity (1 for LTE and 0 for no LTE), type of operating system (1 for Android and 0 for WearOS). We considered Android and WearOS as these two operating systems were the most commonly occurring in the dataset. We also checked for correlation between the independent variables and found no significant multicollinearity among the variables."",,,,",0.24913267658766686,0.72408086,0.8207804560661316,0.42792792792792794,0.8045292920292919
7,Tables_5731/h110.png," The table shows the path coefficients and their significance. The path coefficient is a measure of the strength of the relationship between two variables. The significance value is a measure of the probability that the relationship is due to chance.

All of the path coefficients are significant, which means that the relationships between the variables are not due to chance. This supports all of the hypotheses.","7,""While there are various motivations and triggers to business model innovation, firms often use technologies as key means of achieving business model innovation (Muhic and Bengtsson, 2019). AI can be one of the technologies that underpins business model innovation. A rich stream of research has underpinned existing knowledge of how computing (including machine learning and expert systems) can support human decisions in organizational contexts (see for example Bonczek et al., 1979). There is an equally rich stream of research associated with successful implementation of AI – at least at a technical level (Maragno et al., 2023, Merhi, 2023, Uren and Edwards, 2023).While AI technologies are generally globally available, uptake is non-uniform and the touted exemplars of business model transformation using AI seem to be concentrated in the same few companies, being large multinational companies such as Amazon and IKEA. Furthermore, the current wave of adoption has seen organizations focused primarily on utilizing AI for improving existing business models rather than creating new ones (Deloitte, 2020).The Deloitte (2020) survey identified a set of IS and non-IS capabilities associated with success in AI. Three IS capabilities were identified, the first of these is data. Success at AI is not just about volumes of data, it is about having the right types of data and adequately supported digital processes (Reim et al., 2020). The second IS capability is digital agility, as rapid changes in business models require the ability to scale up and down as well as quickly modify application landscapes, with that adaptability supported and not inhibited by information systems (Grover, 2022). The third IS capability is that of the skills of the technology team themselves (Wamba-Taguimdje et al., 2020). Multiple elements must be in place for successful implementation of AI in an organization including data management as well as having the right domain knowledge and relevant technologies. The Deloitte survey also suggested a critical capability in the non-IS parts of the organization, namely a “digital culture” that enhances organizational ability to pursue change initiatives in parallel with delivering the existing business model.There is limite",0.43154222622845645,0.78682226,0.792611300945282,0.0097235309137269,0.8327891805164533
8,Tables_5731/h112.png," Table 7 reports the mediation effects and their significance. The results show that the indirect effect of IC on ATB through ATS is significant (p = 0.009), as well as the indirect effect of IC on PI through ATS (p = 0.01). The indirect effect of PV on ATB through ATS is also significant (p = 0.01). Furthermore, the indirect effect of HML on ATB through ATS is significant (p = 0.003), as well as the indirect effect of HML on PI through ATS (p = 0.004). Finally, the indirect effect of ASP on PI through ATS is significant (p = 0.021).","8,""The data structure has three aggregate dimensions, each of which are supported by two or more 2nd order themes. The first aggregated dimension is internal behaviors, which reflects the behaviors of the leadership and staff of organizations undergoing business model transformation enabled by AI. This aggregated dimension includes three 2nd order themes: AI-sensitive risk tolerance, proactive leadership, and tech-sensitive innovation culture. The second aggregated dimension is internal capabilities, which refers to the capabilities associated with an organization’s ability to adapt the firm’s resource base (Teece, 2007). This aggregated dimension includes four 2nd order themes: ability to run & change, AI oriented data / IS readiness, market / customer awareness and strategic process strength. The final aggregated dimension is that of external conditions and reflects the fact that organizations do not operate in isolation from competitors and the broader business environment (including regulation and changing social norms). Two 2nd order themes are tied to this aggregated dimension: industry dynamism and opportunity / threat drivers.Table 3 summarizes the resulting theoretical constructs, built through the meshing of data (from the participant comments, reflecting the nuances of the sensitizing concepts in practice) with theory (identified in the sensitizing concepts described in the research model). These theoretical constructs will hereafter be referred to as factors."",,,,",0.25747190644623863,0.6706626,0.7931681871414185,0.16322995070912583,0.8449224386724388
9,Tables_5731/h113.png," The table shows the results of the predictive power assessment using the PLS-SEM model and the linear model. The Q2_predict column shows the predictive power of each item for the PLS-SEM model, while the RMSE column shows the root mean square error for each item for both models.

The results show that the PLS-SEM model has a higher predictive power than the linear model for all items. This is because the PLS-SEM model takes into account the relationships between the items, while the linear model does not.","9,""The applicability check was structured around obtaining feedback from three specific cohorts: executives (senior practitioners – typically C-suite or a direct report thereof - that are involved in business model transformation initiatives), advisors (senior management consultant professionals - typically at the partner level - that support executives in their business model transformation initiatives) and practice-oriented researchers (many of which have 10 + years industry experience). Some of the participants of study 1 also participated in study 2 in the “executive cohort”. These three cohorts were selected as each cohort would bring a different and complimentary perspective to the question of applicability of the findings in study 1. In total, 14 participants were engaged in the applicability check process, as outlined in Table 5.Each focus group was conducted by one or more members of the author group. Each member of the author group participated in at least two sessions, and the lead author participated in all sessions, including the initial pilot session. The sessions were approximately one hour in duration and conducted via Zoom with Zoom recording functionality enabled."",,,,",0.33968611701663587,0.77974665,0.813339352607727,0.17096262179648303,0.8589427813565742
10,Tables_5731/h114.png," Table 9. Sufficient configurations of purchase intentions during social media live streams.

Solutions for high purchase intention
Model: PI = f (SBC, INV, ATS, PV, IC, HML, ATB, ASP)
Frequency cut-off: 10

Configurations	1	2	3
Purposeful value	-	-	-
Human-message interaction	-	-	-
Invasiveness	-	-	-
Self-brand congruity	-	-	o
Social pricing	-	-	-
Attitude towards social media live streams	-	-	-
Attitude towards the brand	-	o	-
Raw coverage	0.579	0.662	0.524
Unique coverage	0.023	0.106	0.097
Consistency	0.956	0.970	0.897
Solution coverage	0.696	0.952	0.794

Solutions for low purchase intention
Model: PI = f (SBC, INV, ATS, PV, IC, HML, ATB, ASP)
Frequency cut-off: 5

Configurations	1	2	3
Purposeful value	-	-	-
Human-message interaction	-	-	o
Invasiveness	o	-	-
Self-brand congruity	-	-	-
Social pricing	-	-	-
Attitude towards social media live streams	-	-	-
Attitude towards the brand	0.443	0.438	0.469
Raw coverage	0.072	0.084	0.049
Unique coverage	-	-	-
Consistency	0.858	0.819	-
Solution coverage	-	-	-","10,""There are four specific results of the applicability check. First, the participants were strongly supportive of the research need. The words of participant P4.1, an advisor, are illustrative of this support: “I think someone needs to tackle this, first of all, and I think you're starting to do that.” Participant P5.2, a practice-oriented researcher, also commented positively about the appropriateness of the selected theoretical lens of dynamic capabilities: “I feel like [the model] is aligned well to the dynamic capabilities theory.”Second, there was a strong sense of resonance with the empirically derived model of factors outlined in Fig. 4. Participant 2.2, an executive, confirmed that, “This model reflects the way I think about the problem as I've gone through various roles.” Advisors similarly thought that the model resonated with their lived experience across multiple situations: participant P3.1 noted: “this model actually does resonate very well with me.” Furthermore, there was a strong sense of support for the six factors introduced/refined/deleted between the literature-based model of factors and the empirically derived model of factors. Nearly all participants commented on the need for proactive leadership rather than the more passive concept of top management support. Participant P2.2's comment was representative of the collective perspective of the executive and other cohorts: “Certainly the proactive leadership part. I think if it wasn't in [the literature based model], and it is there now [in the empirically supported model], I mean, I think that's a very vital part.” The participants spoke about the criticality of the environmental context, often clumping together the concepts of industry dynamism and opportunity/threat drivers. Participant P4.1’s view was illustrative when talking about the lack of change in one industry sector: “I think there's a couple of things. One is the environmental context… the industry dynamism, and the threats - they haven't been there, or they haven't been perceived as being real. There's no real burning platform, no one's hair is on fire to say, ‘Look, I need to do something about this’. And that permeates through to the organizational precursor, and we talk about proactive leade",0.08177337476003245,0.56594634,0.7653294205665588,0.13923752183524166,0.7382513837737718
11,Tables_5731/h116.jpg," The figure shows the structural equation model (SEM) results for the full sample (U.S. and China). The model includes seven latent variables: perceived social influence, perceived performance expectancy, perceived effort expectancy, hedonic motivation, emotion, trust in AI robots, and willingness to use AI robots. The model also includes three control variables: age, gender, and education. The results show that perceived social influence, perceived performance expectancy, and hedonic motivation have positive effects on emotion. Perceived effort expectancy has a negative effect on emotion. Emotion has a positive effect on trust in AI robots. Trust in AI robots has a positive effect on willingness to use AI robots. Age has a negative effect on willingness to use AI robots. The model explains 47% of the variance in willingness to use AI robots.","11,""The empirically derived model of factors has been updated to reflect the findings of the applicability check (Study 2) and is shown in Fig. 5.There are two specific refinements between the empirically supported model of factors (Fig. 4) and the refined model of factors (Fig. 5). First, the definition of industry dynamism has been refined to reflect both the rate of change of AI relative to that industry as well as the receptivity of industry participants to change in that industry. Second, the factor of strategic process strength has been more properly described as strategic process discipline."",,,,",0.2618266598625748,0.89417076,0.8246579170227051,0.4358974358974359,0.7880755355755358
12,Tables_5731/h118.jpg," The figure shows the relationships between different factors that influence a person's willingness to use AI robots. The factors are perceived social influence, perceived performance expectancy, hedonic motivation, anthropomorphism, perceived effort expectancy, emotion, trust in interaction with AI robots, objection to use AI robots, and willingness to use AI robots. The arrows between the factors show the direction of the relationship. For example, the arrow from perceived social influence to emotion shows that perceived social influence has a positive effect on emotion. The arrow from emotion to trust in interaction with AI robots shows that emotion has a positive effect on trust in interaction with AI robots. The arrow from trust in interaction with AI robots to willingness to use AI robots shows that trust in interaction with AI robots has a positive effect on willingness to use AI robots. The arrow from objection to use AI robots to willingness to use AI robots shows that objection to use AI robots has a negative effect on willingness to use AI robots.","12,""We tested our conceptual framework and differences between monetization strategy (limiting features vs. selling virtual items) by using a MASEM approach (Jeyaraj & Dwivedi, 2020). Following the procedure of Viswesvaran and Ones (1995), we compiled separate correlation matrices for both monetization strategies (see Table 4, Table 5). We managed to include all the variables from our conceptual framework in these matrices. The matrices with the harmonic means (nfeatures = 1069; nitems = 1910) were used as inputs in SPSS AMOS 28. Based on the past research, harmonic mean was used to represent the sample size (Mishra et al., 2023, Yu et al., 2020). Using the harmonic mean produces more conservative results when compared with using the arithmetical mean (Viswesvaran & Ones, 1995). As per Viswesvaran and Ones (1995) and Yu et al. (2020), we used the maximum likelihood estimation method. The moderating effects of the monetization strategies were compared using multigroup analysis. Following Iyer et al. (2020), we set error variances to zero."",,,,",0.1718202676246571,0.48158082,0.7837518453598022,0.41130604288499023,0.8174378821308649
13,Tables_5731/h12.png," The table shows the results of the ablation study. We can see that the fskms model achieves the best performance in terms of consistency, coverage, and RoN. The ~fskms model, which is the fskms model without the skip connections, achieves lower performance than the fskms model. This suggests that the skip connections are important for the performance of the fskms model. The fscult model, which is the fskms model with the self-attention layer replaced with a convolutional layer, also achieves lower performance than the fskms model. This suggests that the self-attention layer is important for the performance of the fskms model. The ~fscult model, which is the fscult model without the skip connections, achieves lower performance than the fscult model. This suggests that the skip connections are also important for the performance of the fscult model. The fksha model, which is the fskms model with the kernel size of the convolutional layers reduced to 3, achieves lower performance than the fskms model. This suggests that the larger kernel size is important for the performance of the fskms model. The ~fksha model, which is the fksha model without the skip connections, achieves lower performance than the fksha model. This suggests that the skip connections are also important for the performance of the fksha model.","13,""The proposed model was tested using a MASEM approach. We performed a multigroup analysis to examine parameter estimate differences between the monetization strategies. The results (see Table 6 and Fig. 2) suggest that the formation of WTP for freemium services differs in several ways according to the monetization strategy. As the research model is saturated, both models display a perfect fit (χ2 = 0; d.f. = 0; SRMR =.000; RMSEA =.000; CFI = 1.000; GFI = 1.000). For the “limited features” monetization strategy, the model explained 44.2% of the variance in trust and 50.5 % of the variance in WTP. For the “virtual items” monetization strategy, the model explained 20.9 % of the variance in trust and 40.0 % of the variance in WTP.Overall, the results of this meta-analysis highlight the differential roles of perceived value and trust in influencing WTP in the monetization strategies as all the paths differ significantly (see Table 6). Consequently, our findings confirm the moderating effect of the monetization strategy. In the context of virtual items, trust had a significant impact on WTP (β = .269, p < .05), whereas its impact for the “limited features” monetization strategy was non-significant, confirming H1. Consequently, we argue that trust mediates the effects of perceived value on WTP in the case of purchasing virtual items but does not have a similar role in the “limited features” monetization strategy. Thus, we highlight the importance of the direct effects of perceived value on WTP for the “limited features” monetization strategy, instead of mediation through trust.Our results underline the strong impact of functional value on WTP for the “limited features” monetization strategy (β = .673, p < .05). This path was non-significant for the “virtual items” monetization strategy. Therefore, H2 was confirmed. The impact of hedonic value on WTP was negative for the “limited features” monetization strategy (β = −.629, p < .05) and positive for the “virtual items” monetization strategy (β = .136, p < .05). Thus, H3 was confirmed. Interestingly, the impact of social value was stronger for the “limited features” monetization strategy (β = .562, p < .05) than it was for the “virtual items” monetization strategy (β = .122, p < .05).",0.493146375796167,0.7738388,0.792207658290863,0.2614173777239113,0.8305777425495728
14,Tables_5731/h120.png, Table 2 shows the correlation matrix and square roots of AVE. All of the correlations are significant at the 0.05 level. The square roots of AVE are shown in parentheses on the diagonal.,"14,""In information systems literature, the terms interpretability and explainability have multiple definitions are sometimes used interchangeably. We define interpretability of an AI-system as a characteristic indicating whether an individual is able to understand the full decision-making process of an AI (Guidotti et al., 2018, Rudin, 2019). Table 1 presents different definitions in literature for explainability and compares them with interpreterability.As shown in Table 1, the literature reveals a lack of consensus regarding the definitions of explainability. To gain insight into the lack of consensus, it would be worthwhile to consider the definition of XAI provided by Gunning et al., 2019 defining XAI as a suite of AI techniques that enables human users to understand, and effectively manage the emerging generation of artificially intelligent partners (Gunning et al., 2019). While this definition incorporates the essential concept of understanding, it fails to account for other significant purposes that drive the demand for XAI models. We will explore these aspects further in the subsequent discussion, highlighting them as evidence of the definition’s incompleteness.Definition of explanation is essential to understanding XAI. According to the Cambridge Dictionary for English, an explanation refers to """"the details or reasons that someone gives to make something clear or easy to understand"""". In the context of AI, this can be restated as “the details or reasons that an AI system provides to clarify or simplify its outcome."""" However, in this definition, two ambiguities emerge. First, the reasons used for explanation are entirely contingent on the audience to whom they are presented. Second, whether the explanation effectively renders the concept clear or easy to understand also relies entirely on the audience. The definition needs to be reformulated to account for the audience of a given XAI. A revised definition presented by (Arrieta et al., 2020) defines explainability as follows:Given a certain audience, explainability refers to the details and reasons a model gives to make its functioning clear or easy to understand."""".(Arrieta et al., 2020)’s perspective on explainability aligns with the definition given by (Herm et al.,",0.36083361683264736,0.7611303,0.7988126873970032,6.755619674710205e-05,0.8815426997245178
15,Tables_5731/h122.png," The table shows the distribution of news stories in the dataset across six HNR ratings and other tweet-related metrics. The HNR rating is a measure of how newsworthy a story is, and it ranges from 0 to 5. The table shows that the majority of stories in the dataset have an HNR rating of 3 or higher, which indicates that they are considered to be relatively newsworthy. The table also shows that stories with a higher HNR rating are more likely to have a large number of tweets associated with them. For example, stories with an HNR rating of 5 have an average of 222.1 tweets, while stories with an HNR rating of 0 have an average of only 140 tweets. This suggests that stories that are considered to be more newsworthy are also more likely to be shared and discussed on Twitter.","15,""Table 3 provides a summary of selected research on how AI Capability can affect firm performance. The table highlights two promising areas for expanding upon existing research. First, the current body of literature focuses on functional competencies, specifically those related to AI infrastructure and associated management capabilities. Simultaneously, AI infrastructure is increasingly becoming a standardized commodity, and AI applications that offer differentiation tend to depreciate rapidly due to shifts in the market. Realizing the benefits of AI under these conditions requires continuous efforts to construct and maintain a portfolio of AI applications. Prior research highlights the significance of updating AI applications portfolio as a dynamic capability for adapting to evolving market conditions and enhancing firm performance. Drawing from this discussion, we propose that a firm's ability to refresh its portfolio of AI applications stands as a critical driver of its overall performance"",,,,",0.26828202050550387,0.80494267,0.8225606679916382,0.49184149184149184,0.8182650682650681
16,Tables_5731/h123.png," The table shows the information extracted from the Health Review Network dataset. 

(a) Examples of the experts' ratings on health news reports. 

(b) Examples of a tweet from news media, a retweet, and a reply to it. 

(c) Examples of a tweet from a user about a health news report, a retweet, and a reply to it.","16,""All measuring items were adapted from prior established studies as a benchmark to define latent variables in the research model (Westland, 2015). Appendix item 1 contains the questions, the corresponding variables they represent, and the source supporting the operationalization of the variable. These latent variables include AAPUC, process agility and firm performance. To measure AAPUC, we used established literature that describes how companies update their resource portfolios through three key actions: (a) acquiring resources, (b) developing resources internally, and (c) discontinuing legacy resources (Sirmon et al., 2011, Sirmon et al., 2007). In the context of IT resources, it is argued that certain companies excel in obtaining valuable IT applications from suppliers (Tanriverdi, 2006), while their abilities for in-house IT application development or discontinuation of legacy IT applications may be limited (Lee and Xia, 2010, van Oosterhout et al., 2006). Consequently, our operationalization of AI applications portfolio update capability employs formative items that collectively define the construct, departing from reflective items used when each indicator is an """"imperfect reflection of the construct"""" (MacKenzie et al., 2011). In essence, the three competences of acquiring, developing and discontinuing AI applications comprehensively characterize AAPUC. Thus, our measurement as presented in Appendix A involves formative items that relate to those competences in relation to AI applications. We also developed measures for explainability of AI following the three-stage process posited by (Boateng et al., 2018), presented in Table 5."",,,,",0.2533658118113444,0.85648227,0.7988283634185791,0.024269779411268642,0.8762708539024329
17,Tables_5731/h124.png," The logit model for ratings is shown in Table 3. The model includes the following variables: constant, length, media type, and number of ratings. The constant is the intercept of the model, and it represents the predicted rating for a news article with all other variables set to zero. The length variable is the length of the news article in words. The media type variable is a categorical variable that indicates the type of media in which the news article was published. The number of ratings variable is the number of ratings that the news article has received.

The results of the logit model show that the constant is significant and positive. This means that, all other variables being equal, news articles are more likely to be rated higher if they are longer. The length variable is also significant and positive. This means that, all other variables being equal, news articles are more likely to be rated higher if they are longer. The media type variable is significant and positive for the newspaper and television categories. This means that, all other variables being equal, news articles are more likely to be rated higher if they are published in a newspaper or on television. The number of ratings variable is not significant. This means that, all other variables being equal, the number of ratings that a news article has received does not affect its rating.","17,""To examine the measurement model, convergent and discriminant validities were tested. Although our questionnaire was constructed utilizing preexisting instruments in the literature as well as inputs and pre-test from experts, we evaluated our instrument as a new measure that requires checking of unidimensionality. Unidimensionality tests whether all items measured in a metric contribute to measurement of the construct under study (Gerbing & Anderson, 1988). Since PLS does not measure for unidimensionality, we used SPSS to carry out a scree test (B. D’agostino Sr and Russell, 2014) to determine the number of latent constructs on the dataset. Then we used smartPLS to examine the questionnaire’s items for loading, weights, validity, and reliability. Table 6 presents the results of the factor analysis of our constructs.We assessed construct-to-item loadings for our reflective constructs to see if item loadings were sufficient to include an item under a specific construct. Only item loadings that exceeded 0.70 were retained (Hair et al., 2011), which is consistent with the results of the scree test before and after the loading test. Next, we measured composite reliability for each reflective construct to assess internal consistency (Raykov, 1998). In early research development, reliability scores above 0.70 are acceptable, whereas 0.80 is recommended for established constructs (Nunnally, 1978, Werts et al., 1978). Table 6 shows our constructs’ validity, reliability, and correlation matrix. Each construct’s dependability exceeds 0.70. In Table 6 the square root of AVE is bigger than off-diagonal correlations. To assess the validity of constructs, we compared the square root of AVE with correlation between each pair of constructs (Fornell & Larcker, 1981). Table 6 shows that for each construct, the square root of AVE is greater than their off-diagonal correlation of that construct. In order to avoid product unstable path estimates, we ran several Variance Inflation Factors tests that all returned a maximum of 2.1 while the threshold of concerns is 10 for reflective constructs (MacKenzie et al., 2011). All scales showed good discriminant validity, supporting the XAI scales' psychometric features."",,,,",0.402915929826875,0.8769013,0.7974726557731628,0.34109885198384965,0.8973441681775011
18,Tables_5731/h125.png," The table shows the top 10 most tweeted stories and the discussion generated by them. The stories are ranked by the number of tweets they generated. The table shows the story ID, rating, total number of posts, tweets, retweets, replies, and the response ratio. The response ratio is calculated by dividing the number of replies by the number of tweets.

The story with the highest number of tweets is story_reviews_00931, which generated 1,014 tweets. This story has a response ratio of 29%, which means that 29% of the tweets about this story were replies. The story with the lowest number of tweets is story_reviews_00943, which generated 589 tweets. This story has a response ratio of 1%, which means that only 1% of the tweets about this story were replies.","18,""To test the structural model, we examined the path coefficients (β) to demonstrate the strengths of the relationships involved in our hypotheses. R2 shows the extent to which the dependent variable’s variance can be predicted by each independent variable. In this study, we used both path coefficients as well as R2 to explain how well the model is performing. The hypotheses were tested by estimating the research model outlined in Fig. 1. The results of our analysis appear in Table 7."",,,,",0.37303501455691673,0.7779145,0.8109519481658936,0.4315245478036176,0.8157807308970098
19,Tables_5731/h126.png," The table shows the top 10 stories in descending order of response ratio. The response ratio is calculated by dividing the number of replies by the number of retweets. The higher the response ratio, the more likely people are to engage with the story.

The top story is about a same-day hip replacement. It has a response ratio of 66%, which means that for every 100 retweets, there were 66 replies. This is a high response ratio, and it indicates that people are very interested in this story.

The second story is about suicide risk reduction. It has a response ratio of 63%, which is also high. This story is also likely to be of interest to many people.

The third story is about a diabetes vaccine study. It has a response ratio of 61%, which is still high. This story is also likely to be of interest to many people.

The fourth story is about increased dementia risk. It has a response ratio of 60%, which is high. This story is also likely to be of interest to many people.

The fifth story is about incontinence. It has a response ratio of 54%, which is still high. This story is also likely to be of interest to many people.

The sixth story is about a carotid artery scan. It has a response ratio of 54%, which is still high. This story is also likely to be of interest to many people.

The seventh story is about a cell-based flu vaccine. It has a response ratio of 53%, which is still high. This story is also likely to be of interest to many people.

The eighth story is about an IBS test. It has a response ratio of 52%, which is still high. This story is also likely to be of interest to many people.

The ninth story is about cancer stress. It has a response ratio of 49%, which is still high. This story is also likely to be of interest to many people.

The tenth story is about beet juice lowering BP. It has a response ratio of 49%, which is still high. This story is also likely to be of interest to many people.","19,""Our scale development process was adopted from (Boateng et al., 2018). We used four measures for explainability of artificial intelligence applications within firms, as follows: (1) confidence to stability and reliability, (2) accessibility, (3) interactivity, (4) privacy and confidentiality. We investigated the variations in the performance outcomes of AAPUC as firms focused on different characteristics of XAI. In order to accomplish this, we applied Hayes (2013) regression-based method to test conditional effects (Hayes, 2013). This approach enables us to investigate how the impact of AAPUC varies depending on the different focuses of firms on characteristics of XAI. It also allows us to generate confidence intervals to assess the effects of AAPUC across different XAI characteristics. We estimated two models using the PROCESS macro for SPSS with 1000 bootstrap samples (Preacher & Hayes, 2008). The initial model examines the impact of AAPUC on firm performance without considering agility as the mediator in the analysis. The second model assesses the effects of AAPUC while controlling for the influence of agility.The findings presented in Table 5 indicate that AAPUC has a significantly positive impact on the performance of firms focusing on accessibility (β: 0.21, ρ = 0.03) and interactivity (β: 0.25, ρ = 0.01) of AI applications and not confidence or privacy and confidentiality, but only when agility is not considered in the analysis. However, when accounting for the influence of agility, the effects of AAPUC are not statistically significant, as presented in Table 8. This underscores the importance of identifying and considering mediators like agility and other variables that may influence the relationship between AAPUC and performance. The additional analysis results in Table 8 align with our discussion on the importance of agility as a mediator for the relationship between AAPUC and performance. The analysis also highlights the more significant role of accessibility and interactivity in the direct effect of AAPUC on performance."",,,,",0.30490496149435947,0.7185482,0.7752397656440735,0.43142597638510444,0.8657050261273704
20,Tables_5731/h127.png," The table shows the top 10 stories for which the tweets persisted for the longest duration. The stories are ranked by the number of tweets, with the story with the most tweets at the top. The table also shows the rating of each story, as well as the duration for which the tweets persisted.","20,""The study involved purposive sampling recommended by (Palinkas et al., 2015). The sample group was seven (7) IT managers at a high administrative level within their organizations (c-level executives) who have experience with updating their portfolio of AI applications and have adopted or plan to adopt XAI. The sample group focused on individuals with knowledge of XAI. The rationale for this sampling decision is that individuals need to demonstrate a knowledge of XAI to provide informed responses to the qualitative survey. The overlap between managerial practitioners with knowledge of XAI and a desire to adopt the technology is sizeable, the 7 individuals we interviewed happened to fit both criteria. However, we acknowledge that there are individuals that are aware of XAI but have no plans to adopt it within their organizations. We have acknowledged this shortcoming in the limitations of this study in Section 6.3. The seven participants were not involved in the previous quantitative survey. Table 9 presents the demographics of participants.We facilitated in-depth discussions in a focus group to explore the contextual factors and subjective experiences that may have influenced the observed quantitative relationships from the previous survey. Through open-ended questions and interactive dialogue, we delved into the intricacies of updating portfolio of AI applications and XAI seeking to evaluate our findings in Study 1. The online meeting was recorded and transcribed through zoom. The transcripts were analyzed based on their potential insights about hypotheses in Study 1."",,,,",0.3985097308975446,0.8112311,0.8132874965667725,0.01891703219845671,0.8948412698412698
21,Tables_5731/h128.png," The table shows the number of tweets in the first and second half of the tweet period for each story, ordered by the total number of tweets. The first column is the story ID, the second column is the interval, the third column is the total number of tweets, the fourth column is the number of retweets, and the fifth column is the number of replies.","21,""he proposed research model was tested in a quantitative study with Spanish service companies. First, a preliminary structured questionnaire was developed based on existing literature. Several company directors, academics and consultants were then interviewed to check the comprehensibility of the items and to ensure appropriate content and wording. Based on suggestions from the experts consulted in the pretest, the questionnaire was revised to incorporate the recommended changes and obtain the final questionnaire, which examined how organizations handle these strategic issues.General managers were selected as strategic informants because they lead departmental strategy design, and plan and direct the organization’s future actions (Westphal & Fredickson, 2001). Drawing on information from the different departments, these CEOs steer strategic activity to enhance performance (Baer & Frese, 2002).Using the Iberian Balance Sheet Analysis Systems (SABI) database and information from Spain’s Ministry of Science and Research, the Andalusian regional government, and the Ministry of Economy, Innovation and Science, an accurate list of Spanish tourism firms was compiled to identify the study population. The SABI database has economic and financial information on more than 2.6 million companies (Spain and Portugal), including balance sheets and qualitative data. It is updated daily, and the information is obtained from various official sources.Our study used stratified random sampling of 950 companies, establishing equal probability that any firm could be selected at any step during sampling. The companies were contacted by phone and e-mail to explain the study’s purpose and offer them the opportunity to receive the results once the study was finished. Analyzing the results in aggregate and promising confidentiality of responses increased the response rate (36.10%, 343 valid responses (see Table 4)) and reduced the possibility of desirability bias."",,,,",0.4937539328444175,0.7482338,0.796486496925354,0.024039715226969814,0.900937950937951
22,Tables_5731/h129.png," The table shows the sentiment analysis results of the VADER algorithm on the sample posts from the dataset. The algorithm is able to identify the sentiment of the posts correctly. For example, the post ""From Chaos To Calm: A Life Changed By Ketamine"" has a positive sentiment, and the post ""The Healthy Skeptic: Is caffeine an effective weight-loss aid?"" has a neutral sentiment.","22,""A comparative analysis of two groups of respondents was performed, the companies that returned the completed survey within three weeks of receiving it and the companies that returned the survey only after follow-up reminders. This test assumes that late respondents are similar to non-respondents (Armstrong & Overton, 1977). Comparing the characteristics of the firms with late vs. early respondents (Table 5) indicated no significant differences between early and late respondents."",,,,",0.3132970116138935,0.70192736,0.8307700157165527,0.4024409625884731,0.8318027210884357
23,Tables_5731/h13.png," The table shows the coverage and consistency of two configurations for a model. The first configuration has a higher raw coverage and unique coverage than the second configuration. However, the second configuration has a higher consistency than the first configuration. The solution coverage is 0.850607 and the solution consistency is 0.758331.","23,""Next, the standard deviations, means and factor correlation matrix of the study variables were calculated (Table 7). The correlations were positive and significant."",,,,",0.29608033434056,0.7969309,0.8247306942939758,0.4117647058823529,0.736190606778842
24,Tables_5731/h130.png," The table shows the summary of sentiment scores by rating. The columns are rating, count, tweet, retweet, and reply. The rows are sentiment scores, which are negative, neutral, positive, and compound.

The table shows that the majority of tweets are positive, followed by neutral, and then negative. This is true for all ratings. The compound sentiment score is also positive for all ratings. This means that the overall sentiment of the tweets is positive.","24,""Finally, comparison of different models confirmed that our proposed model provides the best representation of the data (Hair et al., 2016). Comparing this structural model (Model 1) to another models shows Model 1 to be the most acceptable, preferable, and parsimonious, as it best supports relationships among the study constructs (Table 10). Model 3, for example, showed worse AIC (Δ = 76.21), NCP (Δ = 77.21), RMSEA (Δ = 0.03), and ECVI (Δ = 0.23). The results thus confirm preference for our Model 1 over Model 3 (Δχ2 =78.21) and the additional models."",,,,",0.25248050525306187,0.5187611,0.8169912695884705,0.35541778392056966,0.8173048048048046
25,Tables_5731/h131.png," The table shows the topic keywords in stories from three rating groups revealed by LDA analyses. The keywords are acupuncture, Alzheimer's, autism, blood, bone, brain, cancer, coffee, colon, egg, heart, implant, knee, laser, migraine, pain, prostate, skin, stem, study, therapy, tumor, vaccine, mammogram, diabetes, weight, fish, hormone, lung, stroke, depression, vitamin, and pregnancy.","25,""A total of 123 participants (Mage = 25.36, SDage = 4.75) were recruited by Qualtrics (see Table 2). In the experiment, participants were randomly allocated into one of two priming conditions (maximisers = 62 and satisficers = 61).Prior to data collection, participants were presented with a participant information statement, which outlined the study’s goals and procedures. They were provided with an explanation of the omnichannel concept. Those who expressed their interest in participating were asked to read and sign a consent form and complete the demographic information section.Participants were first presented with a priming task to induce a specific decision-making style (maximiser or satisficer). We used the priming technique recommended by Ma and Roese (2014) and Mao (2016). The priming task consisted of five questions asking participants to choose either the ‘best’ or the ‘good enough’ option among five alternative choices. For example, in the maximiser condition, participants were asked Please choose the country you think is the best place to visit: A. Belgium, B. Denmark, C. The Netherlands, D. Norway, E. Sweden’. In the satisficers condition, participants were asked: ‘Please choose the countries you think would be acceptable to visit: A. Belgium, B. Denmark, C. The Netherlands, D. Norway, E. Sweden’.After completing the priming task, participants were presented with a shopping scenario in which they were given a shopping task (buying a new pair of sunglasses), asked to search various digital channels and touchpoints and asked to select a product of their preference. To replicate the dynamic nature of omnichannel shopping, participants were provided with a real-world omnichannel sunglasses store. They were also provided with multiple digital channel links that were integrated to represent an omnichannel setup. Participants were free to explore these links based on their interests and preferences. After completing their shopping task, participants were asked to return to the questionnaire and reflect on their omnichannel shopping experience.Perceived omnichannel interaction quality was measured using six items adapted from Lee et al. (2019) and Sousa and Voss (2006). Participants responded to all items using a seven-",0.14319019717182763,0.7635395,0.7659262418746948,0.0019467965086308397,0.8169185112581341
26,Tables_5731/h132.png," Table 11 shows the top 10 keywords in stories from five news media types. The keywords are ranked by their frequency in the stories. The most frequent keyword in the stories is ""study"", which appears in all five news media types. Other common keywords include ""cancer"", ""drug"", ""treatment"", and ""health"".

The table shows that the top 10 keywords in stories from different news media types are similar. This suggests that the stories in these different news media types are about similar topics.","26,""A total of 120 participants (Mage = 30.98, SDage = 8.14) were recruited by Qualtrics (see Table 4).Participants were randomly assigned to one of the two priming conditions (maximisers = 60 and satisficers = 60). The priming task and shopping task were the same as in Study 1. In this study, participants were asked to shop and select a new footwear product using a real-world omnichannel retailer. Perceived omnichannel interaction quality and MTS were measured as advised in Study 1. Perceived content integration capability was measured using two items adapted from Sun et al. (2020), such as ‘I trust my ability to process the information I gather from different channels’. Participants responded to all items using a seven-point Likert scale ranging from 1 (strongly disagree) to 7 (strongly agree)."",,,,",0.17058377178843395,0.61090624,0.8090165853500366,0.24749348005921765,0.8096205962059617
27,Tables_5731/h135.png," | Component | Misinformation generators’ view | Misinformation mitigators’ views |
|---|---|---|
| Subject | Creators or senders of the messages: Twitter users | Authorities working to eliminate or minimize prejudiced messages during Boston bombing |
| Objects | Spreading prejudiced messages: Offensive or hate messages and misinformation | Identifying intergroup prejudiced messages automatically |
| Community | Boston citizens and people reading posts and shares on Twitter | Entire involved community: Message receivers and victims; message senders and mitigators |
| Labor division | Creating, posting and sharing prejudiced messages on social media | Obtaining, preprocessing, cleaning, labeling, analyzing, reporting and concluding data from messages |
| Instruments | Social media channels and accounts | Machine learning based automatic detection system of intergroup prejudice message on social media |
| Rules | Sensitive emotions and angers of the public after the crises creates good environment for widespread prejudiced messages | Six rules of detection: ‘Groups and names’, indicators, verbal aggression, emotional accentuation, empathetic expression, mentions of prominent social groups, and fact-indicative linguistic cues |","27,""3.1. Measures and data collection We measure telepresence using a four-item scale adopted from Rose, Clark, Samouel, and Hair (Rose et al., 2012), and the attitude toward virtual shopping with a three-item scale from Grohmann (2009). The 12-item Need for Touch (NFT) scale, which is divided into autotelic and instrumental need for touch, comes from Peck and Childers (2003a), and the four-item scale for measuring imagination is based on Johnson (2014). We use a seven-point Likert scale, ranging from 1 = Strongly disagree to 7 = Strongly agree, to measure the constructs of telepresence and imagination, and a scale ranging from -3 = Strongly disagree to 3 = Strongly agree to measure the need for touch. When measuring the attitude toward virtual shopping, we use a seven-point semantic differential scale ranging from negative to positive, dislike to like, and favorable to unfavorable. Prior to running the analysis, we reverse coded the last item of the attitude scale (Appendix A). Table 1 shows the descriptive statistics of our research constructs."",,,,",0.22168440935664752,0.54413265,0.7715186476707458,0.41333333333333333,0.7387745055553273
28,Tables_5731/h136.png," | Scenario | Descriptions |
| ----------- | ----------- |
| Scenario 1: | Various rumors spread quickly on social media after a bombing erupted near the finish line of Boston Marathon event on April 15th, 2013. It was reported that many services were shut down, including cell phone services and flights. Later, official news corrected the misinformation with the rebuttal that cell phone services did not shut down, and the flights were grounded because of computer problems but not the bombing crisis. |
| Scenario 2: | A rumor during hurricane Harvey claimed that shelters would check immigration status. Undocumented immigrants were said to be reported to U.S. Immigration and Customs Enforcement (ICE) and U.S. Customs and Border Protection (CBP). That information was then officially announced to be false by both ICE and CBP as well as the organizations running the shelters. |
| Scenario 3: | An evacuation order was sent to the nearby community due to rapidly eroding area because of flooding. However, National Weather Service (NWS) Sacramento wrongly released mapped pictures of widespread flooding covering all of Sacramento County and the Oroville Dam, which misled people to believe that the entire Sacramento County needed to be evacuated. Although the information was corrected on Twitter half an hour later, evacuation calls had already spread. The state of Sacramento County EOC had to make a Facebook Live Video in order to officially reject the misinformation. |
| Scenario 4: | Although it is common in California to see wildfiress annually, the 2018 wildfires got caught on social media channels. Numerous pictures were posted. It later turned out that several images were old pictures from other fires in 2000, 2007 and 2017. The misinformation created unnecessary fears, worries and other consequences for California citizens. |","28,""To collect the data for this study, we used an independent market research company. The market research company compensated the participants with a small monetary incentive for their participation in the study. The data collection began with participants filling out their background characteristics, including gender and age. Then, we instructed all the participants to visit the 360-virtual store of a Danish furniture retailer BoConcept (https://www.boconcept.com/en-gb/inspiration/virtual-store-visit) for a minimum of 180 s in order to provide them with a realistic 360-virtual store experience. This was to ensure that all respondents had an equal experience of the 360-virtual store before they continued to fill out the questionnaire. Thereafter, the participants responded to questionnaire items related to the following: telepresence, attitude toward virtual shopping, autotelic and instrumental need for touch, and imagination. Finally, we asked the participants about their prior experience of using a 360-virtual store. The sample consists of 900 valid responses and Table 2 describes respondent characteristics."",,,,",0.3787350216598756,0.7169135,0.7931209206581116,0.42567567567567566,0.8541519571410879
29,Tables_5731/h137.png," The table summarizes student assignments to crisis scenarios.

In the first scenario, students were asked to consider the Boston Marathon Bombing of 2013. They were given the following information:

* There were two bombs that exploded near the finish line of the Boston Marathon.
* Three people were killed and more than 260 were injured.
* The bombs were placed in backpacks and left on the ground.
* The suspects were two brothers, Dzhokhar and Tamerlan Tsarnaev.
* Dzhokhar Tsarnaev was captured alive, but Tamerlan Tsarnaev was killed in a shootout with police.

Students were asked to answer the following questions:

* What were the challenges that first responders faced in responding to the bombing?
* How did the bombing affect the city of Boston?
* What were the long-term effects of the bombing?

In the second scenario, students were asked to consider Hurricane Harvey of 2017. They were given the following information:

* Hurricane Harvey was a Category 4 hurricane that made landfall in Texas on August 25, 2017.
* The hurricane caused widespread flooding in Texas and Louisiana.
* More than 1 million people were displaced from their homes.
* The damage caused by the hurricane was estimated to be in the billions of dollars.

Students were asked to answer the following questions:

* What were the challenges that first responders faced in responding to the hurricane?
* How did the hurricane affect the cities of Houston and New Orleans?
* What were the long-term effects of the hurricane?

In the third scenario, students were asked to consider the Oroville Dam evacuation of 2017. They were given the following information:

* The Oroville Dam is a concrete arch dam on the Feather River in Butte County, California.
* In February 2017, the dam's spillway began to erode, threatening to cause the dam to fail.
* More than 180,000 people were evacuated from their homes.
* The dam was ultimately saved, but the evacuation caused widespread disruption.

Students were asked to answer the following questions:

* What were the challenges that first responders faced in responding to the dam failure?
* How did the evacuation affect the city of Oroville?
* What were the long-term effects of the dam failure?

In the fourth scenario, students were asked to consider the California wildfires of 2018. They were given the following information:

* The California wildfires of 2018 were a series of wildfires that burned more than 1 million acres of land in California.
* The fires destroyed more than 10,000 homes and businesses.
* More than 100 people were killed.
* The fires were the deadliest and most destructive in California history.

Students were asked to answer the following questions:

* What were the challenges that first responders faced in responding to the wildfires?
* How did the wildfires affect the state of California?
* What were the long-term effects of the wildfires?","29,""A confirmatory factor analysis indicates adequate fit with the data (χ2 = 1327.964 (df = 220) p < 0.001, CFI = 0.937, TLI = 0.927; RMSEA = 0.075). Cronbach’s alpha (α) and composite reliability (CR) scores both indicate appropriate reliability (Fornell & Larcker, 1981), and all factor loadings are statistically significant (p < 0.001) and greater than the generally considered threshold of 0.70 (Appendix A) (e.g., (Hair et al., 2019). Further, the average variance extracted (AVE) values are all greater than 0.6, supporting convergent validity, and the square roots of AVE values exceed the between-construct correlations (Table 3), supporting discriminant validity (Fornell & Larcker, 1981). Given the study’s cross-sectional nature, we controlled for common method variance in the study design before the data collection and by using statistical procedures after the data collection (Chang et al., 2010, Podsakoff et al., 2003). To control for the common method variance during the data collection, we used differently coded scales (semantic differential and Likert scales), reverse coded questions and protected the respondents’ anonymity, as suggested by Podsakoff et al. (2003). As for the statistical procedures, we used the CFA marker technique approach (Lindell and Whitney, 2001, Williams et al., 2010) with a theoretically unrelated questionnaire item stating “I like blue clothes” as the marker variable (Miller & Chiodo, 2008). The results show that study variables have low and non-significant correlations (0.062–0.115) with the marker variable, indicating that common method bias should not be a concern. We follow Armstrong and Overton (1977) in examining for non-response bias, and our comparison between the first and the last quartile of the respondents show no systematic differences between early and late respondents."",,,,",0.4178785199096412,0.5384307,0.7601962089538574,0.391304347826087,0.8362697935935826
30,Tables_5731/h138.png," Table 4. AT components’ names and descriptions.

Component	Descriptions/explanations
Subjects	The individual creators of an activity
Objects	The actual results that the creators (Subjects) can create, or the purpose or objectives that the creators want to reach by doing an activity
Community	The group of people that will be involved in the context of such misinformation generation or mitigation
Instruments	Systems, infrastructures, or other kinds of resources that creators (Subject) can use to create the Object
Rules	Regulations or patterns that the Subjects should or must follow in order to do the activity. These rules form the boundaries of the context of activity
Labor	Different responsibilities of tasks related to the activity
Division","30,""The survey instrument was developed based on existing scales that have been empirically tested and validated in previous studies (see Table 4). All items were measured using a 7-point Likert scale (1: strongly disagree; 7 strongly agree). Once the measurement instrument was assembled, we developed an online questionnaire on the Qualtrics survey platform.1 We conducted a pretest with 20 graduate students with experience participating in online SMLS shopping. The pretest was to validate the clarity of the questionnaire and its fluidity online (face validity). As expected, we had no major feedback because the items used are from existing scales. Thus, they have been tested and validated in previous studies. After validation, we hosted the complete survey and recruited participants using the Prolific2 platform. This GDPR3-compliant platform allows researchers to identify high-quality survey participants while respecting their privacy (Harnish and Roster, 2019, Lelieveld and Hendriks, 2021). Participation in this survey was voluntary, and the participants received financial compensation for their time based on the platform's policies. We did not focus our research on any specific world region, so participants were selected randomly worldwide. Using the G*Power 3.1 statistical software (Erdfelder et al., 2009), the recommended minimum sample size for this research was 386 participants. However, we collected 800 responses from November 24 to December 10, 2021. Based on the attention check set in the questionnaire (""""select strongly agree if you are following""""), five responses were eliminated from our dataset, leaving 795 valid responses (99.4% response rate) that were used for analysis. Table 2 presents a description of the sample used in this study."",,,,",0.3121458867587771,0.90489936,0.7850253582000732,0.12547108116131064,0.8166489483967357
31,Tables_5731/h139.png," The table summarizes the views of misinformation generators and misinformation mitigators in the Boston bombing scenario. The misinformation generators view the situation as an opportunity to spread fear and panic, while the misinformation mitigators view it as an opportunity to provide accurate information and help people stay safe. The misinformation generators believe that they can use social media and other online platforms to spread their message quickly and easily, while the misinformation mitigators believe that they can use the same platforms to spread accurate information and help people stay safe. The misinformation generators believe that they can use the element of surprise to their advantage, while the misinformation mitigators believe that they can use their knowledge of the situation to their advantage. The misinformation generators believe that they can use the fear and panic that they create to their advantage, while the misinformation mitigators believe that they can use the trust that they have built with the public to their advantage.","31,""Table 3 presents different live streaming platforms and the number of respondents who had used them to participate in e-commerce SMLSs at least once. Several participants had used more than one platform. The reported dominant platforms for e-commerce SMLSs are YouTube, Instagram, Facebook (Meta), TikTok, and Twitch."",,,,",0.167979949597498,0.67866004,0.8214104175567627,0.37060041407867494,0.7550621566149515
32,Tables_5731/H14.png," The table summarizes the key findings and research gaps in the three research themes.

For the theme of feature intensity, the key findings are that more advanced features increase perceived innovativeness but risk subsequent overload, and the presence of legacy models with fewer features moderates adoption. The research gaps are what curvilinear relationship exists between feature expansion and sales over time, how does legacy model availability shift that inverted U shape.

For the theme of product update frequency, the key findings are that faster generational release cycles keep products more updated but heighten consumer learning costs, and accelerated schedules also depress residual sales of older generations faster. The research gaps are what pace of introducing new generations maximizes short-term sales versus long-term brand equity, and how does active legacy model availability interact with ideal cadence.

For the theme of expert reviews versus user reviews, the key findings are that expert reviews influence adoption by assessing technical product performance, and user reviews highlight experiential quality from real-world usage. The research gaps are how does the volume and dispersion of expert versus user reviews interact to shape sales, and when do the review types complement versus compete in driving adoption.","32,""The Fornell-Larcker criterion was used to establish discriminant validity (Henseler et al., 2015, Leguina, 2015). According to this criterion, the square root of the AVE of each latent variable should be greater than the correlation values among the latent variables, which is the case in this study, as shown in Table 5."",,,,",0.2711852342309342,0.79334253,0.79254549741745,0.367003367003367,0.7189567026688238
33,Tables_5731/h140.png, Table 6. Summary of validation exercise – Scenario 2: Hurricane Harvey 2017.,"33,""The structural model was assessed based on the significance of path coefficients and the endogenous constructs' R2 values (Hair et al., 2019, Leguina, 2015). The model's predictive power was assessed using the PLS predict procedure with ten folds and ten repetitions (Shmueli et al., 2019). The structural model's path coefficients range between absolute values of 0.071 and 0.522, and they are all significant (p < 0.05) based on the bootstrapping results of 10,000 subsamples, thus supporting all hypothesised relationships. Purchase intention has an R2 of 0.424, indicating that the model explains 42.4% of the variance in purchase intention during SMLSs. This variance explained is satisfactory considering the model's complexity (Rasoolimanesh et al., 2021, Shmueli et al., 2019). Table 6 and Fig. 2 present a summary of the structural model results."",,,,",0.07739009126042275,0.6238692,0.8187283873558044,2.3837191008124623e-05,0.821861471861472
34,Tables_5731/h142.png," The table shows the demographic breakdown of the respondents. There are more females (60%) than males (40%). The majority of the respondents are aged between 25 and 30 years old (59%), followed by those aged between 31 and 40 years old (34%). The majority of the respondents have a bachelor's degree (82%), followed by those with a master's degree (17%). The majority of the respondents have 3-6 years of work experience (56%), followed by those with 7-10 years of work experience (38%).","34,Mediation analyses also reveal that attitude towards social media live streams and attitude towards the brand mediate the relationship between the independent variables and purchase intention. The mediations are presented in Table 7.,,,,",0.2605183814094641,0.36205575,0.8122762441635132,0.3983739837398374,0.6628735086052158
35,Tables_5731/h16.png," The table shows the summary statistics of the variables used in the model. The mean sales is $145,000 with a standard deviation of $22,000. The range of sales is from $500 to $12,000,000. The mean variety is 5 with a standard deviation of 3. The range of variety is from 1 to 15. The mean brand age is 8.5 with a standard deviation of 6.1. The range of brand age is from 1 to 25. The mean average price is $180 with a standard deviation of $55. The range of average price is from $50 to $400. The mean prior generation sales is $120,000 with a standard deviation of $190,000. The range of prior generation sales is from $10 to $10,000,000. The mean update frequency is 2.8 with a standard deviation of 1.5. The range of update frequency is from 1 to 8. The mean feature intensity is 15 with a standard deviation of 6. The range of feature intensity is from 5 to 30. The mean search volume is 73,500 with a standard deviation of 112,000. The range of search volume is from 100 to 950,000. The mean expert polarity is 0.68 with a standard deviation of 0.15. The range of expert polarity is from 0.20 to 0.95. The mean consumer polarity is 0.72 with a standard deviation of 0.22. The range of consumer polarity is from 0.10 to 0.99. The mean expert mentions is 4.2 with a standard deviation of 1.9. The range of expert mentions is from 1 to 10. The mean consumer mentions is 550 with a standard deviation of 420. The range of consumer mentions is from 20 to 2500.","35,""Q2predict values from the PLSpredict analysis are all above zero for all items of the dependent variables. Furthermore, the root mean square error (RMSE) values for all the dependent variables are lower for PLS-SEM than for the linear model. These results indicate that the PLS path model acceptably predicts purchase intention, attitude towards SMLSs and brand attitude (Table 8)."",,,,",0.23167230816316575,0.62384236,0.7858266830444336,0.35515151515151516,0.7473203463203462
36,Tables_5731/h17.png," The table summarizes the key themes, limitations, research gaps, and references from the literature review on the role of IT in business model innovation and transformation. The key themes are business model innovation, business model transformation, required capabilities, environmental context, and AI as other IT enablers. The limitations and research gaps identified in the literature include:
1. How does one differentiate between incremental business model innovation that maintains organizational viability for the immediate planning horizon and fundamental business model transformation that prepares the business for long-term success?
2. How do the specific capabilities inter-relate and are some more important than others?
3. How does the environmental context influence success in IT-enabled business model transformation as opposed to lower stakes business model innovation?
4. Do the capabilities and interactions change when the technology enabler is AI - a technology that is quickly evolving and regulation and 'accepted practices' are not yet solidified?","36,""Table 9 presents the configurations with acceptable consistency (>0.8) and coverage (>0.2) levels (Rasoolimanesh et al., 2021) required to sufficiently explain high and low purchase intentions. The results highlight three configurations covering 69.6% of high purchase intentions with 94.6% consistency. Meanwhile, it highlights three configurations that account for 59.2% of low purchase intentions with 79.4% consistency."",,,,",0.1491421095276758,0.62195456,0.8056063055992126,0.3730684326710817,0.7696180301180298
37,Tables_5731/h21.png," Enablers, Capabilities, and Environmental Context are first-order themes in the research model. Internal Behaviours, Internal Capabilities, and External Conditions are second-order themes in the research model.","37,""To examine the roles of trust, a SEM analysis was performed using the full sample. The results demonstrated acceptable model fit for the structural model (χ2 =1883.00; df=718; RMSEA=0.04; CFI=0.95; TLI=0.95; SRMR=0.05), indicating the reliability of the extended AIDUA framework. In addition, as shown in Fig. 3 performance expectancy (β = .35, p < .001) and hedonic motivation (β = .39, p < .001) positively predicted trust in interaction with AI robots, whereas effort expectancy (β = −.19, p < .001) negatively predicted trust. Hence, H1a, H1b, and H1c were supported. In addition, trust positively influenced willingness to use AI robots (β = .32, p < .001) and negatively influenced objection to the use (β = −.26, p < .001), supporting H1d."",,,,",0.18535549814631266,0.6930765,0.7835016250610352,0.01213780448628261,0.739920976459438
38,Tables_5731/h23.png," The table shows the participation of executive advisors, practice-based researchers, and participants in the five focus groups. The executive advisors and practice-based researchers were present in all the sessions. The participants were present in different sessions. For example, participant P1.1 was present in the pilot group and the first focus group.","38,""Prior to examining the moderation effects of culture, this study validated the cultural differences between the U.S. and China. A battery of independent t-tests was performed to compare these two nations in terms of Hofstede’s cultural dimension score. The results (Table 3) reveal that, compared to the Chinese culture, the U.S. culture was significantly lower in term of power distance (t = −3.26, p = 0.001), collectivism (t = −8.68, p < 0.001), uncertainty avoidance (t = −13.37, p < 0.001), and long-term orientation (t = −16.69, p < 0.001). However, there was no significant difference in the level of masculinity (t = −0.76, p = 0.45) across the two cultures."",,,,",0.3559617503818667,0.6388113,0.7926364541053772,0.15519031325514232,0.7321581468640294
39,Tables_5731/h24.png," The table shows the original and revised definitions of two factors: Industry Dynamism and Strategic Process Strength.

The original definition of Industry Dynamism is ""the degree of change in the industry within which the firm operates"". The revised definition is ""the degree of change in the industry within which the firm operates as well as the willingness of industry participants to accept and support change from other industry participants"".

The original definition of Strategic Process Strength is ""formal processes for formulating and reviewing strategies, executive decisiveness in choosing initiatives, and sound analytic capabilities supporting their choices"". The revised definition is ""the degree to which an organisation follows formal processes for formulating and reviewing strategies, displays executive decisiveness in choosing initiatives, and deploys sound analytic capabilities to support those choices"".

The revised definitions are more comprehensive and provide a clearer understanding of the factors.","39,""Lastly, power distance is found to magnify the negative impacts of effort expectancy on trust and emotion. Specifically, the negative impact of effort expectancy is not statistically significant in the U.S. culture, which has low power distance. Moreover, performance expectancy and hedonic motivation are factors that drive U.S. customers’ trust and emotion toward AI hospitality robots. In contrast, in a high-power distance culture (e.g., China), a significantly negative effect of effort expectancy is found. Furthermore, the effect size of effort expectancy is greater than performance expectancy and hedonic motivation. Therefore, service providers should consider providing high-level facilitating conditions (e.g., guidance or demonstrations) to help customers from a high-power distance culture to use AI robots. The key findings of AI robot application in different cultures are summarized in Table 5."",,,,",0.3022576441916382,0.8968516,0.8126539587974548,0.46853146853146854,0.7970356954622686
40,Tables_5731/h25.jpg," The figure shows the relationship between enablers, capabilities, and performance in the context of artificial intelligence (AI).

The enablers are:
- AI-sensitive risk tolerance
- Tech-sensitive innovation culture

The capabilities are:
- Ability to run and change
- AI-oriented data and information systems readiness
- Market and customer awareness
- Strategic process discipline

The performance is:
- Business model transformation

The environmental context includes industry dynamism and opportunity/threat drivers.

The organizational precursor is proactive leadership.

The arrows show the relationships between the different elements. The enablers influence the capabilities, which in turn influence the performance. The environmental context and organizational precursor also influence the performance.

The figure provides a comprehensive view of the factors that influence the successful implementation of AI in an organization. It can be used by organizations to assess their readiness for AI and to identify the areas where they need to improve.","40,""The dataset for this study was generated from HealthNewsReview.org as described by Dai et al. (2020). It contains 1661 news stories on health topics ranging from cancer, Alzheimer's to heart disease published in 2007–2018. The distribution of stories by ratings is shown in Table 1. Each story is evaluated on 10 different criteria as satisfactory (S), not satisfactory (NS) or not applicable (NA), and an overall numerical score is then assigned to the story based on the 10 individual values. A snippet of the dataset is shown in Table 2(a). Many of these criteria are also consistent with a directive from the National Institutes of Health on evaluating health information on the Internet (NIH, 2011). Further descriptions and details about these criteria for data collection and processing are provided on the website of HNR. The 10 criteria are:"",,,,",0.39330560273316106,0.7786606,0.8005185127258301,0.4657534246575342,0.8077697317963928
41,Tables_5731/h27.png, The table shows the correlation coefficients between different variables. The correlation coefficient between willingness to pay and functional value is 0.419. The correlation coefficient between willingness to pay and hedonic value is 0.421. The correlation coefficient between willingness to pay and social value is 0.429. The correlation coefficient between willingness to pay and price value is 0.492. The correlation coefficient between willingness to pay and trust is 0.425.,"41,""Specifically, a rating is assigned using a scale based on the percentage of criteria that are satisfied as follows: 0%: 0 stars; 1–20%: 1 star; 21–40%: 2 stars; 41–60%: 3 stars; 61–80%: 4 stars; 81–100%: 5 stars. As shown in Table 2(a), we created our own dataset in Excel consisting of story, HNR overall rating, HNR review title, and HNR ratings on individual criteria from the various data elements provided through a website (Dai et al., 2020). The above ratings on a scale of 0–5 provide ground truth for research. Stories with higher ratings (4 or 5) would represent high quality information. The stories with ratings of 2 or 3 are of variable quality, which are treated as proxies for misinformation. Hence, this paper mainly centers on comparing stories rated 4 or 5 versus those rated 2 or 3. We refer to the latter group as lower rated stories (with ratings 2 or 3) as opposed to higher rated stories (with ratings 4 or 5)."",,,,",0.0967682801371278,0.4763635,0.799686074256897,0.09653290591590118,0.7635175282234107
42,Tables_5731/h28.png," The table shows the results of a study that examined the effects of trust, functional value, hedonic value, social value, and price value on willingness to pay (WTP). The study used two different models: a limited features model and a virtual items model. The limited features model included only the direct effects of the independent variables on WTP. The virtual items model included the direct effects of the independent variables on WTP, as well as the indirect effects of the independent variables on WTP through trust.

The results show that, in the limited features model, trust, functional value, hedonic value, social value, and price value all had significant direct effects on WTP. In the virtual items model, trust, functional value, hedonic value, social value, and price value all had significant direct effects on WTP, and trust also had a significant indirect effect on WTP through functional value.

The model difference column shows the difference in the R-squared values between the two models. The R-squared value is a measure of how well the model fits the data. The larger the R-squared value, the better the model fits the data. The model difference column shows that the virtual items model fits the data significantly better than the limited features model. This suggests that the indirect effects of the independent variables on WTP through trust are significant.

The p-value column shows the significance of the difference in the R-squared values between the two models. The p-value is a measure of the probability that the difference in the R-squared values is due to chance. The smaller the p-value, the less likely it is that the difference in the R-squared values is due to chance. The p-value column shows that the difference in the R-squared values between the two models is significant, which suggests that the indirect effects of the independent variables on WTP through trust are significant.","42,""Still, the dummy variable 3 corresponding to medical websites shows a significance at the 1% level with a negative coefficient, suggesting that medical websites in this category have a negative effect on the ratings. Moreover, dummy variable 4 corresponding to television shows a significance at the 10% level also with a negative coefficient. The length variable is significant at the 0.1% level with small coefficient (see Table 3)."",,,,",0.3370271366006857,0.80112195,0.8046278357505798,0.38232161874334397,0.778275434185977
43,Tables_5731/h29.png," | Gender | Monetization strategy | Service |
|---|---|---|
| Female | Limited features | Spotify |
| Male | Virtual items | Fortnite |
| Male | Limited features | Spotify |
| Male | Limited features | Spotify |
| Male | Limited features | Spotify |
| Female | Virtual items | Pokemon Go |
| Male | Virtual items | Roblox |
| Male | Limited features | Fortnite |
| Male | Virtual items | Pokemon Go |
| Female | Limited features | LinkedIn |
| Male | Virtual items | Pidro |
| Male | Limited features | iCloud |
| Male | Limited features | Spotify |
| Male | Virtual items | Fortnite |
| Male | Virtual items | Habbo Hotel |","43,""Next, we study how the mix of various types of responses, i.e., tweets, retweets and replies, varies between health news reports with higher or lower ratings. To understand this phenomenon, the expression (#Retweets + #Replies)/ #Total posts is computed as the Response Ratio, i.e., a measure of how much discussion is generated by a tweet about a health news story. Table 4 shows the most tweeted stories along with numbers of retweets and replies for them (in a descending order of number of tweets). The last column of this table reports the response ratio of the top 10 stories of which 6 have a 3 rating, and the rest 5. The response ratio of the stories with a rating of 3 is much higher than the response ratio of those with a 5 rating. Evidently, the extent of the response, or discussion of the topic, varies across stories based on their ratings."",,,,",0.0,0.054899223,0.7600345015525818,0.0,0.7064143567874911
44,Tables_5731/h35.png," | Interpretability vs Explainability | Definition | Limitation(s) | Relevant Work |
|---|---|---|---|
| Interpretability | ""the extent to which the reason for a decision made by AI can be understood by a human and subsequently reproduced"" (Miller, 2019) | Understanding the cause of the decision is the aim and not the way the decision has been made. | (Biran and Cotton, 2017; Lindardatos et al., 2021; Miller, 2019) |
| Explainability | A suite of AI techniques that enables human users to understand, and effectively manage the emerging generation of artificially intelligent partners. | Does not account for the purpose of XAI. Does not account for multiple audiences. | (Gunning et al., 2019) |
|  | ""Explanation decisive for the efficacy of the intelligent system as the end user decides based on the given information whether he or she integrates the prediction into his or her decision-making or not."" (Herm et al., 2023) ""Explainability can be considered as the perceived quality of an explanation by an individual or user group."" (Herm et al., 2023) | Does not account for multiple audiences. | (Herm et al., 2023; Shin, 2021; Thiebes et al., 2021; van der Waa et al., 2021) |
| Adopted in this study:  | ""Given a certain audience, explainability refers to the details and reasons a model gives to make its function clear or easy to understand."" (Arrieta et al., 2020) |  | (Arrieta et al., 2020) |","44,""Further, Table 5 shows the top 10 stories with 100 or more tweets (i.e., ones that generated more interest) after sorting them in a descending order by response ratio. It appears that stories with higher ratings generate less discussion than those with lower ratings."",,,,",0.07223955121130639,0.6005072,0.7817189693450928,0.3499999999999999,0.6827927005497101
45,Tables_5731/h36.png," | Study                                             | AI Capability                                             | Other Constructs                                                                                                                                                              |
|---------------------------------------------------|----------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| (Wamba-Taguimdje et al., 2020)                       | AI Management                                          | Process Level Effects of AI: <br>- Automation Effect <br>- Informational Effect <br>- Transformational Effects                                                                 |
| (Mishra et al., 2022)                                 | Tangible                                                | Organizational Creativity                                                                                                                                                 |
|                                                      | Human                                                   |                                                                                                                                                                    |
| (Chen et al., 2022)                                  | Basic (Tangible)                                       | Firm Creativity                                                                                                                                                    |
|                                                      | Skills (Human)                                          | AI Management                                                                                                                                                    |
|                                                      | Productivity (Intangible)                                 | Al-driven Decision Making                                                                                                                                            |
|                                                      |                                                          | Innovative Culture                                                                                                                                               |
|                                                      |                                                          | Environmental Dynamism                                                                                                                                             |
| (Mishra et al., 2022)                                 | AI Focus                                                 | Sale per Employee                                                                                                                                                 |
| (Kumar et al., 2023)                                  | Al-enabled CRM                                         | Customer Service Innovation                                                                                                                                        |
| (Wang et al., 2022)                                  | Chatbot Routine Use                                     | Internal Agility                                                                                                                                                   |
|                                                      | Chatbot Innovative Use                                  | External Agility                                                                                                                                                   |
| (Fosso Wamba, 2022)                                 | AI Assimilation                                         | Customer Agility                                                                                                                                                    |
| (Dubery et al., 2022)                                 | Big Data Analytics                                       | Supply Chain Agility                                                                                                                                               |
|                                                      |                                                          | Information Complexity                                                                                                                                            |
| **This study**                                        | AI Applications Portfolio Update                        | Agility                                                                                                                                                           |
|                                                      |                                                          | Explainability                                                                                                                                                     |","45,""Temporal analysis was conducted to uncover temporal patterns in the heath news stories circulated on Twitter and relationships between them. We uploaded our dataset to a MySQL database and ran SQL queries to calculate the total duration of each story on Twitter, i.e., the time span from the first tweet, retweet or reply until the last one related to a story. Table 6 shows the top 10 stories (in descending order of duration in days) for which the tweets persisted for the longest duration. Among these stories, two have a rating of 4 and one is rated 1, while the rest have ratings of 2 or 3. This shows that discussion continues for a longer period for lower rated stories. In fact, on the list of longest duration stories, the first one with a rating of 5 did not appear until position 22 (story_00009 with a duration of 4320 days and with 495 tweets). On applying the Wilcoxon test in R to this data, however, H1a is not supported because the difference between the reports with higher and lower ratings is not significant."",,,,",0.011441695631628343,0.16338453,0.6914288401603699,0.3369175627240143,0.7086414445927718
46,Tables_5731/h38.png," The table summarizes the steps taken in this study to develop and validate a measurement instrument for assessing the explainability of artificial intelligence (AI) applications. 

In the first step, a literature review was conducted to identify existing work on explainability in AI. 

This review led to the adoption of the XAI objectives as measures of explainability. 

The XAI objectives are: (1) confidence to stability and robustness, (2) fairness, (3) accessibility, (4) interactivity, and (5) confidentiality and privacy of AI applications. 

In the second step, these objectives were used to develop a set of 20 questions. 

These questions were then pre-tested with 20 practicing IT leaders working with XAI. 

The feedback from this pre-test was used to refine the questions and ensure that they were relevant and understandable. 

In the third step, the refined set of questions was used to assess the measurement model. 

This assessment was conducted using a variety of statistical techniques, including reliability analysis and validity analysis. 

The results of this analysis showed that the measurement model was reliable and valid, supporting the use of the instrument to assess the explainability of AI applications.","46,""To gain a deeper understanding of the temporal effects of tweets, we divided the timespan of a news story on Twitter (i.e., the duration from the chronologically first tweet about it until the last retweet or reply posted) into two equal intervals by writing MySQL queries. The results from this analysis are shown for the top 10 stories in descending order of total posts (Total) in Table 7. The table shows the individual numbers for tweets, retweets and replies in intervals 1 and 2 labeled as 'Int1' and 'Int2' respectively, along with their corresponding totals, Total1 and Total2. Note that most stories in this table have a rating of 3."",,,,",0.5251188869963452,0.8682373,0.8089454770088196,0.45878136200716846,0.8059674495158364
47,Tables_5731/h39.png," The table shows the factor correlation between four constructs: business process agility, AI applications portfolio update capability, performance, and explainability. All the constructs have a high composite reliability (CR) and average variance extracted (AVE), indicating that they are reliable and valid measures. The constructs are also highly correlated with each other, suggesting that they are all related to the overall concept of digital transformation.","47,""For sentiment analysis, we used the Vader package (Hutto & Gilbert, 2014) to associate a sentiment with each post. Vader has been used in other studies and shown to be the most consistent in its performance (Al-Natour & Turetken, 2020). This package assigns four scores to each post as: negative, neutral, positive, and compound. Using a combination of qualitative and quantitative methods, Vader first constructs and empirically validates a """"gold-standard"""" list of lexical features (along with their associated sentiment intensity measures), which are specifically attuned to sentiments in microblog-like contexts, such as Twitter. Then, these lexical features are combined using five general rules that reflect grammatical and syntactical conventions for expressing and emphasizing sentiment intensity. Individual scores for negative, neutral, and positive intensities are then combined into a compound score that captures the overall sentiment of a post. Some example sentiment value calculations by Vader for sample posts are shown in Table 8. These are examples from five different stories, though it is not possible to generalize from them."",,,,",0.2550339568330723,0.932989,0.8222812414169312,0.10298751015425062,0.7802083333333335
48,Tables_5731/h40.png," The table shows the results of a regression analysis. The dependent variable is performance. The independent variables are AI applications portfolio update capability, business process agility, and the interaction between AI applications portfolio update capability and explainability. The control variables are size of firm, public/private/not-for-profit, main line of business, and tenure with the company.

The results show that AI applications portfolio update capability has a significant positive effect on performance (β = 0.41, p < 0.001). Business process agility also has a significant positive effect on performance (β = 0.36, p < 0.05). The interaction between AI applications portfolio update capability and explainability does not have a significant effect on performance (β = 0.07, p > 0.05).

The control variables show that size of firm has a significant positive effect on performance (β = 0.09, p < 0.05). Public/private/not-for-profit and main line of business do not have a significant effect on performance. Tenure with the company has a significant positive effect on performance (β = 0.07, p < 0.05).

The variance explained by the model is 78%. The variance explained by business process agility is 55%.","48,""We included Vader in a Python script to generate the sentiments for all the tweets for the stories in the HNR database. Then we grouped the sentiments by considering the subset of high-interest stories with more than 50 tweets and 100 total posts as explained above. Within each rating group (except rating 0 where only one result was found), we calculated the average sentiments and presented them in Table 9. The average values are split up by tweets, retweets and replies. T-, T0, T + and T-com give the values for the negative, neutral, positive and compound sentiment values, respectively. The counts for different types of posts are also given. We observe that among tweets and retweets, the highest T-com score appears for rating 2 stories, while for replies, it occurs for rating 3 stories, with rating 2 stories just slightly behind. The sentiment scores for rating 4 and 5 stories are much lower in all three categories than for stories with lower ratings."",,,,",0.27956789463538967,0.8402741,0.7957388162612915,0.4265232974910394,0.7094231683720317
49,Tables_5731/h42.png," The table shows the results of a study that examined the effects of using agile methods on software development teams. The study found that teams that used agile methods had higher levels of confidence, accessibility, and interactivity than teams that did not use agile methods. However, there was no significant difference between the two groups in terms of privacy and confidentiality.

The results of this study suggest that agile methods can be beneficial for software development teams. Agile methods can help teams to develop software that is more reliable, accessible, and interactive. However, agile methods do not appear to have a significant impact on privacy and confidentiality.

It is important to note that this study was conducted with a small number of teams and the results may not be generalizable to all teams. Additionally, the study did not examine the effects of agile methods on other aspects of software development, such as cost and time to market. Therefore, more research is needed to determine the full effects of agile methods on software development teams.","49,""To rule out any possible confounding effect on the ratings from the actual topics of the news stories, we conducted Latent Dirichlet Allocation (LDA) topic modeling (Blei, Ng, & Jordan, 2003) on the titles of stories rated in three subgroups: 0 & 1; 2 & 3; and 4 & 5. Table 10 reports the main topic keywords uncovered in the posts of the three different rating groups (24 for 0–1 ratings; 20 for 2–3 ratings; and 19 for 4–5 ratings). Ten keywords out of a total of 36 are common among all three rating groups, and 8 keywords belong to two out of the three subgroups. By random chance, the probability that two subsets of 20 words selected randomly from a group of 38 words will have 10 words in common is . To further corroborate this finding, we calculated the similarity between pairs of these three topic groups using SciPy package as (1-cosine distance between topic keyword vectors). In all three pair-wise comparisons, the similarity was 0.46 or higher, suggesting that the topics are not identical but generally similar across rating groups. Of course, the LDA analyses cannot identify any possible confounding effect that influences both the dependent variable and independent variable."",,,,",0.3502475125633601,0.7430725,0.8088498711585999,0.4183760249459357,0.7832846272501445
50,Tables_5731/h43.png," 1. Female, 45 or older, Bachelor's degree or some college degree, Small to medium (fewer than 500 employees), Services (2-digit SIC: 68-78)


2. Male, 45 or older, Graduate degree, Large (500 employees or more), Wholesale trade (2-digit SIC: 50 and 51)


3. Male, 35-44, Bachelor's degree or some college degree, Large (500 employees or more), Services (2-digit SIC: 68-78)


4. Female, 35-44, Graduate degree, Small to medium (fewer than 500 employees), Finance, insurance, and real estate (2-digit SIC: 52-67)


5. Male, 45 or older, Graduate degree, Small to medium (fewer than 500 employees), Services (2-digit SIC: 68-78)


6. Male, 35-44, Graduate degree, Large (500 employees or more), Manufacturing (2-digit SIC: 20-39)


7. Male, 45 or older, Graduate degree, Small to medium (fewer than 500 employees), Finance, insurance, and real estate (2-digit SIC: 52-67)","50,""Finally, we carried out a second topic modeling analysis to control for effects across media types to check how much the topics varied between media types. As Table 11 shows, when comparing topic keywords across a pair of media types, we find that they are closely related, indicating that the stories published by different types of media outlets are generally similar in terms of ratings, indicating their quality. Hence, the topics that are covered across media types are similar and should not affect their ratings."",,,,",0.018455574372203548,0.5147811,0.763617992401123,0.3483709273182957,0.644505724017002
51,Tables_5731/h45.png," The table shows the data for the variables sector, geographic location, methodology, universe of population, sample size, sampling error and data collection period.

The sector is services.
The geographic location is Spain.
The methodology is stratified random sampling.
The universe of population is 3210 firms.
The sample size is 950 firms (36.10% response).
The sampling error is 5%.
The data collection period is June to October 2022.","51,""In order to evaluate the relevancy of the proposed framework with the roles of Human and Machine components using the case study approach (Hevner et al., 2004, Hevner and Storey, 2021), we consider the case of Boston Marathon Bombing 2013 as an example. Numerous misinformation was generated, and later was detected and corrected (Lee et al., 2015). The specific use- case that we discuss focuses on the intergroup prejudice detection system as reported in Dutta et al. (2018). Their ultimate goal was to identify prejudiced messages automatically by examining specific lists of words like “swear words, subjective words and sentiment lexicons” (Cardoso Durier da Silva et al., 2019). Early detection can help prevent the harms created by such messages. In this section, applying the adapted Activity Theory framework as shown in Fig. 2 into this scenario, we mapped the elements as part of the misinformation generator and misinformation mitigator related loops, as shown in Table 1"",,,,",0.26304830941004614,0.81017953,0.7910441756248474,0.1067555153312144,0.8131183907303311
52,Tables_5731/h46.png," From the table, we can see that the early respondents have a higher mean value in terms of size, annual turnover, growth of sales, market share, ROI, ROA, ROS, and ROE. However, the p-values of all the variables are greater than 0.05, which means that there is no significant difference between the early and late respondents in terms of these variables.","52,The four chosen scenarios for validation were: (1) Boston marathon bombing of 2013 with misinformation regarding cancelled cell phone services and air flights; (2) Hurricane Harvey of 2017 with misinformation about immigration status check for people seeking shelter; (3) Oroville Dam evacuation of 2017 with misinformation about the affected areas of flooding; and (4) California wildfires of 2018 with misinformation about its severity through fabricated pictures of other incidents. Details of the four scenarios are shown in Table 2,,,,",0.2510124486495151,0.5801133,0.8076059818267822,0.32951975729945354,0.8195384760958531
53,Tables_5731/h47.png," Correlation Matrix

                    1         2         3        4        5        6        7
1. Social Media Use  1.000    0.333     0.31      0.03     -0.30     0.31      -0.23
2. Collaboration Networks  0.555    1.000     0.40      0.17     -0.31     0.50      0.08
3. Service Innovation  0.535    0.600     1.000     0.47      -0.31     -0.06     0.08
4. Org. Resilience  0.272    0.380     0.650     1.000     0.46      -0.03     -0.24
5. Org. Performance  0.520    0.530     0.510     0.630     1.000     0.18      -0.26
6. Size               0.650    0.500     0.260     0.310     0.500     1.000     -0.41
7. Sector             0.030    0.080     0.080     0.030     -0.040    -0.010     1.000

**. Correlation is significant at the 0.01 level (2-tailed).
*. Correlation is significant at the 0.05 level (2-tailed).","53,""The four aforementioned crisis situations were chosen based on the following criteria. First, these have been reported by other studies for which response and recovery efforts were plagued by misinformation (Bell, 2018, Holdeman, 2018, Nealon, 2017). Second, these situations have gathered widespread coverage on social media and other channels. Table 3 shows a summary of student group assignment to the crisis scenarios."",,,,",0.035119184119602194,0.41192052,0.7313141822814941,0.3541666666666667,0.6037137507882188
54,Tables_5731/h49.png," The table shows the fit indices for four different structural equation models. The first model is the proposed structural model, which includes all of the hypothesized relationships between the constructs. The second model is a restricted model in which the relationship between social media use and service innovation is removed. The third model is a restricted model in which the relationship between service innovation and organizational resilience is removed. The fourth model is a restricted model in which the relationship between organizational resilience and organizational performance is removed.

The fit indices show that the proposed structural model has the best fit to the data, followed by the second model, the third model, and the fourth model. This suggests that the hypothesized relationships between the constructs are supported by the data.

Specifically, the proposed structural model has a chi-square value of 1580.44, a degrees of freedom of 21, a root mean square error of approximation (RMSEA) of 0.07, a comparative fit index (CFI) of 0.97, and an Akaike information criterion (AIC) of 1031.44. The second model has a chi-square value of 1589.47, a degrees of freedom of 22, an RMSEA of 0.07, a CFI of 0.97, and an AIC of 1039.47. The third model has a chi-square value of 1658.65, a degrees of freedom of 23, an RMSEA of 0.07, a CFI of 0.96, and an AIC of 1108.65. The fourth model has a chi-square value of 1595.17, a degrees of freedom of 24, an RMSEA of 0.07, a CFI of 0.96, and an AIC of 1045.17.

The chi-square difference tests show that the proposed structural model is significantly different from the second model (?2 = 9.03, p < 0.05), the third model (?2 = 78.21, p < 0.05), and the fourth model (?2 = 16.73, p < 0.05). This suggests that the hypothesized relationships between the constructs are necessary to explain the data.

The RMSEA values for all of the models are below 0.08, which indicates that the models have a good fit to the data. The CFI values for all of the models are above 0.95, which indicates that the models have a good fit to the data. The AIC values for all of the models are below 1100, which indicates that the models are parsimonious.

Overall, the fit indices show that the proposed structural model has the best fit to the data. This suggests that the hypothesized relationships between the constructs are supported by the data.","54,""For step 1 of validation, we provided the undergraduate student groups with the definition of AT basic components (subject, object, community, tools, labor divisions, rules) as in Table 4."",,,,",0.2827956379082663,0.88593864,0.7751632928848267,0.34150326797385616,0.6922421276898886
55,Tables_5731/h51.png," The table shows the percentage of people in each category. The categories are gender, age, and marital status.

The majority of the people are female (72%), aged between 18 and 25 (56.9%), and single (52%).","55,""For step 2 of validation, we provided the graduate students and professionals with the definition of AT basic components. In addition, we also provided the graduate students with the undergraduate student group’s responses (i.e., the aforementioned common examples of AT components) as presented in Table 5, Table 6, Table 7, Table 8 (based on the activity system of misinformation creation and the activity system of misinformation mitigation). We asked the graduate students and professionals to provide examples from their experience where AT components (from misinformation mitigation activity system) could alleviate misinformation attributed to another AT component (from misinformation generation activity system). In other words, we asked to identify interacting components from the two activity systems. Our goal here was to capture some of the common human-machine interactions in tackling misinformation on social media in the context of humanitarian crises."",,,,",0.3347473815130754,0.6511045,0.8050054311752319,0.024883177932506828,0.7783673469387755
56,Tables_5731/h52.png," The table shows the percentage of people in each category. The categories are gender, age, and marital status.

The majority of the people in the sample are female (85.8%), aged between 26 and 35 (36.7%), and single (35.8%).","56,""For step 2 of validation, we provided the graduate students and professionals with the definition of AT basic components. In addition, we also provided the graduate students with the undergraduate student group’s responses (i.e., the aforementioned common examples of AT components) as presented in Table 5, Table 6, Table 7, Table 8 (based on the activity system of misinformation creation and the activity system of misinformation mitigation). We asked the graduate students and professionals to provide examples from their experience where AT components (from misinformation mitigation activity system) could alleviate misinformation attributed to another AT component (from misinformation generation activity system). In other words, we asked to identify interacting components from the two activity systems. Our goal here was to capture some of the common human-machine interactions in tackling misinformation on social media in the context of humanitarian crises."",,,,",0.3597632643207151,0.66643476,0.8091428279876709,0.03566269214123533,0.8134085213032581
57,Tables_5731/h6.png," | SN | Select adverse impacts | Study |
|-----|------------------------|-------|
| 1 | Carbon Dioxide emission related challenges increase with the use of ICTs (personal computers) | Miyamoto et al. (2001), Muresan (2008) |
| 2 | Toxic disposal after use for old ICTs creates pollution in the land and water environment | Barba-Guitiérrez et al. (2008), Osibanjo and Nnorom (2007) |
| 3 | Electricity consumption increase by ICTs leads to the release of pollutants into the atmosphere. | Asongu et al. (2020), Tamburini et al. (2015) |
| 4 | Emerging ICTs requiring high processing power create higher pollution from high energy consumption | Howson, (2019), Stoll et al. (2019) |
| 5 | ICT components like microelectronics, sensors and actuators often have a short shelf life so land pollution challenges are faced while disposing them | Chakraborty and Gupta (2016), Nizetić et al. (2020) |
| 6 | Digital initiatives across firms and nations will have challenges towards managing disposal of ICTs, energy management and emission control while focusing towards sustainability | Ismagilova (2019), Singh and Sahu (2020) |","57,""Table 2 shows that 60% of the 305 public relations practitioners in the sample were females, while 40% were males. In terms of age, 59% of the respondents were in the age group of 25–30, while 34% were between 31 and 40. As for the education level, the results showed that 82% of the respondents held a bachelor’s degree. In terms of experience, 56% of the respondents had between 3 and 6 years of experience, 38% between 7 and 10 years, and 6% between 11 and 14 years."",,,,",0.21588581069466092,0.3781253,0.7717592120170593,0.4065934065934066,0.7500746258099198
58,Tables_5731/h8.png," The table shows the results of a study that examined the relationships between knowledge management (KM) systems, competitive culture, and quality of care in hospitals. The results show that KM systems and competitive culture are both positively related to quality of care, and that KM systems also mediate the relationship between competitive culture and quality of care. These findings suggest that KM systems and competitive culture are both important factors in improving quality of care in hospitals.

The specific hypotheses tested in the study were:

* H1: KM systems are positively related to quality of care.
* H2: Competitive culture is positively related to quality of care.
* H3: KM systems mediate the relationship between competitive culture and quality of care.
* H4: Competitive culture is positively related to KS.
* H5: KS is positively related to quality of care.

The results of the study support all of these hypotheses. The findings suggest that KM systems and competitive culture are both important factors in improving quality of care in hospitals. KM systems can help to improve quality of care by providing a central repository for information and knowledge, which can be accessed by all members of the healthcare team. Competitive culture can help to improve quality of care by creating an environment in which employees are motivated to excel and to provide the best possible care to patients.

The study's findings have implications for healthcare managers who are looking to improve quality of care in their hospitals. The findings suggest that KM systems and competitive culture are two important factors that healthcare managers should focus on. By investing in KM systems and creating a competitive culture, healthcare managers can help to improve the quality of care provided to patients.","59,""Despite the contribution of the IS/IT industry toward the economic and social welfare of society, IS/IT has often been criticized for having a negative environmental impact. Concerns surrounding the adverse effects both hardware and software have on the environment date back to the Y2K era which led to the massive adoption of enterprise systems (Miyamoto, Harada, & Fujimoto, 2001). These negative impacts include high levels of energy consumption, greenhouse gas emissions and toxic disposal of IS/IT systems (Muregesan, 2008). The disposal of electronic waste (e-waste) while following recycling processes has been widely viewed as not being environmentally friendly, especially the impact of fossil fuels or respiratory inorganics (Barba-Gutiérrez, Adenso-Diaz, & Hopp, 2008). Refurbished ICTs are often used in developing countries where devices tend to have a short life-span and subsequently create environmental damage during disposal (Osibanjo & Nnorom, 2007). Studies have argued that electricity is a major cause of climate change, as many power stations throughout the world still rely on fossil fuels to generate electricity (Asongu et al., 2020, Tamburini et al., 2015). Energy hungry technologies such as applications of blockchain in the form of bitcoin, has been widely criticized for producing over 22–29 million metric tonnes of carbon dioxide emission each year. These figures are comparable to the carbon dioxide production of entire countries such as Jordan and Sri Lanka (Marr, 2018, Stoll et al., 2019). Technologies such as the Internet of Things (IoT), sensors and actuators have a shorter lifespan which leads to increased waste in the environment (Chakraborty and Gupta, 2016, Chakraborty et al., 2014, Nižetić et al., 2020). Digital transformation initiatives such as smart cities have concerns surrounding ICT waste management, energy management and emission management which needs to be addressed for achieving long term sustainability and viability (Ismagilova, Hughes, Dwivedi, & Raman, 2019).From an IS/IT perspective, IoT and Artificial Intelligence (AI) could potentially offer solutions for reducing the impact of technology projects (Salam, 2020). High ICT-driven initiatives need to plan for sustainability by thinking from",0.36787281434375596,0.77533406,0.7826177477836609,0.41990160757790135,0.8183534872795435
59,Tables_5731/T_10.png," The table shows the frequency and percentage of different characteristics of the organizations in the dataset.

The majority of the organizations have less than 10 employees (35.5%), are less than 5 years old (48%), and do not have a public relations department (68%). 

The majority of organizations use social media (64%), with 36% using it for less than a year and 44% using it for more than 6 years. 

The main mission or focus of the organizations is most frequently healthcare (36%), followed by the environment (25%) and youth programs (25%).","60,""After the assessment of the measurement model, we examined the path coefficients and the coefficient of determination (R2) to determine the significance of the relationships proposed in the structural model. Following best practices, we use the SmartPLS® bootstrapping procedure using 5000 subsamples and a parallel process technique (Hair et al., 2017). Results show that both KMS (β = 0.482; t = 10.986) and KS (β = 0.128; t = 2.202) have a positive influence on the quality of care provided to patients (H1, H3). By extension, findings also suggest that the existence of KMS positively influence KS (β = 0.168; t = 2.035) (H2). Similarly, a competitive culture also positively influences the quality of care provided to patients (β = 0.105; t = 2.154) (H5). However, results show no statistically significant relationship between competitive culture and KS (H4). Therefore, H1, H2, H3 and H5 were supported. H4 was not supported. Table 7 presents the main structural model results."",,,,",0.41022345365624,0.6741611,0.8024739623069763,0.24032704262931337,0.8558203091170122
60,Tables_5731/T_11.png," | Article | # Citations |
|---|---|
|Agarwal et al. (2010) | 292 |
| Hess et al. (2016) | 128 |
| Hagberg et al. (2016) | 118 |
| Vial (2019) | 109 |
| Kathan, Matzler, and Veider (2016) | 105 |
| Bogers, Chesbrough, and Moedas (2018) | 97 |
| Karimi and Walter (2015) | 85 |
| Singh and Hess (2017) | 82 |
| Hinnings et al. (2018) | 77 |
| Sebastian et al. (2017) | 76 |
| Trantopoulos, Von Krogh, Wallin, and Woerter (2017) | 76 |","61,""FsQCA requires the calibration of conditions and outcomes. Thus, datasets are transformed into fuzzy-set membership scores based on the theoretical and empirical knowledge of the researchers. All the conditions and the outcomes were measured using a 7-point Likert scale based on the average values of each latent variable (Ragin, 2008). This technique allows us to resize data based on thresholds defined in the literature (Fiss, 2011) into full non-membership, crossover point of maximum ambiguity in membership, and full membership (Ragin, 2008). We transformed variables that were measured on a Likert scale into fuzzy sets (Woodside et al., 2011) by applying the three levels from best practices in fsQCA, establishing the cuts at 0.95, 0.5, and 0.05, considering the range and distribution of each scale (Ragin, 2008, Pappas and Woodside, 2021). FsQCA uncovers how conditions combine into configurations that produce the outcome of interest by exploring how set memberships intersect (Renkema et al., 2016). Table 8 presents the descriptive statistics and calibration of the research conditions and outcomes."",,,,",0.15431550999109003,0.32214594,0.78555828332901,0.18536238160635998,0.7926521164021164
61,Tables_5731/T_12.png," The table shows the number of papers published in each category and the percentage of papers in each category. The total number of papers is 134. The percentage of papers in each category is as follows:
- Conceptual: 6%
- Scale development: 5%
- Qualitative research: 9%
- Netnography: 4%
- Qualitative + Netnography: 4%
- Quantitative by content analysis: 15%
- Quantitative by survey research: 56%
- Total: 100%","62,""After the calibration procedure and following best practices (Greckhamer et al., 2018), we examined the conditions for necessity and sufficiency. The analysis of the necessity indicates the degree of the effect of a condition on achieving a specific result. The necessity analysis shows that there are no necessary conditions for quality of care (consistency levels below the recommended threshold of 0.9 (Ragin, 2008)). Such results are aligned with the literature, suggesting that to generate quality of care, an interplay of several conditions is needed (Desveaux et al., 2019, Hannawa et al., 2021). When the distributions for membership of either the conditions, the outcome, or both, have a skew, the presence (or the absence) of necessary conditions might have flaws (Schneider & Wagemann, 2012). To overcome this problem, and since the set of the KS condition in this study has a skew toward high membership, we followed Schneider and Wagemann’s (2012) suggestion of reporting the relevance of necessity (RoN). The analysis shows that there are no necessary conditions for the outcome (Table 9)."",,,,",0.3415414128495777,0.47682807,0.7858931422233582,0.1064689169142147,0.7196739053296429
62,Tables_5731/T_13.png," Summary of Respondent Characteristics

The survey was conducted among 198 respondents. Slightly more than half of the respondents were female (57.6%), and the majority were aged between 28 and 37 (30.3%). In terms of education, 37.9% of the respondents had a higher secondary education, while 25.8% had a postgraduate degree. The majority of the respondents were employed in the private sector (40.4%), while 17.7% were self-employed. In terms of place of residence, 61.1% of the respondents lived in urban areas.","63,""The sufficiency analysis indicates the degree of relation between the configuration of conditions as an explanation of a specific result or outcome (Fiss, Sharapov, & Conqvist, 2013). We adopted the 0.8 threshold for the sufficiency analysis, which is high enough to conclude the level of care is sufficient for the outcome (in this case, quality of care) (Ragin, 2006). The analysis identified limited diversity (no rows with no cases - truth table in Appendix A displaying symmetric consistency and proportional reduction in inconsistency analysis), resulting from no difference between the number of manifested versus hypothetical configurations (Pappas & Woodside, 2021). Such evidence reflects competitive pressures from the context that are likely to discourage undesirable configurations (Miller, 1986). Considering the setting and the outcome of this study, this result is more than comprehensible, and is desirable. FsQCA delivers three solutions. The core conditions are the ones that are both present in the intermediate and parsimonious solutions. In this study, all conditions are core conditions. Table 10 reports the intermediate solution for quality of care as recommended by best practices (Greckhamer et al., 2018, Ragin, 2008). The symbol “∼” prior to the conditions’ name represents its absence."",,,,",0.4139443874708161,0.67112356,0.7885742783546448,0.12865711034337315,0.7886345598845598
63,Tables_5731/T_14.png,Error: Invalid response from model,"64,""The exploration of successive product generations within marketing and economics literature began with a primary focus on non-digital goods. Initial research delved into the cannibalization effect, emphasizing the negative impact of new product introductions on legacy models. Stokey (1979) identified a detrimental influence on the sales of previous versions of physical products, leading to subsequent studies revealing intricate pricing and positioning strategies for managing generational transitions. However, the realm of digital goods, marked by unique facets, has received limited scholarly attention. Feature intensity, characterized by the breadth and complexity of product features (Rathore and Ilavarasan, 2020, Sheng and Teo, 2012), has witnessed exponential growth with each new generation of digital devices. For instance, contemporary smartwatches now incorporate thousands of apps, biometric tracking capabilities, and a myriad of productivity features that were unimaginable even five years ago (Joung & Kim, 2023). Despite this surge in information intensity, research has yet to directly examine the impacts on consumer decisions and sales.The accelerated cadence at which new product generations are introduced, especially in categories like smartphones and laptops, poses challenges that warrant deeper investigation. This is particularly relevant for information-laden digital devices where capability layers expand exponentially each year (X. Fu et al., 2020, Fu et al., 2020). Leading brands adopt agile development approaches, rapidly acquiring user input to fulfill feature requests (Santos et al., 2022). However, variations across brands and products in terms of agility and responsiveness introduce uncertainty (Hollebeek et al., 2021). Unpacking these variations represents a gap needing empirical examination. Hence, key digital product attributes like exponentially growing features and accelerated release cycles require greater scholarly attention (Rauschnabel, 2021). As each new generation introduction intensifies complexity and change, it remains unclear how these facets affect navigation and purchase choices. For instance, despite exponential growth in capability layers, no study has directly investigated how informatio",0.0,0.55941445,0.7859224081039429,0.0,0.8128571428571428
64,Tables_5731/T_15.png," Research questions for climate-neutral digital economy.

**Information Research Topic	Suggested Research Questions**
Industry 4.0 to Climate 4.0	
- How can IT enable inter-organisational eco-innovation in Climate 4.0?
- How to ensure effective knowledge transfer of Climate 4.0 technology to developing countries?

Climate Fintech	
- What are the IT affordances/perceptions/innovation mechanisms of climate Fintech applications?
- How can AI augment decision makers’ ability to identify and avoid greenwashing in investment or financing?

Clean tech	
- What are the design principles for an energy-efficient information system?
- What constitute climate-conscious digital information practices?
- How can digital businesses foster climate-conscious IT behaviours in a way that enhances their performance?","65,""The descriptive statistics for variables used in the study are given in Table 3 below. Additionally, we included dummy variables to indicate type of wearable band (1 for fitness band and 0 for smartwatch), type of connectivity (1 for LTE and 0 for no LTE), type of operating system (1 for Android and 0 for WearOS). We considered Android and WearOS as these two operating systems were the most commonly occurring in the dataset. We also checked for correlation between the independent variables and found no significant multicollinearity among the variables."",,,,",0.14537728514140696,0.63717955,0.7932837605476379,0.40809968847352024,0.7435843571633045
65,Tables_5731/T_16.png," | Information Research Topic | Suggested Research Questions |
|---|---|
| Digitally enabled agile government | - How to identify action-worthy insights in climate analytics?
 - How can governments institutionalize grassroots IT innovations to improve climate agility? |
| Open government for climate action | - How can governments track and visualize climate performance for public disclosure?
 - How does publishing climate enforcement and compliance data online affect business/consumption decisions/actions? |","66,""While there are various motivations and triggers to business model innovation, firms often use technologies as key means of achieving business model innovation (Muhic and Bengtsson, 2019). AI can be one of the technologies that underpins business model innovation. A rich stream of research has underpinned existing knowledge of how computing (including machine learning and expert systems) can support human decisions in organizational contexts (see for example Bonczek et al., 1979). There is an equally rich stream of research associated with successful implementation of AI – at least at a technical level (Maragno et al., 2023, Merhi, 2023, Uren and Edwards, 2023).While AI technologies are generally globally available, uptake is non-uniform and the touted exemplars of business model transformation using AI seem to be concentrated in the same few companies, being large multinational companies such as Amazon and IKEA. Furthermore, the current wave of adoption has seen organizations focused primarily on utilizing AI for improving existing business models rather than creating new ones (Deloitte, 2020).The Deloitte (2020) survey identified a set of IS and non-IS capabilities associated with success in AI. Three IS capabilities were identified, the first of these is data. Success at AI is not just about volumes of data, it is about having the right types of data and adequately supported digital processes (Reim et al., 2020). The second IS capability is digital agility, as rapid changes in business models require the ability to scale up and down as well as quickly modify application landscapes, with that adaptability supported and not inhibited by information systems (Grover, 2022). The third IS capability is that of the skills of the technology team themselves (Wamba-Taguimdje et al., 2020). Multiple elements must be in place for successful implementation of AI in an organization including data management as well as having the right domain knowledge and relevant technologies. The Deloitte survey also suggested a critical capability in the non-IS parts of the organization, namely a “digital culture” that enhances organizational ability to pursue change initiatives in parallel with delivering the existing business model.There is limit",0.10332896117181417,0.6565015,0.7860124707221985,0.009265860244775643,0.7742641925121152
66,Tables_5731/T_17.png,Error: Invalid response from model,"67,""The data structure has three aggregate dimensions, each of which are supported by two or more 2nd order themes. The first aggregated dimension is internal behaviors, which reflects the behaviors of the leadership and staff of organizations undergoing business model transformation enabled by AI. This aggregated dimension includes three 2nd order themes: AI-sensitive risk tolerance, proactive leadership, and tech-sensitive innovation culture. The second aggregated dimension is internal capabilities, which refers to the capabilities associated with an organization’s ability to adapt the firm’s resource base (Teece, 2007). This aggregated dimension includes four 2nd order themes: ability to run & change, AI oriented data / IS readiness, market / customer awareness and strategic process strength. The final aggregated dimension is that of external conditions and reflects the fact that organizations do not operate in isolation from competitors and the broader business environment (including regulation and changing social norms). Two 2nd order themes are tied to this aggregated dimension: industry dynamism and opportunity / threat drivers.Table 3 summarizes the resulting theoretical constructs, built through the meshing of data (from the participant comments, reflecting the nuances of the sensitizing concepts in practice) with theory (identified in the sensitizing concepts described in the research model). These theoretical constructs will hereafter be referred to as factors."",,,,",0.03674097834046072,0.6405156,0.7936027646064758,9.377293136009932e-19,0.7878571428571428
67,Tables_5731/T_18.png," The table shows the demand and supply of tourism organisations and destinations. The demand side includes information finding, building itineraries, searching for specialised services, eliminating choice, dynamic itineraries, and content sharing. The supply side includes concierge services for consumers, marketing content text/pictures generation, menu engineering and recipe development, fact-finding, identification of resources, and social media and organisations' own web pages.","68,""The applicability check was structured around obtaining feedback from three specific cohorts: executives (senior practitioners – typically C-suite or a direct report thereof - that are involved in business model transformation initiatives), advisors (senior management consultant professionals - typically at the partner level - that support executives in their business model transformation initiatives) and practice-oriented researchers (many of which have 10 + years industry experience). Some of the participants of study 1 also participated in study 2 in the “executive cohort”. These three cohorts were selected as each cohort would bring a different and complimentary perspective to the question of applicability of the findings in study 1. In total, 14 participants were engaged in the applicability check process, as outlined in Table 5.Each focus group was conducted by one or more members of the author group. Each member of the author group participated in at least two sessions, and the lead author participated in all sessions, including the initial pilot session. The sessions were approximately one hour in duration and conducted via Zoom with Zoom recording functionality enabled."",,,,",0.20981145888014824,0.8573674,0.8016745448112488,0.05907838383248618,0.7594879194879197
68,Tables_5731/T_19.png," The table summarizes the methods used in co-citation analysis studies.

The first column lists the author of the study. The second column lists the co-citation methods used in the study. The third column lists the topic of the study. The fourth column lists the data used in the study. The fifth column lists the methods used in the study. The sixth column lists the factor used in the study. The seventh column lists the cluster used in the study. The eighth column lists the MDS used in the study.

The studies are listed in chronological order. The first study, by Culnan (1987), used author co-citation analysis to study the field of management information systems. The second study, by Pilkington and Liston-Heyes (1999), used author co-citation analysis to study the field of production and management. The third study, by Andrews (2003), used author co-citation analysis to study the field of medical informatics. The fourth study, by Liu (2005), used journal co-citation analysis to study the field of urban studies. The fifth study, by Pilkington and Meredith (2009), used document co-citation analysis to study the field of production and management. The sixth study, by Hsiao and Yang (2011), used document co-citation analysis to study the field of technology acceptance model. The seventh study, by Shiau and Dwivedi (2012), used document co-citation analysis to study the field of electronic commerce. The eighth study, by Shiau et al. (2015), used document co-citation analysis to study the field of supply chain management.","69,""There are four specific results of the applicability check. First, the participants were strongly supportive of the research need. The words of participant P4.1, an advisor, are illustrative of this support: “I think someone needs to tackle this, first of all, and I think you're starting to do that.” Participant P5.2, a practice-oriented researcher, also commented positively about the appropriateness of the selected theoretical lens of dynamic capabilities: “I feel like [the model] is aligned well to the dynamic capabilities theory.”Second, there was a strong sense of resonance with the empirically derived model of factors outlined in Fig. 4. Participant 2.2, an executive, confirmed that, “This model reflects the way I think about the problem as I've gone through various roles.” Advisors similarly thought that the model resonated with their lived experience across multiple situations: participant P3.1 noted: “this model actually does resonate very well with me.” Furthermore, there was a strong sense of support for the six factors introduced/refined/deleted between the literature-based model of factors and the empirically derived model of factors. Nearly all participants commented on the need for proactive leadership rather than the more passive concept of top management support. Participant P2.2's comment was representative of the collective perspective of the executive and other cohorts: “Certainly the proactive leadership part. I think if it wasn't in [the literature based model], and it is there now [in the empirically supported model], I mean, I think that's a very vital part.” The participants spoke about the criticality of the environmental context, often clumping together the concepts of industry dynamism and opportunity/threat drivers. Participant P4.1’s view was illustrative when talking about the lack of change in one industry sector: “I think there's a couple of things. One is the environmental context… the industry dynamism, and the threats - they haven't been there, or they haven't been perceived as being real. There's no real burning platform, no one's hair is on fire to say, ‘Look, I need to do something about this’. And that permeates through to the organizational precursor, and we talk about proactive leade",0.4572355345007212,0.73369426,0.7845388054847717,0.3239953947194488,0.876474571312628
69,Tables_5731/T_20.png," The table shows the number of papers published in each journal. The top 5 journals are:

1. Computers in human behavior (488)
2. Cyberpsychology, behavior and social networking (151)
3. New media & society (64)
4. Information & communication (62)
5. Computers & education (47)","70,""The empirically derived model of factors has been updated to reflect the findings of the applicability check (Study 2) and is shown in Fig. 5.There are two specific refinements between the empirically supported model of factors (Fig. 4) and the refined model of factors (Fig. 5). First, the definition of industry dynamism has been refined to reflect both the rate of change of AI relative to that industry as well as the receptivity of industry participants to change in that industry. Second, the factor of strategic process strength has been more properly described as strategic process discipline."",,,,",0.22541454642686162,0.6946249,0.8145796656608582,0.12828548477940752,0.67067205281491
70,Tables_5731/T_21.png," The table shows the path through the variables and the polarity of the path. The path is from the driver variables to the acceptability. The polarity of the path is positive for the path from awareness to acceptability and negative for the path from difficulty & complexity and cost to acceptability. This means that the path from awareness to acceptability is a positive path, while the path from difficulty & complexity and cost to acceptability is a negative path.","71,""We tested our conceptual framework and differences between monetization strategy (limiting features vs. selling virtual items) by using a MASEM approach (Jeyaraj & Dwivedi, 2020). Following the procedure of Viswesvaran and Ones (1995), we compiled separate correlation matrices for both monetization strategies (see Table 4, Table 5). We managed to include all the variables from our conceptual framework in these matrices. The matrices with the harmonic means (nfeatures = 1069; nitems = 1910) were used as inputs in SPSS AMOS 28. Based on the past research, harmonic mean was used to represent the sample size (Mishra et al., 2023, Yu et al., 2020). Using the harmonic mean produces more conservative results when compared with using the arithmetical mean (Viswesvaran & Ones, 1995). As per Viswesvaran and Ones (1995) and Yu et al. (2020), we used the maximum likelihood estimation method. The moderating effects of the monetization strategies were compared using multigroup analysis. Following Iyer et al. (2020), we set error variances to zero."",,,,",0.3070344484194522,0.5148339,0.79880291223526,0.1937857421491139,0.8456511742226028
71,Tables_5731/T_22.png," The diagram shows the steps involved in a systematic literature review. The process starts with the identification of relevant studies. This can be done by searching electronic databases, library catalogs, and other sources. The initial pool of studies is then screened for relevance based on the inclusion and exclusion criteria. The full text of the selected studies is retrieved and assessed for quality. The data from the included studies is then extracted and analyzed. The final step is to interpret the findings and draw conclusions. This diagram provides a clear and concise overview of the systematic literature review process.","72,""The proposed model was tested using a MASEM approach. We performed a multigroup analysis to examine parameter estimate differences between the monetization strategies. The results (see Table 6 and Fig. 2) suggest that the formation of WTP for freemium services differs in several ways according to the monetization strategy. As the research model is saturated, both models display a perfect fit (χ2 = 0; d.f. = 0; SRMR =.000; RMSEA =.000; CFI = 1.000; GFI = 1.000). For the “limited features” monetization strategy, the model explained 44.2% of the variance in trust and 50.5 % of the variance in WTP. For the “virtual items” monetization strategy, the model explained 20.9 % of the variance in trust and 40.0 % of the variance in WTP.Overall, the results of this meta-analysis highlight the differential roles of perceived value and trust in influencing WTP in the monetization strategies as all the paths differ significantly (see Table 6). Consequently, our findings confirm the moderating effect of the monetization strategy. In the context of virtual items, trust had a significant impact on WTP (β = .269, p < .05), whereas its impact for the “limited features” monetization strategy was non-significant, confirming H1. Consequently, we argue that trust mediates the effects of perceived value on WTP in the case of purchasing virtual items but does not have a similar role in the “limited features” monetization strategy. Thus, we highlight the importance of the direct effects of perceived value on WTP for the “limited features” monetization strategy, instead of mediation through trust.Our results underline the strong impact of functional value on WTP for the “limited features” monetization strategy (β = .673, p < .05). This path was non-significant for the “virtual items” monetization strategy. Therefore, H2 was confirmed. The impact of hedonic value on WTP was negative for the “limited features” monetization strategy (β = −.629, p < .05) and positive for the “virtual items” monetization strategy (β = .136, p < .05). Thus, H3 was confirmed. Interestingly, the impact of social value was stronger for the “limited features” monetization strategy (β = .562, p < .05) than it was for the “virtual items” monetization strategy (β = .122, p < .05).",0.48076556435029777,0.7537259,0.7899210453033447,0.035537183477883774,0.8257196787499819
72,Tables_5731/T_23.png," The table shows the number of documents (No. doc), Journal Citation Reports Impact Factor (JCR-IF) in 2017, and quartile (quartile) of the journals in which the author has published. The author has published 38 documents in 14 journals. The average JCR-IF of the journals is 2017. The author's quartile is Q1.","73,""We conducted 15 one-on-one in-depth semi-structured interviews with consumers with rich prior experience in freemium services. The interviews followed a semi-structured guide designed according to the main themes of Study 1. More specifically, the interviewees were asked to describe their recent experiences with freemium services and answer questions related to the perceived value of these services, perceptions regarding the service providers, and WTP for freemium services. The interview guide comprised three sections. The first part initiated with general inquiries, such as which freemium service interviewees utilized. The subsequent part involved questioning interviewees about the factors that lead them to pay for freemium services, aiming to capture their experiences with the service and discern the dimensions of perceived value. In the final section, interviewees were prompted to consider the significance of trust in their relationship with the service provider.We collected data for the two monetization strategies identified in Study 1—eight interviewees focused on services with limited features and seven interviewees focused on services relying on a “virtual items” selling strategy. We used a purposeful criterion sampling method to gain knowledge about the research topic (Patton, 2002, pp. 40–46). The interviews were conducted in Finland during October 2023 in quiet locations. The interviews were audio-recorded, and transcribed into text files, and translated from Finnish to English. The profile of our sample is presented in Table 7. The last interviews did not offer new insights, indicating data saturation (Namey et al., 2016)."",,,,",0.36792756119303516,0.75680554,0.7996450066566467,0.013925115835075557,0.8412854030501089
73,Tables_5731/T_24.png,Error: Invalid response from model,"74,""In information systems literature, the terms interpretability and explainability have multiple definitions are sometimes used interchangeably. We define interpretability of an AI-system as a characteristic indicating whether an individual is able to understand the full decision-making process of an AI (Guidotti et al., 2018, Rudin, 2019). Table 1 presents different definitions in literature for explainability and compares them with interpreterability.As shown in Table 1, the literature reveals a lack of consensus regarding the definitions of explainability. To gain insight into the lack of consensus, it would be worthwhile to consider the definition of XAI provided by Gunning et al., 2019 defining XAI as a suite of AI techniques that enables human users to understand, and effectively manage the emerging generation of artificially intelligent partners (Gunning et al., 2019). While this definition incorporates the essential concept of understanding, it fails to account for other significant purposes that drive the demand for XAI models. We will explore these aspects further in the subsequent discussion, highlighting them as evidence of the definition’s incompleteness.Definition of explanation is essential to understanding XAI. According to the Cambridge Dictionary for English, an explanation refers to """"the details or reasons that someone gives to make something clear or easy to understand"""". In the context of AI, this can be restated as “the details or reasons that an AI system provides to clarify or simplify its outcome."""" However, in this definition, two ambiguities emerge. First, the reasons used for explanation are entirely contingent on the audience to whom they are presented. Second, whether the explanation effectively renders the concept clear or easy to understand also relies entirely on the audience. The definition needs to be reformulated to account for the audience of a given XAI. A revised definition presented by (Arrieta et al., 2020) defines explainability as follows:Given a certain audience, explainability refers to the details and reasons a model gives to make its functioning clear or easy to understand."""".(Arrieta et al., 2020)’s perspective on explainability aligns with the definition given by (Herm et al.,",0.005503789531740081,0.6318745,0.7846533060073853,8.293007897472478e-30,0.8414285714285714
74,Tables_5731/T_25.png, Summary statistics of variables used in the analysis.,"75,""Table 3 provides a summary of selected research on how AI Capability can affect firm performance. The table highlights two promising areas for expanding upon existing research. First, the current body of literature focuses on functional competencies, specifically those related to AI infrastructure and associated management capabilities. Simultaneously, AI infrastructure is increasingly becoming a standardized commodity, and AI applications that offer differentiation tend to depreciate rapidly due to shifts in the market. Realizing the benefits of AI under these conditions requires continuous efforts to construct and maintain a portfolio of AI applications. Prior research highlights the significance of updating AI applications portfolio as a dynamic capability for adapting to evolving market conditions and enhancing firm performance. Drawing from this discussion, we propose that a firm's ability to refresh its portfolio of AI applications stands as a critical driver of its overall performance"",,,,",0.16230834627952767,0.7959451,0.826399564743042,3.1008747317475796e-08,0.8154761904761905
75,Tables_5731/T_26.png," The table shows the number of users and messages in each organizational unit, as well as the final number of users and messages after applying the filter. The filter removes all rows where the number of messages is less than 1,000.

The final number of users is 3,930 and the final number of messages is 33,292.","76,""All measuring items were adapted from prior established studies as a benchmark to define latent variables in the research model (Westland, 2015). Appendix item 1 contains the questions, the corresponding variables they represent, and the source supporting the operationalization of the variable. These latent variables include AAPUC, process agility and firm performance. To measure AAPUC, we used established literature that describes how companies update their resource portfolios through three key actions: (a) acquiring resources, (b) developing resources internally, and (c) discontinuing legacy resources (Sirmon et al., 2011, Sirmon et al., 2007). In the context of IT resources, it is argued that certain companies excel in obtaining valuable IT applications from suppliers (Tanriverdi, 2006), while their abilities for in-house IT application development or discontinuation of legacy IT applications may be limited (Lee and Xia, 2010, van Oosterhout et al., 2006). Consequently, our operationalization of AI applications portfolio update capability employs formative items that collectively define the construct, departing from reflective items used when each indicator is an """"imperfect reflection of the construct"""" (MacKenzie et al., 2011). In essence, the three competences of acquiring, developing and discontinuing AI applications comprehensively characterize AAPUC. Thus, our measurement as presented in Appendix A involves formative items that relate to those competences in relation to AI applications. We also developed measures for explainability of AI following the three-stage process posited by (Boateng et al., 2018), presented in Table 5."",,,,",0.2968719213050608,0.65911454,0.801902711391449,0.02372126245955532,0.8439625850340136
76,Tables_5731/T_27.png," The table shows the cumulative number of new messages and the cumulative total number of messages for each period. It also shows the organizational unit that completed the implementation process.

In the first period, from 10/1/2014 to 12/31/2014, there were 4,774 new messages, and the cumulative total number of messages was also 4,774. The organizational unit that completed the implementation process was N/A.

In the second period, from 1/1/2015 to 5/31/2015, there were 3,923 new messages, and the cumulative total number of messages was 8,697. The organizational unit that completed the implementation process was Network.

In the third period, from 10/1/2015 to 9/30/2016, there were 6,096 new messages, and the cumulative total number of messages was 14,793. The organizational unit that completed the implementation process was Delivery.

In the fourth period, from 10/1/2016 to 12/31/2016, there were 8,431 new messages, and the cumulative total number of messages was 23,224. The organizational unit that completed the implementation process was HR.

In the fifth period, from 1/1/2017 to 5/31/2017, there were 15,324 new messages, and the cumulative total number of messages was 38,548. The organizational unit that completed the implementation process was R&D, Services.

In the sixth period, from 10/1/2017 to 9/7/2017, there were 7,935 new messages, and the cumulative total number of messages was 46,483. The organizational unit that completed the implementation process was Finance.","77,""To examine the measurement model, convergent and discriminant validities were tested. Although our questionnaire was constructed utilizing preexisting instruments in the literature as well as inputs and pre-test from experts, we evaluated our instrument as a new measure that requires checking of unidimensionality. Unidimensionality tests whether all items measured in a metric contribute to measurement of the construct under study (Gerbing & Anderson, 1988). Since PLS does not measure for unidimensionality, we used SPSS to carry out a scree test (B. D’agostino Sr and Russell, 2014) to determine the number of latent constructs on the dataset. Then we used smartPLS to examine the questionnaire’s items for loading, weights, validity, and reliability. Table 6 presents the results of the factor analysis of our constructs.We assessed construct-to-item loadings for our reflective constructs to see if item loadings were sufficient to include an item under a specific construct. Only item loadings that exceeded 0.70 were retained (Hair et al., 2011), which is consistent with the results of the scree test before and after the loading test. Next, we measured composite reliability for each reflective construct to assess internal consistency (Raykov, 1998). In early research development, reliability scores above 0.70 are acceptable, whereas 0.80 is recommended for established constructs (Nunnally, 1978, Werts et al., 1978). Table 6 shows our constructs’ validity, reliability, and correlation matrix. Each construct’s dependability exceeds 0.70. In Table 6 the square root of AVE is bigger than off-diagonal correlations. To assess the validity of constructs, we compared the square root of AVE with correlation between each pair of constructs (Fornell & Larcker, 1981). Table 6 shows that for each construct, the square root of AVE is greater than their off-diagonal correlation of that construct. In order to avoid product unstable path estimates, we ran several Variance Inflation Factors tests that all returned a maximum of 2.1 while the threshold of concerns is 10 for reflective constructs (MacKenzie et al., 2011). All scales showed good discriminant validity, supporting the XAI scales' psychometric features."",,,,",0.3613381938713972,0.88882947,0.7685189843177795,0.3087294235285285,0.7835211167800455
77,Tables_5731/T_28.png," The table shows the number of messages sent by each department, the percentage of messages sent by each department, the number of users in each department, the percentage of users in each department, the average number of messages sent per user in each department, and the rank of each department by average number of messages sent per user.

The top 3 departments by average number of messages sent per user are:

1. Human Resources (18.60)
2. Delivery (7.44)
3. Research and Development (R&D) (7.85)

The bottom 3 departments by average number of messages sent per user are:

1. Management & Corporate (7.45)
2. Network (6.62)
3. Finance (6.33)","78,""To test the structural model, we examined the path coefficients (β) to demonstrate the strengths of the relationships involved in our hypotheses. R2 shows the extent to which the dependent variable’s variance can be predicted by each independent variable. In this study, we used both path coefficients as well as R2 to explain how well the model is performing. The hypotheses were tested by estimating the research model outlined in Fig. 1. The results of our analysis appear in Table 7."",,,,",0.29986780390853784,0.6852497,0.8021363019943237,0.4444444444444444,0.7923713098946743
78,Tables_5731/T_29.png," The table shows the results of a Heckman analysis. The dependent variable in the first stage is the propensity to engage in digital collaboration (DV = CIC), and the dependent variable in the second stage is the level of digital collaboration capability (DV = DCC). The endogenous factors are digital collaboration capability, the inverse Mills ratio, and the antecedent of DCC. The Heckman analysis results show that the endogeneity of digital collaboration capability is a problem, as the coefficient on the inverse Mills ratio is significant in the second stage regression. This suggests that there is a selection bias in the OLS regression, and that the Heckman analysis results are more reliable. The Heckman analysis results show that digital collaboration capability has a positive and significant effect on collaborative innovation capability. This suggests that firms that are able to collaborate digitally are more likely to be innovative.","79,""Our scale development process was adopted from (Boateng et al., 2018). We used four measures for explainability of artificial intelligence applications within firms, as follows: (1) confidence to stability and reliability, (2) accessibility, (3) interactivity, (4) privacy and confidentiality. We investigated the variations in the performance outcomes of AAPUC as firms focused on different characteristics of XAI. In order to accomplish this, we applied Hayes (2013) regression-based method to test conditional effects (Hayes, 2013). This approach enables us to investigate how the impact of AAPUC varies depending on the different focuses of firms on characteristics of XAI. It also allows us to generate confidence intervals to assess the effects of AAPUC across different XAI characteristics. We estimated two models using the PROCESS macro for SPSS with 1000 bootstrap samples (Preacher & Hayes, 2008). The initial model examines the impact of AAPUC on firm performance without considering agility as the mediator in the analysis. The second model assesses the effects of AAPUC while controlling for the influence of agility.The findings presented in Table 5 indicate that AAPUC has a significantly positive impact on the performance of firms focusing on accessibility (β: 0.21, ρ = 0.03) and interactivity (β: 0.25, ρ = 0.01) of AI applications and not confidence or privacy and confidentiality, but only when agility is not considered in the analysis. However, when accounting for the influence of agility, the effects of AAPUC are not statistically significant, as presented in Table 8. This underscores the importance of identifying and considering mediators like agility and other variables that may influence the relationship between AAPUC and performance. The additional analysis results in Table 8 align with our discussion on the importance of agility as a mediator for the relationship between AAPUC and performance. The analysis also highlights the more significant role of accessibility and interactivity in the direct effect of AAPUC on performance."",,,,",0.5273525912080979,0.94222677,0.8207967877388,0.19543311091226748,0.8478210486831178
79,Tables_5731/T_30.png," The table shows the results of a reliability analysis. The AVE values are all above 0.5, which is considered to be acceptable. The CR values are all above 0.7, which is also considered to be acceptable. The Cronbach's alpha values are all above 0.7, which is considered to be acceptable. Therefore, the reliability of the constructs is good.","80,""The study involved purposive sampling recommended by (Palinkas et al., 2015). The sample group was seven (7) IT managers at a high administrative level within their organizations (c-level executives) who have experience with updating their portfolio of AI applications and have adopted or plan to adopt XAI. The sample group focused on individuals with knowledge of XAI. The rationale for this sampling decision is that individuals need to demonstrate a knowledge of XAI to provide informed responses to the qualitative survey. The overlap between managerial practitioners with knowledge of XAI and a desire to adopt the technology is sizeable, the 7 individuals we interviewed happened to fit both criteria. However, we acknowledge that there are individuals that are aware of XAI but have no plans to adopt it within their organizations. We have acknowledged this shortcoming in the limitations of this study in Section 6.3. The seven participants were not involved in the previous quantitative survey. Table 9 presents the demographics of participants.We facilitated in-depth discussions in a focus group to explore the contextual factors and subjective experiences that may have influenced the observed quantitative relationships from the previous survey. Through open-ended questions and interactive dialogue, we delved into the intricacies of updating portfolio of AI applications and XAI seeking to evaluate our findings in Study 1. The online meeting was recorded and transcribed through zoom. The transcripts were analyzed based on their potential insights about hypotheses in Study 1."",,,,",0.31976138169238216,0.8855452,0.8123589158058167,0.022932555128241803,0.8224554659899489
80,Tables_5731/T_9.png," The table shows the demographic breakdown of the survey respondents.

The majority of respondents were female (60%), aged between 25 and 30 years (59%), and had a bachelor's degree (82%). Most respondents had 3-6 years of work experience (56%).","81,""he proposed research model was tested in a quantitative study with Spanish service companies. First, a preliminary structured questionnaire was developed based on existing literature. Several company directors, academics and consultants were then interviewed to check the comprehensibility of the items and to ensure appropriate content and wording. Based on suggestions from the experts consulted in the pretest, the questionnaire was revised to incorporate the recommended changes and obtain the final questionnaire, which examined how organizations handle these strategic issues.General managers were selected as strategic informants because they lead departmental strategy design, and plan and direct the organization’s future actions (Westphal & Fredickson, 2001). Drawing on information from the different departments, these CEOs steer strategic activity to enhance performance (Baer & Frese, 2002).Using the Iberian Balance Sheet Analysis Systems (SABI) database and information from Spain’s Ministry of Science and Research, the Andalusian regional government, and the Ministry of Economy, Innovation and Science, an accurate list of Spanish tourism firms was compiled to identify the study population. The SABI database has economic and financial information on more than 2.6 million companies (Spain and Portugal), including balance sheets and qualitative data. It is updated daily, and the information is obtained from various official sources.Our study used stratified random sampling of 950 companies, establishing equal probability that any firm could be selected at any step during sampling. The companies were contacted by phone and e-mail to explain the study’s purpose and offer them the opportunity to receive the results once the study was finished. Analyzing the results in aggregate and promising confidentiality of responses increased the response rate (36.10%, 343 valid responses (see Table 4)) and reduced the possibility of desirability bias."",,,,",0.3657207803667323,0.5611318,0.7983810901641846,0.001108058134059605,0.8281200281200282
