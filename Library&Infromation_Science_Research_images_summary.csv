index,Image Name,AI generated Summary,Author Summary,Cosine_Similarity Score,ROUGE-WE,BertScore,BLEU Score,METEOR Score
0,images/F1.png, The taxonomy of graphic elements.,"Numerical labels refer to the section headings below which describe how the various membership values are assigned. Note that joint membership states are, in principle, possible but are not allowed in the approach chosen",10.60%,79.12%,84.54%,0.00%,61.79%
1,images/F10.png," The diagram shows the steps taken by the system to suggest keywords and subject areas for a resource to be cataloged. The process starts with the cataloger providing the system with the resource to be cataloged. The system then extracts the title, author, and abstract of the resource. It also identifies the keywords and subject areas that are relevant to the resource. The system then compares the extracted information with the information in its database of previously cataloged resources. It then suggests keywords and subject areas for the resource based on the comparison results. Finally, the cataloger reviews the system's suggestions and makes any necessary changes.","The present processing architecture can be separated in three main components: (I) a preprocessing and segmentation stage (see sections 3.1 to 3.4), (II) a node and edge classification stage (sections 3.5 to 3.7), and (III) a text extraction and recognition stage (sections 3.8 and 3.9).In addition to the processing steps, the rounded vertical boxes represent the data structures aggregating the output of the connector identification (box ”C”), the edge classification (box ”E”, which also contains the edge-node relationships) and the node classification (box ”C”). Dashed lines represent a delayed transfer of data: Either the passage of the graphic component of the flowchart for the detection of the lines connections between nodes, or of the text layer used to extract individual text regions prior to OCR.",55.34%,66.27%,81.50%,44.16%,80.91%
2,images/F11.png," The PRISMA flow diagram shows the process of identifying, screening, and selecting studies for inclusion in the review. A total of 462 articles were identified through database searching, and an additional 120 articles were identified through Google Scholar. After removing duplicates, 550 records were screened, and 350 were removed for various reasons. The remaining 200 records were assessed for eligibility, and 95 were excluded, leaving 105 records to be included in the synthesis.","In the ""Dyspnea"" clinical guidance tree, the question ""Have any fever symptom?"" is directly used as a condition. This approach is not only intuitive for doctors and patients to understand, but it also enables the LLM model to perform reasoning on the CGT.",20.24%,72.22%,82.34%,38.81%,63.36%
3,images/F12.png," In the behavioral domain, the focus is on basic skills required for manipulation and search on the Internet. This includes the ability to control search engines and their features, as well as an awareness of one's own searching orientation and what to do in the information searching process.

In the procedural domain, the focus is on content-general searching approaches and overcoming problems that occur during the search process. This includes the ability to apply trial and error techniques, solve problems, and monitor the search process.

In the metacognitive domain, the focus is on monitoring the search process, identifying key information, and interpreting and evaluating information obtained from the Internet. This includes the ability to think purposefully, select main ideas, and evaluate information sources.","The process for the algorithm starts with the thermal simulation conducted on the patient-specifc model with initial parameters. This generates a computed image that gets aligned, or registered, with the IR image at the corresponding view. The ROI is extracted for the given views and are analyzed by the IRI detection algorithm. If there is no match, a new parameter is generated for thermal simulation and the cycle starts all over again. If there is a match, then the algorithm ends, and the outcome is given. Any red arrow indicates the initial inputs needed for the algorithm to start. Te main detection process can be followed using the blue arrows. Te fowchart legend on the lef shows this distinction between paths as well as the distinction and signifcance of the shapes. A rhombus indicates the typing to be a data. A diamond indicates a decision process. A rectangle indicates a computational or algorithm process. And a rounded rectangle indicates the outcome of the algorithm.",53.64%,91.80%,81.66%,37.87%,80.35%
4,images/F14.png," The table shows the degrees held by literary critics and where they were obtained. The data is broken down by region (North America, Europe, and Other) and degree type (Bachelor's, Master's, PhD, and Other).

For Bachelor's degrees, 59.6% of critics in North America hold a degree, 20.5% in Europe, and 4.7% in Other. For Master's degrees, 62.6% of critics in North America hold a degree, 13.5% in Europe, and 4.1% in Other. For PhDs, 61.4% of critics in North America hold a degree, 19.9% in Europe, and 1.8% in Other. For Other degrees, 6.4% of critics in North America hold a degree, 8.2% in Europe, and 0.0% in Other.

Overall, the table shows that literary critics in North America are more likely to hold a degree than critics in Europe or Other. Critics in North America are also more likely to hold a Bachelor's or Master's degree, while critics in Europe are more likely to hold a PhD.","Experts changed their evaluations after reading the full-text documents for scientific assessed claims. A statistically significant direct association was observed between unfounded statements and the false contextual information (OR = 18.83 for false statements versus correct statements. A direct statistically significant association with unfounded statements emerged for incorrect scientific statements (OR = 2.90 for incorrect versus correct scientific statements. Likewise, unfounded information was significantly associated with undefined scientific claims .",5.31%,61.43%,79.74%,34.60%,74.47%
5,images/F15.png," The table shows the gender and academic rank of literary critics. There are 167 literary critics in total, 43 (25.7%) of whom are female and 124 (74.3%) of whom are male. Of the 43 female literary critics, 6 are full professors, 27 are associate professors, 8 are assistant professors, 0 are emeriti, and 2 are in other ranks. Of the 124 male literary critics, 69 are full professors, 39 are associate professors, 12 are assistant professors, 3 are emeriti, and 1 is in other ranks.","This figure presents a flow chart showing the number of studies at each step in the search and screening process. A total of 258 studies were identified that met the study criteria, including 182 phenomenological studies and 76 phenomenographic studies.",13.88%,70.24%,83.50%,39.61%,71.66%
6,images/F16.png," This diagram of the research process shows the different stages involved in writing a research paper, from the initial idea to the final dissemination of the findings. The first stage is the idea stage, where the researcher comes up with an idea for a research project. The second stage is the preparation stage, where the researcher gathers information and resources for the project. The third stage is the elaboration stage, where the researcher develops the idea and creates an outline for the project. The fourth stage is the writing stage, where the researcher writes the first draft of the paper. The fifth stage is the analysis stage, where the researcher revises and edits the paper. The sixth stage is the dissemination stage, where the researcher shares the findings of the research with others. The seventh stage is the further writing and dissemination stage, where the researcher continues to refine and disseminate the findings.","Papers on information behaviour topics comprise 58.14% and are common in both phenomenological and phenomenographic studies, while other topics represent smaller portions. See Fig. 2. There is a low representation of topics such as legal and ethical aspects (0.39%), cataloguing and library cooperation (0.78%), and historical sources (1.55%).",6.08%,50.20%,80.34%,37.69%,81.07%
7,images/F17.png," The image shows the architecture of the Vision Transformer (ViT) model. 
The model consists of two main components: 
1. a ViT encoder 
2. a modified BERT transformer. 

The ViT encoder is responsible for converting the input image into a sequence of tokens. The modified BERT transformer is then used to process the sequence of tokens and generate a text description of the image.

The ViT encoder is a type of transformer model that is specifically designed for processing images. The transformer model is based on the self-attention mechanism, which allows the model to learn relationships between different parts of the image. The ViT encoder typically consists of a series of transformer layers, each of which consists of a self-attention layer and a feed-forward layer. The self-attention layer allows the model to learn relationships between different parts of the image, while the feed-forward layer allows the model to learn more complex representations of the image.

The modified BERT transformer is a type of transformer model that is specifically designed for processing text. The BERT transformer model is based on the self-attention mechanism, which allows the model to learn relationships between different parts of the text. The modified BERT transformer typically consists of a series of transformer layers, each of which consists of a self-attention layer and a feed-forward layer. The self-attention layer allows the model to learn relationships between different parts of the text, while the feed-forward layer allows the model to learn more complex representations of the text.","Only three studies specifically mentioned validity and reliability as the strategies used for obtaining rigour (Cogan & Martzoukou, 2018; Cutajar, 2017; Klentzin, 2011). Validity criteria form a large part of the strategies that are used for rigour in both phenomenological and phenomenography based on the number of codes (41.96%), followed by generalizability (38.92%), reliability (17.91%), and frameworks (1.21%) See Fig3",24.12%,48.31%,77.55%,37.63%,82.06%
8,images/F18.png, The image shows a neural machine translation model. The model consists of an encoder and a decoder. The encoder converts the input sequence into a numerical embedding. The decoder then uses the embedding to predict the next token in the output sequence.,"Fig. 1 presents the number of references identified at each stage of the review process (not including Chinese journals). In total, 464 references were identified. This was subsequently reduced to 129 references upon detailed examination of the titles and abstracts. Only 38 studies met the final criteria for inclusion in the review. In addition, 12 studies were identified by supplementary methods. For Chinese journals, the review process was similar to the above, but ultimately only one reference met the inclusion criteria for LIS, leading to a total of 51 references selected for syntheses and analysis. Appendix B includes the complete list of papers included in the data set. A list of excluded references, together with the reasons for their exclusion, is available on request from the authors.",39.89%,79.67%,82.12%,6.29%,81.61%
9,images/F19.png," A simplified block flow diagram of a typical chemical process, including the main steps of:
- Feed preparation
- Thermal separation
- Reaction
- Product conditioning

The diagram also shows the possible recycle streams and the addition of reactants. The numbers in the diagram represent the probability of each stream.","Fig. 1 outlines the SciELO Suggester processing cycle. The system starts from a to-be-cataloged incoming resource, which is used to automatically generate queries. The queries are submitted to a library of cases consisting of previously cataloged resources. The retrieved cases that are sufficiently similar to the to-be-cataloged resource under analysis are used to produce suggestions of keywords and subject areas. The cataloger is in charge of deciding which suggestions to include in the new bibliographic record. Once generated, this new record becomes part of the library of cases, expanding the set of suggestions that can be provided by the tool in future requests.",38.51%,90.74%,81.85%,17.55%,76.14%
10,images/F2.png," The flowchart shows the main steps of the proposed approach. Given a flowchart image, the first step is to preprocess the image and remove noise. Then, the graphic components are segmented and postprocessed. In the next step, the closed regions are segmented and the main orientation of the flowchart is checked. Then, the regions are classified into different types and the nodes and edges are identified. The next step is to associate the nodes and edges and identify the no-box nodes. Then, the edge properties are extracted and the text regions are identified. Finally, the text is extracted and recognized using OCR, and the output is generated.","A number of citations for each source was computed from Google Scholar. Based on the inclusion and exclusion criteria, Boolean search statements, and citation tracking, 105 sources were finally included for analysis as can be seen in Fig. 1.",17.70%,90.75%,83.15%,35.83%,77.08%
11,images/F21.png," The table summarizes different phenotype recognition models. The columns are:

- Rule based
- Hybrid
- Deep learning
- Year

The rows are:

- MetaMap
- NCBO
- OBO
- Doc2Hpo
- ClinPhen
- NCR
- Phenotagger
- BERN2
- PhenoBERT","Tsai (2003) reported that individuals' online information searching processes were made up of three domains: behavioral, procedural, and metacognitive. As shown in Fig. 1, these three domains include seven fundamental online information searching strategies (Tsai, 2009). Studying online information searching strategies based on a specific theoretical framework is important in terms of coming up with a systematic and holistic evaluation of these strategies (Hariri, Asadi, & Mansourian, 2014; Kinley, Tjondronegoro, Partridge, & Edwards, 2014). In this context, the present study is mostly based on Tsai's (2009) online information searching strategies framework.",3.47%,49.53%,78.16%,10.33%,74.89%
12,images/F22.png," The table shows the comparison of cryptographic strength after Sub-Bytes transformation. The plaintext is in English and Tamil. The mean, standard deviation, runs test score, and randomness are calculated. The results show that the cryptographic strength of the English sentence is lower than that of the Tamil sentences. This is because the Tamil sentences have a higher mean and standard deviation. The runs test score for the English sentence is also higher than that of the Tamil sentences. This indicates that the English sentence is less random than the Tamil sentences.",The back-round and research interests of the 171 literary critics who responded to the questionnaire were varied. Over 70% of the participating literary critics were men (124 of 167 respondents) and more than 80% were tenured (142 of 168 repondents). Seventy-five were professors and 67 were associate professors (see Table 1).,27.37%,52.54%,80.70%,42.12%,77.74%
13,images/F23.png," The table shows the comparison of cryptographic strength after ShiftRows transformation. The plaintext is in English and Tamil. The mean, standard deviation, runs test score, and randomness are calculated. The results show that the ShiftRows transformation is effective in increasing the cryptographic strength of the plaintext.","Beginning with their Master's degree work, the number of years the participants had spent doing literary criticism ranged from two to 50 years. The majority of the degrees held by the participants were granted by North American institutions (see Table 2). Of the respondents who provided data about their degrees, over 90% held Bachelor's, Master's, and Doctoral degrees; however, there were two who did not have a Bachelor's degree, 12 who did not obtain the Master's degree, and 15 who did not have a doctorate. There were very few critics who had more than three degrees.",26.58%,75.53%,81.26%,15.64%,75.54%
14,images/F24.png,Error: Invalid response from model,"The research-phases model of the literary critical process eveloped from the present study incorporates both scholarly activities and information functions 4 (see Figures 3). The model incorporates six stages: idea generation, preparation, elaboration, analysis and writing, dissemination, and further writing and dissemination. During the first stage, the literary critic generates and develops an idea. The activities during this stage are mainly solitary, with the exception of literary critics wishing to discuss their idea(s). Information is used minimally and for the purpose of developing ideas and identifying the literary text(s) to be used.",4.66%,59.49%,80.55%,0.00%,81.29%
15,images/F25.png," The presented methodology consists of the following steps:
1. Create a digital ontology knowledge base.
2. Create a dataset of question-answer-passage triples.
3. Data preprocessing.
4. Use an IR module to select segments of text that contain answers.
5. Fine-tune a pre-trained BERT model to identify answer spans in the selected text segments.
6. Implement the methodology and evaluate it on a prototype.","A multi-head cross-attention layer is added to each layer of the text classifier to allow it to attend to the features of the visual encoder. The figure depicts the integration into a single layer of the textual encoder. Each answer candidate is concatenated with the question and separately encoded by our model using Bert (Devlin et al., 2019). Visual features are extracted from the flowchart image using the Vision Transformer (ViT) (Dosovitskiy et al.,2021) which BERT can attend to during encoding using cross-attention (cf. Figure 3). After encoding, we obtain a probability distribution over the answer candidates using a linear layer.",31.59%,80.53%,83.27%,28.66%,75.62%
16,images/F26.png," The table shows the classification statistics of geology ontology. There are 16 types of geology ontology, and the number of concepts in each type is listed. The most common type is Minerals Geology, which has 13,794 concepts. The least common type is Hydrogeology, which has only 15 concepts.","Typically, a sequence-to-sequence model comprises an encoding and decoding stack as depicted in Figure 1. During encoding, a numerical embedding of the input sequence is determined, which is subsequently used by the decoder stack to generate the output sequence in an autoregressive way. The decoder iteratively processes the preceding output sequence together with the numerical embedding of the encoder to predict the next token (e.g., a word). The iterative decoding is stopped as the decoder predicts the end of the sequence as the next token.",32.81%,83.70%,81.94%,23.77%,71.25%
17,images/F27.png," The input layer consists of the input tokens, which are converted into vectors by the word embedding layer. The word embedding layer is followed by the encoding layer, which consists of a series of Transformer blocks. The Transformer blocks are responsible for learning the relationships between the input tokens and generating a contextualized representation of the input. The contextualized representation is then passed to the answer layer, which consists of a feed-forward network and a softmax layer. The feed-forward network is responsible for learning a mapping from the contextualized representation to a vector of logits. The softmax layer is responsible for converting the logits into a probability distribution over the possible answers.","The probabilities, shown in Figure 4, for the transition between the subprocesses are selected based on our experience to generate realistic process flowsheets sufficient for pretraining the model. The utilization of fixed probabilities result in a general structure of the process flowsheet consisting of feed treatment, followed by reaction, thermal separation and final conditioning",43.11%,91.51%,82.03%,44.05%,80.32%
19,images/F29.png," This is a flowchart of the NetLogo program. The program starts by setting up the simulation parameters. Then, it creates agents and assigns them attributes. It also creates an external environment and network and assigns attributes to them. Next, it defines the motivational factor and sets up the survey.

The program then calculates the social learning function and the behavioral function for each agent. It also updates the agent's behavior and checks if the agent is participating in the DR program. If the agent is participating in the DR program, the program updates the agent's state.

The program then checks if the simulation has reached the end. If it has, the program displays the results. Otherwise, the program repeats the steps from Step 2 to Step 4.","Table 1, we summarize three major types of methods to tackle this problem: (1) rule-based (string matching, dictionary-based, statistical model, etc.) algorithms, (2) machine learning algorithms, including recently developed deep learning methods, and (3) hybrid models combining both approaches. The first generation of tools for clinical concept recognition were either dictionary-based or rule-based approaches, such as MetaMap,18 NCBO annotator,19 ClinPhen,20 and the AhoCorasick algorithm used in Doc2HPO.",15.41%,73.67%,80.90%,38.06%,84.56%
20,images/F3.png," This is a medical decision tree which is used as a diagnostic tool to help healthcare professionals determine the cause of a patient's symptoms. The tree is based on the patient's answers to a series of questions about their symptoms. Each question leads to a different branch of the tree, and the final branch of the tree will indicate the most likely cause of the patient's symptoms.","The results of Sub-Bytes in Table 2 show that the Tamil texts achieve significant randomness with scores that range from 0 to 0.355 and an average score of 0.088. We can also observe that Tamil sentence 1 has achieved a perfect randomness based on the runs test score, while Tamil sentences 3, 4, and 5 achieve very high randomness.",21.16%,55.88%,82.26%,43.28%,76.92%
21,images/F30.png," In this paper, a methodology is proposed for the classification of Parkinson’s disease using machine learning techniques. The methodology consists of five main steps:
1. Pre-processing of datasets: In this step, the datasets are pre-processed to remove any missing values and outliers.
2. Numericalization: In this step, the categorical variables in the datasets are converted into numerical variables.
3. Normalization: In this step, the numerical variables in the datasets are normalized to have a mean of 0 and a standard deviation of 1.
4. Classification: In this step, different machine learning algorithms are used to classify the datasets into different classes.
5. Prediction and performance metrics: In this step, the performance of the machine learning algorithms is evaluated using different performance metrics.",Table 3 shows the results after the application of ShiftRows transformation of the AES encryption flow to the Tamil texts used. The results show that the Tamil texts yield the randomness with runs test scores that range from 0.355 to 1.068 and an average score of 0.6068.,30.93%,87.70%,82.04%,40.44%,75.40%
22,images/F31.png, The image shows how to generate figure captions via text summarization. The model takes the scientific paper and the target figure as input. It then extracts the paragraphs that mention the figure and generates a summary of those paragraphs. The summary is then used as the caption for the figure.,"The responses from ChatGPT-3.5 and the content of the ""Epilepsy Patient and Caregiver Guide"" were also compared and assessed against the responses generated by ChatGPT-4. The performance of ChatGPT-4 was rated as “much better,” “better,” “similar,” “worse,” or “much worse” than that of the other two sources. In cases where the evaluations of the two raters differed, the final assessment was derived using the method presented in Table 1.",45.61%,63.81%,82.85%,34.65%,79.58%
23,images/F32.png," The table shows the BLEU-4 scores between captions and mentions of each figure. The BLEU-4 score is a measure of how similar two pieces of text are. It is calculated by comparing the n-grams (sequences of n words) in the two pieces of text. The higher the BLEU-4 score, the more similar the two pieces of text are.

The table shows that the BLEU-4 scores for the first mention of a figure are higher than the BLEU-4 scores for the random mention of a figure. This suggests that the writers of the captions may give more details when they first introduce a figure. This is perhaps because the first mention of a figure is more important than the random mention of a figure, as it is the first time that the reader is introduced to the figure.","An overview of the proposed methodology is demonstrated in Fig. 1. The presented approach consists of two important modules: the information retrieval (IR) module and the pretrained BERT model. The IR module aims to choose segments of a set of texts that includes a list of answers. Then, the BERT model recognizes an answer span from the sentence clause based on the combination of segments. The core stages of the presented approach are as follows: (1) domain-geoscience ontology construction, (2) data preprocessing, (3) dataset development, (4) BERT module training and testing, and (5) approach evaluation and prototype development.",50.92%,70.26%,81.18%,46.96%,84.70%
24,images/F33.png," The table shows the results of human evaluation on the generated text. The first column is the name of the model, the second column is the average rank of the model, and the third column is the caption of the model. The model with the lowest average rank is the best model. In this case, the best model is the BTR model.","An ontology, as an information model, can explicitly represent specific domains by defining concepts (e.g., geological entities, strata) and various relationships between concepts (e.g., spatiotemporal relationships, functional property relationships). The detailed statistical results are demonstrated in Table 2. Considering the relevance and practicality of geological research, we select 11 categories as the object of this study.",28.77%,82.64%,83.02%,43.01%,91.17%
25,images/F34.png," In this example, the original question is ""Prim's Algorithm is used to solve what problem?"". The system then generates three distractors:
(A) Finding the lowest parent of a heap
(B) Minimum spanning tree
(C) Shortest path in a graph from a source
(D) Sorting integers

The system then generates a new question stem ""Prim's Algorithm is used to solve what problem?"" and uses the distractors generated above to form a multiple-choice question.","The representation vector c obtained by BERT can be used for subsequent classification tasks. The [SEP] mark needs to be placed between two sentences to separate the two input sentences, while the [MASK] mark is used to cover some words in the sentence to use the [MASK] vector output in the BERT model to predict the word.",33.34%,60.86%,82.00%,44.44%,77.22%
26,images/F35.png," The figure shows an overview of how to generate answer choices for a question stem with LLMs. 
- The process starts with a question stem, which is then used to generate three prompts. 
- Each prompt is then used to generate three responses, resulting in a total of nine responses. 
- These responses are then used to generate nine LLM-generated groups of distractors and answers.","Our platform offers a streamlined, automated text analysis process that accepts plain text and produces structured data.Figure 1 illustrates the complete workflow. First, we extract the title and abstract from an article and use GPT-3.5, guided by question ①, for an initial screening to identify articles focused on new material research. If the model deems it relevant (judged as True), we proceed to the next step:",14.98%,85.59%,83.49%,40.90%,80.17%
27,images/F36.png," The data generation pipeline consists of three main steps:

- Figure extraction: In this step, figures are extracted from the PDF files. 
- Clustering: In this step, the extracted figures are clustered into different groups based on their visual similarity. 
- Automatic annotation: In this step, the clusters are labeled with the corresponding metadata.",Two scenarios are developed to test how social learning would affect the willingness to participate among consumers. The results for each of these scenarios are obtained from the application of the ABM simulation framework which previously detailed described in Fig. 2. The primary results are illustrated through a series of graphs that depict the proportion of agents willing to engage in the DR program. These engagements are colour-coded by green patches on consumers and graphs are,32.86%,87.06%,82.31%,31.22%,78.76%
28,images/F37.png," The Venn diagram shows the numbers of extracted images. There are three categories: PDF Figures 2, DeepFigures, and the intersection of both. The numbers in the circles represent the number of images in each category. For example, the number in the circle that represents the intersection of PDF Figures 2 and DeepFigures is 9,046. This means that there are 9,046 images that are in both the PDF Figures 2 dataset and the DeepFigures dataset.",The end to end flow diagram of the implemented hybrid intrusion detection system is represented in the following Fig. 2. The datasets are preprocessed using numericalization and normalization. The preprocessed train and test data passed as input to the models. The models predict malicious and classify as multi class malicious then evaluated and analyze the performance.,44.76%,85.93%,82.49%,45.95%,76.37%
29,images/F38.png," | Dataset | Labels | #Figures | Image Source |
|---|---|---|---|
| Deepchart | 5 | 5,000 | Web Image |
| Figureseer | 5 | 30,600 | Web Image |
| Prasad et al. | 10 | 653 | Web Image |
| Revision | 5 | 2,000 | Web Image |
| FigureQA | 5 | 100,000 | Synthetic figures |
| DeepFigures | 2 | 1,718,000 | Scientific Papers |
| DocFigure | 28 | 33,000 | Scientific Papers |
| ACL-FIG-PILOT | 19 | 1,671 | Scientific Papers |
| ACL-FIG (inferred) | - | 112,052 | Scientific Papers |","As shown in Figure 1, our system then automatically summarizes all the extracted Mentions (or Paragraphs) into a figure caption. In this work, we used PEGASUS, an abstractive summarization model [59], and fine-tuned it on our dataset. Figure 1 overviews the proposed pipeline. The system extracts all Mentions (or Paragraphs) associated with a target figure from the document and summarizes them to generate a caption. This section describes each step of the pipeline. Our proposed system",0.37%,13.05%,77.15%,0.00%,53.52%
30,images/F39.png,Error: Invalid response from model,"For captions we examined first caption and whole caption. The results are shown in Table 1. The extremely low BLEU-4 score for the Random Sentence baseline (First: 0.01, Whole: 0.01) indicates that a randomly selected sentence has very limited information related to the caption. In contrast, the results for First Mention (First: 9.39, Whole: 10.54) and Random Mention (First: 9.15, Whole: 10.28) show the presence of significantly more information relevant to the caption. All scores in First Mention are slightly better than the corresponding ones in Random Mention, suggesting that writers tend to give more detail when they first introduce the figure.",0.00%,72.61%,79.77%,0.00%,74.43%
31,images/F4.png," The figure shows the flowchart of the proposed IRI detection method. The inputs of the method are multi-view IR images and patient-specific breast models. The outputs are the predicted tumor size and location. The method consists of three main steps: (1) thermal simulation, (2) image registration, and (3) IRI detection. In the thermal simulation step, the initial parameters of the breast model are updated using a thermal simulation process. In the image registration step, the computed images are registered to the multi-view IR images. In the IRI detection step, an IRI detection algorithm is used to detect the IRI in the registered images. The predicted tumor size and location are then obtained.","Figure 3 shows two samples of generation output. The information generated by Pegasus𝑃+𝑂+𝐵 could be helpful (A), but it could also introduce factual errors (B)",13.01%,80.37%,81.31%,35.12%,76.37%
32,images/F40.png," The table shows an example of input and output in wikibio. The input is a list of field names and values. The output is a sentence that is generated from the input data. The sentence is generated by concatenating the values of the fields in the order that they appear in the table. In this example, the output sentence is ""abhinay deo is an indian film director"".","Professor Avery could rapidly draft question stems and then following the process outlined in Figure 1, she could use a prompt with each question stem to automatically generate a list of answer choices with the correct answer marked using an ’(X)’ symbol. The example question stem in Figure 1 asks the test-taker to provide the type of problem that Prim’s Algorithm would be used to solve. The LLM generates a correct answer and three distractors.",32.20%,79.92%,83.14%,45.48%,81.43%
33,images/F41.png," The figure shows the approach to extract information from scientific documents. The approach consists of three main steps: training, assisted annotation, and inference. In the training step, a sequence-to-sequence model is trained on a dataset of manually annotated chemical named entities and their corresponding structures. In the assisted annotation step, the trained model is used to partially annotate a new dataset of chemical named entities and their corresponding structures. The partially annotated dataset is then manually corrected. In the inference step, the retrained model is used to extract chemical named entities and their corresponding structures from new chemical documents.","To generate the multiple choice questions, we followed the process outlined in Figure 2. The first step was to randomly select an MCQ from the dataset. From each randomly selected MCQ, we used the question stem to generate a new correct answer and distractors using a large language model (i.e.: GPT-3 or GPT-4). To account for the effect of the prompt, we developed three prompts based on the prompt engineering process described in the previous sub-section.",39.90%,93.80%,83.52%,46.13%,76.06%
34,images/F42.png,Error: Invalid response from model,"The ACL Anthology is a sizable, well-maintained PDF corpus with clean metadata covering papers in computational linguistics with freely available full-text. Previous work on figure classification used a set of pre-defined categories (e.g., [14], which may only cover some figure types. We use an unsupervised method to determine figure categories to overcome this limitation. After the category label is assigned, each figure is automatically annotated with metadata, captions, and inline references. The pipeline includes 3 steps: figure extraction, clustering, and automatic annotation (Figure 2).",0.00%,62.48%,80.76%,0.00%,69.79%
35,images/F43.png," The table shows the statistics of two software specification datasets. The first dataset is Javadoc, which is a dataset of Java API documentation. The second dataset is DocTer, which is a dataset of Python API documentation.

The Javadoc dataset has 674 annotations. The annotations are of three types: preconditions, postconditions, and exceptional postconditions. Preconditions are conditions that must be true before a method is called. Postconditions are conditions that must be true after a method is called. Exceptional postconditions are conditions that must be true if an exception is thrown by a method.

The DocTer dataset has 2,696 annotations. The annotations are of four types: TensorFlow, PyTorch, MXNet, and total. TensorFlow is a library for machine learning. PyTorch is a library for deep learning. MXNet is a library for deep learning. The total is the sum of the number of annotations for TensorFlow, PyTorch, and MXNet.","The numbers of figures extracted by PDFFIGURES2 and DEEPFIGURES are illustrated in Figure 3, which indicates a significant overlap between figures extracted by two software packages.",14.83%,85.12%,81.20%,37.44%,74.52%
36,images/F44.png," The figure shows the typical bioinformatics workflow for RNA-seq data analysis. The input data are the raw sequencing reads in FASTQ format, and the output is a table of gene expression values. The workflow consists of the following steps:

1. **Quality control**. The first step is to check the quality of the sequencing reads. This is typically done using a tool such as FastQC. FastQC will generate a report that summarizes the quality of the reads, including the number of reads, the average read length, and the percentage of reads that are aligned to the reference genome.
2. **Alignment**. The next step is to align the reads to the reference genome. This is typically done using a tool such as STAR. STAR will generate a SAM file that contains the alignments of the reads to the reference genome.
3. **Transcript quantification**. The third step is to quantify the expression of the genes in the RNA-seq data. This is typically done using a tool such as Cufflinks. Cufflinks will generate a table of gene expression values, which can be used to identify differentially expressed genes.
4. **Quality control**. The final step is to perform quality control on the RNA-seq data. This is typically done by examining the alignment statistics and the gene expression values. The alignment statistics can be used to identify regions of the genome that are poorly aligned, and the gene expression values can be used to identify genes that are not expressed.","There are several existing datasets for figure classification such as DocFigure [12], FigureSeer [10], Revision [7], and datasets presented by [13] (Table 1). FigureQA is a public dataset that is similar to ours, consisting of over one million question-answer pairs grounded in over 100,000 synthesized scientific images [14] with five styles.",11.33%,56.49%,79.88%,37.16%,83.48%
37,images/F45.png," Figure 2: The overall workflow of the data augmentation for creating SciCap+ dataset. For each figure in SciCap+, we extracted OCR tokens, OCR bounding boxes, body text, and mention-paragraph.","The February 13th 2023 release of OpenAI’s ChatGPT (a version of GPT-3.5) was given a basic prompt requesting scientific citations, to which it replied with several hallucinations. The results of this interaction are summarized in Table I. However, after providing the same prompt to ChatGPT using the GPT-4 model, the response",14.68%,86.16%,83.04%,19.92%,71.92%
38,images/F48.png," abc Text
(a) Annotation of data in the text.

Table
(b) Annotation of data in tables.

Figure
(c) Annotation of data in figures.

Figure 1: Example annotation format output. Data is distributed via three sources: (a) text, (b) table and (c) figure. The type of Data is one of composition (x), characterization (v), or performance property (p). Multiple compositions are denoted as \(CoMnGa\), \(Co_2MnGa\) and \(CoMn_2Ga\).","The input of the NLDT is a table which includes a series of field-value pairs. Then after embedding, encoding and decoding, it outputs an intermediate text including three types of words. Finally, NLDT outputs the natural language text through word conversion from the intermediate text. Table I represents an example of input and output text in WIKIBIO using NLDT.",31.00%,51.65%,81.04%,47.47%,77.54%
39,images/F49.png," The table shows zero-shot and few-shot performance metrics on the WebNLG test set evaluated by BLEU, METEOR, TER, and BERTScore-F1. The best value per metric is indicated in bold.

For the zero-shot setting, the best performing model is LLaMA-7B with a BLEU score of 0.06, a METEOR score of 0.21, a TER score of 1.03, and a BERTScore-F1 score of 0.84. 

For the few-shot setting, the best performing model is LLaMA-7B with a BLEU score of 0.52, a METEOR score of 0.41, a TER score of 0.42, and a BERTScore-F1 score of 0.96.","As a separate experiment, we evaluated the use of partially trained LLMs in a “human-in-the-loop"" annotation process for constructing outputs with the GPT-3/General-JSON, as seen in Fig. 2. . To accelerate the collection of training data, new annotations are collected via a “human in the loop"" approach where models are trained on small datasets and their outputs are used as starting points and corrected by human annotators (see Fig. 2.) This process of training and annotation is completed multiple times until a sufficiently large set of training data was achieved. Each dataset was annotated by a single domain expert annotator.",24.35%,79.97%,80.91%,46.21%,79.43%
40,images/F5.png," This flowchart describes the process of fact checking a news article. It starts with the text breakdown and labeling, and then goes through methodological analysis and content analysis. The content analysis is divided into two parts: Phase I and Phase II. After that, the results are checked for correctness and a final determination is made.","Table 3 shows the adjusted scores based on manual scoring. It assess if the model extracts equivalent information to that of the true annotation - regardless of the exact form. Simply, if a domain expert would agree the model’s extraction and the true extraction are equivalent, the model’s extraction is marked as correct.",26.17%,90.48%,84.44%,44.24%,73.49%
41,images/F50.png," The Transformer model is an attention-based neural network architecture that can be used for a variety of natural language processing tasks, including translation, summarization, and question answering. 

The model is based on the idea of self-attention, which allows the model to attend to different parts of its own input sequence when generating an output. This allows the model to learn long-range dependencies in the input sequence, which is important for tasks such as translation and summarization.

The Transformer model consists of a stack of Transformer blocks, each of which consists of a self-attention layer and a feed-forward layer. The self-attention layer allows the model to attend to different parts of its own input sequence, while the feed-forward layer allows the model to learn non-linear relationships between the input and output sequences.

The Transformer model has been shown to achieve state-of-the-art results on a variety of natural language processing tasks. The model is particularly well-suited for tasks that require the model to learn long-range dependencies in the input sequence.","Table 1 presents the number of data points in each dataset in column “#Annotation”, listing the number of document-specification pairs annotated for Jdoctor-data, and the parameter-specification pairs from each library of DocTer-data. We treat the three tag types from Jdoctor-data (Table 1)",25.42%,81.93%,80.65%,38.10%,79.74%
42,images/F51.png," The table shows the sample characterization. There are 28 participants in the in-class condition and 104 participants in the remote condition. There are 14 teams in the in-class condition and 52 teams in the remote condition. The gender breakdown is as follows: in the in-class condition, there are 24 males, 4 females, and 0 other; in the remote condition, there are 82 males, 20 females, and 2 others. The mean age of the participants in the in-class condition is 21.1 years, with a standard deviation of 1.2 years and a range of 20-24 years. The mean age of the participants in the remote condition is 20.9 years, with a standard deviation of 1.1 years and a range of 20-26 years.","Figure 1a illustrates the computational steps, the tools, and the data flow of a bioinformatics workflow for performing differential gene expression analysis. During workflow execution, a single computation step often involves multiple processes, which are typically executed in a distributed fashion on different machines and batches of the input data, resulting in a much more complex execution graph. Consequently, scientific workflows help facilitate the reproducibility and traceability of data analyses by explicitly outlining the steps and parameters involved. Furthermore, they allow for automation, scaling, and optimization of computational processes, which is especially critical in disciplines dealing with large datasets. we are particularly investigating the exchange of used tools in the bioinformatics workflow WF2-RS-Star whose computational scheme is given in Figure 1a.",42.03%,75.91%,80.31%,50.69%,80.29%
43,images/F52.png," The table summarizes the escape room puzzles. The first column is the puzzle number, the second column is the learning objective, and the third column is the puzzle mechanics.

The first puzzle's learning objective is to use GitHub for managing code projects, identify node.js apps, install their dependencies, and start them. The puzzle mechanics are noticing something obvious in a room and searching for something hidden.

The second puzzle's learning objective is to interpret and write EJS code for dynamically generating HTML. The puzzle mechanics are searching for something hidden and reading.

The third puzzle's learning objective is to understand promises. The puzzle mechanics are searching for something hidden, searching for objects in images, symbol substitution, light, and shape manipulation.

The fourth puzzle's learning objective is to perform SQL queries and operate with HTML forms. The puzzle mechanics are the element of surprise.",SciCap is a large-scale figure-caption dataset comprising graph plots extracted from 10 years of collections of arXiv computer science papers. We used around 414k figures from SciCap and augment each figure with its mention paragraphs and OCR tokens with metadata. This section details the data set creation and data augmentation processes. Figure 2 shows the overall workflow behind the creation of SciCap+.,19.57%,84.68%,80.59%,38.00%,77.94%
44,images/F53.png," The table shows the distribution of learners over conditions and MOOCs. There are three MOOCs: Child Development, Clinical Epidemiology, and Human Rights. For each MOOC, there are two conditions: control and intervention. The control condition is the traditional way of learning, while the intervention condition is the new way of learning.

For Child Development, there are 721 learners in the control condition and 723 learners in the intervention condition. For Clinical Epidemiology, there are 148 learners in the control condition and 160 learners in the intervention condition. For Human Rights, there are 337 learners in the control condition and 337 learners in the intervention condition.

Overall, there are 2,426 learners in the study. Of these learners, 1,214 are in the control condition and 1,212 are in the intervention condition.","The data was hand-annotated by systematically isolating each sentence throughout the paper including the main body of the text, supplementary material, tables, and figures, then determining whether a relevant expression of data was presented. If it was determined that a relevant data was presented, the source through which the data was presented along with the type or category of that data point was annotated. The most consistent test for whether relevant information was presented in a given sentence was whether the meaning of that sentence related to or progressed understanding with respect to one of the four defined data types or categories.",23.24%,87.36%,80.45%,41.60%,73.40%
45,images/F54.png, Table 1. Overview of inclusion and exclusion criteria.,"Results of Performance Metrics Table 1 summarizes the calculated metrics. The Copy-Baseline denotes copying the triples as output without processing. It is included as a metric reference point to establish a lower bound (Kasner and Dusek, 2022). We distinguish between scores for raw and postprocessed (+ PP) outputs. Post-processing involved the removal of “Output text” or “Output” since they are not intended parts of the desired text prediction but were present in the few-shot prompt. Additionally, repeated instructions or in-context examples from the prompt were removed when they appeared in the generated output.",9.53%,79.53%,83.66%,0.00%,82.12%
46,images/F55.png," This diagram shows the relationship between monitoring and control in self-regulated learning. Monitoring involves paying attention to one's own learning and making adjustments as needed. Control involves setting goals and directing one's own learning. The arrows between monitoring and control indicate that these two processes are互相影响的. For example, monitoring can help learners to identify areas where they need to improve, and control can help learners to stay on track and achieve their goals.","As depicted in Figure 3 (a), we utilize the core Transformer model implementation for text generation and propose significant structural alterations in the attention module. We propose models that utilize the attention-on-attention mechanism [15] (initially proposed for LSTM models) for image to-token sequence translation.",15.93%,66.28%,82.64%,37.90%,74.07%
47,images/F56.png," The diagram shows the three dimensions of ML literacy: cognitive, affective, and sociocultural.
The cognitive dimension refers to the knowledge and skills needed to understand and use ML. This includes understanding the basic concepts of ML, such as algorithms, data, and models, as well as being able to develop and use ML models.
The affective dimension refers to the attitudes and beliefs about ML. This includes being aware of the ethical implications of ML and being open to new and innovative uses of ML.
The sociocultural dimension refers to the social and cultural context of ML. This includes understanding the different ways that ML is used in different cultures and societies, as well as the impact of ML on society.","Table 1 summarizes the characteristics of the sample of this study. All the participants were students of subsequent offerings of the same course arranged in pairs. All of them completed the pre-test, the post-test and the questionnaire individually. As can be seen, the sample characteristics are very similar in both groups in terms of age and gender ratio.",41.49%,75.64%,82.21%,42.78%,81.64%
48,images/F57.png," The lessons covered in the program are:

1. Introduction to AI
2. Decision Trees
3. K-nearest Neighbor
4. Convolutional Neural Network
5. Algorithm Bias
6. Ethics and Societal Implications of ML","Table 1 provides an overview of all the puzzles that the educational escape room activity comprises indicating, for each one of them, the learning objectives addressed and the puzzle mechanics used. The terminology employed for naming these puzzle mechanics has been primarily extracted from [2], although new terms have been introduced.",16.75%,71.77%,81.48%,22.00%,70.65%
49,images/F58.png," The image shows a taxonomy of the different types of looks that people use when looking at another person's screen. 

There are three main types of looks: 
- Monitoring looks: These are used to check on the user's availability or to get them back on task. 
- Inquiring looks: These are used to gather information or to check the relevance of the information on the screen. 
- Escaping looks: These are used to find a topic of conversation, to spectate, or to engage in a joint activity.","Data were gathered in three MOOCs. The MOOCs were titled Child Development, Clinical Epidemiology, and Human Rights. In each MOOC, participants were randomly divided over two versions of the course: an experimental version and a control version. In total, 2,426 learners enrolled in one of the three MOOCs. However, there is a large difference in the number of learners who enroll in a MOOC and the number of learners who actually log in to the course at least once and engage in any activity (Davis et al., 2018; DeBoer, Ho, Stump, & Breslow, 2014; Jordan, 2014). In our sample, 955 out of the 2,426 enrolled learners (39%) never engaged in any behavior within the MOOCs. These learners were excluded from further analyses. A distribution of the learners included in the analyses over conditions and MOOCs is presented in Table 1.",24.09%,73.57%,80.19%,26.46%,81.60%
50,images/F59.png," Table 1. Number of vertical transitions performed by Dekalb White hens at 19, 23, and 27 wk of age.","Titles and abstracts of the found studies were filtered based on a predefined list of inclusion and exclusion criteria, which can be found in Table 1. Some of these criteria were already included in the search terms to reduce the number of hits, for instance by excluding articles containing the words gifted, disab* and disorder in the title, abstract or keywords. A total of 700 studies was retained after filtering based on titles and abstracts. Only the first identified reason for exclusion was recorded. The most often identified reason for exclusion was that the study did not focus on SRL as defined in the Introduction or that it did not fit any of the three relations.",14.35%,64.46%,81.28%,0.33%,74.04%
51,images/F6.png, Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) flow diagram.,"Self-regulated learners are actively involved in their learning, and they make conscious decisions about what, where, and how they study (Zimmerman, 2002). It involves activities such as planning, monitoring, time management, and help seeking. Nelson and Narens (1990) described SRL as a continuous cycle between monitoring and control (see Figure 1). Learners engage in learning activities to perform a task. These activities are overt; they can be observed by others. While working on the task, learners monitor their progress. As a result, learners form a metacognitive representation of their learning at a meta-level.",7.57%,74.95%,80.56%,0.02%,68.32%
52,images/F60.png," Table 2. Proportion of descending transitions crossing more than 1 zone by Dekalb White hens.
Time of day and age (wk)	FL estimate (95% CI)	ST estimate (95% CI)	TT estimate (95% CI)
Morning
17, D1	0.32 (0.23, 0.43)	0.41 (0.32, 0.52)	0.40 (0.30, 0.51)
17, D7	0.56 (0.44, 0.68)	0.45 (0.35, 0.55)	0.45 (0.35, 0.53)
19	0.46 (0.35, 0.57)	0.34 (0.26, 0.42)	0.41 (0.32, 0.44)
23	0.11 (0.03, 0.34)	0.29 (0.21, 0.39)	0.12 (0.03, 0.19)
Afternoon
17, D1	0.41 (0.30, 0.53)	0.44 (0.33, 0.56)	0.43 (0.32, 0.61)
17, D7	0.59 (0.47, 0.69)	0.49 (0.38, 0.60)	0.55 (0.42, 0.67)
19	0.56 (0.45, 0.67)	0.50 (0.42, 0.59)	0.60 (0.52, 0.68)
23	0.48 (0.38, 0.59)	0.42 (0.34, 0.51)	0.59 (0.44, 0.69)
Evening
17, D1	0.71 (0.56, 0.83)	0.53 (0.46, 0.61)	0.51 (0.43, 0.61)
17, D7	0.46 (0.35, 0.57)	0.51 (0.40, 0.62)	0.50 (0.38, 0.62)
19	0.54 (0.43, 0.62)	0.45 (0.35, 0.55)	0.47 (0.39, 0.57)
23	0.52 (0.42, 0.62)	0.37 (0.29, 0.46)	0.42 (0.33, 0.51)","As shown in Fig. 1, the three dimensions were adapted in this study to include applicable concepts in the scope of extracurricular activities designed to promote ML ideas in a public middle school. The participants a) learned about some ML techniques, specifically supervised learning which include classification algorithms such as decision trees, k-nearest neighbor (k-NN), convolutional neural networks (CNN), and expanded the scope to include algorithm bias (cognitive dimension); b) engaged with ML platforms such as Google’s Teachable Machine (GTM, Carney et al., 2020) and Doodleit (Mahipal et al., 2023) among other unplugged activities to learn to confidently interact with ML as well as to be inspired to formulate new solutions and understand the impact of ML for the social good (affective dimension); and were c) prompted to think ethically through discussions and videos of some negative and positive examples of facial recognition systems as well as public cameras (socio-cultural dimension).",1.71%,65.41%,75.42%,34.57%,53.90%
53,images/F61.png,Error: Invalid response from model,"The learning phase was organized as six sessions with different ML topics and learning activities per session. Each of the sessions lasted for an hour period. The adopted AI MyData curriculum with slight modification to its activities to further calibrate it and as well ensure contextual relevance. Learning the concepts in Fig. 2 contribute to ML literacy as depicted in Fig. 1 (see 2.1). As shown in Fig. 2, we specifically taught the students six ML-related concepts which includes: Introduction to AI & classification, Decision trees, k-nearest neighbors (k-NN), Convolutional neural network (CNN), Algorithm bias, and Ethics of ML. Our pedagogical strategy across the sessions includes a fair mix of activity-based",0.00%,62.66%,79.13%,0.00%,69.79%
54,images/F62.png," From the table above, the purpose of teaching reading lessons to students in grades 5-8 is to help them to:
- Teach the skill of reading - 88 (100%)
- Teach how to pronounce - 88 (100%)
- Teach vocabulary - 88 (100%)
- Teach comprehension questions - 88 (100%)
- Teach them to read - 88 (100%)
- Teach the student to get the information of the text for different text - 88 (100%)
- Teach how to get the main idea - 88 (100%)
- Support the student to develop skill of reading - 88 (100%)","On the basis of the analysis of naturally occurring interactions, we have delineated three natures of looking at another’s phone—monitoring, inquiring, and escaping—and three functions corresponding to each of these natures (see Figure 5). We will now shortly describe each of the natures and functions as well as their distribution in our collection of 82 cases.",17.23%,49.16%,79.28%,39.46%,70.65%
55,images/F63.png," From the table above, the most important pre-reading strategy that teachers use in their reading classes is ""Making the purpose of reading clear"". This is followed by ""Encouraging students to predict the message of the text"" and ""Asking students to guess the relation of picture and their context"". The least important pre-reading strategy is ""Setting a context by using realia, picture etc."".","From 19 to 27 wk, there was also an interaction among rearing environment, age, and time of day (x 2 = 15.73, df = 8, P = 0.046; Table 1). ST and TT hens made more transitions than FL hens during the evening at 23 wk of age. Across ages, all hens were most active in the evening compared to the morning and afternoon.",23.16%,41.48%,81.52%,44.77%,76.69%
56,images/F64.png," The table shows the characteristics of counties included in the analysis. There are 110 counties in the Southern region with an anchor business. Of these, 83 have one anchor business, 16 have two anchor businesses, and 11 have more than two anchor businesses. In terms of closure duration, 65 counties had no closure, 17 had a short-term closure (1-21 days), and 28 had a long-term closure (22 or more days). Of the counties with a closure, 27 had a full closure, 8 had a partial closure, and 10 had both a full and partial closure.","From 19 to 27 wk, rearing environment had a main effect on the proportion of descending transitions crossing more than 1 zone, such that FL hens displayed a higher proportion of these transitions than ST hens across ages (x 2 = 7.05, df = 2, P = 0.029; Table 2).",13.32%,75.71%,81.36%,39.65%,71.35%
57,images/F65.png," The table shows the profile of plant employees and community health. 

For company 1, the number of hourly employees in plant A is 2401, while in plant B, it is 1082. The percentage of male employees is 83% in plant A and 81% in plant B. The percentage of black employees is 5.5% in plant A and 27.9% in plant B. The mean age of employees in plant A is 38.2 years, while in plant B, it is 45.8 years. The median employee years with the company in plant A is 6.0, while in plant B, it is 10.8.

For company 2, the number of hourly employees in plant C is 979, while in plant D, it is 1641. The percentage of male employees is 62% in plant C and 76% in plant D. The percentage of black employees is 84.8% in plant C and 4.2% in plant D. The mean age of employees in plant C is 46.3 years, while in plant D, it is 46.2 years. The median employee years with the company in plant C is 9.7, while in plant D, it is 8.8.

In terms of community health, the weighted average of employees' county-level community health measures shows that the percentage of children on free or reduced lunch is 67.6% in plant A, 50.1% in plant B, 77.9% in plant C, and 52.4% in plant D. The drug overdose deaths per 10,000 is 30.3 in plant A, 20.2 in plant B, 15.6 in plant C, and 13.6 in plant D. The physical inactivity is 31.2% in plant A, 24.9% in plant B, 21.1% in plant C, and 17.6% in plant D. The adult smoking is 19% in plant A, 16.8% in plant B, 30.6% in plant C, and 25.2% in plant D.

Overall, the table shows that there are some significant differences in the profile of plant employees and community health between the two companies and their plants.","The behaviors selected for this study are often used in determining space allowance guidelines for housing systems, perching in particular, because they are believed to be important to hens. In 2016, [4] separated behaviors by the type of space they required: body and behavioral. In the present study, we examined behaviors within both of these categories with ‘lying’, ‘standing’, and ‘perching’ representing body space, and ‘dust bathing’ and ‘wing flapping’ representing behavioral space. The full ethogram used during this study can be found in Table 1.",26.21%,47.99%,77.74%,36.65%,81.43%
58,images/F66.png," The figure shows the study profile. A total of 3,106,690 participants were included in SAIL between January 1, 2016, and August 1, 2021. Of these, 350,553 were excluded because primary care data were not available. The remaining 2,756,137 participants had available primary care data and were included in the study. Of these, 2,696,232 did not have a dementia diagnosis before August 1, 2021. A total of 59,905 participants had a dementia diagnosis before August 1, 2021. Of these, 2509 were excluded because the dementia diagnosis was before the age of 60 years. The final study population included 57,396 participants.","The result in table 1 indicated that the most important purposes of teaching reading to grades 5-8 were to help students to get information from the reading passage, to support students develop the skills of reading silently, to teach the skills of reading, to teach how to do comprehension questions, to teach how to pronounce words, and to enable students do grammar exercises. The percentage of the respondents who indicated this was respectively 74%, 69%, 61%, 60%, 59%, and 53%.",20.45%,77.29%,79.93%,42.76%,66.69%
59,images/F67.png," Figure 3. Patient inclusion. World Health Organization (WHO) classification: 0=uninfected, 1=asymptomatic, viral RNA detected, 2=symptomatic, independent, 3=symptomatic, assistance needed, 4=hospitalized, oxygen by mask or nasal prongs, 5=hospitalized, oxygen by high flow, 6=hospitalized, invasive ventilation or high flow + intubation and mechanical ventilation partial pressure of oxygen in arterial blood-fraction of inspired oxygen concentration (PaO2/FiO2) ratio of <150, 7=intubation and mechanical ventilation PaO2/FiO2 ratio of ≥150 or vasopressors, 8=mechanical ventilation PaO2/FiO2 ratio of <150 and vasopressors, 9=extubation, 10=dead. PCR: polymerase chain reaction; WP: work package.","According to the data in table 2, predicting the message of a text, explaining the reading purpose, giving prereading tasks, Guessing from context by looking at pictures and asking student to activate their background knowledge were respectively stated as the most important pre-reading activities employed by the English teachers. The average of the respondents who stated that the listed pre-reading activities are most important in the teaching of reading skills to students is 53.",7.32%,60.86%,76.98%,38.89%,64.85%
60,images/F68.png," Table 4 shows the vaccination details of 162 patients with Bell's palsy. Of these, 105 (67%) were vaccinated, 37 (21%) were not vaccinated, and 20 (12%) had an unknown vaccination status. Among the vaccinated patients, 72 (68%) received the BNT162b2 mRNA vaccine (Pfizer), 24 (23%) received the mRNA-1273 vaccine (Moderna), 4 (4%) received the ChAdOx1-S vaccine (AstraZeneca), and 4 (4%) received the Ad26.COV2.S vaccine (Janssen). The mean time between vaccination and the onset of Bell's palsy was 108.5 days (range, 1-376 days) for the BNT162b2 mRNA vaccine, 79.6 days (range, 9-241 days) for the mRNA-1273 vaccine, 104.5 days (range, 24-156 days) for the ChAdOx1-S vaccine, and 102.8 days (range, 14-206 days) for the Ad26.COV2.S vaccine.","We identified 110 counties that had a total of 153 anchor businesses. Forty-five counties experienced an anchor closure (Table 1, Fig. 1). County-level daily incidence of positive COVID-19 tests ranged from 0 to 214 per 100,000 population on March 31, 2020; from 0 to 59 per 100,000 population on April 30, 2020; and from 0 to 46 per 100,000 population on May 31, 2020.",2.90%,80.99%,79.66%,36.23%,66.44%
61,images/F69.png,Error: Invalid response from model,"A profile of the hourly workers with at least 12 months of service is shown in Table 1. Although there was variation in the number of employees at each plant, all four plants were large and overwhelmingly employed men. The average age of employees ranged from 38.2 to 46.3 years, and average number of years with the company ranged from 6.0 to 10.8 years. There were large differences in the percent of workers who were black, ranging from 4.2 to 84.8%. Employees at plants A and C lived in counties that had poorer community health indicators, compared to their company peers in plants B and D.",4.63%,40.00%,79.44%,0.00%,73.43%
62,images/F7.png," The network shows the relationships between different concepts in the field of library and information science. The most prominent concepts are ""phenomenography"", ""information literacy"", ""user"", and ""library"". These concepts are all related to each other in some way, and they all play an important role in the field of library and information science.

""Phenomenography"" is a research method that is used to study how people experience and understand the world around them. It is often used in library and information science to study how people interact with information and how they use libraries.

""Information literacy"" is the ability to find, evaluate, and use information effectively. It is an essential skill for anyone who wants to succeed in the 21st century. Libraries play an important role in helping people develop their information literacy skills.

""User"" is a term that refers to anyone who uses a library or information service. Libraries serve a wide variety of users, including students, researchers, and business people.

""Library"" is a place where people can find and access information. Libraries have been around for centuries, and they have played an important role in the development of society.

The network of concepts in the field of library and information science is a complex one. The concepts are all related to each other in some way, and they all play an important role in the field. This network shows how the concepts are connected, and it can be used to help researchers and practitioners understand the field better.","Of 3106690 participants included in SAIL between Jan 1, 2016, and Aug 1, 2021, 350553 (11·3%) did not have primary care data available and 2 696232 (86·8%) did not have a dementia diagnosis before Aug 1, 2021. A further 2509 (<0·1%) were then excluded for being younger than 60 years at the time of dementia diagnosis, resulting in a final study cohort of 57396 (1·8%) individuals (figure 1), who contributed 101 428 person-years of followup. 35 148 (61·2%) of 57396 participants were women and 22248 (38·8%) were men. The median observation time per person was 32 months (IQR 12–66) and the median age at study start date was 82 years (76–87). Participant demographics are displayed in the table. Data on race and ethnicity, which are poorly coded within UK primary routinely collected datasets, were not collected.Of the 57396 participants, 11 929 (20·8%) were prescribed an antipsychotic drug at any point during follow-up. The median age of patients who received an antipsychotic drug (80 years [IQR 64–86]) was lower than that of patients who did not (82 years [76–87]), and a higher proportion of patients who received an antipsychotic drug were care-home residents at the study start date (18·5% vs 14·4% of those who did not receive antipsychotic medication; table)",24.71%,39.69%,77.09%,43.78%,82.45%
63,images/F70.png," Table 2 shows the characteristics of the 239 PLWH. The median CD4 count was 350 cells/mm3 (IQR 161–620 cells/mm3) and 52.3% (n = 125) of the participants had a CD4 count of 200 cells/mm3 or more. Almost half of the participants (n = 114, 47.7%) had a CD4 count of less than 200 cells/mm3. Of the 239 PLWH, 175 (76.1%) had a HIV-1 RNA of less than 50 copies/mL. A total of 78 (34.8%) of the participants had a previous AIDS event. Of the 239 PLWH, 16 (6%) were on an ART regimen containing 2 NRTIs + INSTI, 83 (34.7%) were on a 2 NRTIs + NNRTI based regimen, 30 (12.5%) were on a 2 NRTIs + PI based regimen and 31 (13%) were on other ART regimens. A total of 42 (17.6%) of the participants were either ART-naïve or on a regimen containing only one ART drug.","Adult patients (≥18 years) hospitalized with polymerase chain reaction–confirmed COVID-19 or high clinical suspicion of COVID-19 will be included (Figure 3). Pregnant patients and patients receiving corticosteroids for other conditions during or prior to hospital admission are eligible, although a prespecified sensitivity analysis excluding these patients will be performed. Patients who die within 48 hours after admission or patients who object to participate will be excluded from the study. In WP1 and WP4, we will include patients from all SARS-CoV-2 epidemic waves, and in WP2-3, we will include patients from the first and second waves only. Specific inclusion and exclusion criteria for each work package will be applied.",8.00%,66.30%,79.32%,37.39%,76.67%
64,images/F71.png," The table shows the frequency of cases in terms of intensity of fever. There are five groups: no fever, 37.2°C to 37.7°C, 37.8°C to 38.9°C, >39°C, and unknown. The frequency of cases in each group is 55, 48, 165, 71, and 28, respectively. The percentage of cases in each group is 15.0%, 13.1%, 45.0%, 19.3%, and 7.6%, respectively.","Of the 162 patients included in the retrospective study (BP between March 2021 and March 2022), 105 patients (67%) had received at least 1 dose of the COVID-19 vaccine prior to presenting BP (Table 4). In 23 of them (22%), the paralysis appeared within the first 30 days after a vaccine dose, with a mean time from vaccination to occurrence of palsy of 14.7 + 8.9 days. No statistical differences were found between vaccination groups.",32.57%,77.42%,81.27%,32.58%,77.29%
65,images/F72.png," The figure shows the MAFA analysis of a novel clustering method. The analysis is based on four criteria: security and validation, merits, algorithms, and achievements.

The security and validation of the method are based on three algorithms. The first algorithm is responsible for resolving clustering algorithm's data inconsistencies. The second algorithm is used to present results in 3D format. The third algorithm is used to reduce the number of resources used.

The merits of the method are that it has good computation complexity and that it is based on three algorithms. The time complexity of the method is O(n), which is better than the time complexity of other clustering methods.

The algorithms used in the method are all based on a novel approach to clustering. The first algorithm is a hierarchical clustering algorithm that uses a new distance measure. The second algorithm is a k-means clustering algorithm that uses a new medoid selection method. The third algorithm is a density-based clustering algorithm that uses a new density measure.

The achievements of the method are that it has been shown to be effective in clustering large datasets. The method has also been shown to be able to identify clusters that are not easily identifiable by other clustering methods.","In table 5, the results of the logistic regression analysis to assess the relationship between demographic, epidemiological, clinical variables and mortality are summarised. In the univariate analysis on mortality the following variables reached statistical significance: age, being male, having more than one comorbidity, type 2 diabetes mellitus, cardiovascular disease, chronic respiratory disease, chronic renal disease, presence of key symptoms, invasive ventilation and hospitalisation due to COVID-19 (table 5). The final multivariable logistic regression model included age (10-year increase), male gender and need for invasive ventilation as independent contributors to mortality (table 5). Adding other covariates did not significantly increase the performance of the model. A nomogram for the estimation of the risk of death was generated on the basis of the final multivariable model. As depicted in figure 2, each indicator is measured, and the corresponding points are assigned using the row “score”. Thus, the sum is reported on the row “total score”, and the corresponding probability of death is identified in the row “probability (%) of death”",47.67%,83.99%,80.45%,46.54%,86.94%
66,images/F73.png," The table shows the mean absolute error (MAE) for three different methods in three different locations. The methods are probabilistic, fuzzy, and antonyms. The locations are office, hall, and corridor. The best method for each location is the one with the lowest MAE.

For the office, the best method is probabilistic, with an MAE of 0.2115. For the hall, the best method is also probabilistic, with an MAE of 0.1985. For the corridor, the best method is antonyms, with an MAE of 0.0767.","PLWH less frequently presented with pneumonia and/or PaO2/FiO2 <300 at hospital admission in all age and CD4 cell strata when compared to the general population group (P <0.001). PLWH had a median CD4 cell count of 395 (IQR 161-620) cells/mm3 with a proportion of subjects with an HIV-RNA <50 cp/mL of 76.1% (Table 2). When compared to the general population group, a higher proportion of PLWH did not require oxygen supply during the hospital stay in all age and CD4 strata (P <0.001) (Supplementary Table 2). The highest proportion of subjects requiring intensive care assistance was observed among PLWH <65 years with CD4 cell count ≤200 cell/mm3 (19.4%) followed by those aged <65 years in the general population (10.5%). Regarding pharmaceutical interventions during the hospitalization, PLWH were exposed with a lower frequency to heparin in all age and CD4 strata (P <0.001), steroids (P <0.001) and hydroxychloroquine (P <0.001) when compared to the general population group, whereas no evidence for a difference in remdesivir use was observed (P = 0.639), such as for monoclonal antibodies (P = 0.718), early antiviral treatments (P = 0.146), immunomodulant agents (P = 0.149).",25.26%,52.88%,78.67%,13.77%,86.93%
67,images/F74.png," The tree representation of an XML document fragment is a hierarchical data structure that represents the elements and their relationships in the XML document. The root node of the tree is the document element, and the child nodes are the elements that are contained within the document element. The child nodes can be either element nodes or text nodes. Element nodes represent the elements in the XML document, and text nodes represent the text that is contained within the elements.

The tree representation of an XML document fragment can be used to navigate the document and to access the data in the document. For example, to find all of the elements that have a particular name, you can traverse the tree and find all of the nodes that have that name. To get the text that is contained within an element, you can find the text node that is a child of the element node.

The tree representation of an XML document fragment is a powerful tool that can be used to access and manipulate the data in an XML document.","Fever categories and the number of cases in each range are provided in the Table 4. However, the temperature range did not influence the clinical outcome in the cases presented here (Table 4). In previous studies, sepsis and COVID-19 were influenced by the temperature trajectory during the sepsis [30,31], and it would be interesting to investigate whether the temperature trajectory can influence the clinical outcome of COVID-19 in a similar manner.",41.69%,73.56%,80.37%,41.80%,78.16%
68,images/F75.png," The figure shows the workflow of a distributed XML query using the MapReduce framework. The client submits a job to the master, which splits the input data into blocks and assigns them to the mappers. The mappers read the data blocks, extract the key-value pairs, and write them to the local disk. The master then shuffles and sorts the intermediate data and assigns the sorted data to the reducers. The reducers read the sorted data, aggregate the values for each key, and write the results to the output.","In Fig. 34, it shows a comprehensive analysis of a novel clustering method. The proposed system uses all attributes only once for processing when developing data clusters in three-dimensional format, so it is free from intrinsic threats. Similarly, there is no violation of results when exchanging the positions of attributes as mentioned in figures (Fig. 20, Fig. 21, Fig. 22, Fig. 23, Fig. 24, and Fig. 25), so it is free from extrinsic threats. Furthermore, a novel clustering method uses three algorithms to provide consistent data in all clusters. Finally, the proposed algorithms (Algorithm 1, Algorithm 2, Algorithm 3) provide good time complexity, which is about T (n) = 𝑂(𝑛).",17.21%,78.35%,82.46%,34.22%,84.76%
69,images/F8.png," The graph shows the number of papers and codes related to four different aspects of research: frameworks, generalisability, reliability, and validity. The number of papers is shown in the black bars, while the number of codes is shown in the grey bars. The highest number of papers is in the validity category, followed by generalisability, reliability, and frameworks. The highest number of codes is in the validity category, followed by frameworks, generalisability, and reliability.","To obtain a more global evaluation of the obtained maps Obt we also calculated the Mean Absolute Error (MAE) with respect to the reference map Ref (the results can be seen in Table 4). For a more global comparison we also calculated the Mean Absolute Error (MAE), obtaining as result that antonyms-based method has the smallest MAE in the three environments, as can be seen in Table 4, and therefore it can be considered more accurate than the other methods, since the map obtained is closer to the reference map.",33.56%,76.29%,81.92%,36.29%,76.76%
70,images/F9.png, The Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) flow diagram of the study selection process.,"XPath is an expression language that can process values conforming to the data model, which provides a tree representation of XML documents, as shown in Fig. 2. XPath is, fundamentally, a general purpose language for addressing, searching, and matching pieces of an XML document. The semantics of the language is based on a representation of the information content of an XML document as an ordered tree [6]. The result of an XPath expression may be a selection of nodes from the input XML documents",22.77%,74.92%,79.46%,1.10%,80.01%
71,images/s1.png, An illustration of the cGAN training procedure,"When processing a distributed XML query on a large amount of XML data, we use the HDFS as the data storage system and MapReduce as the programming framework. In this section, we present the process, which involves three steps, as shown in Fig. 4. First, we split up the XML data using XMLInputFormat, which decides how to partition an input file into file-splits, suitable for XML grammar rules. Then the file-splits are provided as input to the distributed storage system. Normally, these parsing and partitioning operations are only executed once for a massive XML document. In the second and third steps, we execute a parallel query, which includes a distributed XPath query and a Twig query. The results of these queries are presented to the MapReduce job on the Hadoop platform. During the Map operation, clusters perform parallel computations for XML queries on all computers that store XML data splits, while in the Reduce operation, all the intermediate results are collected to generate the final result.",18.18%,75.94%,80.85%,0.00%,83.33%
72,images/s10.png," In this image, you can see the complete data preprocessing pipeline, which consists of the following steps:

1. Data Extraction from Time Series Data: In this step, the raw time series data is extracted from the dataset. 
2. Feature Extraction: In this step, the relevant features are extracted from the raw time series data. In this case, these features include speaking duration, number of utterances, number of interruptions, valence, arousal, and dominance.
3. Data Cleaning: In this step, the data is cleaned by removing any missing values or outliers. 
4. Feature Engineering: In this step, the features are engineered to make them more suitable for the machine learning model. This may involve feature selection, dimensionality reduction, or other techniques.
5. Model Training: In this step, the machine learning model is trained using the preprocessed data. 
6. Model Evaluation: In this step, the performance of the machine learning model is evaluated using a holdout test set.","The generator, depicted in Figure 3, aims to create realistic missing value imputations. It takes three inputs: Real Time Series (xk): The actual air pollution data points surrounding the missing value. Real Predicted Value ( xk+1): The predicted value for the next time step based on the available data. Gaussian Noise Vector (z): A random noise vector that introduces variability and helps the generator create diverse imputations.",31.56%,88.99%,82.95%,38.92%,75.19%
73,images/s100.png, Table 1: Performance on the prediction of initial codes measured in terms of the evaluation scheme shown in Figure 4. The inclusion of expert feedback into the prompt results in notable improvements across the board.,"Once the C-GAN is trained, it can generate potential values to fill in the missing data points. However, there might be some uncertainty associated with these generated values. To address this, Bayesian inference is applied; see Figure 5",15.82%,86.38%,85.76%,37.59%,68.12%
74,images/s101.png,Error: Invalid response from model,"Air pollution forecasting is a promising application of time series prediction using neural networks (NNs). Researchers typically aim to predict concentrations of various pollutants, such as PM10, PM2.5, sulfur dioxide, carbon monoxide, and nitrogen oxides, in parts per million (ppm) [18]. Existing studies on air pollution forecasting with NNs often focus on spatio-temporal series, incorporating factors like air velocity, temperature, and wind direction [19]. While over 139 studies utilizing NNs for air pollution forecasting were published between 2001 and 2019, only 70 specifically focused on feedforward NNs for forecasting (see Table 1).",0.00%,52.93%,79.10%,0.00%,66.93%
75,images/s102.png,Error: Invalid response from model,"The block scheme of the OFDM chirp communication system architecture is illustrated in Figure 1. Firstly, the communication data bits are divided into parallel streams via serialto-parallel (S/P) conversion, and mapped into complex modulation symbol sequences according to different modulation schemes",0.00%,63.46%,81.39%,0.00%,69.79%
76,images/s103.png,Error: Invalid response from model,"The block diagram of OFDM chirp receiver with phase noise estimation and compensation is shown in Figure 2. The phase noise mitigation can be carried out either by CPE correction only or simultaneously CPE and ICI suppression. While the latter should firstly estimate the phase noise utilizing ML and LMMSE, and then the de-correlation or cancellation approach can be applied to compensate the phase noise effect.",0.00%,61.09%,80.80%,0.00%,72.29%
77,images/s104.png," The table shows the frequency of the top five entries in each column of the OSHA 300 log. The most common Nature of Injury was fractures, which accounted for 35% of all injuries. The most common Part of Body Affected was the leg(s), unspecified, which accounted for 7% of all injuries. The most common Event or Exposure was highway-environmental, which accounted for 5% of all injuries. The most common Source of Injury or Illness was nonclassifiable, which accounted for 4% of all injuries.","Figure 1 provides an overview of the experimental methodology. Initially, it is essential to note that data about PD patients are typically limited due to confidentiality concerns. The experiments are divided into two distinct branches. The first branch serves as the control group and does not incorporate data augmentation techniques, while the second branch leverages three different forms of data augmentation. Subsequently, the workflow involves configuring model parameters and implementing a cosine annealing scheduler. This scheduler facilitates fine-tuning network weights and expedites convergence toward the optimal solution by dynamically adjusting the learning rate. The ultimate output of the process is a binary classification, where “0” signifies a healthy condition and “1” indicates the presence of PD.",31.08%,72.38%,80.78%,28.33%,74.29%
78,images/s105.png," The table shows the top 5 emerging words that influenced the evolutionary dynamics of cooperative behavior in terms of game outcomes (PC), defection (DD), cooperation (DC), and conflict (CD), as well as the fitness of the individuals. The words appeared at least 500 times across all genes. The highest-ranked word was ""skepticism"" which had a successful defection rate of approximately 26%. The individuals with personality traits containing ""environments"" achieved an average fitness of 2.980.","Table 1 provides the classification accuracy percentages for different deep learning models (VGG16, VGG19, ResNet18, ResNet50, ResNet101, Vit_base_patch16_224) across various augmentation methods (no augmentation, rotation and flipping, AugMix, and PixMix) and two different datasets (spiral and wave).",9.67%,88.59%,80.85%,36.04%,76.03%
79,images/s106.png," The table shows the results of a normality test. The Shapiro-Wilk statistic is a measure of how close the data are to being normally distributed. The p-value is a measure of the statistical significance of the test result. A p-value less than 0.05 is usually considered to be statistically significant.

For the language mindset variable, the Shapiro-Wilk statistic is 0.971 and the p-value is 0.350. This means that the data are not significantly different from a normal distribution.

For the corrective feedback preference variable, the Shapiro-Wilk statistic is 0.947 and the p-value is 0.047. This means that the data are significantly different from a normal distribution.

For the follow-up strategy based corrective feedback variable, the Shapiro-Wilk statistic is 0.905 and the p-value is 0.002. This means that the data are significantly different from a normal distribution.

In conclusion, the data for the language mindset variable are normally distributed, while the data for the corrective feedback preference variable and the follow-up strategy based corrective feedback variable are not normally distributed.","Figure 2 illustrates the structured approach taken in this study. It has three main phases: (1) dataset collection, (2) prediction calculation, and (3) prediction analysis.The IT support availability seems to be more important than the hardware maintenance for Saudi users. IT support is also an essential feature that impacts ICT users’ satisfaction with using ICT systems and their trust in the institution providing the system, as shown in Figure 2.",30.98%,76.59%,80.17%,38.07%,75.73%
80,images/s107.png," The table shows the CO2 separation performance of different materials. The CO2 GPU is the amount of CO2 that can be separated per unit of membrane area per unit of time. The CO2/N2 selectivity is the ratio of the amount of CO2 that is separated to the amount of N2 that is separated.

The table shows that the MMHFM material has a higher CO2 GPU and CO2/N2 selectivity than the pure Ultem HFM material. This means that the MMHFM material is a better material for separating CO2 from N2.","Table 1 summarises the most commonly used models in the literature. For example, different algorithms are utilised to predict the student’s academic success, including Random Forest (RF), Support Vector Machine (SVM), Gradient boosting, Decision Tree (DT), Logistic Regression (LR), Linear Regression, Extreme Gradient Boosting (XGBoost), and Artificial Neural Networks (ANNs). They achieved 97% accuracy using XGBoost [33]. Another variant of tree-based algorithms, the Gradient Boosting Machine (GBM), has been used to predict students’ academic performance in Brazil. With the ability to process enormous amounts of data quickly, the GBM was able to accurately predict student performance based on a variety of factors",23.82%,66.66%,80.91%,37.87%,82.65%
81,images/s108.png,Error: Invalid response from model,"The following section first describes the full pipeline, consisting of feature extraction, data cleaning, and feature engineering. This is presented in Figure 2. To curate the dataset that served as input to this pipeline, we extracted the nine time-series features from the MP4 files of the 17 teams that were included in the final dataset. The students who did not sign an informed consent form were excluded from the feature extraction and analysis using our visual speaker identification pipeline. Subsequently, all teamwork sessions in a day were concatenated and assigned to the corresponding daily PERMA scores, as scores were collected at the individual level and on a daily basis.",2.85%,56.15%,81.01%,0.00%,80.14%
82,images/s109.png," The table is a prompt template that can be used to generate prompts for different tasks. The table has three columns: Prompt Component, Prefix, and Instruction. The Prefix column contains a phrase that can be used to introduce the prompt. The Instruction column contains a phrase that can be used to instruct the user on how to complete the task. The Suffix column contains a phrase that can be used to provide additional information or guidance to the user.","In order to train the classification models, the best model per pillar was identified by grid search and LOOCV. The hyperparameters used to train the four selected models are listed in Table 2. For the knearest neighbor (k-NN) classifier, the hyperparameters used were the number of neighbors, distance weighting, and distance metric. For the random forest model, class_weight was set to balanced to account for imbalanced datasets, and the number of estimators in the ensemble and the maximum depth were chosen as hyperparameters to prevent overfitting.",40.58%,85.43%,82.26%,41.32%,85.45%
83,images/s11.png," The table shows the hyperparameters that were tuned for each classifier. 

For k-NN, the hyperparameters that were tuned were the number of neighbors (n_neighbors), the weights (weights), and the distance metric (metric). 

For random forests, the hyperparameters that were tuned were the number of estimators (n_estimators) and the maximum depth of the trees (max_depth). 

For XGBoost, the hyperparameters that were tuned were the learning rate (learning_rate), the maximum depth of the trees (max_depth), and the number of estimators (n_estimators). 

For CatBoost, the hyperparameters that were tuned were the learning rate (learning_rate), the maximum depth of the trees (max_depth), and the number of estimators (n_estimators).","The left tree in Figure 2 is a standard AST of the code given in the middle part, which contains complete information about the code. Given this AST, we can revert to its original code exactly. However, we want to mitigate the infinity and randomness of the possible text representations, so we should create an AST without variable names, like the tree on the right side. Unfortunately, the AST will not be able to maintain the semantics of the original code. Adding control flow edges and data dependence as indicated by the dotted lines would not work either. We need a solution and so our abstract syntax graph comes into play",40.38%,50.48%,79.89%,41.95%,76.83%
84,images/s110.png, The table shows the main characteristics and hyperparameters of the MarianMT model.,"we need a way to express the name dependence when names are absent. A solution is to add an edge of name dependence between two related nodes. After adding such edges, the tree structure turns into a graph structure as illustrated in Figure 3, which we call an abstract syntax graph. From the graph, we can construct a fragment of code with the exact semantics of the original code, but perhaps with a different text representation, which would not be a problem at all for the task of vulnerability detection.",27.31%,86.59%,83.83%,0.08%,79.10%
85,images/s111.png," The table shows the results of few-shot semantic parsing with Codex using various decoding strategies. The model is evaluated on three datasets: GeoQuery, SMCALFlow, and Overnight-BLK. The results show that the oracle grammar + program constraint decoding strategy achieves the best performance on all three datasets.","In the YOLO model, the authors use the C3 module as an essential part of the backbone network. The structure of the C3 module is shown in Figure 4. It is faster and more accurate than the CSPBottleneck, which can further extract feature information and Figure 3. The Channel Shuffle schematic (LighterFace). The data from different channels (red, blue, green) are not interconnected. Channel Shuffle can extract data from different channels and rearrange them to establish connections. In the YOLO model, the authors use the C3 module as an essential part of the backbone network. The structure of the C3 module is shown in Figure 4. It is faster and more accurate than the CSPBottleneck, which can further extract feature information and increase the depth and width of the network for better learning of semantic features in images. However, the degree of lightweight of the multiple separated convolutions it uses could be improved. According to the Rule i criterion of ShuffleNetv2, the higher the number of channels, the more significant the gap between the number of input channels and the number of output channels, which results in the C3 module running at a less-than-optimal speed on a CPU or ARM",43.79%,92.27%,81.57%,1.78%,80.10%
86,images/s112.png," The table summarizes the statistics of the TSCC corpus across the train, dev, and test sets. The train set has 2747 samples, with an average of 7.7 turns and 7.29 tokens per turn. The dev set has 305 samples, with an average of 7.92 turns and 7.21 tokens per turn. The test set has 273 samples, with an average of 5.23 turns and 8.27 tokens per turn.","Face detection is a crucial prerequisite for the stable execution of face recognition. The face detection algorithm LighterFace proposed in this paper is compared with other recent face detection algorithms, including TinaFace, Retina-Face, LFFD, and YoloV5; the comparison results are shown in Table 1. The dataset used is the WiderFace dataset, which is more widely recognized. For a better comparison, this paper u",17.88%,81.66%,81.09%,41.29%,75.22%
87,images/s113.png," Table 1: Dataset Features and Justifications for Assembly

Feature	Description and Justification
Title	Each paper’s title reflects the study’s focus, aiding in the preliminary selection process for relevance to the research themes.
Authors	The authors’ details offer insights into the paper’s credibility and the diversity of research affiliations and backgrounds.
Abstract	Abstracts provide a concise summary, crucial for initial screening and relevance assessment to the research themes.
Publication Date	Dates help to ensure the timeliness and relevance of the studies included in the review process.
Full Text	Access to the complete text is essential for a thorough analysis and review by the Mistral LLM.
Human Reviews	Inclusion of expert reviews serves as a benchmark for comparison with Mistral LLM’s performance, emphasizing the model’s adaptability and effectiveness across different scientific domains.","A comparison between the initial dataset and the new one is presented in Table 1. From an exploratory data analysis point of view, notable observations about our extended dataset must be made. As shown in Figure 1, he set is unbalanced, with “Defense Evasion” being the dominant tactic. “Privilege Escalation”, “Persistence”, “Execution”, “Discovery”, and “Lateral Movement” are also well represented. Some other tactics, like “Initial access”, “Collection”, “Credential Access”, “Command and Control”, and “Impact” still have hundreds of samples, while the rest of the tactics have few samples; more specifically, Exfiltration has 171 samples; Resource Development and Reconnaissance each have 170 samples.
",34.40%,73.15%,81.18%,44.10%,78.42%
88,images/s114.png," The table shows the results of the three repair approaches on the ARIE benchmark. The first column is the result type, the second column is the template-based approach, the third column is the LLM-BASE approach, and the fourth column is the AutoSD approach. The first row shows the number of plausible repairs, and the second row shows the number of correct repairs. The template-based approach has the highest number of plausible repairs, but the lowest number of correct repairs. The LLM-BASE approach has the lowest number of plausible repairs, but the highest number of correct repairs. The AutoSD approach has a number of plausible repairs that is in between the template-based and LLM-BASE approaches, and it has a number of correct repairs that is also in between the template-based and LLM-BASE approaches.","To take advantage of transfer learning capabilities and the text-to-text format, the training entries were adapted as shown in Table 2. The tactics formed of two words (e.g., Lateral Movement and Initial Access) were reduced to only one word (e.g., Movement and Access). The predictions contained padding sequences and also had the format of the labels shown in Table 2, so they had to be parsed and transformed into the original encoding to compute the scores.",39.73%,80.73%,81.09%,42.93%,80.65%
89,images/s115.png," The table shows the breakdown of the Galactica Corpus. The corpus contains 106 billion tokens in total. The largest source of tokens is papers, which account for 83% of the total. Code accounts for 6.9% of the total, reference material accounts for 6.5%, knowledge bases account for 2%, filtered CommonCrawl accounts for 1%, prompts account for 0.3%, and other sources account for 0.2%.","Figure 1 illustrates different models for sharing 5G network infrastructures, categorizing them into two groups: passive sharing and active sharing, where A and B represent two different MNOs [11]. Passive sharing involves the sharing of non-electronic infrastructure components, such as sites and towers, power supplies, and the physical elements of transport in backhaul, e.g., optical fibers. Site sharing is a common and straightforward practice that allows operators to maintain their competitive strategies. It is operationally simple since the equipment is independent for each operator, yet it can still provide longterm cost reductions. Active sharing refers to the sharing of electronic components of the network, including elements of the RAN, such as base stations, antennae, controllers, etc. It can also encompass spectrum sharing and even sharing the CN, including servers and network functionalities",24.69%,57.06%,80.10%,15.75%,77.24%
90,images/s116.png," The table shows the parameter size, accuracy, peak memory usage, and inference latency of LLM variants. The experiments in (a) are performed on PyTorch while the experiments in (b) are performed on llama.cpp.","The proposed architecture, exemplified in Figure 2, leverages network slicing and RAN sharing with the LBO roaming architecture described in Section 2.3. This figure illustrates three distinct network slices, each represented by a different color and dedicated to a specific client. As represented, while all UEs access the network through the shared RAN and the access and mobility management function (AMF), indicated by solid lines, each client has its dedicated slice, responsible for managing the session, along with the user plane function (UPF), session management function (SMF), and policy control function (PCF). In this example, two operator clients (Slice 2 and Slice 3), with their respective PLMN IDs 2 and 3, are requesting service via roaming agreements, while the non-operator client (Slice 1), with PLMN ID 1, does not require roaming agreements and is authenticated directly in the neutral host’s core",26.69%,90.70%,81.58%,1.88%,78.68%
91,images/s117.png," | Step | LLM's Role | Scientist's Role |
|---|---|---|
| Initial Interpretation | Provides a preliminary analysis of the XPS data based on the curve-fitting parameters. | N/A |
| Expert Review | N/A | Reviews the LLM's interpretation for accuracy and relevance to the specific material system. |
| Refinement and Contextualization | May provide further clarification or additional details upon request. | Refines the LLM's interpretation, adding in-depth contextual understanding and highlighting any overlooked aspects. |
| Formulation of Conclusions | Assists in drafting initial conclusions and recommendations based on the analysis. | Collaborates with the LLM in finalizing the conclusions and recommendations, ensuring they are grounded in domain-specific knowledge and practical considerations. |","Figure 3 represents the procedures undertaken to enable a new client on the neutral host network. The steps are slightly different depending on whether the client is an operator or not. For an operator client, we use roaming agreements to provide user authentication and set up the neutral host SEPP; whereas for a non-operator client, it is necessary to obtain a user database and set UDM and AUSF to perform the user’s aut",27.38%,41.88%,80.25%,42.45%,70.31%
92,images/s118.png," The table shows the three lexicons used in the study. 

The first lexicon is the NRC Emotion Lexicon (NRC EmoLex), which contains 14,154 terms and is used for emotion detection. 

The second lexicon is the NRC Emotion Intensity Lexicon (NRC EIL), which is also used for emotion detection and contains the same 14,154 terms as the NRC EmoLex. 

The third lexicon is the NRC Valence, Arousal, and Dominance Lexicon (NRC VAD), which is used for emotion classification and contains 20,007 terms.","This test, which used the evaluation scenario presented in Figure 6, measured the maximum throughput obtained in the utilization of the infrastructure and compared using our neutral host architecture, sharing resources with a network slice per different clients, and using the neutral host infrastructure as a traditional network operator, i.e., one client/one slice serving its users. Given the resource limitations of our testing hardware, we limited the maximum number of clients to test in our proposed architecture to four, resulting in four network slices. To overcome the limitations imposed by the VMs with UERANSIM, and to make it a fair comparison between the two configurations, the users were distributed across the same number of different UERANSIM VMs both in the single client configuration and in the configuration with four clients",31.03%,77.65%,80.00%,25.40%,84.62%
93,images/s119.png," The table shows the baseline LLM architectures used in the study. The models are listed in order of increasing number of parameters. The first column shows the name of the model, the second column shows the number of parameters, the third column shows the pre-training data, the fourth column shows the number of layers, the fifth column shows the number of heads, the sixth column shows the embedding size, and the seventh column shows the context length.","Referring to Figure 1, the entire set of operations essential for developing the proposed method emphasizes the implementation of a decentralized blockchain operation. This decentralization is instrumental and involves various actors, such as users, service providers, and product manufacturers. A strategically designed smart contract leverages this blockchain operation, facilitating many explicit functions crucial for the enrollment process, updating process, sales management, request, response management, and validation in the proposed SEaaS model",31.52%,84.93%,81.43%,41.13%,79.75%
94,images/s12.png," The image shows how variable names are removed from an abstract syntax tree (AST). 
The AST on the left has variable names, while the AST on the right does not. 
The variable names are removed by replacing them with unique identifiers.","Table 1 lists the simulation parameters used in the experiment. Of the 200 sensors, a scheme was devised in which a minimum of five and a maximum of ten seller nodes were randomly selected. These nodes express interest in selling the sensed data. Concurrently, the model considers another set of ten randomly chosen buyer nodes. Both sellers and buyers undergo a verification process, culminating in confirmation only after completing their enrollment.",16.50%,80.01%,82.65%,18.38%,81.81%
95,images/s120.png,Error: Invalid response from model,"Parts of speech and morphology constitute what we may call “shallow” syntactic features. These features reflect some syntactical structures, but do not represent them directly. In contrast, the “head_token_id” and “dep_rel” columns are a direct representation of syntactic organization. The head token is the item that is the immediate syntactic “parent” of a given token. The “dep_rel” reports the dependency-type label as specified in the UD annotation guidelines. The dependency relation specifies the type of grammatical structure between the parent and target. From these columns, we can calculate the grammatical structure of an entire sentence, as visualized in a dependency tree such as the one shown below (Figure 1).",1.36%,63.59%,79.90%,0.00%,73.29%
96,images/s121.png, Table 1. Performance on the prediction of initial codes measured in terms of the evaluation scheme shown in Figure 4. The inclusion of expert feedback into the prompt results in notable improvements across the board.,"Figure 1 gives an overview of the approach. The following processing steps are performed to organize text from posts. The association between posts and concepts is the result of step 3, whereas the summarization of recurrent concepts used in posts is the result of step 4",41.62%,92.31%,86.03%,38.25%,78.53%
97,images/s122.png,Error: Invalid response from model,"Figure 2 shows an example of a cluster identified in the ontology FND/TransactionsExt/MarketTransactions.rdf. The cluster is illustrated using a tree structure. The root node of the tree (the box on the left) shows the URI label of a class (in capital letters within the box) along with its definition (words in the box below the label). This root node is inherited by other URIs (in the center). The yellow node is a node that is inherited by other nodes (on the right). Each node shown is connected to posts obtained from Reddit. For each node, the number of posts connected to each ontology class is shown within round brackets beside the label.",1.12%,55.74%,80.43%,0.00%,71.93%
98,images/s123.png," The table shows the evaluation metrics for language models in PromptBench. The metrics are accuracy, fluency, and contextual understanding. Accuracy measures the correctness of the model's outputs against standard answers. Fluency evaluates the naturalness and readability of the text, focusing on grammar, syntax, and style. Contextual understanding assesses the ability to maintain coherence and reflect linguistic and cultural nuances over longer text spans.","The user’s workflow of the HMU-RLP is presented in Figure 3. After the user logs in to the HMU-RLP, the user then has to activate an activity. The main object in the RLP is the activity. The activity is the scenario or the experiment that will run on the RLP; everything begins with activity activation. The user activates an activity in the RLP and receives instructions about the scenario and also relevant documentation. After activation, the user creates the code required from the activity’s scenario in the Arduino IDE. It must be reassured that the code contains no syntax errors using the Arduino IDE Compiler. After verifying that the code is correct, the code is stored in the RLP users’ profile. The code must be compiled and uploaded in the Arduino experimental microcontroller.",46.65%,84.08%,81.88%,16.20%,75.15%
99,images/s125.png," The table shows the parameters for the models trained on the three materials information extraction tasks. The tasks are doping, MOFs, and general materials. The models are trained on 413 sentences, 507 abstracts, and 634 abstracts, respectively. The output format for the doping task is JSON, while the output format for the MOFs and general materials tasks is abstract.",Table 4 lists the main tasks of the application for users and administrator groups.,39.80%,78.23%,85.62%,38.98%,72.68%
100,images/s126.png, Table 3 summarizes the performance of different models on three datasets. We can see that BERT-BiLSTM-CRF outperforms other models on all datasets.,"Figure 1 illustrates the flow diagram of the primary study selection and analysis process. Using the inclusion and exclusion criteria detailed in Table 2, studies were filtered in several stages. Initially, the search yielded a total of 705 papers, 331 from Web of Science, 346 from Scopus, and 28 from other sources. After a preliminary review of the titles and abstracts, we identified 156 duplicate papers, reducing the selection to 549. Of these, 455 were discarded because they did not fully meet the established criteria, leaving out the least relevant studies. A more detailed evaluation of the full text of the remaining 95 papers led to the exclusion of a further 84, resulting in the final selection of 10 relevant studies. Zotero was used to organize and manage bibliographic references throughout the review.",14.23%,81.59%,82.75%,0.29%,76.29%
101,images/s127.png, Table 1 shows the collection of NLP tasks in the meta-dataset of the MatSci-NLP Benchmark.,"SLR aims to summarize, clarify, and examine the implementation of a BI system for decision support in HEIs, based on a roadmap that can serve as a benchmark for HEIs, from January 2017 to May 2023 inclusive. Table 1 presents the research questions (RQ) addressed in this review process.",20.28%,72.86%,84.55%,6.22%,83.61%
102,images/s128.png, The table compares the results of our approach with the results from [9]. The best results are shown in bold. Our approach outperforms [9] on all datasets except RTE.,"Figure 1 showcases ViT’s design, which involves dividing input images into small blocks, converting them to vectors, and then processing them through a Transformer. The encoder follows a traditional Transformer approach, incorporating embedded patches, layer normalization, and MSA. The MSA combines results from V and Q, enhances them through MLPs, and returns them to their original structure. Regarding image classification, ViT incorporates a unique token into the input, with its output as the final prediction. This adaptability allows ViT to excel in image classification tasks and leverage its sequential processing capabilities.",17.24%,60.89%,83.68%,6.10%,82.64%
103,images/s129.png," Table 1 shows the comparison of ratings of models or clinicians to expert recommendation. The top choice for the augmented model had substantial agreement with the expert (kappa = 0.31, 95% CI 0.28 to 0.35), as did the top choice for the base model (kappa = 0.34, 95% CI 0.27 to 0.41). When examining the poor choices, the augmented model and base model also had substantial agreement with the expert (kappa = 0.31, 95% CI 0.24 to 0.38 and kappa = 0.32, 95% CI 0.25 to 0.39, respectively). In the augmented model, black men and black women had almost perfect agreement with the expert regarding their top choice (kappa = 1.00, 95% CI 1.00 to 1.00 and kappa = 0.86, 95% CI 0.63 to 1.00, respectively). When examining the poor choices, black men and black women also had almost perfect agreement with the expert (kappa = 1.00, 95% CI 1.00 to 1.00 and kappa = 0.88, 95% CI 0.63 to 1.00, respectively). In the base model, black men and black women had substantial agreement with the expert regarding their top choice (kappa = 0.67, 95% CI 0.42 to 0.92 and kappa = 0.61, 95% CI 0.33 to 0.88, respectively). When examining the poor choices, black men and black women also had substantial agreement with the expert (kappa = 0.66, 95% CI 0.37 to 0.94 and kappa = 0.71, 95% CI 0.38 to 1.00, respectively). Overall, the augmented model and the base model had substantial agreement with the expert regarding their top and poor choices. Black men and black women in both models also had substantial agreement with the expert regarding their top and poor choices.","The original YOLOv8s object detection network focuses on capturin local information in feature maps to enhance the model's receptive field. However, for highly similar data, it may struggle to extract fundamental entity-specific features [48]. To address this issue, we propose a new object detector for detecting insulator damage defects, termed YOLOv8sSwinT (as shown in Figure 3). This model integrates Swin Transformer modules into the backbone and neck, facilitating global self-attention modelling during feature extraction. The traditional feature pyramid structure in YOLOv8s is replaced by an improved BiFPN Information 2024, 15, 206 6 of 15 structure, dynamically balancing features with different weight information across different scales. A small object detection layer is introduced to enhance the network’s ability to detect insulator damage defects",20.45%,65.03%,77.08%,36.97%,75.65%
104,images/s13.png," In this image, you can see how the variables a and b are declared in the first block, and then used in the second block. The arrow between the two blocks shows the name dependency between the two blocks. This means that the second block depends on the first block for the values of a and b.","Currently, deep-learning-based object detection methods primarily employ CNNs as backbone networks. However, convolutional structures are constrained by the size of convolutional kernels, limiting their focus to local regions of the feature map and rendering them less sensitive to global information. This limitation is particularly problematic for detecting small defective targets characterized by small volumes and limited feature information, which often results in feature loss and an increased risk of false negatives. This paper introduces a C2fSTR module designed to overcome the limitations of convolutional structures, enabling the model to better capture global gradient flow information while remaining lightweight. Its structure is shown in Figure 4",24.74%,83.91%,81.54%,21.41%,88.88%
105,images/s130.png," The table shows MAUVE scores with Chatbot Arena instructions as the target dataset. The best scores of DP models are marked in bold. Private synthetic instructions achieve significantly better scores than non-private but out-of-distribution FLAN instructions. Furthermore, filtering synthetic instructions with Algorithm 2 improves the scores by large margins.","The AI Literacy dimension recorded the highest average response (3.56), highlighting that the factor of using and applying AI had the highest average response (3.85), followed by the ethics of AI factor with an average of 3.73. Still in this dimension, the knowing and understanding AI factor had an average response of 3.46 and detecting AI was at 3.20 (see Figure 1). In fact, most respondents reveal the capacity to use and apply AI as well as saying they are able to act in an ethical way, regarding AI",17.79%,76.85%,82.31%,20.15%,72.85%
106,images/s131.png," The table shows the performance of different language models on two tasks: CrossSum and WikiLingua. The models are evaluated on their ability to generate coherent and fluent text. The results show that the models perform well on both tasks, with the best model achieving a score of 73.4 on CrossSum and 71.9 on WikiLingua.","In terms of correlations between dimensions, as presented in Table 4, there was a very high level of correlation resulting from the three-factor factor analysis, with correlation values from 0.501 to 0.766 between dimensions and values from 0.636 to 0.949 between the total dimensions and each of them. The results demonstrate that the first dimension is highly significant for the total dimensions, i.e., for AI Literacy in the sample.",25.55%,89.31%,84.89%,37.41%,77.15%
107,images/s132.png," The table shows the characteristics of the sensors dataset gathered. The dataset consists of 1299 tables, with a total of 163,981,050 rows and 10,487 columns. The average number of rows per table is 126,236.37, the average number of columns per table is 8.07, and the average number of numerical columns per table is 3.65. The maximum number of rows in a table is 324,000, the maximum number of columns in a table is 26, and the maximum number of numerical columns in a table is 20.","The system is deployed on a web client and a server, as shown in Figure 1. The web client displays a product catalog from a custom door manufacturer named Portes Milette in Quebec, Canada. For customers, the website allows the selection of different door characteristics. These characteristics are “Door model”, “Wood texture”, “Dyeing texture”, “Paint texture”, and ”Glass texture”. The global objective of the mandate was to enhance the visual perception of the doors by rendering high-quality images of the doors alone and in a home design context. Not every custom door fits every home design. The style, color, stain, and glass of the door must be aesthetic in terms of the characteristics of the home design. The type of room (bedroom, kitchen, bedroom) and its color must match the door. To complete the task, the selection of a suitable home design according to the door specifications and the generation of the images are done on the server side. Server software is used to communicate with the web pages. It receives requests from the web client, including the specifications of the door.",44.35%,75.14%,79.85%,19.29%,79.97%
108,images/s133.png, Table 5: Configurations applied for fine-tuning each model.,"The first part of the architecture constructs the training file and trains with these data using an RF classifier. Figure 2 shows this process. A random door/interior design is generated and displayed to a home design expert. This expert has to classify this image combination as either “YES” (1) or “NO” (0). “YES” means that the combination is aesthetically appealing, whereas ""NO"" means that the combination is not appropriate. A class label is assigned to each presented image, and a row is added to the training.csv file. Table 1 describes each feature in the training file.",3.98%,76.64%,83.70%,0.00%,61.01%
109,images/s134.png," **Decompose & Serialize**: The first step is to decompose the input data into a sequence of tokens. This can be done using a variety of methods, such as word segmentation or part-of-speech tagging. Once the data has been decomposed, it is serialized into a format that can be processed by the model.

**Tokenize**: The next step is to tokenize the data. This involves converting the sequence of tokens into a sequence of integers. Each integer represents a unique token in the vocabulary.

**Model**: The model is a deep learning model that is used to predict the next token in a sequence. The model is trained on a large dataset of text data.

**Aggregate**: The final step is to aggregate the predictions from the model. This involves combining the predictions from the model into a single output. The output is a sequence of tokens that represents the predicted text.","The proposed model is shown in Figure 1. This model aims to offer an extensive understanding of how these factors collectively influence the acceptance and intention of using voice assistants for shopping. By assessing these variables, the model intends to provide valuable insights into the dynamics of consumer behavior in the evolving domain of voice commerce",49.07%,75.01%,81.42%,42.34%,83.43%
110,images/s135.png," Table 1 lists the error types found in the study. The most common error type was the omission of a finding, which occurred in 15.8% of cases. This was followed by the misinterpretation of a finding, which occurred in 11.7% of cases. The least common error type was the inclusion of an extraneous finding, which occurred in 2.6% of cases.","Figure 2 underscore the significance of enjoyment and performance expectancy concerning perceived usefulness (H1 and H2). The presence of features related to enjoyment and performance expectancy contributes to an explanation of the perception of usefulness in voice shopping with VAs. These findings align with the work presented in [64] where the authors also highlighted the importance of emotions and expectations when using VAs, as evidenced through gratifications and emphasizing the role of emotions in shaping user experiences and expectations with VAs, and focusing on how user expectations and the gratifications sought from VAs influence their overall satisfaction and continued usage.",29.60%,73.39%,83.07%,26.24%,76.46%
111,images/s136.png," The table shows the summary of domain-wise uncertainty scores for the FOs dataset. The dataset contains 12 domains, and the table shows the average uncertainty score for each domain. The uncertainty score is calculated using the normalized predictive entropy and the semantic entropy. The higher the uncertainty score, the more uncertain the model is about the predictions in that domain.

From the table, we can see that the domain with the highest uncertainty score is Art, followed by Philosophy and History. This means that the model is most uncertain about the predictions in these domains. The domain with the lowest uncertainty score is Sociology, followed by Economics and Engineering. This means that the model is most certain about the predictions in these domains.","The purpose of the profile-matching (PM) module is to determine the target attitude from a given mask detected and segmented with Mask R-CNN or the mask resulting from the SS module. PM additionally renders the projectile profile from the determined target attitude to facilitate refined segmentation in the SS module, as described in Figure 5. There are two components in the PM module: mask-based pose estimation and profile matching, which involves differentiable rendering and optimization with respect to the pose parameters. The inputs of the PM module are the segmentation mask (the mask detected with Mask R-CNN or the segmentation masks resulting from the SS module) and the 3D projectile model.",50.08%,77.30%,81.84%,47.97%,82.59%
112,images/s138.png, The table summarizes the datasets used in the experiments. The first column is the name of the dataset. The second column is the maximum sequence length of the samples in the dataset. The third column is the total number of image-text pairs in the dataset. The fourth column is the number of image-text pairs in the training set. The fifth column is the number of image-text pairs in the validation set. The sixth column is the number of image-text pairs in the test set. The seventh column is the average number of tokens per sample in the dataset.,"The workflow of 2D TETRIS is given in Figure 10. The input of the network consists of the target chip that contains the flying projectile and a given shape prior in the form of a binary template, as shown in the purple dashed box. The network consists of two modules: a transformation prediction module and a template warping module. The output is a warped template serving as the segmentation of the flying projectile.",60.52%,88.91%,82.49%,48.30%,83.30%
113,images/s139.png," The figure shows the process of how the system works. The user inputs a question, which is then processed by the LLM1 model to generate a probe. The probe is then sent to the LLM2 model, which provides an answer. The answer is then sent back to the user.",Figure 1 shows the overall design of this study including the evaluation where the proposed method is compared against similar approaches.,37.18%,76.68%,85.60%,41.50%,80.97%
114,images/s14.png," This is a diagram of a residual block, a common component of convolutional neural networks. The residual block consists of two convolutional layers, each followed by batch normalization and ReLU activation. The output of the second convolutional layer is added to the input of the residual block, and the result is passed through a final ReLU activation. The residual block is designed to allow the network to learn more complex features by adding a shortcut connection between the input and the output. This helps to alleviate the problem of vanishing gradients, which can occur when the network is very deep.","Figure 2 depicts a visual overview of the JTS framework. Further along in this paper, we assumed that the model input is a collection of short-form textual social media posts x1, x2, . . . , xn, n ∈ N.",27.40%,86.60%,82.42%,38.67%,69.56%
115,images/s140.png," The table shows the evaluation metrics for LLM-generated ransomware policies. The metrics are divided into three categories: relevance, effectiveness, and efficiency. 

The relevance category includes the following metrics: coverage, clarity, consistency, and adaptability. 
* Coverage measures the extent to which the policy addresses known ransomware vectors. 
* Clarity measures the ease of understanding and implementing the policy. 
* Consistency measures the absence of conflicting directives within the policy. 
* Adaptability measures the ability of the policy to evolve with the changing ransomware threat landscape.

The effectiveness category includes the following metrics: compliance, effectiveness, and efficiency. 
* Compliance measures the adherence of the policy to legal, ethical, and regulatory frameworks. 
* Effectiveness measures the demonstrable mitigation of ransomware threats. 
* Efficiency measures the resource utilization in implementing the policy.

The usability category includes the following metrics: usability and auditability. 
* Usability measures the ease of integration into existing cybersecurity frameworks. 
* Auditability measures the traceability of policy decisions and modifications.","we propose an innovative approach to incorporate artificial attention priors into the backbone network’s pipeline, termed the Attention-Enhanced Branch. This branch allows for the customization of prior types based on specific tasks. In the cell segmentation domain addressed in this paper, where the primary task involves cell identification, the most pronounced feature of cells is the morphology of their edge membranes. Therefore, we chose an edge filter to extract features of the cell membrane and integrated it as a strong prior into the feature extraction network. Considering computational complexity and algorithm interpretability, we used a traditional image edge detection filter as the edge attention enhancement module. The modulation is performed through a learnable Fusion Gate, which controls the proportion of edge prior information integrated into the backbone network. The structure of the edge detection branch is shown in Figure 3.",47.01%,88.54%,80.83%,45.91%,76.95%
116,images/s141.png," TABLE 1 Summary of LLM applications to protein analysis, modeling and design (see text for more details).","Based on the characterization of the selected variables and a general understanding of the market structure, we have established a Structural Causal Model that depicts the landscape of our target market. Figure 6 illustrates the causal graph, outlining the relationships among the variables included in the model.",4.98%,76.91%,84.59%,7.05%,74.93%
117,images/s142.png," Table 1. Entity types.

Chinese Name | English Name | Interpretation
------- | -------- | --------
疾病 | Disease | Entities used to describe various diseases or pathological states in TCM.
症状 | Symptom | Subjective feelings or objective manifestations experienced by patients during the course of a disease, such as fever.
药物 | Drug | Various herbs, plants, minerals, and animal tissues used in TCM.
方剂 | Prescription | Combinations of herbs used in TCM prescriptions.
饮食 | Diet | Specific foods and food combinations emphasized in TCM health preservation and regulation.
治疗方法 | Treatment methods | Methods used for treating diseases in TCM.
病因病机 | Etiology and pathogenesis | Refers to the causes and mechanisms of disease occurrence and development. Etiology refers to the factors leading to the onset of a disease, such as external wind-cold, emotional imbalances, etc. Pathogenesis refers to the mechanisms and patterns of disease development, such as qi stagnation and blood stasis, yin deficiency with yang excess, etc.","The bands of interest, the spectrum portions to be sensed, and the operators assigned to each band are summarized in Table 1. The bands selected for the experiment are paired (operating in FDD mode), and sensing was performed on the downlink sub-bands, considering that it is easier and more reliable to measure them since transmission is carried out from a single point, the BTS (Base Transceiver Station).",27.73%,60.56%,78.83%,40.65%,72.40%
118,images/s143.png," The rubric shown is an example of an analytic coding rubric. This rubric is used to code data on the tradeoffs between water and energy in the production of biofuels. The rubric is divided into two parts: Part A and Part B.

Part A of the rubric is used to code the impacts of biofuels production on water resources. The bins in Part A are:

* Increased water consumption
* Water scarcity/not enough water total
* Generally less water/decrease in water available
* Less water for other things
* Change in human behavior in water use
* Water prices change
* Changes to river
* Impacts to biodiversity/wildlife/ecosystem

Part B of the rubric is used to code the impacts of biofuels production on energy resources. The bins in Part B are:

* Less food produced
* More land converted to meet food needs
* More water use
* Less water available
* Energy produced (corn creates biomass energy)
* Energy return on investment (ethanol is less efficient/lower EROI than other sources)
* Renewable energy, more sustainable energy, lower environmental impact source of energy

The rubric can be used to code data from a variety of sources, including interviews, surveys, and observations. The data can be used to identify the key tradeoffs between water and energy in the production of biofuels. The rubric can also be used to track changes in the tradeoffs over time.","The parameters for sensing (measurement) are shown in Table 2. The abbreviations in Table 2 correspond to the following: • BT: Total bandwidth of the observed band. • NCH: Number of channels (or frequency sub-blocks) scanned during the TR period. It depends on the specific observation objectives and hardware limitations used for measurements. • B: Bandwidth to sense in each iteration period. B = BT/NCH. • fs: Sampling frequency. fs = B. • Ts: Sampling period. Ts = 1/fs. • NFFT: FFT size. • ∆f : Frequency step (frequency resolution). ∆f = B/NFFT. • T: Sampling duration (duration of the waveform sampled at fs Hz). T = ∆f × NFFT. • K: Number of times the sampling is repeated on a channel. • NF: Total number of samples taken per measurement. NF = K × NFFT. • TM: Actual (net) measurement time for a channel or frequency. TM = NF × Ts = K × T. • Tproc: Processing time (includes tuning, post-processing, storage, etc.). It is estimated that approximately Tproc = ½ TM. • Tobs: Observation time (TM + Tproc). • TR: Iteration time. It is the time needed to measure all channels/frequencies (perform a scan). TR = Nch × Tobs. If only one channel is measured, TR = Tobs. • TI : Integration time, referring to how often an iteration is performed. TI > TR. It can be 5 min, 1 h, 1 day, or TT. • NI : Number of iterations (integrations) performed during the TT. • TT: Observation duration. TT = NI × TI . If only one iteration is performed, TT = TI . • NT: Total number of samples taken over the entire bandwidth BT (during the TR time). NT = NF × Nch. • N: Total number of samples taken in the channel during the TI . • NO: Number of measurements whose level was above the threshold. • TO: Occupation time. TO = NO × TR. • U: Threshold that defines whether there is occupation or not. • FCO: Occupation of the frequency channel. FCO = TO/TI ; if TI
is constant, FCO = NO/N. • FBO: Occupation of the frequency band. FBO = NO/N, considering the entire band. • SRO: Spectrum resource occupation. SRO = NO/N, considering the entire measured spectrum. If only one channel is measured, SRO = FCO.",30.49%,74.90%,77.65%,24.24%,85.48%
119,images/s144.png," The DALL-E model is a neural network model trained to generate images from text prompts. It is a transformer model, which means it uses attention to learn relationships between different parts of the input text and generate an image that is relevant to the text.

To generate an image, the DALL-E model first encodes the text prompt into a vector of numbers. This vector is then used to initialize the model's internal state. The model then decodes the vector into an image by repeatedly applying a series of operations to the vector. These operations include convolutions, which are used to learn spatial relationships between pixels, and self-attention, which is used to learn relationships between different parts of the image.

The DALL-E model is capable of generating a wide variety of images, from realistic photographs to abstract paintings. It can also be used to generate images that are based on a combination of different text prompts. For example, you could use the DALL-E model to generate an image of a cat wearing a hat, or an image of a car driving down a road.

The DALL-E model is a powerful tool that can be used to create new and interesting images. It is still under development, but it has the potential to revolutionize the way we create images.","The study employs convolutional neural networks (CNNs) based on deep learning to categorize images sourced from the Fashion-MNIST dataset. To enhance the learning process, the researchers utilized three CNN architectures integrated with batch normalization and residual skip connections. Table 1 presents the literature for detecting attire with machine learning and other computer vision base methodologies.",25.41%,91.15%,82.62%,37.63%,85.75%
120,images/s145.png," Table 1 lists the features used in the LTR model. We use four categories of features: (i) basic statistics of terms in the table, (ii) BM25, (iii) query likelihood, and (iv) Word Frequency (WF).","The ResNet152 [25–27] model is a critical deep-CNN architecture in CV-computer vision. Its inception can be traced back to the seminal research paper where its innovative design first took center stage. ResNet152′ s distinctive feature is its ability to overcome this challenge. By incorporating skip connections, which allow information to flow more efficiently, it has enabled the training of profound networks. This architectural breakthrough has led to ResNet50 consistently delivering state-of-the-art performance in various image-related applications, solidifying its reputation as a pioneering force in CV. Figure 5 presents basic architecture diagram of ResNet152",18.24%,48.04%,81.62%,8.30%,82.22%
121,images/s146.png," The table shows the autoencoder parameters and performance ordered by increasing validation loss. The best model has the lowest validation loss, which is 0.339. This model has an embedding dimension of 100, a batch size of 64, and a training loss of 0.534.","Table 3 provides a detailed overview of the specifications and configurations of the neural network models utilized in this research study. Model have meticulously tailored two prominent architectures, ResNet152 and EfficientNetB7, for image analysis tasks. These models have undergone training with images resized to a uniform 224 × 224-pixel dimension, ensuring consistency in dataset input. The training process spans ten epochs, reflecting the depth of learning and model refinement achieved during the training phase.",32.48%,91.35%,84.55%,25.26%,78.01%
122,images/s147.png, Figure 1: Taxonomy of LLM explainability techniques.,"Within Table 4, the capabilities of three models are exploited to assess their efficacy. The baseline models, EfficientNetB7 and ResNet152, are pivotal criteria for comparison. The EfficientNetB7 model, with an accuracy of 0.91, demonstrates remarkable performance, boasting precision, recall, and F1 scores ranging from 0.91 to 0.92. Conversely, the ResNet152 model excels with an accuracy of 0.86, distinguished by notable precision (0.86) and recall (0.86), peaking in an impressive F1 score of 0.86. These baseline models lay a solid foundation for evaluating the proposed hybrid Learning Model. The Hybrid Learning Model emerges as the unequivocal, with an accuracy soaring to 0.94. Beyond its accuracy, this model exhibits improved precision (0.94) and recall (0.94), achieving an equilibrium culminating in a commendable F1 score of 0.94. This outstanding performance underscores the potential of the hybrid learning model to recognize attire prediction, promising a future where recognition accuracy reaches new heights. These meticulous model evaluations corroborate the effectiveness of the proposed model and shed light on its capacity to drive unparalleled advancements in attire prediction.",6.55%,60.92%,81.76%,0.00%,71.65%
123,images/s148.png," The table shows statistics of the dataset. The dataset contains 10 projects, with a total of 283 bugs. The number of bugs per project ranges from 5 to 73. The average number of bugs per project is 28.3. The average number of single-hunk bugs per project is 16.2. The average number of lines of code changed per bug is 4.65. The average number of tokens changed per bug is 28.76. The average length of the issue title is 10.53 words. The average length of the issue description is 231.92 words.","Figure 1 shows the diagram representing the IMIS-DBN design. The model comprises two main components: feature selection and detection. The dataset is used as input to the feature selection (IMIS), in which several procedures like initial relevance estimation, weight adjustment, update relevance score, and top n features selection take place. Then, the selected features are used as input to train a DBN classifier for the detection model",24.37%,77.39%,81.00%,40.74%,72.44%
124,images/s149.png," The table shows the experimental results of automatic evaluation. The scales marked with (-) mean that the lower the score is, the better the data quality is. Conversely, those with (+) imply that the higher the score is, the better the quality is. SELF-BLEU represents SELF-BLEU, which measures the coherence of the generated text. Div represents token diversity, the number of unique vocabulary tokens utilized. Tox represents PerspectiveAPI toxicity. Bold numbers and underlined numbers are the first and second best quality groups according to post hoc tests, respectively.","In Table 1, The performance evaluation using Python profiler demonstrates the proposed IMI technique’s computational efficiency compared to related techniques (RCGU, EMRMR, MIFS, and JMI). IMIS shows the lowest per-call execution time (0.01 s) and total time (Tottime) (3.5 min), significantly outperforming others in training time as well (19 min). This improvement can be attributed to the incremental nature of IMIS, which selectively updates feature relevance with incoming data, reducing unnecessary computations and enhancing adaptability",28.24%,88.19%,81.78%,41.67%,79.58%
125,images/s15.png, 表格展示了CSPNet在CPU和ARM上的推理速度。可以看出，CSPNet在CPU上的推理速度为69.66ms，在ARM上的推理速度为4578ms。CSPNet-ShuffleBlock在CPU上的推理速度为37.16ms，在ARM上的推理速度为1423ms。CSPNet-ShuffleBlock+在CPU上的推理速度为39.50ms，在ARM上的推理速度为1543ms。GAMA-Attention在CPU上的推理速度为ms，在ARM上的推理速度为ms。,"Table 2 shows the top 10 API call features identified by IMIS. It can be observed that these features are directly linked to the actions ransomware typically performs, which makes them crucial to understanding ransomware behavior. Crypto APIs like CryptEncrypt and CryptGenKey are vital for encrypting files, a hallmark of ransomware attacks. File access APIs, including CreateFile and DeleteFile, are used for accessing and potentially altering or deleting files, indicating unauthorized file manipulation. Network APIs such as WinHttpConnect and WinHttpOpenRequest are essential for establishing network connections, possibly for data exfiltration or command-and-control communication. The high relevance and ranking of these APIs underscore the ability of the proposed IMIS technique to identify the crucial features necessary for detecting ransomware activities.",0.00%,31.10%,74.56%,0.00%,0.00%
126,images/s150.png," The figure shows the steps involved in constructing a knowledge graph from scientific tables. The first step is to parse the table and identify its structure and syntax. The next step is to flatten the table, which means converting it into a one-dimensional array. The third step is to link the entities in the table to Wikidata, which is a knowledge graph that contains information about millions of entities. The fourth step is to perform joint inference, which means combining the information from the table and Wikidata to create new knowledge. The final step is to generate triples, which are the basic units of knowledge in a knowledge graph.",Creating a network dataset poses formidable challenges owing to network traffic’s dynamic and heterogeneous nature. The general roadmap is illustrated in Figure 1.,21.99%,88.67%,84.04%,37.00%,77.77%
127,images/s151.png," Table 2 shows the test accuracy of different models. Our model achieves the highest accuracy on all datasets. Among the interpretable baselines, Bag of n-grams performs the best. The black-box baselines perform better than the interpretable baselines, with BERT finetuned achieving the highest accuracy. Our model outperforms all the baselines, demonstrating the effectiveness of our approach.","The proposed architecture in Figure 2 shows a comprehensive network configuration to present a real-world corporate environment. This architecture is designed to emulate the complexities and vulnerabilities inherent in such environments, including the potential for DDoS attacks. We have structured the architecture within this environment to reflect typical organizational dynamics. The victim’s VPC represents the internal network of a typical company. It includes four Windows machines for daily normal user activities, such as web browsing and email checking. These users exemplify the end-users typical of the company’s operational environment.",29.59%,90.74%,82.92%,25.76%,78.60%
128,images/s152.png," Table 1 shows the main quantitative results of our text-to-figure generation models. We report the number of parameters, the CFG score, FID score, IS score, KID score, and OSR-SIM score. The best results for each metric are shown in bold.

As can be seen from the table, our FigGen model with a BERT-8 layer text encoder achieves the best results on the CFG, IS, and OSR-SIM metrics. The FigGen model with a BERT-32 layer text encoder achieves the best results on the FID and KID metrics. 

Overall, our FigGen model with a BERT-8 layer text encoder is the best performing model on the majority of the metrics, and is therefore our preferred model.","Table 1 furnishes detailed information regarding the captured data, delineating the specific days allocated for benign and adversarial traffic capture. The data highlights a significant trend, indicating that over 90 percent of all user behavior on the network side, irrespective of the specific activity, is associated with the TCP protocol. This prominence underscores the importance of analyzing TCP behavior and implementing effective methods to mitigate potential malicious activities",35.64%,87.08%,82.45%,44.54%,84.27%
129,images/s153.png," The table shows the benchmark performance of LLMs in tourism NLP tasks. The models are evaluated on four tasks: sentiment analysis, named entity recognition (NER), question answering (QA), and text summarization. The results show that the models achieve high accuracy and F1 scores on all tasks. The efficiency of the models is also high, with the exception of the TravelGPT model.","The first requirement prevents merging states that have different optimal actions. The second defines the transitivity of the mapping function. The last requirement states that the potential of using the described representation function depends on the efficiency of dimension reduction: if no significant reduction can be reached, then the method cannot raise the efficiency of the learning process. According to the above requirements, we design a modified Q-table-based policy iteration method by integrating a discretization step into it. In the simplest RL framework, the agent observes its states directly and takes its actions accordingly. In our approach, the agent takes observations, determines the simplified state, and takes actions based on it. So observations determine the state, but observation space differs from state space: the first one is a mixed-integer space, while the last one is purely discrete. The key component in the process is the state space definition and its projection. We suggest maintaining a compression-based Q-table learning process due to the following steps, which are summarized in Figure 1",53.01%,88.59%,82.12%,9.43%,81.13%
130,images/s154.png," The table summarizes the large language models. The training corpus, vocabulary size, model size, number of layers, hidden size, maximum sequence length, and date of each model are listed.","Table 2 summarizes the increase in Q-table size by episodes for the gridbased method and the Q-compression method. It shows that the Q-table continuously grows using the grid-based discretization method, even if with decreasing momentum. In contrast, the Q-compression method keeps the Q-table compact, which definitely supports the better learning capability that we observed in the achieved objective values.",28.08%,81.48%,83.90%,14.30%,83.95%
131,images/s155.png," The table shows the accuracy (Acc.) of different models on the ScienceQA dataset across natural science (NAT), social science (SOC), and law (LAN) domains. The models are evaluated on zero-shot in-context learning and supervised learning settings. The best results of LLMs with different hints are shown in bold.

In the zero-shot in-context learning setting, the best performing model is InstruGPT w/ Analogy with example, which achieves an average accuracy of 73.77% across all three domains. This model is followed by InstruGPT w/ CoT and Chatbot w/ Analogy with example, which achieve average accuracies of 73.41% and 72.34%, respectively.

In the supervised learning setting, the best performing model is LLMA-Adapter, which achieves an average accuracy of 85.68% across all three domains. This model is followed by UnifiedQA and Human, which achieve average accuracies of 83.50% and 87.56%, respectively.

Overall, the results show that LLMs can achieve high accuracy on the ScienceQA dataset, even in the zero-shot in-context learning setting. However, the performance of LLMs is still significantly below that of humans.","Table 5 shows, the grid-based method grows the Q-table to an average size of 2672 records, while the Q-compression method keeps the Q-table very compact by having 146 records on average, which definitely supports the better learning capability that we observed in the achieved objective values.",36.69%,87.08%,82.47%,39.22%,72.40%
132,images/s156.png," The figure shows the workflow of using DALL-E for dataset creation in this research focusing on fruit crops in agriculture. The input is a text description of the desired image, and the output is a generated image that matches the description. The text encoder converts the text description into a vector of numbers, and the image encoder converts the input image into a vector of numbers. These two vectors are then concatenated and passed through the decoder, which generates the output image.","The Docker-based Flutter development environment is designed and implemented for novice students to start mobile application developments without struggling in complex environment setups. In this environment, they can start the mobile application learning process by modifying the exercise Flutter projects included in the environment. Figure 1 shows the overview of the environment.",35.29%,84.54%,83.79%,44.72%,80.69%
133,images/s157.png," The table shows the dataset statistics and examples of the NSR-1K benchmark for image layout planning and text-to-image (T2I) generation with an emphasis on numerical and spatial reasoning. The dataset contains 14,890 training examples, 197 validation examples, and 114 test examples for the single category task. For the two categories task, there are 7,402 training examples, 197 validation examples, and 100 test examples. For the comparison task, there are 7,402 training examples, 100 validation examples, and 100 test examples. For the natural T2I spatial reasoning task, there are 9,004 training examples, 351 validation examples, and 199 test examples. For the two categories T2I spatial reasoning task, there are 360 training examples, 99 validation examples, and 84 test examples.","To help students complete the projects in the exercises, we provide the modification guidance to each exercise. Table 1 lists the essential items as the guidance for successful completions of the three exercises.",19.33%,87.49%,81.43%,37.85%,63.58%
134,images/s158.png,Error: Invalid response from model,"Table 2 shows the four questions to the students and their answers from the students that were collected through Google Forms. The results show that many students are familiar with GitHub and VSCode. This suggests that the utilization of the proposed environment may not pose significant challenges for them. Conversely, fewer students are acquainted with the mobile app and Docker. This development-environment-setup exercise becomes a valuable opportunity for students to know the important tools for software development",1.76%,58.01%,81.57%,0.00%,81.29%
135,images/s159.png,Error: Invalid response from model,"Figure 1 illustrates the essential elements of the DL framework under review, including a collection of Raspberry Pi and Odroid devices, virtual machines, and a centralized server responsible for consolidating parameters from the user community",3.70%,62.64%,82.52%,0.12%,73.29%
136,images/s16.png," The table shows the number of samples in the initial dataset and our dataset. The initial dataset contains 2563 samples, while our dataset contains 16285 samples. The number of samples in our dataset is significantly larger than the initial dataset. This is because we have oversampled the minority classes in the initial dataset. Oversampling is a technique used to increase the number of samples in a dataset by duplicating the samples from the minority classes. This helps to balance the dataset and make it more representative of the real world.","The virtual clients were allocated access to all system resources, ensuring consistent performance and enabling seamless integration with the federated learning framework. The specifications of the hardware used in this experiment are summarized in Table 1, which compares the capabilities of all different client types, including CPU speed, RAM size, storage capabilities, and other relevant specifications",32.24%,86.27%,83.82%,42.96%,79.80%
137,images/s160.png," Table 1: Human Alignment Performances of LLMs on ChaosNLIDatasets.  and  refer to MCR (3, 1) and LPR (3, 2), and  and # refer to OS and NS, respectively (4, 3). * are reported results from Nie et al., 2020, and bold and underlined texts indicate the first and the second best value for each column.","we propose a novel approach that integrates evolutionary algorithms (EAs) for optimizing CNN architectures with a sophisticated transfer learning strategy. This approach aims to refine the process of manual CNN architecture design, which is often cumbersome and inefficient. Our method focuses on exploring a vast array of network block topologies to discover more streamlined and effective designs that enhance accuracy without unnecessary complexity. Initially, our strategy involves identifying the most suitable block structures for CNNs. Subsequently, we employ a deep learning system based on transfer learning to detect COVID-19 in chest X-ray images. This process, depicted in Figure 1, leverages evolutionary optimization to streamline architecture development and incorporates advanced transfer learning techniques for efficient model adaptation",20.35%,57.28%,79.96%,14.99%,77.82%
138,images/s161.png," This is a figure that shows the workflow of CODEDITOR for multilingual code editing. CODEDITOR leverages the context of code histories of multiple programming languages from three sources: the old version of the source programming language (Es_old), the new version of the source programming language (Es_new), and the target programming language (Mt). CODEDITOR has two variants that both generate the code changes in the target programming language (Et) but in different formats: Et_old and Et_new. The meta edit plan which is represented as Ep, is then applied to the changes in the old version of the code (Et_old) to obtain the new version of code (Mt_new) in the target programming language.","A glance at Table 1 unearths a range of classification accuracy (Acc) figures within the domain of X-ray-based COVID-19 diagnosis, spanning from 88.39% to a remarkable 98.12%. Notably, Biraja Ghoshal et al. [45] manifest the relatively modest end of this spectrum, achieving an Acc of 88.39%. Linda Wang et al. [46], in terms of classification accuracy, attain a commendable 92.4% concerning the COVIDx dataset. Meanwhile, Asmaa Abbas et al. [34] shine with an Acc of 95.12%, fortified by an impressive sensitivity of 97.91% and a specificity of 91.87%. Prabira Kumar Sethy et al. [32] also make a notable entry, securing an Acc of 95.38%. Ioannis D. Khalid EL Asnaoui et al. [47], Muhammad Farooq and Abdul Hafeez [48], and Gusztav Gaal et al. [33] bolster the upper echelons of this spectrum, boasting Acc rates of 96.23% and 97.5%, as delineated in Table 1.",26.29%,61.20%,77.35%,33.54%,80.72%
139,images/s162.png,Error: Invalid response from model,"A use case offers an exhaustive illustration of how users will interact with a future system. Use case analysis assists in determining system requirements during the design phase and in elucidating key information for system procedures [15,29]. Diverse use cases can be sorted through use case analysis. By employing this analysis technique to envisage application scenarios for ECG-based user authentication, three unique authentication categories were identified (see Table 1): hospital patients (HOS), identity verification at building entrances (SCK), and continuous authentication for personal use (WD). It is paramount to recognize that system performance requirements, in terms of the authentication speed and accuracy rate vary among each category and are dependent on the intended application systems [15].",0.00%,68.67%,79.66%,0.00%,77.29%
140,images/s163.png," |Dimension|	Characteristics|
|:-:|:-:|
|Knowledge Domain|	Open-domain/ General-purpose| Closed-domain/ Domain-specific|
|Service Provided|	Interpersonal| Intrapersonal| Inter-agent|
|Goal|	Informative| Task-based| Conversational/ Non-task based|
|Input Processing/ Response Generation|	Rule-based| Retrieval-based| Generative|
|Human-aid|	Human mediation| Autonomous|
|Permission|	Open-source| Commercial|
|Text Processing|	Word Embeddings| Text-level (Latin Alphabet)|
|Interaction/ Communication Mode|	Text-based| Voice-based| Both|
|Implementation|	Programming| Modeling| Supervised Learning| Hybrid|
|Language|	Single Language| Multi Language|","This research focuses on an ECG-based authentication system designed for the security check use case (SCK) [15,16]. As indicated in the table, this use case utilizes user ECG data for security checks at building entrances and, if necessary, room entrances. Security checkpoints are commonly employed by companies to verify the identities of employees and visitors. With the availability of portable ECG detection devices or sensors, ECG-based biometric authentication systems are poised to become a viable option alongside fingerprint scanning, facial recognition, voice identification, iris recognition, and retina scans for security checkpoints. In the SCK use case, the ECG-based authentication system can identify both registered regular employees and unknown individuals [15–17]. The underlying assumption is that authorized employees have previously registered their identities and historical ECG data in the ECG authentication system. Additionally, it is presumed that the measured ECG signals from the same employee exhibit sufficient stability for both the registration and inference phases. During the inference phase, the sampling time period is relatively short, lasting less than 30 s. Within this brief interval, the system can identify unknown entities [17]. After constructing the dataset, multiple machine learning models are selected and applied to the framework for training and testing, in order to compare and determine the optimal machine learning model. The system design model is shown in Figure 5.",3.79%,43.99%,77.26%,0.00%,67.84%
141,images/s164.png, Table 1: Overview of the classification of the LLM answers to the false-belief tasks.,"This investigation primarily centers on ECG data processing techniques, and hence, we developed a relatively straightforward machine learning model. Recognizing the versatility of different machine learning algorithms for ECG data authentication, we constructed four prevalent models: CNN, LSTM, KNN, SVM, and RF for ECG data training and testing. CNN and LSTM are neural network algorithms, with common hyperparameters inclusive of the loss function, learning rate, optimization algorithm, dropout, hidden layer count, and epoch [43]. Each ML algorithm was assessed several times to find these hyperparameters and to pinpoint the optimal configuration. The specifics of the CNN and LSTM model hyperparameters are detailed in Table 2. Employing the cross-entropy error as the loss function for both the CNN and LSTM models, the CNN model utilizes the Adam algorithm with a learning rate of 0.003, while the LSTM model adopts the same algorithm with a learning rate of 0.002. Training occurs over 50 epochs for the CNN model and 100 epochs for the LSTM model, with the hidden layer count being 7 for the former and 4 for the latter.",33.97%,65.90%,82.09%,0.00%,80.15%
142,images/s165.png," Table 1. Performance of the zero-shot Flan-T5 model in identifying postpartum hemorrhage (PPH) concepts in discharge summaries.

Concept (n)	Sensitivity	Specificity	PPV	Binary F1	Accuracy
Laceration (n = 421)	0.993	0.996	0.993	0.994	0.995
Baki balloon (n = 46)	0.957	1.000	1.000	0.978	0.978
Cesarean delivery (n = 470)	0.978	1.000	0.957	0.984	0.983
Methylergonovine (n = 104)	0.952	0.986	0.961	0.952	0.969
Placenta previa (n = 170)	0.923	0.996	0.923	0.952	0.982
Fresh frozen plasma (n = 79)	0.962	0.995	0.938	0.950	0.993
Caboprost (n = 49)	0.986	0.999	0.978	0.965	0.993
Misoprostol as a uterotonic (n = 112)	0.938	0.991	0.913	0.923	0.982
Hysterectomy (n = 55)	0.982	0.991	0.871	0.925	0.988
Uterine atony (n = 107)	0.850	0.999	0.919	0.915	0.986
O'Leary sutures (n = 12)	0.917	0.989	0.989	0.917	0.983
Retained products of conception (n = 362)	0.929	0.993	0.914	0.909	0.986
Direct mention of PPH (n = 165)	0.881	0.963	0.929	0.897	0.938
Packed red blood cells (n = 44)	0.915	0.991	0.860	0.887	0.991
Coagulation disorders (n = 47)	0.795	0.996	0.843	0.881	0.981
Abruption of the placenta (n = 29)	1.000	0.990	0.909	0.975	0.996
Dilation and curettage (n = 122)	0.762	0.990	0.725	0.823	0.961
Platelets (n = 29)	0.822	0.987	0.644	0.784	0.986
Placenta accreta spectrum (n = 45)	0.900	0.986	0.712	0.763	0.980
Manual extraction of placenta (n = 10)	0.782	0.972	0.513	0.606	0.954
PPH due to surgical causes (n = 27)	0.741	0.983	0.741	0.761	0.978
Uterine rupture (n = 5)	1.000	0.992	Note: Acc.	0.526	0.992
Estimated blood loss (n = 212)	0.745	0.905	0.351	0.395	0.92","Figure 1 illustrates the proposed concept. Unlike conventional trucks, EAA offer the advantage of bypassing ground traffic and infrastructure constraints, significantly reducing transit times for time-sensitive shipments. In comparison to high-speed rail at airport terminals, EAA provide greater flexibility in terms of deployment locations and do not require extensive infrastructure, which can be prohibitively expensive and timeconsuming to construct. The expense of high-speed rail infrastructure, however, may not be as pronounced in other regions such as Europe where such modes may offer more potential to carry low-weight, high-value cargo [7]. EAA facilities will require planners to overcome the challenges of higher initial investment costs for vertiport infrastructure, the current limitations in battery technology, community acceptance, regulatory restrictions, and resistance from organizations such as labor unions. Despite these challenges, EAA exhibit a lower environmental impact through reduced greenhouse gas emissions and energy consumption, presenting a scalable solution for urban freight transport as technology advances and regulations adapt",8.17%,24.85%,76.66%,36.30%,36.14%
143,images/s166.png,Error: Invalid response from model,"Initial Data Extraction from the FAF Database: The freight analysis framework (FAF) database (FAF OD Dataset) contained over 1.6 million origin–destination records of various commodity categories moved across 132 FAF zones. The procedure filtered it to extract records relevant to commodities moved by air, resulting in approximately 354,782 records. This step isolated air freight data for a more specific analysis of domestic movements among FAF zones. Identification of Commodity Categories Moved by Air: Pivot table operations identified 40 commodity categories transported by air within the CONUS. This step helped in focusing on commodities specifically relevant to air transport. Data Cleaning on the CFS Geography Dataset: The commodity flow survey (CFS) geography dataset underwent a cleaning process that matched area names via text strings to identify and replace 13 unique metropolitan statistical area (MSA) codes that differed from those in the FAF dataset. This step ensured consistency in geographical identifiers across datasets",2.50%,64.36%,79.61%,0.00%,74.43%
144,images/s167.png," The table shows the distribution of label combinations in OLiD (Zampieri et al., 2019b). The columns are:
- A: the value of the A label
- B: the value of the B label
- C: the value of the C label
- Train: the number of training instances with the given label combination
- Test: the number of test instances with the given label combination
- Total: the total number of instances with the given label combination","Table 2 shows the results in the validation and in the test set, which consists of a set of in vivo CIs unseen in the model training stage. It is important to note that the training and validation set consists of in vitro images. The methods compared include global thresholding (GT), k-means, morphological approach, UNet, and modified UNet. The results in the validation step improved the IoU in multiple input networks and the regression model, increasing from 0.8228 ± 0.075 to 0.844 ± 0.065 for the multiple input regression model. On the other hand, more experiments were performed to assess the generalization of the segmentation models. R-UNet + ET + LA achieved the highest performance with a mean score of 0.812 ± 0.080 for the test set. In general terms, the addition of exposure time and lens aperture helps to improve IoU in segmentation, but the regression task with them significantly increased the quality of segmentation compared to the UNet (Multiple comparisons, δ = 0.05, F-value = 6.48, p-value = 0.00).",54.45%,75.49%,79.27%,16.98%,87.59%
145,images/s168.png," The table shows the evaluation of readme generation with representative code identification and the random file baseline.
In the overall human evaluation, the representative code performs better than the random file. 
In the fine-grained human evaluation, the representative code performs better than the random file in terms of grammatical correctness, factual correctness (text), and factual correctness (code). 
In the automatic evaluation, the representative code performs better than the random file in terms of ROUGE-1, ROUGE-2, and L.","Table 3 shows the comparative analysis with different contrast representations. The R-UNet with multiple inputs obtained a mean Root Mean Squared Error (RMSE) of 0.0061 ± 0.0163, which is the lowest error compared with the single input network that obtained 0.0144 ± 0.0423 for all the CIs that feed the models (Multiple comparisons, δ = 0.005, F = 26.05, p = 0.00). On the other hand, the adaptive method aK with a d = 11 obtained the lowest RMSE (0.0095 ± 0.0281). This may be because the method generates more stable images where the contrast values in the blood vessel change less in its center, as discussed in [49]. In addition, the reference that the ET and LA provide to the network may cause an improvement in RMSE. The linear regression between the estimated blood vessel depth and the ground truth of the validation set obtained R 2 of 0.8299 for the single input and 0.9295 for the multiple input.",47.12%,79.94%,80.79%,18.12%,79.14%
146,images/s169.png," The table describes the data used to train the LLMs. 

The data consists of two parts: clinical notes and laboratory values. 

The clinical notes are the notes that the doctors have written about the patients. They include the patient's chief complaint, present illness, past medical and surgical history, physical examination findings, and assessment. 

The laboratory values are the results of the laboratory tests that have been performed on the patients. They include the patient's blood test results, urine test results, and other laboratory test results.","In this paper, we present a combined dataset of whispered speech and neutral speech, labeled with labels, such as speaker, gender, and mode of speech. Its comparison with existing whispered datasets is shown in Table 1. This paper also demonstrates the usefulness of the Whisper40 dataset by implementing a baseline WSR system. In the following sections, we describe in detail the content structure of the dataset and the data collection process, and experimentally analyze the performance of state-of-the-art speaker recognition methods on this dataset.",37.40%,91.06%,82.64%,45.88%,79.48%
147,images/s17.png," The text is a Common Vulnerabilities and Exposures (CVE) entry. It describes a vulnerability in the FreeWVS software that could allow a user to create a large file that would cause the software to crash. The vulnerability has been patched in version 0.1.1 of the software.

The label for the text is a vector of 10 integers. The first integer indicates the Common Weakness Enumeration (CWE) ID of the vulnerability. The second integer indicates the Common Vulnerability Scoring System (CVSS) base score of the vulnerability. The third integer indicates the CVSS temporal score of the vulnerability. The fourth integer indicates the CVSS environmental score of the vulnerability. The fifth integer indicates the CVSS exploitability score of the vulnerability. The sixth integer indicates the CVSS impact score of the vulnerability. The seventh integer indicates the National Vulnerability Database (NVD) severity score of the vulnerability. The eighth integer indicates the NVD exploitability score of the vulnerability. The ninth integer indicates the NVD impact score of the vulnerability. The tenth integer indicates the NVD overall score of the vulnerability.

The predicted MITRE ATT&CK tactics for the vulnerability are Access, Persistence, and Impact.","The dataset contains a total of 3200 uĴerances, including 1600 each of neutral speech and whispered speech, totaling 655.897 min of speech data. It consists of 40 speakers (21 males and 19 females) performing neutral speech and whispered speech in Chinese. Each speaker is assigned a different number and is divided into a training set and an evaluation set in order to verify the reproducibility of the experiment and to conduct follow-up studies. Each speaker title has subfolders containing neutral speech files and whispered speech files. Each speaker audio file was divided into a training subset and a test subset. In addition, the 40 speakers in the dataset were divided into two subsets as shown in Table 2. One speaker’s 5 s neutral speech and whispered speech audio were selected and ploĴed with Mel spectrograms, as shown in Figure 3. It",20.72%,87.42%,78.48%,42.50%,80.49%
148,images/s170.png," The table summarizes the data used in the study. The data is from 212,936 patients with diabetes and 160,478 patients without diabetes. The data was used to train and test machine learning models to predict diabetes.","TDNN is a feedforward neural network with a multilayer structure. Unlike fully connected feedforward neural networks, the output units of TDNN are only connected to the input units within a certain time range. Thus, it captures the temporal relationships between neighboring frames. It aggregates variable-length inputs across time to create fixed-length representations that capture speaker features. The shallow network units are connected over a narrow time range, while the deep network learns information over a wider time range. The network structure of TDNN is shown in Figure 4.",19.33%,80.12%,82.10%,11.79%,76.25%
149,images/s171.png," Table 1 shows different tasks. For the medical text summarization task, the input is medical text, and the output is a short summary. The ground truth is the summary written by experts. The reference is the input. For the radiology report summarization task, the input is a radiology report, and the output is an impression. The ground truth is the impression written by radiologists. The reference is the impression written by radiologists. For the medical text simplification task, the input is medical text, and the output is simplified text. The ground truth is the simplified text written by experts. The reference is the input. For the medical dialogue generation task, the input is a dialogue, and the output is a response. The ground truth is the response written by experts. The reference is the dialogue history. For the medical question answering task, the input is a medical question, and the output is an answer. The ground truth is the correct answer written by experts. The reference is the correct answer written by experts. For the radiology report generation task, the input is a chest X-ray image, and the output is a radiology report. The ground truth is the radiology report written by radiologists. The reference is the radiology report written by radiologists.","Figure 1 depicts the flow diagram for the proposed technique. The KOA data undergo many preprocessing processes before feature extraction. After picking relevant features, they are fed into machine learning models. Finally, GridSearch optimizes parameters to improve model efficiency. Evaluation steps were made to ensure the performance of the models",30.08%,87.45%,80.44%,35.22%,79.07%
150,images/s172.png," | Code  | Number of Codes  | Total LoC  |
|---|---|---|
| GEMM  | 128  | 11.3k  |
| Convolution  | 15  | 2.8k  |
| FFT  | 15  | 1.9k  |
| LU  | 15  | 1.9k  |
| Total  | 158  | 16.0k  |
| Parboil  | 10  | 1.4k  |
| Caffe  | 182  | 42.3k  |
| ACOTSP  | 13  | 2.8k  |
| cpufetch  | 22  | 5.7k  |
| Total  | 227  | 54.2k  |","The classification report (Table 2) across all classifiers show high precision, recall, and F1 scores, demonstrating their capability to differentiate between the stages of knee osteoarthritis effectively. Table 2 also sums up the optimized hyperparameter value of each classifier which provides the highest model performance. Despite minor misclassifications, primarily between adjacent categories, these results highlight the classifiers’ overall proficiency and the challenge of distinguishing inherently similar stages",1.94%,-2.64%,76.79%,34.16%,49.80%
151,images/s173.png, Table 1. Transformation rules for the two models,"Phase (a): This phase integrates a CNN model with TL for the classification of brain tumor types based on MRI data. In this approach, the acquired features of a pre-trained CNN model serve as an initial foundation, proving particularly advantageous in scenarios involving sparsely labeled data. The data are fed into a CNN, which subsequently processes the data through convolutional layers to capture intricate patterns and spatial hierarchies within the MRI images. Following this, the pooling layer is employed to down-sample and reduce the feature space, optimizing computational efficiency. Progressing along the activation path, the dense layer plays a pivotal role in transforming high-level features for effective classification. Finally, the model makes decisions about tumor types based on the combination of these learned features. When the decision is made, a medical expert becomes curious and seeks to understand how the model makes decisions based on their expertise. Phase (b): This phase uses explainability techniques, including Grad-CAM, GradCAM++, IG, and Saliency Mapping. The explanation aims to shed light on how the CNN model arrives at its classifications, providing valuable insights to the medical expert. Grad-CAM and Grad-CAM++ offer the visualization of crucial regions in the MRI images that contribute to the model’s decisions. IG provides a comprehensive understanding of feature importance by perturbing input features, while Saliency Mapping highlights salient features influencing the classification. Together, these explainability techniques bridge the gap between the model’s predictions and human interpretability, fostering trust and comprehension in the application of DL models to medical imaging. After the model is explained, the focus shifts smoothly to the part where medical experts take over and make sense of it. The explained visualizations and insights provided by techniques like GradCAM, Grad-CAM++, IG, and Saliency Mapping serve as a bridge between the complex nature of DL classifications and the expertise of medical experts.",19.35%,69.70%,82.61%,0.00%,74.58%
152,images/s174.png," In the figure, the Unified Modeling Language (UML) class diagram is used as an intermediate representation between the PIM and PSM. The reason behind this decision is that the UML class diagram is a well-established and widely used modeling language that can be used to represent a wide variety of systems. It is also a relatively simple language to learn and use, which makes it a good choice for this purpose.","The training outcomes, as detailed in Table 2, offer insights into the model’s ability to learn from the training data. High training accuracy and low training loss often signify successful training, yet these metrics may not necessarily ensure performance on the test data. Among the models investigated in this study, DenseNet121, EfficientNetB0, GoogLeNet, Inception V3, ResNet50, and Xception stood out with an acceptable training accuracy, ranging from 99.86% to 100%. These high accuracy scores indicate that these models have effectively learned the statistical regularities present in the training data. Furthermore, the associated training loss values were remarkably low, showcasing the models’ efficiency in minimizing errors during the training phase. It is imperative to note that achieving high training accuracy does not necessarily guarantee superior performance on unseen datasets, emphasizing the importance of the comprehensive evaluation of the test data for a more robust assessment of model generalization",26.44%,86.67%,81.87%,17.87%,83.20%
153,images/s175.png," The image shows the architecture of an extractive question answering model. 
The model consists of an embedding layer, a transformer layer, and a decoding layer. 
The embedding layer converts the input text into a sequence of vectors. 
The transformer layer then uses attention to learn relationships between the different parts of the input text. 
Finally, the decoding layer generates the answer to the question.","The classification results, as detailed in Table 3, provide valuable insights into the model’s capability to classify the test data; it became evident that EfficientNetB0 emerged as the superior model among all those considered in this study. Upon closer examination of the results, it was apparent that some of the models may not be suited for this specific task, with some requiring more computational resources due to higher parameter counts, as observed in VGG16 and VGG19",32.46%,88.29%,83.12%,38.86%,79.18%
154,images/s176.png,Error: Invalid response from model,"As indicated in Table 1, while each incident is associated with a single threat, it can impact one or several controls. To address and potentially prevent the recurrence of the incident, the implementation of these controls requires examination and correction, so different courses of action can be considered to resolve the incident. Traditionally, management and response to security incidents have been focused on rapid resolutions, often overlooking sustainability. However, efficient and environmentally friendly resource management is essential. Incorporating sustainability into these practices not only enhances effectiveness in immediate recovery but also strengthens organizational resilience and sustainability in the long term in a context where social and environmental responsibility is increasingly important.",1.66%,55.05%,80.45%,0.00%,72.29%
155,images/s177.png," The table shows the results of extractive models evaluation. The numbers in bold represent the highest metric score per model. The models are evaluated on three different metrics: SQuAD AD Metric, N-gram Metrics, and Index-based Metrics. The best model is DeBERTa, which achieves the highest score on all three metrics.","this table shows a dataset encapsulating a spectrum of security incidents within a computational system, accompanied by an array of potential resolution methodologies, termed ‘course of action’. The algorithm’s core function lies in the strategic selection of these courses, prioritizing those that yield a superior efficiency in terms of temporal cost or sustainability. This efficiency is quantified via a weighted average, governed by a coefficient α, facilitating adaptability to shifting real-time parameters. Our discourse aims to dissect the fundamental constructs and pivotal considerations integral to the crafting and execution of this optimization algorithm. Through this analytical lens, we endeavor to achieve a thorough comprehension of its operational framework and the consequential impact it bears in the landscape of cybersecurity research and applications",23.19%,89.30%,82.40%,11.06%,86.45%
156,images/s178.png, Table 1: Summary of Large Language Models in the Healthcare Space,This section provides an in-depth description of our proposed deep-learning-based activities recognition approach in the context of student and teacher. Figure 1 shows the architecture diagram of the proposed STAR-3D algorithm.,22.18%,48.57%,86.71%,8.36%,81.09%
157,images/s179.png," Table 1 shows the evaluation of the key extraction using precision (P), recall (R) and F1-measure (F1) for subject, predicate and object.","Figure 3 shows the complete system of a GAN. The key idea behind GANs was to train a generator network to create data that are indistinguishable from real data, while simultaneously training a discriminator network to differentiate between real data and data generated by the generator. We used the GAN to generate more samples from various angles. This allowed us to create realistic classroom images resembling blackboards, sticks, desks, mobile phones, and more relevant images. We used it to generate additional training data for our tasks. Additionally, GAN helped to enhance the resolution of existing and generated images, turning low-resolution images into high-resolution counterparts. This approach enabled us to increase the volume of data while maintaining high resolution.",16.33%,49.74%,82.91%,0.73%,81.88%
158,images/s18.png," The table shows the different types of network sharing and the components that are shared in each type.

Passive sharing is when two or more operators share the same physical infrastructure, such as towers, buildings, and ducts. This type of sharing can save operators money on the cost of building and maintaining their own infrastructure.

Active sharing is when two or more operators share the same active network components, such as antennas, base stations, and core networks. This type of sharing can save operators money on the cost of purchasing and maintaining their own network equipment.

The table shows that passive sharing is the most common type of network sharing, followed by active sharing. The least common type of network sharing is roaming, which is when two or more operators allow their customers to use each other's networks.","This proposed framework (Figure 1) suggests that the adoption of mHealth is affected by the factors outlined in the TOE model, including relative advantage, compatibility, top management support, organizational readiness, external support, and government regulation.",22.51%,83.00%,83.00%,38.16%,77.20%
159,images/s180.png, The table shows the representation of control structures in Maude. The first column shows the M-UML statechart diagram control structures. The second column shows the corresponding Maude rules. The third column provides an explanation of the rules.,"Demographic information showed that of the 314 participants, the majority of males (117 or 78%) were doctors, and the majority of females (99 or 60.4%) were nurses (as shown in Table 1). We found a statistically significant gender distribution in two groups of doctors and nurses (χ 2 = 47.327, p = 0.000, phi’s value = 0.388). Among the doctors, the majority (174 or 95.6%) were below 35 years of age, while the majority of nurses (94 or 71.2%) were within the same age group. Furthermore, there were only two (1.1%) doctors in the 36–50 age group, contrasting with 31 (23.5%) nurses in that category. This age-wise distribution of doctors and nurses showed statistical significance (χ 2 = 42.560, p = 0.000, Cramer’s value = 0.368). A significant difference was also observed in the experience levels of doctors and nurses (χ 2 = 34.114, p = 0.000, Cramer’s value = 0.330). Doctors tended to have more experience compared to nurses in our study cohort. The distribution of work settings between doctors and nurses also exhibited a significant difference (χ 2 = 108.695, p = 0.000, Cramer’s value = 0.588). In our cohort, 44 (33.3%) nurses were working in intensive care compared to 11 (6%) doctors, while 35 (26.5%) nurses were in the emergency unit, contrasting with only one (0.5%) doctor in the same setting (Table 1)",27.40%,49.58%,78.77%,0.29%,76.96%
160,images/s181.png," The table shows an overview of the LLMs that were evaluated and their final score. The LLMs are ranked from 1 to 7, with the highest score being 1. The table also shows the number of trainable parameters, the number of all parameters, the pre-train dataset size, and the final score for each LLM.","The proposed detection framework takes RGB data images of vines as input. It comprises four processing phases, each requiring the previous one to have been completed prior to execution. The outputs of each processing phase are inputs for the next, and so forth. This constitutes a chain of independent processing steps that may stop at one level without further processing, providing specific data or metadata outputs. The first phase is the data filtering/data selection process. Normalized image datasets based on specific criteria, features, rules, or time frames are the output of this step. Usually, metadata information is added to the normalized datasets. The second phase includes data partitioning based on unsupervised autoencoders or supervised data annotation or classification tasks. The outputs of phase 2 are the normalized data with the corresponding metadata localization information. Phase 3 is the model training process. It constructs and produces trained models of complex deep-layer structures, with parameters and biases calibrated via forward and backward operations. The outputs of the training process are models with the best precision—recall scores achieved over a set of iterations of hyperparameter calibration. Finally, phase 4 includes the inference process that loads model structures and parameter values and performs object detections on RGB images or video streams. Object detection outcomes and confidence scores are data inputs for decision support metrics or thresholds that trigger notifications for interventions and alerts for farmers",43.80%,85.81%,81.62%,2.19%,82.54%
161,images/s182.png," The table provides an overview of downstream tasks and their datasets. The tasks are divided into two categories: gene-level and cell-level. The gene-level tasks include dosage sensitivity, bivalent vs non-methylated, bivalent vs lys-4 methylated, long- vs short-range TFs, N1 central vs peripheral, and N1 activated vs non-target. The cell-level tasks include multiple sclerosis cellAnno and Embryo cellAnno. The table also provides the number of training and test samples for each task.","Table 1 shows the examined models, trainable parameters, and sizes. Figure 6 illustrates the labelImg tool [50] annotation tasks, using images acquired by either (a) the IoT devices or (b) drones. The dataset images were obtained in May–July 2023 during a downy mildew outburst in Zitsa, Greece. The annotated dataset was split 20–80% as validation and training sets. An additional 300 images (1200 + 300) were kept separate for the models’ testing. Part of the IoT nodes annotated dataset is available online at [61]. The selected images for either training or inference from the IoT nodes and drones were collected during midday hours of minimum cloudiness (cloud coverage up to 40%) and wind speeds of less than 5 km/h. After image annotation, these IoT node images were used along with the captured drone images, which were resized to 4128 × 4128 px or 640 × 640 px during model training. During training, the annotated box coordinates stored in XML files were automatically extracted and corrected for any image size given or selected. According to Table 1, ResNet-152 and YOLOv5-small (YOLOv5s) were the biggest and smallest cloud models, accordingly. SqueezeNet v1.1 [62] was the biggest for mobile and embedded devices, occupying 98 MB of memory during inferences, while YOLOv8 nano required only 30 MB. The following Section 4 presents the models’ evaluation results.",27.74%,80.09%,79.91%,5.54%,81.73%
162,images/s183.png," The table shows the results of tasks related to the identification of genes, measured by the correct number of predictions. The LLMs are evaluated on six tasks: dosage, methylation, lys-4, range, N1 central, and N1 activated. The accuracy of each model is also shown. The best performing model is Llama-13b, which achieves an accuracy of 0.784.","The taxonomy is presented in Figure 3. As shown there, a first distinction is made between natural and digital presentation of information. In both these categories, information can be captured differently. In natural displays, which comprise the beginnings and current standards of information displays, information is captured by the naked eye directly, or by means of mirrors and through windscreens. In digital displays, information capture might be video-based or sensor-based. Video-based information capture describes all systems in which the outside world is captured by a camera and immediately displayed on a screen. Sensor-based information capture describes SVS where information is completely reconstructed based on different information sources.",21.17%,92.09%,81.38%,19.63%,77.47%
163,images/s184.png," The table shows the results of cell annotation tasks measured by traditional classification metrics. The best results are shown in bold.

For the multiple sclerosis dataset, the best results are achieved by BLOOM, with an F1 score of 0.557. For the hEmbryo dataset, the best results are achieved by Mistral, with an F1 score of 0.782.","The procedure (see Figure 5) began with an assessment of the participants’ visual acuity and a preliminary questionnaire. This questionnaire covered demographic data, technology affinity using the Affinity for Technology Interaction Scale [30], and the prequestionnaire of the Technology Usage Inventory [31]. Subsequently, the experimental trials were conducted, followed by the post-questionnaire of the Technology for Usage Inventory, along with open questions exploring the strategies used during the experiment and preferences for specific representation variants. The entire procedure lasted approximately 75min",37.92%,79.99%,82.18%,32.00%,80.43%
164,images/s185.png," The table shows the results of an ablation study comparing the performance of different models on two tasks: multiple sclerosis and heEmbryo. The models are evaluated on three metrics: accuracy (acc), accuracy plus (acc+), and F1 score (F1). The results show that the best-performing model on both tasks is Llama-13b, which achieves an accuracy of 0.688, an accuracy plus of 0.701, and an F1 score of 0.540 on the multiple sclerosis task, and an accuracy of 0.789, an accuracy plus of 0.802, and an F1 score of 0.761 on the heEmbryo task.","Table 1 shows the result of this matching approach. The slack column indicates how much extra time a traveller is prepared to spend on their trip as a percentage of the shortest travel time possible given their origin and destination. The time column indicates the average time in milliseconds for optimising a time window, calculated as the average optimisation time of the 60 time windows of one minute each in an hourly dataset, including the preoptimisation steps. Matches denotes the number of matches made between pairs of travellers and VHT the vehicle hours travelled",35.35%,68.67%,80.62%,46.09%,74.51%
165,images/s186.png," The image shows the overall architecture of LMEye. The model consists of three main components: an Image Encoder, a Visual Mapping Network, and a Language Model (LM). The Image Encoder extracts visual features from the input image. The Visual Mapping Network then maps these features into a semantic space. The LM finally generates a natural language answer based on the mapped features. During training, the Image Encoder and the Visual Mapping Network are frozen, and the LM is fine-tuned on a large dataset of image-caption pairs. At inference time, the Image Encoder and the Visual Mapping Network are used to extract visual features from the input image, and the LM is used to generate a natural language answer.","Lazy departure leaves matched drivers waiting at their respective origins until their slack runs out. During this time, the pairs may be split up and matched again if this leads to greater savings than the original match. It is no surprise that the eager approach takes less time to optimise, as fewer riders remain for the next iteration. The VHT results for the lazy and eager approaches are nearly identical here. This similarity is primarily due to the comparable number of potential matches between the two approaches, especially at lower levels of slack. However, a significant difference emerges at 50% slack, where the eager policy results in an average of 443 potential matches per minute while the lazy approach offers 688 potential matches every minute to choose from, as shown in Table 2, which shows the average numbers of riders and potential matches for every optimisation window.",33.56%,78.89%,81.34%,38.00%,82.14%
166,images/s187.png,Error: Invalid response from model,"Table 2 shows the results of the simulation experiments for the four types of noise. The results indicate that the influence of these four types of noise on our QConvLSTM model can be neglected. The robustness of QConvLSTM to noise interference is determined by the special structure of the model. Firstly, the circuit depth used in our experiments is only two layers, and circuits with shallower depths are less prone to noise issues. Secondly, the LSTM unit with added convolutional operations can better extract features from the input data, enabling the network to adapt to and fit the influence of noise. Lastly, the introduced variational quantum algorithm can enhance the network’s ability to handle some nonlinear problems, assisting the network in better capturing and processing nonlinear information in the noise",3.27%,58.31%,81.40%,0.00%,81.29%
167,images/s188.png," The table shows the model performances on SEED-Bench. We evaluate LMEye (Flan5-XL-4.4B) on 9 dimensions for image understanding, including Scene Understanding (SU), Instance Identity (II), Instance Location (IL), Instance Attribute (IA), Instance Counting (IC), Spatial Relation (SR), Instance Interaction (IIR), Visual Reasoning (VR), and Text Recognition (TR).","As shown in Table 3, we tested the performance of the models under three scenarios. The single-layer circuit structure yielded the worst results, while the performance of the three-layer structure was slightly better than the two-layer structure. However, as the number of layers increased, both the computational complexity and time complexity grew exponentially, and an increase in network depth was more likely to lead to the emergence of noise. Therefore, we ultimately chose two layers as the number of layers for the experimental circuit.",12.49%,47.64%,80.39%,17.75%,75.91%
168,images/s189.png,Error: Invalid response from model,"Further regression analysis combining all variables (domains, official languages and the submission time) confirmed this conclusion (see Table 1,2 and 3 in the Materials and Methods).",0.00%,60.03%,81.52%,0.00%,71.93%
169,images/s19.png," This diagram shows the logical network architecture of a 5G network. The 5G network is divided into two parts: the core network and the radio access network (RAN). The core network is responsible for routing traffic between different parts of the network, while the RAN is responsible for connecting user devices to the network.

The core network is further divided into two parts: the packet core and the service core. The packet core is responsible for routing traffic between different parts of the network, while the service core is responsible for providing services to users, such as voice and data services.

The RAN is also divided into two parts: the central unit (CU) and the distributed unit (DU). The CU is responsible for controlling the RAN, while the DU is responsible for connecting user devices to the network.

The 5G network is a significant upgrade over previous generations of wireless networks. It offers faster speeds, lower latency, and greater capacity. This will enable a wide range of new applications and services, such as self-driving cars, virtual reality, and augmented reality.","Four different datasets were used in this study, listed for reference in Table 1. During training, we used a training dataset used for finetuning the models and a dataset from Commonlit used for domain adaptation.",12.60%,88.64%,81.02%,36.30%,72.22%
170,images/s190.png,Error: Invalid response from model,"To create the dataset for training MPIrigen out of the corpus, several pre-process stages have been done (Figure 1):",0.00%,56.99%,81.24%,0.00%,51.07%
171,images/s191.png, The figure shows the pipeline of the study. The first step is to generate the dataset. This is done by first collecting a corpus of text data. The text data is then preprocessed and cleaned. The next step is to annotate the data. This is done by manually labeling each data point with a label that indicates whether the data point is an example of legal or moral wrong. The final step is to analyze the data. This is done by using a variety of statistical and machine learning techniques to identify patterns and trends in the data.,"Table 1 reports the results of the experiments focused on the prediction of initial codes. After the first round, 72.6% of the 785 predicted codes were deemed reasonable, i.e., they described how and what. 13.2% of the codes appeared to lack the focus on how, and at least 14.1% did not seem to describe what was stolen",36.56%,62.76%,83.53%,44.22%,78.86%
172,images/s192.png," The figure shows the offline and online components of the BPLM framework. The offline components include the knowledge augmentation, embedding model, and LLM fine-tuning. The online components include the embedding model, query encoding, retrieval, and answer generation.",Summary of the paper: This paper presents a machine learning (ML) model for predicting COVID-19 case status using data from the US COVID-19 Trends and Impact Survey (CTIS).,20.76%,62.25%,82.45%,40.54%,70.88%
173,images/s193.png," Table 2 shows the evaluation results after chunking and prompts refinements. The results show that the accuracy of the natural text representation is improved after chunking and prompts refinements. The accuracy of the BPMN representation is also improved after chunking, but the accuracy of the refined prompts is lower than the accuracy of the not refined prompts. This is because the refined prompts are more specific to the BPMN representation, and therefore they are not as general as the not refined prompts.","Table 1 shows a comparison of structurally formatted data extracted from research paper text using prompt-based ChatGPT models, along with the generation of knowledge maps from both approaches.",14.37%,88.86%,85.18%,38.21%,78.56%
175,images/s195.png," The table compares different reasoning models on several dimensions. Our model, Faithful Reasoning, is compared against Proof and Answer (P&A), Let's think step-by-step, Kojima et al. 2022, Chain of Thought, EntailmentWriter, ProofWriter, and Bostrom et al. 2022. 

The first column lists the model names. The second column checks whether the model has a definition for the reasoning step. All models except EntailmentWriter and Bostrom et al. 2022 have a definition for the reasoning step. The third column checks whether the model has a definition for the sequence of reasoning steps. All models except Bostrom et al. 2022 have a definition for the sequence of reasoning steps. The fourth column checks whether the model has a trace mechanism. Only our model, P&A, and Bostrom et al. 2022 have a trace mechanism. The fifth column checks whether the model supports valid reasoning. All models support valid reasoning. The sixth column checks whether the model is designed for question answering. Our model, P&A, Let's think step-by-step, Kojima et al. 2022, Chain of Thought, and ProofWriter are designed for question answering. The seventh column checks whether the model can answer ""unknown."" Our model and P&A can answer ""unknown.""","Table 1 defines the top entries for each of the specified columns, but due to the plethora of information in these fields, deriving general statistics to identify major causes of accidents is challenging.",22.10%,83.38%,80.29%,36.08%,72.40%
176,images/s196.png," The image shows the architecture of the study pipeline. The pipeline consists of three main components: a data preprocessing component, a phenotyping component, and a machine learning component. 

The data preprocessing component is responsible for cleaning and preparing the data for analysis. The phenotyping component is responsible for extracting features from the data that are relevant to the task of predicting disease risk. The machine learning component is responsible for training and evaluating models that can predict disease risk based on the features extracted by the phenotyping component.

The pipeline is designed to be flexible and scalable. It can be used to analyze data from a variety of sources, and it can be easily adapted to new tasks. The pipeline is also designed to be efficient, so that it can be used to analyze large datasets in a reasonable amount of time.

The pipeline is implemented using a variety of open-source tools and libraries. This makes it easy to deploy and maintain, and it also ensures that the pipeline is compatible with a wide range of hardware and software platforms.

The pipeline is a valuable tool for researchers who are interested in studying the relationship between genetics and disease. It can be used to identify new risk factors for disease, and it can also be used to develop new strategies for preventing and treating disease.","Table 1 shows the fve top-ranked words that marked the highest value for each index. For example, the highest ranked word “skepticism (0.261)” in the DC category indicates that agents whose personality trait gene included “skepticism” had a successful defection rate (DC) of about 26% in all rounds. We limit our analysis to words (in Table 1) that appeared in the genes of at least 500 individuals across all trials.",25.66%,62.90%,80.86%,38.07%,81.55%
177,images/s2.png, The figure shows the architecture of a GAN-based approach for learning the joint probability distribution between two physical systems. The physical systems are represented by \(Physical \ System \ 1\) and \(Physical \ System \ 2\). \(Neural \ Networks\) are used to learn the forward maps from the physical systems to the latent space. \(GAN\) is used to learn the joint probability distribution between the latent variables. \(Bayesian \ Inference\) is used to infer the posterior probability distribution of one physical system given the observation of the other physical system.,Table 3 shows the Shapiro-Wilk normality test findings since the sample size is less than 100. The normality test shows that language mindset (p=0.330) and corrective feedback preference (p=0.047) are normally distributed since p > 0.05,21.83%,77.26%,80.43%,38.52%,74.59%
178,images/s20.png," This diagram shows the steps involved in the process of onboarding a new client to a mobile network. The process starts with the establishment of SLAs and resource agreements between the two parties. Once this is done, the network operator will need to establish roaming agreements with the new client. If the new client is not an operator, they will need to provide user data to the network operator.

The next step is to set up the necessary network functions (NFs) to support the new client. This includes setting up a SEPP NF to establish roaming and configuring the network to accept the new client. The network operator will also need to agree on QoS and monitoring policies with the new client.

Once all of this is done, the network operator can set up and enable slicing for the new client. This includes setting up UPF, SMF, and PCF. Once this is done, the new client will be able to access the network and use the services that have been agreed upon.","In Membranes’ Technology, for instance, materials’ scientists have synthesized a Mixed Matrix Hollow Fiber Membrane (MMHFM) material and measured its performance to adsorb CO2 in a wet lab. The results were published and the FoM are on Table 1",22.17%,65.46%,80.51%,37.60%,80.81%
179,images/s21.png," La figura muestra la arquitectura de red de un núcleo 5G. La red está compuesta por los siguientes elementos:

* VNF: Virtual Network Function. Es una función de red virtualizada que se ejecuta en una máquina virtual.
* AMF: Access and Mobility Management Function. Es una función de red que gestiona el acceso y la movilidad de los dispositivos.
* SEPP: Session and Policy Enforcement Point. Es una función de red que aplica las políticas de seguridad y de sesión.
* SMF: Session Management Function. Es una función de red que gestiona las sesiones de los dispositivos.
* UPF: User Plane Function. Es una función de red que procesa el tráfico de datos de los dispositivos.
* UERANSIM: User Equipment Radio Access Network Simulator. Es un simulador de red de acceso de radio de usuario.

La red está configurada de la siguiente manera:

* El AMF está conectado al SEPP.
* El SEPP está conectado al SMF.
* El SMF está conectado a los UPF.
* Los UPF están conectados a los UERANSIM.

El tráfico de datos de los dispositivos fluye a través de la red de la siguiente manera:

1. Los dispositivos se conectan al AMF.
2. El AMF autentica a los dispositivos y les asigna una dirección IP.
3. Los dispositivos envían su tráfico de datos al SMF.
4. El SMF reenvía el tráfico de datos a los UPF.
5. Los UPF procesan el tráfico de datos y lo envían a los dispositivos.","Table 1 summarizes the main characteristics of these three models, providing a comparative glimpse into their architectural underpinnings, language and domain proficiency, training data, and use cases.",1.00%,25.38%,76.21%,34.15%,79.18%
180,images/s22.png, This figure shows the interactions between different entities in the proposed system. The smart appliance in the IoT sends sensed data to the service provider. The service provider sends the data to the blockchain (step 2). The user sends an enrollment request to the service provider (step 3). The service provider sends the request to the blockchain (step 4). The blockchain verifies the request and sends an authorization to the service provider (step 5). The service provider sends the authorization to the user (step 6). The user sends a transaction request to the service provider (step 7). The service provider sends the request to the blockchain (step 8). The blockchain verifies the request and sends a transaction confirmation to the service provider (step 9).,"We chose the following configuration for model inference: {temperature 0.1, repetition penalty 1.1} after comparing automatic metrics and qualitative assessments; see Supplemental Table 1)",11.14%,78.43%,79.39%,34.41%,73.73%
181,images/s23.png," | Parameters | Values |
| -------------- | -------------- |
| Total sensors/smart appliances | 200 |
| Number of sellers | 5-10 |
| Number of buyers | 10 |
| Number of service provider | 2 |
| Data packets | 50 gigabytes |
| Size of control message | 10 bits |
| Bandwidth | 5 gigabytes per second |
| Initialized energy of nodes | 10 J |",Table 1 shows the main characteristics and hyperparameters of the ArabianGPT-0.1 model,8.83%,26.62%,79.05%,34.26%,60.82%
182,images/s24.png," The sentence is ""It gives us the basis for several deductions"". The dependency parse tree of the sentence is as follows:

(ROOT
  (S
    (NP (PRP It))
    (VP (VBZ gives)
      (NP (PRP us))
      (NP (DT the) (NN basis))
      (PP (IN for) (NP (JJ several) (NNS deductions)))))",The main results are shown in Table 1. We find that grammar prompting can meaningfully improve upon the standard prompting baseline even without constrained decoding.,12.09%,14.94%,77.67%,36.30%,77.66%
183,images/s25.png," The figure shows the steps of the data analysis. Data acquisition is the first step, which involves collecting data from various sources. In this case, data is collected from Apache Jena and Reddit API. The next step is data collection, which involves filtering and cleaning the data. After that, text processing is performed, which involves removing punctuation and special characters. The next step is data aggregation, which involves associating posts with ontological concepts. Finally, clustering is performed, which involves grouping posts based on their similarity.","Table 1 presents a summary of the statistics of the TSCC corpus across the training, development, and testing sets",20.41%,84.68%,84.35%,37.25%,64.38%
184,images/s26.png," This is a mind map of the different types of monetary amounts. A monetary amount is a scalar quantity value expressed in a unit of currency. It can be positive or negative, and it can be used to represent a variety of different things, such as the price of a good or service, the balance of a bank account, or the amount of money that is owed on a loan.

There are three main types of monetary amounts: prices, balances, and interest. Prices are the amounts that are charged for goods or services. Balances are the amounts of money that are available or owed. Interest is the cost of using money over time.

Prices can be either fixed or variable. Fixed prices are set in advance and do not change. Variable prices are based on a variety of factors, such as the supply and demand for a good or service, the cost of production, and the level of competition.

Balances can be either positive or negative. Positive balances represent the amount of money that is available, while negative balances represent the amount of money that is owed.

Interest is always positive and is expressed as a percentage of the amount of money that is borrowed. The interest rate is determined by a variety of factors, such as the creditworthiness of the borrower, the length of the loan, and the current market conditions.

Monetary amounts are an important part of our everyday lives. They are used to represent the value of goods and services, to track our spending, and to make financial decisions.","Table 1 provides a detailed overview of the dataset’s features and the rationale behind its assembly. This selection was intentionally designed to encompass a broad spectrum of scientific domains, guaranteeing diversity in content and scope.",28.83%,85.62%,80.98%,36.13%,82.06%
185,images/s27.png, The flowchart describes the process of using a remote lab for learning. The user first logs in to the remote lab and chooses an activity. The user is then presented with a scenario for the activity and must follow the instructions to complete it. The user can get feedback on their progress and submit their assessment for the activity. The results of the assessment are stored for learning analytics purposes. The user can then choose to do another activity or log out of the remote lab.,"In Table 1, we present the APR performance of AutoSD on the ARHE benchmark when compared with LLM-Base and the templatebased baseline.",34.69%,61.50%,83.31%,38.76%,78.19%
186,images/s28.png," The table shows the different roles and their corresponding tasks in the system.

Users can:
- Create their own accounts
- Update their profiles
- Store Arduino sketches
- Compile and upload sketches to the Arduino
- Monitor the remote lab
- Interact with the remote lab
- Activate activities
- Monitor the status of activities

Administrators can:
- Set configuration parameters
- Check shadow controllers
- Enable or disable the booking system
- Clear users' sessions
- Set user groups (student/administrator)
- Enable or disable xAPI status
- Create activities","We process LATEX where we can capture it, and also include academic code to capture computational science. We highlight the corpus details in Table",12.00%,67.80%,81.02%,36.26%,69.29%
187,images/s29.png, Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) flow diagram.,"Table 1, T5-Large outperformed T5-Small by a significant margin, achieving a 7.6% improvement in accuracy on the SQuAD dataset. Similarly, LLaMa-13B demonstrated a 6.6% higher QA accuracy on TriviaQA than LLaMa-7B. Indeed, such a phenomenon is well known in ML community as scaling law [11, 12, 21, 34].",0.00%,67.48%,79.43%,0.00%,69.18%
188,images/s3.png," The table summarizes the characteristics of the different machine learning models that have been used to predict PM10 concentrations. The models vary in terms of their input data, training and testing data, hidden layer nodes, activation functions, learning rates, epochs, and missing data handling techniques. The performance of the models is evaluated using the R-squared statistic.","For instance, in a study involving a novel alloy surface, the LLM may identify the predominant chemical states, but the expert’s analysis could reveal subtler interactions or phase transformations not immediately apparent from the XPS data. Table 1 summarizes the framework.",33.13%,94.24%,83.83%,40.48%,76.51%
189,images/s30.png," | RQ# | Research Questions | Motivation |
|---|---|---|
| RQ1 | What are the main decision-making processes at HEIs? | Identify the main processes that underpin decision making at HEIs |
| RQ2 | What BI solutions are used in HEIs? | Identify the BI solutions used in HEIs |
| RQ3 | What are the reference architectures used to implement BI in HEIs? | Identify the reference architectures used to implement BI in HEIs |","Table 2 shows the lexicons we used to generate emotion arcs studied in Section 3.2. These lexicons are widely used to support sentiment analysis and have both categorical and real-valued versions, which is useful to study whether using fine-grained lexicons leads to markedly better emotion arcs than when using coarse categorical lexicons (keeping the vocabulary of the lexicon constant).",16.94%,26.53%,80.61%,41.13%,70.80%
190,images/s31.png,  Swin Transformer的结构,"Table 1 shows the LLMs we used and summarizes design parameters, including the number of layers, heads, embedding size (head dimension), context length, and the data source (natural language (NL) and/or code). As code-davinci-002 is derived from GPT-3 [5], it has the same architecture. Since its parameters are not known, so we leave these as NA.",0.00%,34.05%,76.42%,0.00%,51.79%
191,images/s32.png, 以上是yolov5的网络结构图，包括了backbone、neck和head三个部分。backbone部分负责提取图像的特征，neck部分负责将不同尺度的特征融合起来，head部分负责检测目标。,"This section details the code implementations for the Top-10 MITRE techniques listed in Table 1. Each subsection provides a brief overview of the Technique, code generated by ChatGPT and Google’s Bard and explanation of code snippets.",0.00%,27.73%,74.29%,0.00%,0.00%
192,images/s33.png, Swin Transformer的基本构建块,"Table 1 reports the results of the experiments focused on the prediction of initial codes. After the first round, 72.6% of the 785 predicted codes were deemed reasonable, i.e., they described how and what. 13.2% of the codes appeared to lack the focus on how, and at least 14.1% did not seem to describe what was stolen.",0.00%,20.92%,75.11%,0.00%,37.50%
193,images/s34.png," The table shows the component matrix. The component matrix shows the correlations between the variables and the components. The first column shows the correlations between the variables and the first component. The second column shows the correlations between the variables and the second component. The third column shows the correlations between the variables and the third component. The fourth column shows the correlations between the variables and the total.

The first component is a combination of all three variables. The second component is a combination of the first and third variables. The third component is a combination of the second and third variables.

The total is the sum of all three components.","The study search and selection process is displayed in Figure 1. Keyword searches were conducted in seven research databases, which were selected for their comprehensive coverage of literature on AIG (Alsubait, 2015) or relevance to LLMs. The searches used two keyword components: AIG and LLMs, connected by an ""AND"" operator, as detailed in Table 1.",19.65%,79.14%,81.53%,36.90%,79.75%
194,images/s35.png," In this system, the web client communicates with the server to retrieve the door specifications, home design, and door images. The server responds with the requested data. The web client then uses this data to display the home design and doors in a 3D Unity application. The user can then interact with the 3D environment to explore different design options. On the server-side, an AI model is used to generate random forests based on the door specifications and home design. These random forests are then used to recommend door designs to the user.","As described in Table I, which summarized the evaluation metrics, those metrics provide a robust framework for comparing the performance of the discussed LLMs in processing and generating content across English and Chinese, ensuring that our evaluation covers aspects crucial for real-world applicability",20.69%,84.10%,82.28%,38.35%,80.11%
195,images/s36.png," This diagram shows the training process of a random forest model for predicting the aesthetic appeal of doors and home decors. The process starts with collecting a dataset of images of doors and home decors. The images are then preprocessed to extract features such as color, texture, and shape. The preprocessed data is then split into a training set and a test set. The training set is used to train the random forest model, while the test set is used to evaluate the performance of the model. The model is trained to predict the aesthetic appeal of the images in the training set. Once the model is trained, it can be used to predict the aesthetic appeal of new images.","We use the described approach on three materials information extraction tasks: solid-state impurity doping, metal– organic frameworks, and general materials information extraction. Details for each are summarized in Ta",9.98%,83.45%,82.15%,36.11%,83.40%
196,images/s37.png," The diagram shows the training process of a random forest model for home design. The process starts with collecting a dataset of home design images. The images are then preprocessed to extract features such as color, texture, and shape. The features are then used to train the random forest model. The model is then evaluated on a test set of images. If the performance of the model is satisfactory, it can be used to generate new home design ideas.","Te benchmark corpus is publicly available at https://doi.org/10.57760/sciencedb.1329040. Te extended corpus I and extended corpus II are publicly available at https://doi.org/10.57760/sciencedb.1329241, where include other extendedcorpuscorpus exacted by LLM model. Te two types of Corpus are provided as a fle in CSV format, and the details of them are shown in Table 3.",12.96%,74.37%,80.81%,41.77%,85.91%
197,images/s38.png," The figure shows the relationships between the constructs in the research model. The model proposes that perceived usefulness, perceived ease of use, perceived enjoyment, perceived safety, and social norm have a positive effect on voice shopping intention. In addition, perceived usefulness is influenced by performance expectancy, and perceived ease of use is influenced by social norm.",The benchmark contents are described in Section 3 with a general summary and data sources provided in Table 1. The processed datasets and code will be released after acceptance of the paper for reproducibility,20.90%,66.74%,81.46%,42.86%,73.53%
198,images/s39.png," The figure shows the structural model of voice shopping intention. All the hypotheses are supported. Perceived ease of use, perceived usefulness, and enjoyment have significant positive effects on perceived usefulness. Perceived usefulness, perceived safety, and social norm have significant positive effects on voice shopping intention.","The performance of BO is given in Table 1 for each task (column) and method (row). The last row gives the results of Bayesian Optimization, averaged over three runs for each task, with the relative standard deviation listed in subscript",13.34%,61.13%,82.17%,42.22%,64.78%
199,images/s4.png," The figure shows the block diagram of a chirp spread spectrum communication system. The transmitter consists of a data source, a chirp modulator, an IFFT block, a CP adder, and a D/A converter. The receiver consists of an A/D converter, a matched filter, an FFT block, a CP remover, and a data processing block.

In the transmitter, the data source generates a stream of bits. The chirp modulator modulates the data onto a chirp signal. The IFFT block converts the modulated signal from the frequency domain to the time domain. The CP adder adds a cyclic prefix to the time-domain signal. The D/A converter converts the time-domain signal to an analog signal.

In the receiver, the A/D converter converts the analog signal to a digital signal. The matched filter correlates the received signal with a replica of the chirp signal. The FFT block converts the filtered signal from the time domain to the frequency domain. The CP remover removes the cyclic prefix from the frequency-domain signal. The data processing block demodulates the data from the frequency-domain signal.","In subgroup analyses of the 4 gender-race pairs, model performance exhibited differences of modest magnitude (Table 1; Supplementary Table 1) that were statistically significant (p = 0.02). In post-hoc pairwise contrasts using McNemar’s test, model performance in Black women was significantly poorer than white men (Bonferroni-corrected p = 0.03)",10.27%,65.97%,77.04%,35.22%,84.84%
200,images/s40.png," This diagram shows the steps of the proposed method. The initial segmentation is performed on the input image to obtain the initial pose of the needle. Then, the differentiable rendering is used to refine the segmentation and pose estimation. Finally, the optimization is performed with respect to the pose parameters to obtain the refined pose of the needle.","Table 1 presents the main MAUVE scores. We compute the scores with three random seeds and report the average. The first observation is that the MAUVE scores of FLAN instructions are notably lower than the scores of (private) synthetic instructions, indicating that there is a significant distributional gap between FLAN instructions and user queries. Additionally, filtering synthetic instructions with Algorithm 2 improves MAUVE scores by large margins.",32.35%,82.92%,83.60%,40.35%,83.78%
201,images/s41.png," The proposed method consists of three main modules: a transformation parameter prediction module, a template warping module, and a sampler. Given the detected target bounding box and the shape prior, the transformation parameter prediction module predicts the transformation parameters between the shape prior and the detected target. The template warping module then warps the shape prior according to the predicted transformation parameters. Finally, the sampler samples the warped shape prior to generate the output.","The findings presented in this table underscore a noteworthy observation: the results generated by the LLM exhibit a striking resemblance to those produced by mBART. This remarkable parallelism between the two approaches serves as a compelling demonstration of the LLM’s adeptness in operating under zero-shot conditions, where it can generate summaries for languages it has not been explicitly trained on.",28.35%,89.64%,82.66%,44.14%,80.19%
202,images/s42.png," The diagram shows the JTS framework for evaluating the quality of topics extracted from tweets. The framework consists of three main components:
- **Topic extraction**: This component uses JST and TSWE to extract topics from tweets.
- **Feature engineering**: This component extracts features from the topics extracted in the previous step.
- **Clustering**: This component uses the features extracted in the previous step to cluster the topics into different categories.

The framework also includes an independent approach that uses BERT for topic modeling and RoBERTa for sentiment classification. The results of the two approaches are then compared to evaluate the quality of the topics extracted by the JTS framework.",Table 1 provides an overview of the primary characteristics of the compiled dataset.,33.17%,74.27%,84.65%,36.39%,67.16%
203,images/s43.png," The figure shows the sentiment analysis pipeline, which consists of three main stages:
1. Feature engineering: In this stage, the input documents are preprocessed and transformed into a set of features that can be used for clustering and sentiment analysis. This includes steps such as removing stop words, stemming words, and normalizing the text.
2. Clustering: In this stage, the preprocessed documents are clustered into different groups based on their similarity. This can be done using a variety of clustering algorithms, such as k-means or hierarchical clustering.
3. Information extraction: In this stage, the clustered documents are analyzed to extract relevant information, such as keywords and sentiment. This information can be used to generate a summary of the documents or to identify trends and patterns in the data.","To achieve the most accurate and best results, configurations suggested by the creators of the mentioned models were utilized. Table 5 provides the configurations applied for fine-tuning each model.",23.36%,90.56%,83.94%,36.98%,76.43%
204,images/s44.png," This is the architecture of the attention enhanced branch of the RCAN. The input image is passed through an edge attention filter, which produces an edge attention map. This map is then used to modulate the weights of the subsequent convolutional layers. The convolutional layers are followed by a max pooling layer, which reduces the dimensionality of the feature maps. The feature maps are then passed through a fusion gate, which combines the information from the different convolutional layers. The output of the fusion gate is then passed through a max pooling layer, which reduces the dimensionality of the feature maps by 2.","As depicted in Figure 2, our framework consists of a few components: (1) a decomposer and serializer, which decomposes the problem into smaller subtasks and performs an input serialization; (2) a tokenizer, which performs tokenization to obtain a vectorized representation of the input; (3) a sequence-to-sequence model, which predicts an output for each subtask; and (4) an aggregator, which is responsible for combining the predictions of the subtasks to generate a final prediction. In the rest of this section, we will discuss the details of those components.",42.29%,70.35%,83.91%,48.87%,79.24%
205,images/s45.png," The diagram shows the relationship between the number of operators, users, CPI, operators' income, traffic, and unemployment. The number of operators has a negative effect on CPI and a positive effect on users, traffic, and operators' income. CPI has a negative effect on users and a positive effect on unemployment. Operators' income has a positive effect on traffic. Traffic has a positive effect on users. Unemployment has a negative effect on the number of operators and a positive effect on CPI.","Specific examples of speech recognition errors are detailed in Table 1. Error severity was marked as clinically significant or not clinically significant according to the ontology of Chang et al (3) and as used in recent studies (9,14). Clinically significant errors are considered to change the meaning of the report and risk misinterpretation by the clinician.",11.99%,67.55%,80.94%,39.92%,79.23%
206,images/s46.png," | Band | Sub-band | Operators |
|---|---|---|
| 700 | 758-803 MHz (45 MHz) | Tigo (20 MHz), WOM (10 MHz), Claro (10 MHz), NA (10 MHz) |
| 850 | 849-894 MHz (45 MHz) | Duplex (20 MHz), Claro (11 + 1.5 MHz), Movistar (10 + 2.5 MHz) |
| 1900 | 1945-1990 MHz (45 MHz) | NA (2.5 MHz), Movistar (10 + 5 MHz), Claro (7.5 MHz), Tigo (20 MHz) |
| 1700 | 2110-2155 MHz (45 MHz) | WOM (15 MHz), Movistar (15 MHz), Tigo (15 MHz) |
| 2600 | 2645-2690 MHz (45 MHz) | Claro (30 MHz), DirecTV (15 MHz) |",Table 2 summarizes domain wise model uncertainty scores (Normalized Predictive Entropy and Semantic Entropy) for FOS benchmark dataset,0.00%,54.36%,76.50%,0.00%,38.44%
207,images/s47.png," | Parameter | Value | Unit |
|---|---|---|
| Bandwidth (Br) | 225 | MHz |
| Number of channels (Nch) | 5 | - |
| IF bandwidth (B) | 45 | MHz |
| Sampling frequency (fs) | 45 | MHz |
| Sampling time (Ts) | 22.2 | ns |
| Number of measurements (Nm) | 5 | - |
| Number of FFT points (Nfft) | 15,000 | - |
| Frequency offset (Δf) | 3 | kHz |
| Time window (Tw) | 0.33 | ms |
| Processing time (Tproc) | 0.167 | ms |
| Dead time (Tds) | 0.5 | ms |
| Range (R) | 2.5 | m |
| Time between measurements (T1) | 1 | min |
| Number of averages (N1) | 60 | - |
| Total measurement time (Tt) | 60 | min |
| Band | 700 | MHz |
| Center frequency (f0) | 780.5 | MHz |
| Band | 850 | MHz |
| Center frequency (f0) | 871.5 | MHz |
| Band | 1900 | MHz |
| Center frequency (f0) | 1967.5 | MHz |
| Band | 1700 | MHz |
| Center frequency (f0) | 2132.5 | MHz |
| Band | 2600 | MHz |
| Center frequency (f0) | 2667.5 | MHz |","For example, L-OCRD 250 comprises table sources having less than 250 tokens. LOCRD 500 comprises table sources having less than 500 tokens. In contrast, for the TSR task, we create a single variant TSRD with maximum tokens less than 250.3 The statistics of TSRD, L-OCRD 250, and L-OCRD 500 are shown in Table 1. S",0.91%,9.18%,77.27%,33.63%,55.35%
208,images/s48.png," | Reference | Publication Year | Purpose | Method | Accuracy | Precision |
|---|---|---|---|---|---|
| Agarwal et al. [1] | 2023 | Automatic system to save time via manual dress reading | CNN + YOLOv4 | 81.82% | - |
| Yousef et al. [2] | 2019 | Address the difficulty of using clothes detection in the actual world | Modified YOLO and SSD | - | 91.14% |
| Ma et al. [3] | 2023 | Balance between accuracy and speed | YOLO-FL | 91.14% | - |","As depicted in Figure 1, LLM1 is tasked with the creation of probes based on the given the prompt template, whereas LLM2 is responsible for generating responses to these probes. The prompt template for LLM1 is iteratively created using human-in-the-loop technique described by Shah [20].",10.20%,24.53%,79.81%,37.78%,67.68%
209,images/s49.png," This is a diagram of a convolutional neural network (CNN) architecture for image classification. The input image is first passed through a convolutional layer with a 7x7 kernel size and a stride of 2. This is followed by a pooling layer with a 3x3 kernel size and a stride of 2. The next layer is a convolutional layer with a 3x3 kernel size and a stride of 1. This is followed by a convolutional layer with a 3x3 kernel size and a stride of 1. The final layer is a fully connected layer with 1024 units. The output of the fully connected layer is a 10-dimensional vector, which represents the probability of the input image belonging to each of the 10 classes.",Table 1 presents a comprehensive set of metrics tailored to assess various dimensions of the LLM-generated policies.,17.22%,81.25%,81.65%,36.07%,72.00%
210,images/s5.png," The received signal is first demodulated using an OFDM demodulator. The demodulated signal is then passed through a CPE correction block, which corrects for channel impairments such as phase noise and frequency offset. The corrected signal is then decoded using a decoder, which recovers the original bits that were transmitted.

In the presence of phase noise, the received signal can be expressed as:

$$r(t) = s(t) * h(t) * e^{j2\pi f_0t + j\theta(t)}$$

where \(s(t)\) is the transmitted signal, \(h(t)\) is the channel impulse response, \(f_0\) is the carrier frequency, and \(\theta(t)\) is the phase noise.

The CPE correction block can be used to estimate and correct for the phase noise. The estimated phase noise is used to compensate for the phase noise in the received signal. The compensated signal is then passed to the decoder.

The decoder uses the Viterbi algorithm to decode the received signal. The Viterbi algorithm is a maximum likelihood sequence decoder that can be used to decode convolutional codes. The decoded signal is then passed to the demodulator, which recovers the original bits that were transmitted.","Table 1 summarizes state-of-the-art main applications of LLMs to protein processing, analysis, modeling and design.",15.74%,76.27%,80.48%,34.44%,77.95%
211,images/s50.png," The table shows the training parameters for three different models. The first model is a ResNet152 model, the second model is an EfficientNetB7 model, and the third model is a Two Goal Learning model. All three models are trained on images of size 224x224 pixels. The ResNet152 model is trained for 10 epochs, the EfficientNetB7 model is trained for 10 epochs, and the Two Goal Learning model is trained for 10 epochs. All three models are trained using the categorical cross-entropy loss function and the Adam optimizer. The ResNet152 model uses a softmax activation function, the EfficientNetB7 model uses a softmax activation function, and the Two Goal Learning model uses a softmax activation function. All three models are trained with a learning rate of 0.0001 and a batch size of 16.","This paper focuses on the field of TCM. By consulting the literature, we have established entity types and identifiers within the entity relationship recognition model, totaling seven categories, disease, symptom, drug, prescription, diet, treatment methods, and etiology and pathogenesis, as shown in Table 1.",24.82%,85.69%,81.40%,37.91%,80.34%
212,images/s51.png," | Model | Accuracy | Precision | Recall | F1-Score |
|---|---|---|---|---|
| EfficientNetB7 (Base) | 0.91 | 0.92 | 0.91 | 0.91 |
| Resnet152 (Base) | 0.86 | 0.86 | 0.86 | 0.86 |
| Two-Goal Learning Model | 0.94 | 0.94 | 0.94 | 0.94 |","We provide an example rubric for parts of the Tradeoffs of FEW Page 11/34 Systems: Biomass Energy Production question item (hereafter referred to as “Biomass question item”) in Table 2, and the other rubrics are available in the Appendix.",0.00%,32.03%,78.57%,0.00%,36.09%
213,images/s52.png," The proposed intelligent malware detection model consists of three main components:
- **Incremental learning**: In this component, the model is trained on a dataset of malware samples. The model learns to identify the features that are most relevant to malware detection.
- **Weight adjustment**: In this component, the model's weights are adjusted to improve its performance. This is done by using a technique called incremental learning.
- **Top features selection**: In this component, the model selects the most relevant features for malware detection. This is done by using a technique called top features selection.","In this approach, actual images (ground truth images) representing the specific fruit crop categories were provided to the model as input image prompts as shown in Figure 3. The model was then activated to generate four variations of the given input image upon receiving the command ""Generate Variations."" An illustration of this approach to image generation is depicted in Figure 3.",31.43%,78.36%,83.06%,44.68%,75.60%
214,images/s53.png,Error: Invalid response from model,"A brief description of these fea- tures is given in Table 1. Those table parts are denoted as W (whole table), R (row headers) and O (table contents except for R, see Figure 1) [13]. Each feature is characterized by whether it is dependent on the only table (Q), only sentence (D), and both table and sentence (Q–D). Besides, details of features are given below:",0.00%,50.34%,80.03%,0.00%,60.43%
215,images/s54.png," | Type | Features | Rank |
|---|---|---|
| Crypto APIs | CryptEncrypt | 1 |
|  | CryptGenKey | 3 |
|  | CryptDestroyKey | 6 |
|  | BCryptGenRandom | 9 |
| File access APIs | CreateFile | 2 |
|  | FindFirstFileExA | 5 |
|  | FindNextFileA | 8 |
|  | DeleteFile | 10 |
| Network APIs | WinHttpConnect | 4 |
|  | WinHttpOpenRequest | 7 |","The autoencoder compressing the LLM embedding was fit on the 2019 ICD-10-CM descriptions for 20 epochs, with batch sizes 64, 128, and 256, mean-square error loss between the embedding and autoencoder estimate, and a validation data set comprised of random subset of 10% of the samples. The model performance is shown in Table 1. Based on these results the models with the best validation loss for each of the compressed embedding dimensions selected for further validation and eventual distribution",1.38%,1.12%,75.21%,0.00%,61.66%
216,images/s55.png," The diagram shows the steps involved in the process of developing a network intrusion detection system (NIDS). The steps are as follows:

1. Scope Definition: This step involves defining the scope of the NIDS, including the network segments to be monitored, the types of attacks to be detected, and the level of detection accuracy required.
2. Infrastructure Preparation: This step involves setting up the necessary infrastructure for the NIDS, including the sensors, the network traffic capture devices, and the analysis servers.
3. Defining Users and Entities: This step involves defining the users and entities that will be using the NIDS, as well as their roles and responsibilities.
4. Designing Benign Traffic Generator: This step involves designing a benign traffic generator that will be used to generate legitimate network traffic for the NIDS to learn from.
5. Studying Attack Trends: This step involves studying the latest attack trends and techniques in order to better understand the types of attacks that the NIDS will need to be able to detect.
6. Attack Selection and Implementation: This step involves selecting the attacks that the NIDS will be designed to detect and implementing those attacks in a controlled environment.
7. Data Capturing and Analysis: This step involves capturing network traffic and analyzing it to identify patterns and signatures of malicious activity.
8. Development of Traffic Analyzer: This step involves developing a traffic analyzer that will be used to analyze the network traffic and identify malicious activity.
9. Data Labeling and Testing: This step involves labeling the network traffic data with the appropriate labels (e.g., malicious, benign) and testing the NIDS to ensure that it is able to accurately detect malicious activity.","The training of LLMs can be broadly categorized into two paradigms, traditional fine-tuning and prompting, based on how they are used for adapting to downstream tasks. Due to the substantial distinctions between the two paradigms, various types of explanations have been proposed respectively (shown in Figure 1).",29.39%,89.63%,80.49%,36.70%,75.87%
217,images/s56.png," This diagram shows a network with a bastion host, which is a computer that is placed between two networks and is used to control access between them. In this case, the bastion host is used to control access between the internal network and the Internet. The bastion host has two network interfaces, one connected to the internal network and one connected to the Internet. The bastion host also has a firewall that is configured to allow only certain types of traffic between the two networks. For example, the firewall might be configured to allow only HTTP traffic from the internal network to the Internet, and only SSH traffic from the Internet to the internal network. This helps to protect the internal network from attack.","Table 1 contains a breakdown of the number of bugs per project. We justify our decision to focus on single method bugs as methods generally define a unit of code that can be reviewed independently compared to isolated lines, or an entire file or repository. Second, the input prompt for LLMs are restricted to only a few thousand tokens that may not suffice to capture the entire file or repository level information. APR approaches using the Defects4J dataset often restrict their dataset to contain only single hunk, or single line bugs[59]. We do not make this restriction, and Table 1 shows the average number of hunks for bugs in our dataset.",26.42%,87.87%,80.94%,45.16%,84.20%
218,images/s57.png," The table shows the number of IP packets, TCP packets, and UDP packets on a network on four different days.

The total number of IP packets on the four days is 128,229,471. The total number of TCP packets is 117,647,195. The total number of UDP packets is 10,565,139.

The percentage of TCP packets in the total number of IP packets is 91.69%. The percentage of UDP packets in the total number of IP packets is 8.27%.","As shown in Table 1, polyglot shows worse scores in SELF-BLEU and toxicity than two multilingual LLMs since polyglot fails to generate offensive language in all conditions. Moreover, it fails to generate meaningful text. Although it is a Korean LLM, it usually generates English sentences by following some parts of the given demonstration, even repeating meaningless tokens such as emojis, @username, and URL addresses.",10.29%,58.79%,79.87%,40.35%,77.10%
219,images/s58.png," This diagram shows the standard reinforcement learning loop, which is used to train a Q-table for an optimal control problem. The agent interacts with the environment by taking actions and observing the resulting states and rewards. The agent uses the Q-table to store the expected value of each state-action pair, and it uses this information to choose the best action to take in each state. The Q-table is updated after each action, and the process is repeated until the agent has learned the optimal policy.

The discretization function is used to convert the continuous state space into a discrete state space. This is necessary because the Q-table is a finite data structure, and it cannot store an entry for every possible state in the continuous state space. The discretization function is typically chosen to be a uniform grid, but other methods can also be used.

The update discretization criterion is used to determine when to update the discretization function. This is necessary because the discretization function may not be optimal for all states, and it may need to be updated as the agent learns more about the environment. The update discretization criterion is typically chosen to be a threshold on the error between the expected value of the state-action pair and the value stored in the Q-table.

The check update criterion is used to determine when to update the Q-table. This is necessary because the Q-table may not be optimal for all states, and it may need to be updated as the agent learns more about the environment. The check update criterion is typically chosen to be a threshold on the error between the expected value of the state-action pair and the value stored in the Q-table.","This is especially true for the dense and often implicit semantics and diffuse context inherent in scientific tables in highly specialized domains (Mulwad et al. 2014). Representing scientific tables as semantically annotated linked data artifacts accounts for structural complexities and enables explicit reasoning over tabular content to infer their semantics and relevance to search queries. Hence, entity linking (EL) is fundamental to our end-to-end pipeline for constructing such knowledge graphs of tables drawn from scientific documents, as depicted in Figure 1.",22.52%,86.47%,78.77%,38.21%,84.43%
220,images/s59.png, The table shows the average number of episodes required to reach the goal for each method and discretization. The results show that the Q-compression method outperforms the grid-based method for all discretizations.,"Table 2 shows the test accuracy results for various models when choosing the size of ngrams via cross-validation. Compared with interpretable baselines, Aug-Linear shows considerable gains on three of the datasets and only a minor gain on the tweet dataset (Emotion), likely because this dataset requires fitting less high-order interactions.",31.63%,91.83%,85.94%,29.68%,80.22%
221,images/s6.png," In this study, we propose a deep learning-based approach for the classification of Parkinson’s disease (PD) using handwriting samples. The proposed approach consists of three main stages: data preprocessing, feature extraction, and classification. In the data preprocessing stage, the handwriting samples are preprocessed to remove noise and enhance the quality of the images. In the feature extraction stage, deep learning models are used to extract discriminative features from the preprocessed images. In the classification stage, a machine learning classifier is used to classify the extracted features into two classes: PD and healthy control. The proposed approach is evaluated on a dataset of handwriting samples from PD patients and healthy controls. The experimental results demonstrate that the proposed approach achieves promising performance in classifying PD from healthy controls.","Table 1 presents results of different text encoders, and Figure 1 shows generated samples of FigGenBase. We find that the large text encoder offers the best results and that we can improve conditional generation by increasing the CFG scale. Although qualitative samples do not present sufficient quality to solve the task, FigGen has learned interesting relationships between texts and figures such as the difference between plots and architectures (see also Appendix A.3).",32.60%,92.70%,82.59%,42.78%,79.38%
222,images/s60.png," | Discretization Method | Episode |
|---|---|
| Grid-based | 702 |
| Q-compression | 144 |","The models listed in Table 1 were evaluated using a standardized set of benchmark tasks tailored for the tourism sector. These tasks were designed to assess the models' capabilities in understanding and processing tourism-related content, including customer reviews, travel itineraries, cultural descriptions, and multilingual queries.",0.00%,9.60%,79.46%,0.00%,52.95%
223,images/s61.png," This diagram shows how to set up a development environment for Flutter using Docker.

## Setup instruction:
1. Install Docker on your PC.
2. Install Visual Studio Code.
3. Install the Flutter and Dart plugins for Visual Studio Code.
4. In Visual Studio Code, open the Command Palette (Ctrl+Shift+P) and select ""Flutter: New Project"".
5. Select the location for your new Flutter project and click ""Create"".
6. Open the terminal in Visual Studio Code (Ctrl+`).
7. Run the following command to create a Dockerfile in your project directory:

```
touch Dockerfile
```

8. Copy the following code into the Dockerfile:

```
FROM ubuntu:20.04

RUN apt-get update && apt-get install -y \
    git \
    curl \
    wget \
    zip \
    unzip \
    jq \
    build-essential \
    libgtk2.0-dev \
    libsdl2-dev \
    libglib2.0-dev \
    libxcb-xinerama0-dev \
    libxdamage-dev \
    libnotify-dev \
    libgconf2-dev \
    libnss3-dev \
    fonts-liberation \
    libasound2-dev \
    libpulse-dev \
    libcups2-dev \
    libx11-dev \
    libxtst-dev \
    libxrandr-dev \
    libxcursor-dev \
    libxinerama-dev \
    libxcomposite-dev \
    libgl1-mesa-dev \
    g++-multilib \
    libc6-dev-i386

RUN git clone https://github.com/flutter/flutter.git /flutter

RUN cd /flutter && git checkout tags/stable

RUN echo ""export PATH=\$PATH:/flutter/bin"" >> ~/.bashrc

RUN /flutter/bin/flutter doctor

WORKDIR /flutter/example

CMD [""/flutter/bin/flutter"", ""run""]
```

9. Run the following command to build the Docker image:

```
docker build -t flutter-dev .
```

10. Run the following command to run the Docker container:

```
docker run -it --rm -v ""$PWD:/flutter/example"" -p 8080:8080 flutter-dev
```

11. Open a web browser and go to http://localhost:8080 to see your Flutter app running.","In this study, we evaluated nine LLMs (summarized in Table 1), where six of them were released within the past year (since July 2022). The models vary i.a. in terms of training corpus, vocabulary size, number of parameters, layers and maximum input sequence length.",7.11%,51.14%,74.65%,34.69%,59.11%
224,images/s62.png," **Exercise 1:**

* The size of the box should be 400 x 400.
* The color of the box should be yellow.
* The box should have a pink shade.
* The text inside the box should be ""50"".

**Exercise 2:**

* The list should be shown in descending order.
* The arrow direction should be modified.

**Exercise 3:**

* The icon color of the alert dialog should be red.
* The button style should be outlined.
* The text of the button should be ""OK"".","The results in Table 1 shown that 1) Using zeroshot CoT and analogy prompting can enhance the model performance to natural science questions; 2) Conversely, in the social science and language science domains, the model performance declines, indicating that knowledge reserves are more critical in the humanities, rendering zero-shot CoT and analogical reasoning less effective for these subjects; 3) Analogical reasoning yields superior performance in natural science questions compared to the zero-shot CoT instruction",20.78%,34.49%,79.59%,39.53%,75.09%
225,images/s63.png," The table shows the number of students who responded to each question. For each question, the number of students who responded with ""yes"" is shown in the ""Yes"" column, and the number of students who responded with ""no"" is shown in the ""No"" column.

The most popular question was Q4, which asked students if they were familiar with VSCode. 21 students responded to this question, and 18 of them responded with ""yes"". The least popular question was Q3, which asked students if they were familiar with Docker. 10 students responded to this question, and 6 of them responded with ""yes"".","In this study, the focus of image analysis was six distinct fruit crops datasets, as shown in Figure 1. The dataset encompassed a variety of fruit crops, including strawberries, mangoes, apples, avocados, rockmelons, and oranges. These fruits were carefully selected for their distinctive morphological, textural, and color characteristics, as well as their diverse backgrounds.",16.02%,64.93%,81.65%,40.67%,75.92%
226,images/s64.png," In the figure, the Federated Averaging Server is responsible for coordinating the training process. It maintains a global model, which is initially randomly initialized. The local devices (e.g., Raspberry Pis, Odroids, Virtual Machines) train their local models on their respective datasets. The local models are then uploaded to the Federated Averaging Server, which aggregates the models and updates the global model. The updated global model is then sent back to the local devices, which continue the training process. This process is repeated until the global model converges.","Table 1 summarizes our dataset statistics with examples. For template-based prompts, we apply a set of filters to obtain images with only 1-2 types of object and then create prompts based on object categories and bounding box information. As for natural prompts, we extract COCO captions with keywords to suit the task of numerical reasoning (e.g. “four”) or spatial reasoning (e.g. “on top of”) and ensure that all objects from the bounding box annotations are mentioned in the caption to avoid hallucination.",16.65%,82.31%,82.80%,41.76%,77.61%
227,images/s65.png," | HW | RAM | SWAP | CPU | No. of Cores | Memory |
| :--- | :--- | :--- | :--- | :--- | :--- |
| PI | 1 GB LPDDR2 SDRAM | 4 GB | Cortex-A53 (1.4 GHz) | 4 | 16 GB Micro SD |
| Odroid | 4 GB LPDDR4 RAM | 0 | Quad-core Cortex-A73 (2.2 GHz), Dual-core Cortex-A53 (2 GHz) | 6 | 32 GB eMMC |
| PC | 12 GB DDR4 SDRAM | 0 | Core i7-6500U (3.1 GHz) | 2 | 1 TB Hard Drive |",Component Analysis Table 3 presents the component analysis of our CSS-style prompt on spatial reasoning prompts. Comparisons between line 1-3 entails that the task instructions (#2) and CSS format (#3) effectively improve layout accuracy.,0.78%,55.69%,76.93%,34.02%,56.52%
228,images/s66.png," In this study, we propose a deep learning-based approach for COVID-19 detection using chest X-ray images. The proposed approach consists of three main stages: data preprocessing, feature extraction, and classification. In the data preprocessing stage, the chest X-ray images are collected and preprocessed to remove noise and enhance the image quality. In the feature extraction stage, a deep convolutional neural network (CNN) is used to extract features from the preprocessed images. In the classification stage, a support vector machine (SVM) classifier is used to classify the extracted features into two classes: COVID-19 and normal. The proposed approach is evaluated on a dataset of 100 chest X-ray images, and it achieves an accuracy of 95%. The proposed approach is promising for COVID-19 detection and can be used as a potential tool for screening and diagnosis of COVID-19.","In Table 1, we present in detail the test results of GPT3.5- 410 Turbo on three types of methods: baseline, single grimoire, 411 and SLEICL. Overall, the single grimoire and SLEICL have 412 better average accuracy than baseline on all task datasets, 413 with HSS-PG (r=0.5) and KCS-PG having the highest aver414 age accuracy, exceeding baseline by 4.72% and 3.5%, respec415 tively. This indicates that the grimoire generated by strong 416 language model can effectively improve the performance of 417 weak language model on various tasks",27.21%,89.62%,80.95%,42.16%,74.78%
229,images/s67.png," | Research                                                           | Model Approach                                                                                                                                 | Test Acc (%) | G-Mean (%) |
|-------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------|-------------|------------|
| Gustav Gaal et al. [33]                                              | Integration of U-Net with AT, contrast enhancement                                                                                                | 97.49        | 97.13      |
| Abbas et al. [34]                                                   | CNN with FD and enhancement using ImageNet and ResNet (DeTraC)                                                                                   | 95.12        | 94.69      |
| Narin et al. [35]                                                    | Adaptation of ResNet50 via transfer learning                                                                                                    | 97.00        | 96.7       |
| Wang et al. [46]                                                     | Application of TL to COVID-Net                                                                                                                 | 92.4         | 91.06      |
| Asnaoui et al. [47]                                                   | Exploration of multiple architectures including Xception, VGG16-19, and DenseNet201                                                                | 96           | 95.98      |
| Sethy et al. [32]                                                    | Combination of ResNet50 deep features with support vector machines                                                                                  | 95.3         | 94.1       |
| Ioannis et al. [49]                                                  | Fine-tuning of models like Xception, VGG19, and Inception for enhanced accuracy                                                                      | 95.57        | 93.44      |
| Ghoshal et al. [45]                                                   | Implementation of Bayesian CNN with Dropweights for uncertainty                                                                                   | 88.39        | 89.91      |
| AbdulHafeez [48]                                                     | Utilization of a pre-trained ResNet50 architecture with COVIDx dataset                                                                               | 96.22        | 95.8       |
| Louati et al. [50]                                                    | Optimization of CNN architecture via topology                                                                                                     | 98.1         | 97.91      |
| Our Work                                                            | -                                                                                                                                              | **99.03**       | **98.83**      |","To select different reconstruction methods and prompt types for each model in Table 1, we examine three cases - (1) LPR (NS), (2) MCR (NS), and (3) MCR (OS) (Table 3) for 100 randomly selected examples in each task in ChaosNLI. All the PE models except for GPT-3.5-D3 perform the best using MCR (OS), and especially smaller models like Flan-T5-L show significantly higher performance (+10%) for MCR (OS) compared to the results obtained using LPR/MCR (NS). Thus, relatively small models benefit from reconstructing the label distribution with the MCR method and OS prompt type.",6.40%,42.38%,68.75%,37.09%,65.47%
230,images/s68.png," | Category Type | Description | Known ID | Unknown ID | Personal Status |
| ----------- | ----------- | ----------- | ----------- | ----------- |
| HOS | Identifying patients in a hospital before a patient takes their heart test. | O | X | X |
| SCK | Using ECG data in a security check. | O | O | X |
| WD | Identifying ownership for using personal wearable devices. | X | O | O |","We present the overview of the proposed Codeditor model in Figure 2. Codeditor is built upon the encoder-decoder framework which consists of a transformer-based encoder and a transformerbased decoder [46]. Many conditional generation tasks, including code summarization and translation, are being addressed with encoder-decoder models [1, 20, 47, 48].",1.75%,17.72%,77.38%,35.77%,69.82%
231,images/s69.png," In this diagram, there are two main processes: ECG training use cases and ECG testing use cases. The ECG training use cases are used to train the machine learning model, while the ECG testing use cases are used to test the performance of the trained model. Both processes involve several steps:

ECG Training Use Cases:
1. Pre-process: The raw ECG data is pre-processed to remove noise and artifacts.
2. ECG Time-Slice: The pre-processed ECG data is divided into time slices.
3. Machine Learning: A machine learning algorithm is used to train the model on the time-sliced ECG data.
4. ML Model: The trained model is then used for ECG classification.

ECG Testing Use Cases:
1. Pre-process: The raw ECG data is pre-processed to remove noise and artifacts.
2. ECG Time-Slice: The pre-processed ECG data is divided into time slices.
3. Use Case Validation: The time-sliced ECG data is used to test the performance of the trained model.
4. System Authentication: If the model is able to correctly classify the ECG data, then the system will authenticate the user.","We decided that the most reasonable value substitute would be the maximum among the remaining values for each log probability score, respectively. The final evaluation results are shown in Table 2.",22.37%,80.66%,79.29%,35.96%,72.76%
232,images/s7.png," From the table, we can see that:
1. In general, the performance of VGG16 is better than VGG19, and the performance of ResNet50 is better than ResNet101.
2. For the same network, the performance of the model on the Spiral dataset is worse than that on the Wave dataset.
3. For the same dataset, the performance of the model with Rotation and Flipping is better than that without Rotation and Flipping.
4. For the same dataset, the performance of the model with Mixup is better than that without Mixup.
5. For the same dataset, the performance of the model with CutMix is worse than that without CutMix.","While not all chatbots can be fit neatly into categories, several dimensions can classify the types of chatbots considered in scientific discourse, each with different characteristics that form the basis for our research. The combined chatbot classifications or taxonomies presented by Adamopoulou & Moussiades (2020b), Diederich et al. (2019), Lokman & Ameedeen (2019), and Hussain et al. (2019) are depicted in Table 1.",22.45%,61.80%,79.43%,38.32%,78.05%
233,images/s70.png," The table shows the parameters used for training the CNN and LSTM models. The CNN model has a learning rate of 0.003, an Adam optimizer, a cross-entropy loss function, a dropout of 0.5, and 7 hidden layers. It is trained for 50 epochs. The LSTM model has a learning rate of 0.002, an Adam optimizer, a cross-entropy loss function, a dropout of 0.3, and 4 hidden layers. It is trained for 100 epochs.","Theory of mind. The answers to the two false-belief tasks were analyzed to assess the ToM understanding of the personas. The first reply following the question “Where will Maxi look?” (or What will your sister think is inside the box?, respectively) was classified into four categories as displayed in Table 1.",24.45%,75.90%,82.10%,39.73%,71.95%
234,images/s71.png," This diagram shows how drones could be used to transport goods in the future. Drones could be used to deliver packages to homes and businesses, and they could also be used to transport goods between different cities. This could help to reduce traffic congestion and pollution.",We evaluated the Flan-T5 model performance on a random sample of 1175 manually annotated discharge summaries with PPH ICD diagnosis codes. Discharge summaries with PPH diagnosis codes were used to enrich for obstetric discharge summaries more likely to contain PPH-related concepts. The FlanT5 performance is summarized in Table 1.,9.81%,71.96%,82.62%,38.02%,75.43%
235,images/s72.png," This is a flowchart that outlines the procedures for processing the input data to generate the output data. The input data is the CFS Geography dataset and the FAF OD dataset. The procedures include cleaning the CFS zone data, extracting the air CONUS, and then aggregating the MSA (weight, value). After this, the FAF zone is pivoted and then merged with the MSA data. Finally, the outliers are identified for both the MSA and the commodity categories. The output data is the isolated MSAs, the identified outlier commodity categories, and the identified outlier MSAs for those categories.",We present some examples retrieved from the original OLID dataset with their respective labels in Table 1.,15.25%,84.87%,83.78%,35.40%,71.14%
236,images/s73.png," The table shows the validation and test set performance of different methods for estimating the depth of field from a single image. The methods are evaluated using the intersection over union (IoU) metric. The best performing method is R-U-Net + ET + LA, which achieves an IoU of 0.812 on the test set.","OLID, the official dataset for this task, featured 14,100 instances retrieved from Twitter divided into training and testing sets. We present a breakdown of the instances in OLID and their label distribution in Table 2",20.79%,82.25%,84.23%,42.14%,79.30%
237,images/s74.png," The table shows the ablation study results of R-UNet on the validation set. We can see that the addition of the LA module consistently improves the performance of R-UNet on all metrics. The largest improvement is seen for the k3 metric, where the addition of the LA module reduces the error by 47.6%. The addition of the LA module also improves the performance of R-UNet on the total metric, reducing the error by 25.9%. These results demonstrate that the LA module is an effective addition to R-UNet for improving the segmentation of retinal vessels.","For the human evaluation, we compared the two systems in a double-blind setting (pairs of outputs were anonymized and presented in a random order). The results of the human evaluation are shown in Table 2.",38.04%,83.47%,83.63%,38.30%,77.28%
238,images/s75.png," The table shows the number of speakers, the number of speech samples per speaker, and the number of whisper speech samples per speaker in three datasets. The CHAINS dataset has 16 male speakers and 20 female speakers, with 37 speech samples and 37 whisper speech samples per speaker. The wTIMIT dataset has 24 male speakers and 24 female speakers, with 450 speech samples and 450 whisper speech samples per speaker. The Whisper40 dataset has 21 male speakers and 19 female speakers, with 40 speech samples and 40 whisper speech samples per speaker.","Table 1 illustrates a brief overview of our input data format, detailing clinical notes, laboratory values, and textual laboratory values. The remaining group consists of numerical data that explicitly include items related to laboratory test results.",8.38%,77.07%,83.05%,36.23%,60.01%
239,images/s76.png," The table shows the statistics of the ASVspoof2019 LA dataset. 
There are 40 speakers in total. 
Each speaker has 3 enrollment whisper speech and 37 test whisper speech. 
The total duration of whisper speech is 19,804.57 seconds. 
The total duration of neutral speech is 19,549.22 seconds. 
The maximum number of seconds per speaker is 30.46 seconds. 
The minimum number of seconds per speaker is 1.96 seconds. 
The average number of seconds per speaker is 12.38 seconds.","Each dataset was divided into a 80% training set and a 20% testing set. Table 1 illustrates a brief overview of our input data format, detailing clinical notes, laboratory values, and textual laboratory values. The remaining group consists of numerical data that explicitly include items related to laboratory test results. We provide statistical samples of the dataset for the diabetes prediction task in Table 2.",19.31%,83.51%,81.91%,42.11%,70.92%
240,images/s77.png," The image shows a neural network architecture for video captioning. The architecture consists of two main components: a segment-level encoder and a frame-level encoder.

The segment-level encoder takes as input a sequence of video frames and produces a sequence of segment-level embeddings. Each segment-level embedding is a fixed-length vector that represents the content of the corresponding video segment.

The frame-level encoder takes as input the sequence of segment-level embeddings and produces a sequence of frame-level embeddings. Each frame-level embedding is a fixed-length vector that represents the content of the corresponding video frame.

The output of the frame-level encoder is then passed to a statistics pooling layer, which produces a single fixed-length vector that represents the content of the entire video. This vector is then used to generate a caption for the video.","To offer a clearer perspective, Table 1 summarizes the reference standards used in various medical AI tasks to evaluate the factual consistency of AI-generated outputs",18.06%,79.33%,82.12%,36.36%,72.88%
241,images/s78.png," This image shows the block diagram of the proposed knee OA severity classification system. The system consists of four main stages: data preprocessing, feature extraction, machine learning, and results evaluation. In the data preprocessing stage, the input X-ray images are resized to a统一大小 of 128x128 pixels and converted to grayscale. In the feature extraction stage, Histogram of Oriented Gradients (HOG) features and Local Directional Pattern (LDP) features are extracted from the preprocessed images. In the machine learning stage, a Support Vector Machine (SVM) classifier is used to classify the extracted features into three classes: normal, mild, and severe. In the results evaluation stage, the performance of the proposed system is evaluated using various metrics such as accuracy, sensitivity, specificity, and F1-score.","For the non-mainstream code, we included cpufetch [10], a program that gathers CPU architecture information, and an Ant Colony Optimization (ACO) implementation [25]. Furthermore, for those codes that unintentionally contained GEMM, convolution, FFT or LU, we removed them from the dataset to make sure that those codes do not contain such algorithms. A description of the dataset is shown in Table 1",20.76%,88.96%,80.68%,38.84%,78.87%
242,images/s79.png," From the table, we can see that the best model is XGBoost, which has the highest cross-validation accuracy of 98.90%. The best hyperparameters for XGBoost are:

* gamma: 0.1
* learning_rate: 0.1
* max_depth: 5
* n_estimators: 100
* subsample: 1.0","For example, the ""Task"" element according to the condition can be transformed into class or method, sequence flow or message flow with association according to the position of each element in the diagram and its meaning in the whole process of the case study in general shown in Table 1",25.63%,49.73%,80.90%,33.29%,58.17%
243,images/s8.png," The figure shows the three main stages of the proposed approach. The first stage is data collection, which involves gathering data from various sources, such as surveys and IT support tickets. The second stage is prediction calculation, which involves using machine learning models to predict the values of the target variables. The third stage is prediction analysis, which involves analyzing the predictions made by the machine learning models.","Our approach is a solution that will highlight a relationship between simple users and IT analysts, starting by translating the need, vision, and situation of a company into a BPMN business process diagram and transforming after this initial model into a more specialized model, and more technically sophisticated, namely the UML class diagram to complete our global vision which to start by writing the model independent of calculation CIM make transformations towards the PIM and the PSM to finally have the code or the software in Figure 1, in our paper, we will carry out the first step which is to be considered as a bridge which the simple users with the computer developers in an automatic way. In our article we are inspired by other works for example the transformation called refinement at the beginning of CIM (BPMN) towards CIM (the use case diagram of UML) after their passage to carry out an another CIM to PIM transformation two diagrams of the same UML language use case diagram to UML sequence diagram, the passage between BPMN and the UML CIM to CIM activity diagram (refinement) and one can notice that there is a great resemblance between these two diagrams, in the dedescription transformation of two diagrams from UML, CIM to PIM. We chose to start with a case study represented by a BPMN diagram and to go directly to the UML class diagram which allowed us to go more on the IT development side without going through other transformations for example case diagram usage, sequence diagram, or activity diagram of UML [17]–[25].",38.33%,86.27%,81.10%,3.06%,84.59%
244,images/s80.png," In this figure, (a) shows the deep learning model for brain tumor classification. The model consists of a convolutional layer, a pooling layer, and a dense layer. The input to the model is an MRI image of the brain, and the output is a classification of the tumor type. (b) shows the explainability techniques that can be used to interpret the deep learning model. The techniques include Grad-CAM, Grad-CAM++, Integrated Gradients, and Saliency Mapping. The output of the explainability techniques is a heatmap that shows the regions of the MRI image that are most important for the classification.","In Figure 2, one can see the decoding layer placed after the stacked encoding transformer layers, which is just a linear projection. The dot product of sequence context with this linear layer results in two logits for each input token: start and end score. The higher the score is, the more confident the model is that this token is the start or the end of the answer. Therefore, the argmax operation applied to lists of start and end positions logits returns boundaries for the predicted answer. This approach for solving CBQA tasks with encoding Transformer LMs was first introduced with the BERT model release and later became the de facto standard for solving any machine reading comprehension task with transformers",57.32%,88.18%,82.96%,44.57%,84.76%
245,images/s81.png," | Model Name | Parameters | Training Accuracy | Loss |
|---|---|---|---|
| AlexNet | 61.9 M | 0.8763 | 0.3233 |
| DenseNet121 | 8.1 M | 0.9986 | 0.0057 |
| EfficientNetB0 | 5.3 M | 0.9991 | 0.0042 |
| GoogleNet | 11.2 M | 0.9997 | 0.0027 |
| Inception V3 | 23.9 M | 0.9989 | 0.0084 |
| ResNet50 | 25.6 M | 0.9991 | 0.0044 |
| VGG16 | 138.4 M | 0.8698 | 0.4011 |
| VGG19 | 143.7 M | 0.8570 | 0.3953 |
| Vision Transformer | 86 M | 0.7484 | 0.5115 |
| Xception | 22.9 M | 1.0000 | 0.0021 |","Table 3 demonstrates the costs of the N-shot bilingual instruction prompting method for each unique set of parameters. In the table, TOKTOTAL and price columns were calculated as the sum of values for each of all 1343 examples from the test set. The detailed stats for the temperature parameter weren’t included in the table since it affects only the length of the generated answer, so its influence on the total price is close to zero compared to the instruction language parameter ILANG and the number of training examples N added to the prompt",0.40%,-6.99%,76.09%,0.00%,40.89%
246,images/s82.png," | Model Name | Accuracy % | Precision % | Recall % | F1 Score % |
|---|---|---|---|---|
| AlexNet | 78 | 80 | 77 | 77 |
| DenseNet121 | 97 | 97 | 97 | 97 |
| EfficientNetB0 | 98 | 98 | 98 | 98 |
| GoogleNet | 91 | 93 | 92 | 92 |
| Inception V3 | 96 | 97 | 96 | 96 |
| Resnet50 | 95 | 96 | 96 | 96 |
| VGG16 | 85 | 85 | 86 | 85 |
| VGG19 | 85 | 85 | 85 | 85 |
| ViT Transformer | 70 | 72 | 72 | 70 |
| Xception | 96 | 97 | 96 | 96 |","The complete results of the evaluation of baseline extractive models trained on the UA-SQuAD dataset, as well as those trained entirely on or augmented by generated annotations, are demonstrated in Table 5.",0.00%,6.48%,75.64%,0.00%,18.86%
247,images/s83.png," The table shows the results of a risk assessment for a smart home system. The assessment was conducted using the CVSSv3 scoring system. The columns in the table are as follows:

- Ident: The unique identifier for the risk.
- Id Threat: The identifier for the threat.
- Threat: The name of the threat.
- CoA: The name of the control.
- IdControl: The identifier for the control.
- Control: The name of the control.
- Time: The amount of time it would take to exploit the vulnerability.
- Sustainability: The sustainability of the control.

The risks are ranked from highest to lowest according to their CVSSv3 score. The highest-ranked risk is Ident 1, which has a score of 9.1. This risk is associated with the threat of a denial-of-service (DoS) attack. The attack could be launched by a remote attacker and could cause the smart home system to become unavailable. The control that is recommended to mitigate this risk is IdControl 1, which is to implement mechanisms for self-diagnosis and self-repair/healing. This control would help to ensure that the smart home system is able to recover from a DoS attack.

The second-highest-ranked risk is Ident 2, which has a score of 8.8. This risk is associated with the threat of data leakage. The data leakage could be caused by a malicious insider or by a hacker who has gained access to the smart home system. The control that is recommended to mitigate this risk is IdControl 2, which is to implement role-based access control (RBAC). RBAC would help to ensure that only authorized users have access to sensitive data.

The third-highest-ranked risk is Ident 3, which has a score of 8.5. This risk is associated with the threat of interception of information. The information could be intercepted by a malicious insider or by a hacker who has gained access to the smart home system. The control that is recommended to mitigate this risk is IdControl 3, which is to implement encryption. Encryption would help to protect the information from being intercepted.

The fourth-highest-ranked risk is Ident 4, which has a score of 8.2. This risk is associated with the threat of communication protocol hijacking. The attacker could hijack the communication protocol and use it to gain access to the smart home system. The control that is recommended to mitigate this risk is IdControl 4, which is to implement a secure communication protocol. A secure communication protocol would help to protect the smart home system from being accessed by unauthorized users.

The fifth-highest-ranked risk is Ident 5, which has a score of 8.1. This risk is associated with the threat of a failure of devices. The failure could be caused by a hardware defect or by a software bug. The control that is recommended to mitigate this risk is IdControl 5, which is to implement redundant devices. Redundant devices would help to ensure that the smart home system is still able to function even if one or more devices fail.","Table 8 shows that both systems produced output on 30 of the 31 tables, meaning that one table could not be processed by the module. Predicates could be extracted without many problems, followed by subjects and objects.",23.09%,81.90%,79.74%,35.33%,75.61%
248,images/s84.png," From the table we can see that for incident 13, course of action C31 has the lowest time of 1.","Step 1 is an automatic translation from the M-UML diagram to a Maude specification, for we use the control structures in Maude as shown in Table 1.",17.84%,71.14%,83.90%,35.23%,80.21%
249,images/s85.png," The proposed framework consists of three main stages:
1. **Input Video**: In this stage, the input video is preprocessed to extract the relevant objects using a single-shot detector. The objects considered in this work are blackboard, whiteboard, person, notebook, mobile phone, chair, table, book, stick, and food. The detector is applied to every 5th frame of the video to reduce the computational cost. 


2. **Scene Classification**: In this stage, the preprocessed video is classified into two categories: teacher scene and student scene. This is achieved by using a decision tree classifier based on the presence of specific objects in the frame. If the blackboard, whiteboard, or stick is present in the frame, it is classified as a teacher scene, otherwise, it is classified as a student scene. 


3. **Action Classification**: In this stage, the actions of the teacher and students are classified using 3D convolutional neural networks (3D ConvNets) and support vector machines (SVMs). For the teacher scene, the actions considered are writing on the blackboard, writing on the whiteboard, and pointing. For the student scene, the actions considered are reading, writing, and looking at the teacher.","Above we have introduced the basic situation of all the test tasks selected in this paper and the reasons for choosing. Table 1 summarizes the datasets used in all experiments, and Figure 2 provides an example prompt for each of the three categories of tasks.",41.35%,83.94%,80.65%,38.32%,79.37%
250,images/s86.png," This is a diagram of a Generative Adversarial Network (GAN). A GAN consists of two neural networks, a generator and a discriminator. The generator takes random input and generates fake images, while the discriminator tries to distinguish between real and fake images. The two networks are trained together in a zero-sum game, where the generator tries to fool the discriminator and the discriminator tries to correctly classify the images.","All LLMs were uniformly fine-tuned using LORA, with details on the parameter count and pre-training data volume presented in Table 2",11.70%,76.22%,82.83%,36.23%,75.00%
251,images/s87.png," The figure shows the research model, which includes six independent variables and one dependent variable. The independent variables are relative advantage, compatibility, management support, organizational readiness, external support, and government regulations. The dependent variable is mHealth adoption, which is hypothesized to have a positive effect on health disparity reduction. The model is based on the theory of diffusion of innovation, which suggests that the adoption of new technologies is influenced by a variety of factors, including the perceived relative advantage of the technology, its compatibility with existing practices, the support of management and the organization, the readiness of the organization to adopt the technology, the availability of external support, and the existence of government regulations.","The final results, as shown in Table 3, are presented succinctly, with dataset names abbreviated and corresponding to those listed in Table 1 in sequence. It was observed that Llama-13b performed the best, affirming that model parameter size remains a crucial factor in gene-related domains. BLOOM and BioGPT followed closely behind, ranking second and third respectively, suggesting that the diversity (BLOOM was pre-trained on multilingual corpora) and specialization (BioGPT was pre-trained on specialized biological corpora) of pre-training corpora significantly contribute to model performance.",22.40%,87.04%,82.06%,43.19%,77.33%
252,images/s88.png," The table shows the distribution of doctors and nurses according to gender, age, experience, and setting. The chi-square test was used to compare the distribution of doctors and nurses. The results show that there is a significant difference in the distribution of doctors and nurses according to gender (p-value = 0.000), age (p-value = 0.000), and experience (p-value = 0.000). However, there is no significant difference in the distribution of doctors and nurses according to setting (p-value = 0.064).","The performance of all LLMs on cell annotation tasks is shown in Table 5. The left side presents results for the M.S. dataset (comprising 18 categories), and the right side for the human embryonic dataset (comprising 61 categories).",26.02%,84.80%,83.31%,41.77%,72.64%
253,images/s89.png," In this image, you can see the different phases of the machine learning process. The first phase is data collection and preprocessing. This includes collecting the data, cleaning it, and preparing it for training the model. The second phase is model training. This includes choosing the right model, training it on the data, and evaluating its performance. The third phase is model deployment. This includes deploying the model to a production environment and monitoring its performance.","As shown in Table 6, the ""cell sentence plus"" technique improved performance for all LLMs above 6 billion parameters, affirming the validity of our approach. However, for GPT-2 and BioGPT, lacking the capability to process long texts, the ""cell sentence plus"" method proved to be burdensome.",27.27%,84.85%,83.77%,40.35%,75.57%
254,images/s9.png," | ML Model | Application | Key Findings |
|---|---|---|
| Tree-based models e.g., Decision Trees (DT), Random Forest (RF), Gradient Boosting Machine (GBM), Extreme Gradient Boosting (XGBoost) and others | Predicting academic success and user satisfaction | Demonstrated high accuracy in predicting outcomes, comparable to SVM in certain contexts. Efficient in processing large datasets to accurately predict performance. |
| Support Vector Machine (SVM) | Predicting academic success, user satisfaction, and mental health problems | Achieved high accuracy rates, outperforming other models in predicting students' attitudes. |
| Logistic Regression (LR) and Ridge Classifier (RC) | Predicting mental health problems and student dropout in a massive open online course | Commonly used alongside other models for varied predictive tasks. Simple and efficient. |
| Artificial Neural Networks (ANN) | Predicting slow learners and user satisfaction during remote learning | Commonly used for classifying slow learners and predicting satisfaction with varying accuracy. |
| K-nearest Neighbours (KNN) | Analysing mental health issues among students | Accurately used for classifying user responses. |","As shown in Figure 1, the overall architecture of LMEye contains two stages, which are response for different functions. Given an image I and one human’s query X = (x1, ..., xM), where xi represents the i-th token of the human query input to LLMs, we obtain the global and fine-grained image features hI = (h I g , hI 1 , ..., hI 256) via the pretrained visual encoder of BLIP-2. Meanwhile, a learnable special token is added in the word embedding table of LLMs as the input position tag of image feature.",6.94%,69.41%,78.12%,36.05%,69.84%
255,images/s90.png," The table shows the model sizes of various deep learning models for object detection. The models are trained on the COCO dataset and the input image size is 640x640. The table also shows the number of trainable parameters and the estimated model size. The largest model is ResNet-152, which has 199,874,714 trainable parameters and an estimated model size of 980 MB. The smallest model is YOLOv5-nano, which has 3,151,904 trainable parameters and an estimated model size of 29.8 MB.","MMBench Evaluation Results. The evaluation results on the MMBench are presenteded in Table 1. The results show that our proposed model, LMEye, outperformed other comparable models",25.38%,84.96%,82.63%,38.40%,70.78%
256,images/s91.png, The taxonomy of visual information.,"The experimental results presented in Table 2 demonstrate the effectiveness of LMEye in achieving state-of-the-art (SOTA) performance. Specifically, LMEye has shown significant improvements in scene understanding, with an increase of 13 points compared to previous SOTA. Moreover, in the category of sample attribute recognition and spatial connection understanding, LMEye also outperformed InstructBLIP. These results highlight the effectiveness of a plug-and-play interactive perception framework, in enhancing the ability of language models to understand images and multimodal instructions.",25.15%,77.59%,83.94%,0.00%,76.74%
257,images/s92.png," The image shows the experimental design. Participants first completed a visual acuity test, followed by a pre-questionnaire and instruction. Then, they completed two experimental blocks. In the first block, the reference was visible. In the second block, the reference was not visible. The order of the experimental blocks was counterbalanced. Each experimental block consisted of five clutter conditions. The order of the clutter conditions was identical in both experimental blocks. After the experimental blocks, participants completed a post-questionnaire. Finally, they were thanked and debriefed.","To compare BP, PEPITA and MEMPEPITA, LLMs named DistilBERT, GPT-3 Small and AlexaTM were chosen, as they represent respectively encoder-only, decoder-only and encoder-decoder architecture. The quantitative details for each them are reported in Table 2.",12.57%,85.90%,80.60%,38.10%,71.04%
258,images/s93.png," | Slack | Time (Milliseconds) | Matches | VHT (h) |
| :---: | :---: | :---: | :---: |
|  | Eager | Lazy | Eager | Lazy | Eager | Lazy |
| 10% | 325 | 334 | 356 | 356 | 1781 | 1781 |
| 20% | 372 | 388 | 1494 | 1494 | 1707 | 1707 |
| 30% | 447 | 467 | 3151 | 3146 | 1607 | 1607 |
| 40% | 554 | 642 | 4803 | 4774 | 1521 | 1521 |
| 50% | 690 | 860 | 6132 | 6112 | 1464 | 1461 |","About memory, for the three models, BP requires the largest amount of activations with PEPITA falling slightly behind. On the other hand, MEMPEPITA requires significantly less memory than BP and PEPITA. The percentage variations in the memory and computational complexity of PEPITA and MEMPEPITA w.r.t. BP for different values of nctx and for the different models are reported in Table 3.",0.00%,-13.73%,73.96%,0.00%,19.55%
259,images/s94.png," The table shows the average number of riders and potential matches for different percentages of slack. The data is broken down by rider type (eager or lazy) and match type (eager or lazy).

For example, if 10% of riders are slack, then there will be an average of 409 eager riders and 409 lazy riders. There will also be 7 potential matches between eager riders and 7 potential matches between lazy riders.

As the percentage of slack increases, the average number of riders and potential matches also increases. This is because there are more riders available to be matched with each other.","Notably, Alpaca exhibits high disagreement with the gold labels obtained from the lower end of the socio-economic spectrum, and GPT-4 is surprisingly unempathetic toward the underprivileged (even compared to other LLMs). An overview of our entire pipeline is demonstrated in Figure 2.",20.60%,85.01%,82.11%,39.87%,79.28%
260,images/s95.png," The table shows the performance of a quantum image transmission system under different environments. The environment is the type of noise that is present in the transmission channel. The metrics used to evaluate the performance of the system are MSE, SSIM, and LPIPS. MSE is the mean squared error between the original image and the reconstructed image. SSIM is the structural similarity index, which measures the similarity between the original image and the reconstructed image. LPIPS is the Learned Perceptual Image Patch Similarity, which measures the perceptual similarity between the original image and the reconstructed image.

The results show that the system performs best in the noiseless environment. In this environment, the MSE is lowest, the SSIM is highest, and the LPIPS is lowest. This is because there is no noise present in the transmission channel, so the reconstructed image is very similar to the original image.

As the amount of noise in the transmission channel increases, the performance of the system decreases. This is because the noise makes it more difficult to reconstruct the original image. The MSE increases, the SSIM decreases, and the LPIPS increases.

The system performs worst in the depolarizing environment. In this environment, the MSE is highest, the SSIM is lowest, and the LPIPS is highest. This is because the depolarizing noise is the most severe type of noise. It causes the pixels in the image to be randomly flipped, which makes it very difficult to reconstruct the original image.","In this section, we present our BPLLM framework summarized in Figure 2. The figure shows the operational steps utilized by the BPLLM pipeline for answering queries pertaining to business processes.",32.68%,88.46%,81.85%,35.78%,78.78%
261,images/s96.png," From the table, we can see that the performance of the denoising model improves as the number of layers increases. This is because the deeper network can capture more complex noise patterns. However, the improvement is not significant from 2 layers to 3 layers. This suggests that the 2-layer network is a good trade-off between performance and computational cost.","Table 2 reports the accuracy evaluated on different process model representations (natural text and BPMN) and different chunking techniques (no chunking, fixed-size, recursive, BPMN-specific).",10.28%,78.72%,83.58%,37.85%,72.75%
262,images/s97.png," This table shows the results of a multiple linear regression analysis. The dependent variable is the score on a test of bioinformatics knowledge. The independent variables are a set of dummy variables indicating the field of study of the test taker, and a continuous variable indicating the number of years of experience in the field.

The results show that there is a significant positive relationship between the number of years of experience and the score on the test. There is also a significant negative relationship between being in the field of computer science and the score on the test. There is also a significant negative relationship between being in the field of engineering and the score on the test. There is also a significant negative relationship between being in the field of environmental sciences and the score on the test. There is also a significant negative relationship between being in the field of mathematical sciences and the score on the test. There is also a significant negative relationship between being in the field of medicine and the score on the test. There is also a significant negative relationship between being in the field of physical sciences and the score on the test. There is also a significant positive relationship between having a high school diploma and the score on the test.",Table 3 summarizes the insights collected to estimate the impact of process representation format and embedding model on the BPLLM accuracy,37.94%,78.93%,80.76%,35.14%,80.08%
263,images/s98.png," Table 1 shows the list of datasets used in our experiments. We use three datasets for training, fine-tuning, and post-hoc testing. For domain adaptation, we use the Commonlit dataset.","Finally, unlike most other models (Dalvi et al., 2021; Wei et al., 2022), the causal structure of our model (see Figure 10) mirrors the requirements for validity, see Table 10. Other approaches that do satisfy validity have their own limitations, as detailed above.",10.64%,72.40%,83.68%,29.08%,80.87%
264,images/s99.png," The table shows the distribution of MPI common core functions for the HPCcorpusMPI dataset. The most common function is MPI_Finalize, which is called 19,183 times. The least common function is MPI_Reduce, which is called 3,600 times.","Figure 1 illustrates an overview of the study pipeline, which was comprised of two main components—prompting (steps 1-3, highlighted in pink) and evaluating (steps 4-9, highlighted in blue) LLMs.",9.75%,54.76%,82.94%,38.89%,75.15%
